{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ac8bab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### IMPORTS\n",
    "import os\n",
    "\n",
    "import importlib, pkg_resources\n",
    "importlib.reload(pkg_resources)\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_quantum as tfq\n",
    "\n",
    "import cirq\n",
    "import sympy\n",
    "import numpy as np\n",
    "\n",
    "from cirq.contrib.svg import SVGCircuit\n",
    "%matplotlib inline\n",
    "\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc2088d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f234d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'float64'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(\"before\", tf.keras.backend.floatx())\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "tf.keras.backend.floatx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a04676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08a4d201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"1677.7982031250003\" height=\"100.0\"><line x1=\"32.246796875\" x2=\"1647.7982031250003\" y1=\"25.0\" y2=\"25.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"32.246796875\" x2=\"1647.7982031250003\" y1=\"75.0\" y2=\"75.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"691.6241406250001\" x2=\"691.6241406250001\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"851.1458984375001\" x2=\"851.1458984375001\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1010.6676562500002\" x2=\"1010.6676562500002\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><rect x=\"10.0\" y=\"5.0\" width=\"44.49359375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"32.246796875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 0): </text><rect x=\"10.0\" y=\"55.0\" width=\"44.49359375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"32.246796875\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 1): </text><rect x=\"74.49359375\" y=\"5.0\" width=\"79.5217578125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"114.25447265625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(0.318π)</text><rect x=\"174.01535156249997\" y=\"5.0\" width=\"79.5217578125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"213.77623046875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(0.318π)</text><rect x=\"273.537109375\" y=\"5.0\" width=\"79.5217578125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"313.29798828125\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(0.318π)</text><rect x=\"373.0588671875\" y=\"55.0\" width=\"79.5217578125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"412.81974609375004\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(0.318π)</text><rect x=\"472.58062500000005\" y=\"55.0\" width=\"79.5217578125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"512.3415039062501\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(0.318π)</text><rect x=\"572.1023828125001\" y=\"55.0\" width=\"79.5217578125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"611.8632617187501\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(0.318π)</text><circle cx=\"691.6241406250001\" cy=\"75.0\" r=\"10.0\" /><rect x=\"671.6241406250001\" y=\"5.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"691.6241406250001\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"731.6241406250001\" y=\"5.0\" width=\"79.5217578125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"771.3850195312501\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(0.318π)</text><rect x=\"731.6241406250001\" y=\"55.0\" width=\"79.5217578125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"771.3850195312501\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(0.318π)</text><circle cx=\"851.1458984375001\" cy=\"25.0\" r=\"10.0\" /><rect x=\"831.1458984375001\" y=\"55.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"851.1458984375001\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"891.1458984375001\" y=\"55.0\" width=\"79.5217578125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"930.9067773437502\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(0.318π)</text><circle cx=\"1010.6676562500002\" cy=\"75.0\" r=\"10.0\" /><rect x=\"990.6676562500002\" y=\"5.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1010.6676562500002\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"1050.6676562500002\" y=\"5.0\" width=\"79.5217578125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1090.42853515625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(0.318π)</text><rect x=\"1150.1894140625002\" y=\"5.0\" width=\"79.5217578125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1189.95029296875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(0.318π)</text><rect x=\"1249.7111718750002\" y=\"5.0\" width=\"79.5217578125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1289.4720507812501\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(0.318π)</text><rect x=\"1349.2329296875002\" y=\"55.0\" width=\"79.5217578125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1388.9938085937501\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(0.318π)</text><rect x=\"1448.7546875000003\" y=\"55.0\" width=\"79.5217578125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1488.5155664062502\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(0.318π)</text><rect x=\"1548.2764453125003\" y=\"55.0\" width=\"79.5217578125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1588.0373242187502\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(0.318π)</text></svg>"
      ],
      "text/plain": [
       "<cirq.contrib.svg.svg.SVGCircuit at 0x154a52f70>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def one_qubit_unitary(bit, symbols):\n",
    "    \"\"\"Make a Cirq circuit enacting a rotation of the bloch sphere about the X,\n",
    "    Y and Z axis, that depends on the values in `symbols`.\n",
    "    \"\"\"\n",
    "    return cirq.Circuit(\n",
    "        cirq.rx(symbols[0])(bit),\n",
    "        cirq.ry(symbols[1])(bit),\n",
    "        cirq.rz(symbols[2])(bit))\n",
    "\n",
    "\n",
    "# https://arxiv.org/pdf/quant-ph/0308006.pdf\n",
    "def two_qubit_unitary(bits, symbols, full=False):\n",
    "    \"\"\"Make a Cirq circuit that creates a non arbitrary two qubit unitary.\"\"\"\n",
    "    circuit = cirq.Circuit()\n",
    "    if full:\n",
    "        circuit += one_qubit_unitary(bits[0], symbols[0:3])\n",
    "        circuit += one_qubit_unitary(bits[1], symbols[3:6])\n",
    "    \n",
    "    \n",
    "    #circuit += cirq.rz(-np.pi/2.)(bits[1])\n",
    "        \n",
    "    circuit += cirq.CNOT(bits[1],bits[0])\n",
    "    \n",
    "    circuit += cirq.rz(symbols[0+6*full])(bits[0])\n",
    "    circuit += cirq.ry(symbols[1+6*full])(bits[1])  \n",
    "    \n",
    "    circuit += cirq.CNOT(bits[0],bits[1])\n",
    "    \n",
    "    circuit += cirq.ry(symbols[2+6*full])(bits[1]) \n",
    "    \n",
    "    circuit += cirq.CNOT(bits[1],bits[0])\n",
    "        \n",
    "    #circuit += cirq.rz(np.pi/2.)(bits[0]) \n",
    "    \n",
    "    \n",
    "    #circuit += [cirq.ZZ(*bits)**symbols[6]]   They want to replicate this\n",
    "    #circuit += [cirq.YY(*bits)**symbols[7]]\n",
    "    #circuit += [cirq.XX(*bits)**symbols[8]]\n",
    "    if full:   \n",
    "        circuit += one_qubit_unitary(bits[0], symbols[9:12])\n",
    "        circuit += one_qubit_unitary(bits[1], symbols[12:15])\n",
    "        \n",
    "    return circuit\n",
    "\n",
    "bits = cirq.GridQubit.rect(1,2)\n",
    "SVGCircuit(two_qubit_unitary(bits, np.ones(16), full=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "91b098f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"483.537109375\" height=\"100.0\"><line x1=\"32.246796875\" x2=\"453.537109375\" y1=\"25.0\" y2=\"25.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"32.246796875\" x2=\"453.537109375\" y1=\"75.0\" y2=\"75.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"94.49359375\" x2=\"94.49359375\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"254.0153515625\" x2=\"254.0153515625\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"413.537109375\" x2=\"413.537109375\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><rect x=\"10.0\" y=\"5.0\" width=\"44.49359375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"32.246796875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 0): </text><rect x=\"10.0\" y=\"55.0\" width=\"44.49359375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"32.246796875\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 1): </text><circle cx=\"94.49359375\" cy=\"75.0\" r=\"10.0\" /><rect x=\"74.49359375\" y=\"5.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"94.49359375\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"134.49359375\" y=\"5.0\" width=\"79.5217578125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"174.25447265625002\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(0.318π)</text><rect x=\"134.49359375\" y=\"55.0\" width=\"79.5217578125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"174.25447265625002\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(0.318π)</text><circle cx=\"254.0153515625\" cy=\"25.0\" r=\"10.0\" /><rect x=\"234.0153515625\" y=\"55.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"254.0153515625\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"294.0153515625\" y=\"55.0\" width=\"79.5217578125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"333.77623046875\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(0.318π)</text><circle cx=\"413.537109375\" cy=\"75.0\" r=\"10.0\" /><rect x=\"393.537109375\" y=\"5.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"413.537109375\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text></svg>"
      ],
      "text/plain": [
       "<cirq.contrib.svg.svg.SVGCircuit at 0x15b673bb0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bits = cirq.GridQubit.rect(1,2)\n",
    "SVGCircuit(two_qubit_unitary(bits, np.ones(16), full=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1305fbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example circuit simple\n",
    "# Count number of excitations (1), if number of excitations > half qbits, show 1, else 0\n",
    "\n",
    "# to pass data as initial state we must construc it. So we need to give the cirucit. It's just X gate. X^{num} = X^{n0}X^{n1}...\n",
    "\n",
    "\n",
    "def generate_data(qubits):\n",
    "    test = []\n",
    "    label = []\n",
    "    \n",
    "    n = len(qubits)\n",
    "    for i in range(2**n):\n",
    "        b = bin(i)[2:]\n",
    "        b = '0'*(n-len(b)) + b\n",
    "        count = 0\n",
    "        for c in b:\n",
    "            if c == '1':\n",
    "                count+=1\n",
    "            \n",
    "        label.append(-1 if count > n/2 else +1)\n",
    "        test.append(cirq.Circuit( (cirq.X(qubits[l]) for l in range(len(b)) if b[l]=='1')))\n",
    "        \n",
    "    return tfq.convert_to_tensor(test), np.array(label)\n",
    "\n",
    "qubits = cirq.GridQubit.rect(1,5)\n",
    "\n",
    "test, label = generate_data(qubits)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca4fdcfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"overflow: auto; white-space: pre;\">(0, 0): ───X───X───────\n",
       "\n",
       "(0, 1): ───────────X───</pre>"
      ],
      "text/plain": [
       "(0, 0): ───X───X───────\n",
       "\n",
       "(0, 1): ───────────X───"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bits = cirq.GridQubit.rect(1,5)\n",
    "cirq.Circuit(cirq.X(bits[0]), cirq.X(bits[0])) + cirq.Circuit(cirq.X(bits[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "id": "afd04026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"2241.8310937500005\" height=\"250.0\"><line x1=\"36.90890625\" x2=\"2211.8310937500005\" y1=\"25.0\" y2=\"25.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"2211.8310937500005\" y1=\"75.0\" y2=\"75.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"2211.8310937500005\" y1=\"125.0\" y2=\"125.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"2211.8310937500005\" y1=\"175.0\" y2=\"175.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"2211.8310937500005\" y1=\"225.0\" y2=\"225.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"948.6257812500003\" x2=\"948.6257812500003\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1079.0264453125003\" x2=\"1079.0264453125003\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1209.4271093750003\" x2=\"1209.4271093750003\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1269.4271093750003\" x2=\"1269.4271093750003\" y1=\"25.0\" y2=\"125.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1399.8277734375004\" x2=\"1399.8277734375004\" y1=\"25.0\" y2=\"125.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1530.2284375000004\" x2=\"1530.2284375000004\" y1=\"25.0\" y2=\"125.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1590.2284375000004\" x2=\"1590.2284375000004\" y1=\"25.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1720.6291015625004\" x2=\"1720.6291015625004\" y1=\"25.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1851.0297656250004\" x2=\"1851.0297656250004\" y1=\"25.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1911.0297656250004\" x2=\"1911.0297656250004\" y1=\"25.0\" y2=\"225.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2041.4304296875005\" x2=\"2041.4304296875005\" y1=\"25.0\" y2=\"225.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2171.8310937500005\" x2=\"2171.8310937500005\" y1=\"25.0\" y2=\"225.0\" stroke=\"black\" stroke-width=\"3\" /><rect x=\"10.0\" y=\"5.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(-1, -1): </text><rect x=\"10.0\" y=\"55.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 0): </text><rect x=\"10.0\" y=\"105.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 1): </text><rect x=\"10.0\" y=\"155.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 2): </text><rect x=\"10.0\" y=\"205.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 3): </text><rect x=\"83.8178125\" y=\"55.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"109.01814453125\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(p0)</text><rect x=\"154.21847656249997\" y=\"55.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"179.41880859375\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(p1)</text><rect x=\"224.619140625\" y=\"55.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"249.81947265625\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(p2)</text><rect x=\"295.0198046875\" y=\"105.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"320.22013671875004\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(p0)</text><rect x=\"365.42046875000005\" y=\"105.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"390.62080078125007\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(p1)</text><rect x=\"435.8211328125001\" y=\"105.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"461.0214648437501\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(p2)</text><rect x=\"506.2217968750001\" y=\"155.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"531.4221289062501\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(p0)</text><rect x=\"576.6224609375001\" y=\"155.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"601.8227929687502\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(p1)</text><rect x=\"647.0231250000002\" y=\"155.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"672.2234570312502\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(p2)</text><rect x=\"717.4237890625002\" y=\"205.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"742.6241210937502\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(p0)</text><rect x=\"787.8244531250002\" y=\"205.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"813.0247851562502\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(p1)</text><rect x=\"858.2251171875002\" y=\"205.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"883.4254492187503\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(p2)</text><circle cx=\"948.6257812500003\" cy=\"25.0\" r=\"10.0\" /><rect x=\"928.6257812500003\" y=\"55.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"948.6257812500003\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"988.6257812500003\" y=\"55.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1013.8261132812503\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(p3)</text><rect x=\"988.6257812500003\" y=\"5.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1013.8261132812503\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(p4)</text><circle cx=\"1079.0264453125003\" cy=\"75.0\" r=\"10.0\" /><rect x=\"1059.0264453125003\" y=\"5.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1079.0264453125003\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"1119.0264453125003\" y=\"5.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1144.2267773437502\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(p5)</text><circle cx=\"1209.4271093750003\" cy=\"25.0\" r=\"10.0\" /><rect x=\"1189.4271093750003\" y=\"55.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1209.4271093750003\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><circle cx=\"1269.4271093750003\" cy=\"25.0\" r=\"10.0\" /><rect x=\"1249.4271093750003\" y=\"105.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1269.4271093750003\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"1309.4271093750003\" y=\"105.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1334.6274414062502\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(p3)</text><rect x=\"1309.4271093750003\" y=\"5.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1334.6274414062502\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(p4)</text><circle cx=\"1399.8277734375004\" cy=\"125.0\" r=\"10.0\" /><rect x=\"1379.8277734375004\" y=\"5.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1399.8277734375004\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"1439.8277734375004\" y=\"5.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1465.0281054687503\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(p5)</text><circle cx=\"1530.2284375000004\" cy=\"25.0\" r=\"10.0\" /><rect x=\"1510.2284375000004\" y=\"105.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1530.2284375000004\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><circle cx=\"1590.2284375000004\" cy=\"25.0\" r=\"10.0\" /><rect x=\"1570.2284375000004\" y=\"155.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1590.2284375000004\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"1630.2284375000004\" y=\"155.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1655.4287695312503\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(p3)</text><rect x=\"1630.2284375000004\" y=\"5.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1655.4287695312503\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(p4)</text><circle cx=\"1720.6291015625004\" cy=\"175.0\" r=\"10.0\" /><rect x=\"1700.6291015625004\" y=\"5.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1720.6291015625004\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"1760.6291015625004\" y=\"5.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1785.8294335937503\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(p5)</text><circle cx=\"1851.0297656250004\" cy=\"25.0\" r=\"10.0\" /><rect x=\"1831.0297656250004\" y=\"155.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1851.0297656250004\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><circle cx=\"1911.0297656250004\" cy=\"25.0\" r=\"10.0\" /><rect x=\"1891.0297656250004\" y=\"205.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1911.0297656250004\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"1951.0297656250004\" y=\"205.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1976.2300976562503\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(p3)</text><rect x=\"1951.0297656250004\" y=\"5.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1976.2300976562503\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(p4)</text><circle cx=\"2041.4304296875005\" cy=\"225.0\" r=\"10.0\" /><rect x=\"2021.4304296875005\" y=\"5.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2041.4304296875005\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"2081.4304296875007\" y=\"5.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2106.630761718751\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(p5)</text><circle cx=\"2171.8310937500005\" cy=\"25.0\" r=\"10.0\" /><rect x=\"2151.8310937500005\" y=\"205.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2171.8310937500005\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text></svg>"
      ],
      "text/plain": [
       "<cirq.contrib.svg.svg.SVGCircuit at 0x16be7b190>"
      ]
     },
     "execution_count": 721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def quantum_circuit(op_bits, readout_bit, parameters, full=False):\n",
    "    \"\"\"Quantum Convolution Layer following the above diagram.\n",
    "    Return a Cirq circuit with the cascade of `two_qubit_unitary` applied\n",
    "    to all pairs of qubits in `bits` as in the diagram above.\n",
    "    \"\"\"\n",
    "    circuit = cirq.Circuit()\n",
    "    \n",
    "    #obs = np.prod([Z(4n)])\n",
    "    #obs = SymbolicHamiltonian(obs, backend=backend)\n",
    "    \n",
    "    for bit in op_bits:\n",
    "        circuit += one_qubit_unitary(bit, parameters[0:3])\n",
    "        \n",
    "    \"\"\"for bit, bitn in zip(op_bits[:-1], op_bits[1:]):\n",
    "        circuit += two_qubit_unitary([bit, bitn], parameters[6+12*full:9+12*full], full=False)\n",
    "        \n",
    "    circuit += two_qubit_unitary([op_bits[-1], op_bits[0]], parameters[3:6], full=False)\"\"\"\n",
    "        \n",
    "    for bit in op_bits:\n",
    "        circuit += two_qubit_unitary([bit, readout_bit], parameters[3:6+12*full], full=full)\n",
    "        \n",
    "    \"\"\"for bit, bitn in zip(op_bits[:-1], op_bits[1:]):\n",
    "        circuit += two_qubit_unitary([bit, bitn], parameters[9+12*full:12+12*full], full=False)\n",
    "        \n",
    "    circuit += two_qubit_unitary([op_bits[-1], op_bits[0]], parameters[9+12*full:12+12*full], full=False)\"\"\"\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"for bit in op_bits:\n",
    "        circuit += one_qubit_unitary(bit, parameters[6:9])\n",
    "        \n",
    "    for bit in op_bits:\n",
    "        circuit += two_qubit_unitary([bit, readout_bit], parameters[9:12], full=False)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    for bit in op_bits:\n",
    "        circuit += one_qubit_unitary(bit, parameters[12:15])\n",
    "    \n",
    "    for bit in op_bits:\n",
    "        circuit += two_qubit_unitary([bit, readout_bit], parameters[15:18], full=False)\"\"\"\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    #for bit in op_bits:\n",
    "    #    circuit += two_qubit_unitary([bit, readout_bit], parameters[3:], full=full)\n",
    "        \n",
    "    \n",
    "    return circuit\n",
    "\n",
    "param = sympy.symbols('p:100')\n",
    "\n",
    "\n",
    "n = 4\n",
    "\n",
    "\n",
    "qubits = cirq.GridQubit.rect(1,n)\n",
    "readoutqubit = cirq.GridQubit(-1,-1)\n",
    "\n",
    "excitation_input = tf.keras.Input(shape=(), dtype=tf.dtypes.string)\n",
    "input_layer = tfq.layers.AddCircuit()(\n",
    "    excitation_input, prepend=cirq.Circuit())\n",
    "\n",
    "readout_operators = cirq.Z(readoutqubit)\n",
    "\n",
    "quantum_model_circuit = quantum_circuit(qubits, readoutqubit, param, full=False)\n",
    "\n",
    "\n",
    "\n",
    "# CUSTOMIZE\n",
    "quantum_modelPQC = tfq.layers.PQC(quantum_model_circuit,\n",
    "                                  readout_operators, \n",
    "                                  initializer=tf.keras.initializers.Constant(value=1.0),\n",
    "                                  differentiator=tfq.differentiators.ParameterShift())\n",
    "                                  #backend=cirq.Simulator())\n",
    "                                     \n",
    "    \n",
    "                                    ## Differentiators\n",
    "                                  #differentiator=tfq.differentiators.ParameterShift(),\n",
    "                                    \n",
    "                                    ## Sampling\n",
    "                                    #repetitions=None)\n",
    "                    \n",
    "                                    ## Initializer (parameters)\n",
    "                                    #tf.keras.initializers.RandomUniform(0, 2 * np.pi)\n",
    "                                    #tf.keras.initializers.Constant(value=1.0)\n",
    "                                \n",
    "                                  #initializer=tf.keras.initializers.RandomUniform(0, 2 * np.pi))\n",
    "                                  #repetitions=10) # None: state vector expectation / Number: Sampling\n",
    "\n",
    "qm = quantum_modelPQC\n",
    "                                \n",
    "quantum_model = quantum_modelPQC(input_layer)\n",
    "\n",
    "qcnn_model = tf.keras.Model(inputs=[excitation_input], outputs=[quantum_model])\n",
    "\n",
    "\n",
    "\n",
    "SVGCircuit(\n",
    "    quantum_model_circuit)#sympy.symbols('x0:15')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "039d8077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breaks with float 64???\n",
    "\n",
    "@tf.function\n",
    "def custom_accuracy(y_true, y_pred):\n",
    "    y_true = tf.squeeze(y_true)\n",
    "    y_pred = tf.map_fn(lambda x: 1.0 if x >= 0 else -1.0, y_pred)\n",
    "    return tf.keras.backend.mean(tf.keras.backend.equal(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "acec13bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1., 1., 1., 1., 1., 1.], dtype=float32)]\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 1.0031\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.9175\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.8946\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.9009\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.8833\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.8649\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.8516\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.8262\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.8113\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7910\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.7698\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7521\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.7410\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7532\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7267\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7384\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7276\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.7339\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.7301\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.7325\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.7392\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7318\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.7431\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.7338\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.7552\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.7256\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.7298\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.7285\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.7267\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.7299\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.7241\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.7302\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.7282\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.7430\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.7285\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.7343\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.7226\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.7286\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.7216\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.7237\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.7299\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.7201\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.7157\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7301\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.7142\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7211\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7223\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.7201\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.7272\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.7189\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.7239\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.7218\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.7188\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.7134\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7273\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7161\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7228\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7259\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7198\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7228\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.7339\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7230\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7138\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7257\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7173\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7223\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7179\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7275\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7242\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7137\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7240\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7188\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7156\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7246\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.7182\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.7148\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.7133\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.7153\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.7241\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.7248\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7220\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7263\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.7165\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7186\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7224\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.7174\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7248\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7195\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.7254\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.7236\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7160\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7446\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.7256\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7146\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7233\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7162\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7176\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.7177\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.7167\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7221\n"
     ]
    }
   ],
   "source": [
    "inputs, labels = generate_data(qubits)\n",
    "\n",
    "\n",
    "ninp = len(inputs)\n",
    "split = int(ninp*1)\n",
    "\n",
    "train_excitations = inputs[:split]\n",
    "train_labels = labels[:split]\n",
    "\n",
    "test_excitations = inputs[split:]\n",
    "test_labels = labels[split:]\n",
    "\n",
    "#tf.keras.optimizers.Adam(learning_rate=0.02)\n",
    "#tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.0, nesterov=False)\n",
    "#tf.keras.optimizers.Adam(learning_rate=0.02)  # Adams                   # Default parameters, but made explicit. Basic gradient descent\n",
    "qcnn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.02),\n",
    "                   loss=tf.losses.mse)#,\n",
    "                   #metrics=[custom_accuracy])\n",
    "    \n",
    "print(qcnn_model.get_weights())\n",
    "\n",
    "history = qcnn_model.fit(x=train_excitations,\n",
    "                         y=train_labels,\n",
    "                         batch_size=1,\n",
    "                         epochs=100,\n",
    "                         verbose=1,\n",
    "                         validation_data=(test_excitations, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "fa10289d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-183-d92e28cd2d0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training a Quantum CNN to Detect Excited Cluster States'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_loss'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'][1:], label='Training')\n",
    "plt.plot(history.history['val_loss'][1:], label='Validation')\n",
    "plt.title('Training a Quantum CNN to Detect Excited Cluster States')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "eb601d58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.05134811997413635 =?   1   --->       1\n",
      "-0.22285966575145721 =?   1   --->       0\n",
      "-0.22692462801933289 =?   1   --->       0\n",
      "-0.03146733343601227 =?   1   --->       0\n",
      "0.014224156737327576 =?   1   --->       1\n",
      "-0.08988440781831741 =?   1   --->       0\n",
      " -0.0807948037981987 =?   1   --->       0\n",
      " 0.03189695626497269 =?  -1   --->       0\n",
      " 0.46371498703956604 =?   1   --->       1\n",
      " -0.2625795304775238 =?   1   --->       0\n",
      " -0.2849717140197754 =?   1   --->       0\n",
      " 0.23775608837604523 =?  -1   --->       0\n",
      " 0.41558054089546204 =?   1   --->       1\n",
      " -0.1411268711090088 =?  -1   --->       1\n",
      "-0.11158232390880585 =?  -1   --->       1\n",
      " 0.15126290917396545 =?  -1   --->       0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'parameters:0' shape=(24,) dtype=float32, numpy=\n",
       " array([0.9316327, 1.6815913, 1.0111773, 2.1699822, 3.8568354, 6.1286526,\n",
       "        3.102644 , 1.5660274, 2.7262068, 1.72624  , 4.1483912, 4.511825 ,\n",
       "        3.2235281, 3.1371534, 3.6869867, 5.4236717, 4.194628 , 5.3430223,\n",
       "        1.7805375, 5.125231 , 3.3614523, 3.445503 , 4.930834 , 6.0574546],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(*tuple(\"{:20} =? {:3}   --->   {:5}\".format(x[0], train_labels[i], abs(train_labels[i]-x[0])<1)  for i,x in enumerate(qcnn_model.predict(train_excitations))), sep='\\n')\n",
    "\n",
    "\n",
    "qcnn_model.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db3aca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bd9c3a1",
   "metadata": {},
   "source": [
    "####  Manual Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "455aa88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_p(qubits):\n",
    "    test = []\n",
    "    label = []\n",
    "    \n",
    "    n = len(qubits)\n",
    "    for i in range(2**n):\n",
    "        b = bin(i)[2:]\n",
    "        b = '0'*(n-len(b)) + b\n",
    "        count = 0\n",
    "        for c in b:\n",
    "            if c == '1':\n",
    "                count+=1\n",
    "        #b = b[::-1]\n",
    "            \n",
    "        label.append(-1 if count %2 == 1 else +1)\n",
    "        test.append(cirq.Circuit( (cirq.X(qubits[l]) for l in range(len(b)) if b[l]=='1')))\n",
    "        \"\"\"print(b)\n",
    "        print(test[-1])\"\"\"\n",
    "    return tfq.convert_to_tensor(test), np.array(label)\n",
    "\n",
    "def quantum_circuit(op_bits, readout_bit, parameters, full=False, cnot=True, extra=False, depth=1, firstOne = True):\n",
    "    \"\"\"Quantum Convolution Layer following the above diagram.\n",
    "    Return a Cirq circuit with the cascade of `two_qubit_unitary` applied\n",
    "    to all pairs of qubits in `bits` as in the diagram above.\n",
    "    \"\"\"\n",
    "    circuit = cirq.Circuit()\n",
    "    \n",
    "    #obs = np.prod([Z(4n)])\n",
    "    #obs = SymbolicHamiltonian(obs, backend=backend)\n",
    "    \n",
    "    if cnot:\n",
    "        for bit in op_bits:\n",
    "            circuit += cirq.CNOT(bit, readout_bit)\n",
    "    \n",
    "    if firstOne:\n",
    "        for bit in op_bits:\n",
    "            circuit += one_qubit_unitary(bit, parameters[0:3])\n",
    "    \n",
    "    for dd in range(depth):\n",
    "        \n",
    "        \"\"\"for bit in op_bits:\n",
    "            circuit += one_qubit_unitary(bit, parameters[0:3])\n",
    "            circuit += cirq.CNOT(bit, readout_bit)\n",
    "        circuit += one_qubit_unitary(readout_bit, parameters[0:3])\"\"\"  # Really symmetric simple with CNOT\n",
    "            \n",
    "        for bit in op_bits:\n",
    "            circuit += two_qubit_unitary([bit, readout_bit], parameters[3*(dd*(1+4*full)+1):3*(dd*(1+4*full)+2+4*full)], full=full)\n",
    "    \n",
    "    if extra:\n",
    "        circuit += one_qubit_unitary(readout_bit, parameters[-3:])\n",
    "    \n",
    "    \"\"\"for bit, bitn in zip(op_bits[:-2], op_bits[1:]):\n",
    "        circuit += two_qubit_unitary([bit, bitn], parameters[6:9], full=False)\n",
    "        \n",
    "    circuit += two_qubit_unitary([op_bits[-1], op_bits[0]], parameters[12:15], full=False)\n",
    "    \n",
    "    for bit in op_bits:\n",
    "        circuit += one_qubit_unitary(bit, parameters[15:18])\n",
    "    for bit in op_bits:\n",
    "        circuit += two_qubit_unitary([bit, readout_bit], parameters[18:21], full=False)\"\"\"\n",
    "    \n",
    "    return circuit\n",
    "\n",
    "param = sympy.symbols('p:100')\n",
    "\n",
    "\n",
    "n = 4\n",
    "\n",
    "def setup(n, param, full=False, extra=False, cnot=True, depth=1, initialValue = 1, random=False, firstOne=True):\n",
    "    qubits = cirq.GridQubit.rect(1,n)\n",
    "    readoutqubit = cirq.GridQubit(-1,-1)\n",
    "\n",
    "    excitation_input = tf.keras.Input(shape=(), dtype=tf.dtypes.string)\n",
    "    input_layer = tfq.layers.AddCircuit()(\n",
    "        excitation_input, prepend=cirq.Circuit())\n",
    "    readout_operators = cirq.Z(readoutqubit)\n",
    "    quantum_model_circuit = quantum_circuit(qubits, readoutqubit, param, full=full, extra=extra, cnot=cnot, depth=depth, firstOne=firstOne)\n",
    "\n",
    "\n",
    "\n",
    "    # CUSTOMIZE\n",
    "    quantum_modelPQC = tfq.layers.PQC(quantum_model_circuit,\n",
    "                                      readout_operators, \n",
    "                                      initializer=tf.keras.initializers.Constant(value=initialValue) if random==False else tf.keras.initializers.RandomUniform(0,2*np.pi))#Constant(value=1.0))\n",
    "\n",
    "    qm = quantum_modelPQC\n",
    "    quantum_model = quantum_modelPQC(input_layer)\n",
    "    qcnn_model = tf.keras.Model(inputs=[excitation_input], outputs=[quantum_model])\n",
    "    model = qcnn_model\n",
    "    \n",
    "    return model, quantum_model_circuit, qubits, readoutqubit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c287a85d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"2241.8310937500005\" height=\"250.0\"><line x1=\"36.90890625\" x2=\"2211.8310937500005\" y1=\"25.0\" y2=\"25.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"2211.8310937500005\" y1=\"75.0\" y2=\"75.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"2211.8310937500005\" y1=\"125.0\" y2=\"125.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"2211.8310937500005\" y1=\"175.0\" y2=\"175.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"2211.8310937500005\" y1=\"225.0\" y2=\"225.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"948.6257812500003\" x2=\"948.6257812500003\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1079.0264453125003\" x2=\"1079.0264453125003\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1209.4271093750003\" x2=\"1209.4271093750003\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1269.4271093750003\" x2=\"1269.4271093750003\" y1=\"25.0\" y2=\"125.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1399.8277734375004\" x2=\"1399.8277734375004\" y1=\"25.0\" y2=\"125.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1530.2284375000004\" x2=\"1530.2284375000004\" y1=\"25.0\" y2=\"125.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1590.2284375000004\" x2=\"1590.2284375000004\" y1=\"25.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1720.6291015625004\" x2=\"1720.6291015625004\" y1=\"25.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1851.0297656250004\" x2=\"1851.0297656250004\" y1=\"25.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1911.0297656250004\" x2=\"1911.0297656250004\" y1=\"25.0\" y2=\"225.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2041.4304296875005\" x2=\"2041.4304296875005\" y1=\"25.0\" y2=\"225.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2171.8310937500005\" x2=\"2171.8310937500005\" y1=\"25.0\" y2=\"225.0\" stroke=\"black\" stroke-width=\"3\" /><rect x=\"10.0\" y=\"5.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(-1, -1): </text><rect x=\"10.0\" y=\"55.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 0): </text><rect x=\"10.0\" y=\"105.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 1): </text><rect x=\"10.0\" y=\"155.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 2): </text><rect x=\"10.0\" y=\"205.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 3): </text><rect x=\"83.8178125\" y=\"55.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"109.01814453125\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(p0)</text><rect x=\"154.21847656249997\" y=\"55.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"179.41880859375\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(p1)</text><rect x=\"224.619140625\" y=\"55.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"249.81947265625\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(p2)</text><rect x=\"295.0198046875\" y=\"105.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"320.22013671875004\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(p0)</text><rect x=\"365.42046875000005\" y=\"105.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"390.62080078125007\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(p1)</text><rect x=\"435.8211328125001\" y=\"105.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"461.0214648437501\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(p2)</text><rect x=\"506.2217968750001\" y=\"155.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"531.4221289062501\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(p0)</text><rect x=\"576.6224609375001\" y=\"155.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"601.8227929687502\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(p1)</text><rect x=\"647.0231250000002\" y=\"155.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"672.2234570312502\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(p2)</text><rect x=\"717.4237890625002\" y=\"205.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"742.6241210937502\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rx(p0)</text><rect x=\"787.8244531250002\" y=\"205.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"813.0247851562502\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(p1)</text><rect x=\"858.2251171875002\" y=\"205.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"883.4254492187503\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(p2)</text><circle cx=\"948.6257812500003\" cy=\"25.0\" r=\"10.0\" /><rect x=\"928.6257812500003\" y=\"55.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"948.6257812500003\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"988.6257812500003\" y=\"55.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1013.8261132812503\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(p3)</text><rect x=\"988.6257812500003\" y=\"5.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1013.8261132812503\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(p4)</text><circle cx=\"1079.0264453125003\" cy=\"75.0\" r=\"10.0\" /><rect x=\"1059.0264453125003\" y=\"5.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1079.0264453125003\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"1119.0264453125003\" y=\"5.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1144.2267773437502\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(p5)</text><circle cx=\"1209.4271093750003\" cy=\"25.0\" r=\"10.0\" /><rect x=\"1189.4271093750003\" y=\"55.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1209.4271093750003\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><circle cx=\"1269.4271093750003\" cy=\"25.0\" r=\"10.0\" /><rect x=\"1249.4271093750003\" y=\"105.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1269.4271093750003\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"1309.4271093750003\" y=\"105.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1334.6274414062502\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(p3)</text><rect x=\"1309.4271093750003\" y=\"5.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1334.6274414062502\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(p4)</text><circle cx=\"1399.8277734375004\" cy=\"125.0\" r=\"10.0\" /><rect x=\"1379.8277734375004\" y=\"5.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1399.8277734375004\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"1439.8277734375004\" y=\"5.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1465.0281054687503\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(p5)</text><circle cx=\"1530.2284375000004\" cy=\"25.0\" r=\"10.0\" /><rect x=\"1510.2284375000004\" y=\"105.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1530.2284375000004\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><circle cx=\"1590.2284375000004\" cy=\"25.0\" r=\"10.0\" /><rect x=\"1570.2284375000004\" y=\"155.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1590.2284375000004\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"1630.2284375000004\" y=\"155.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1655.4287695312503\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(p3)</text><rect x=\"1630.2284375000004\" y=\"5.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1655.4287695312503\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(p4)</text><circle cx=\"1720.6291015625004\" cy=\"175.0\" r=\"10.0\" /><rect x=\"1700.6291015625004\" y=\"5.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1720.6291015625004\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"1760.6291015625004\" y=\"5.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1785.8294335937503\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(p5)</text><circle cx=\"1851.0297656250004\" cy=\"25.0\" r=\"10.0\" /><rect x=\"1831.0297656250004\" y=\"155.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1851.0297656250004\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><circle cx=\"1911.0297656250004\" cy=\"25.0\" r=\"10.0\" /><rect x=\"1891.0297656250004\" y=\"205.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1911.0297656250004\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"1951.0297656250004\" y=\"205.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1976.2300976562503\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Rz(p3)</text><rect x=\"1951.0297656250004\" y=\"5.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1976.2300976562503\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(p4)</text><circle cx=\"2041.4304296875005\" cy=\"225.0\" r=\"10.0\" /><rect x=\"2021.4304296875005\" y=\"5.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2041.4304296875005\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"2081.4304296875007\" y=\"5.0\" width=\"50.4006640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2106.630761718751\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">Ry(p5)</text><circle cx=\"2171.8310937500005\" cy=\"25.0\" r=\"10.0\" /><rect x=\"2151.8310937500005\" y=\"205.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2171.8310937500005\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text></svg>"
      ],
      "text/plain": [
       "<cirq.contrib.svg.svg.SVGCircuit at 0x1563c03d0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, quantum_model_circuit, qubits, readoutqubit = setup(n, param, cnot=False, full=False, extra=False)\n",
    "\n",
    "SVGCircuit(quantum_model_circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5e5653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_excitations, train_labels, optimizer, loss_fn, loss_list, epochs=100):\n",
    "    for epoch in range(epochs):\n",
    "        print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(train_excitations, training=True)  # Logits for this minibatch\n",
    "\n",
    "            loss_value = tf.math.reduce_mean(loss_fn(train_labels, tf.squeeze(logits)))\n",
    "\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "        loss_list.append(loss_value)\n",
    "        print(\n",
    "            \"Training loss at epoch %d: %.4f\"\n",
    "            % (epoch, float(loss_value)) )#, tf.squeeze(grads)\n",
    "        \n",
    "        \n",
    "\n",
    "def trainStoch(model, train_excitations, train_labels, optimizer, loss_fn, loss_list, epochs=100):\n",
    "    for epoch in range(epochs):\n",
    "        print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "        \n",
    "        loss_value = 0\n",
    "        for it in range(len(train_excitations)):\n",
    "            with tf.GradientTape() as tape:\n",
    "                logits = model(train_excitations[it:it+1], training=True)  # Logits for this minibatch\n",
    "\n",
    "                loss_value += tf.math.reduce_mean(loss_fn(train_labels[it:it+1], tf.squeeze(logits)))\n",
    "\n",
    "            grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "        loss_list.append(loss_value)\n",
    "        print(\n",
    "            \"Training loss at epoch %d: %.4f\"\n",
    "            % (epoch, float(loss_value)) )#, tf.squeeze(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "daeec6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'parameters:0' shape=(3,) dtype=float32, numpy=array([1.2069665, 0.7347753, 4.448836 ], dtype=float32)>]\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 0.5712\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 0.5227\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.8800\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.3892\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.7586\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.2753\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.5071\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.4943\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.2384\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.4855\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.3415\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.2489\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.3860\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.3048\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.2460\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.3271\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.3266\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.2511\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.2692\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.3020\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.2331\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.2380\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.2786\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.2243\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.2521\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.2635\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.2195\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.2476\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.2374\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.2156\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.2409\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.2316\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.2218\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.2381\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.2280\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.2181\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.2301\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.2189\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.2192\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.2274\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.2164\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.2238\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.2204\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.2159\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.2218\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.2157\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.2187\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.2197\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.2156\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.2191\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.2158\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.2158\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.2175\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.2148\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.2176\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.2155\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.2159\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.2160\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.2146\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.2162\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.2148\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.2157\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.2153\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.2148\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.2154\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.2145\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.2153\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.2147\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.2151\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.2148\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.2147\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.2149\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.2145\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.2149\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.2145\n",
      "\n",
      "Start of epoch 75\n",
      "Training loss at epoch 75: 0.2148\n",
      "\n",
      "Start of epoch 76\n",
      "Training loss at epoch 76: 0.2145\n",
      "\n",
      "Start of epoch 77\n",
      "Training loss at epoch 77: 0.2146\n",
      "\n",
      "Start of epoch 78\n",
      "Training loss at epoch 78: 0.2146\n",
      "\n",
      "Start of epoch 79\n",
      "Training loss at epoch 79: 0.2146\n",
      "\n",
      "Start of epoch 80\n",
      "Training loss at epoch 80: 0.2146\n",
      "\n",
      "Start of epoch 81\n",
      "Training loss at epoch 81: 0.2145\n",
      "\n",
      "Start of epoch 82\n",
      "Training loss at epoch 82: 0.2146\n",
      "\n",
      "Start of epoch 83\n",
      "Training loss at epoch 83: 0.2145\n",
      "\n",
      "Start of epoch 84\n",
      "Training loss at epoch 84: 0.2146\n",
      "\n",
      "Start of epoch 85\n",
      "Training loss at epoch 85: 0.2145\n",
      "\n",
      "Start of epoch 86\n",
      "Training loss at epoch 86: 0.2146\n",
      "\n",
      "Start of epoch 87\n",
      "Training loss at epoch 87: 0.2145\n",
      "\n",
      "Start of epoch 88\n",
      "Training loss at epoch 88: 0.2145\n",
      "\n",
      "Start of epoch 89\n",
      "Training loss at epoch 89: 0.2145\n",
      "\n",
      "Start of epoch 90\n",
      "Training loss at epoch 90: 0.2145\n",
      "\n",
      "Start of epoch 91\n",
      "Training loss at epoch 91: 0.2145\n",
      "\n",
      "Start of epoch 92\n",
      "Training loss at epoch 92: 0.2145\n",
      "\n",
      "Start of epoch 93\n",
      "Training loss at epoch 93: 0.2145\n",
      "\n",
      "Start of epoch 94\n",
      "Training loss at epoch 94: 0.2145\n",
      "\n",
      "Start of epoch 95\n",
      "Training loss at epoch 95: 0.2145\n",
      "\n",
      "Start of epoch 96\n",
      "Training loss at epoch 96: 0.2145\n",
      "\n",
      "Start of epoch 97\n",
      "Training loss at epoch 97: 0.2145\n",
      "\n",
      "Start of epoch 98\n",
      "Training loss at epoch 98: 0.2145\n",
      "\n",
      "Start of epoch 99\n",
      "Training loss at epoch 99: 0.2145\n"
     ]
    }
   ],
   "source": [
    "N = 4\n",
    "loss = []\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.02*16)#*16, momentum=0.0, nesterov=False)\n",
    "loss_fn = tf.losses.mse\n",
    "\n",
    "model, quantum_model_circuit, qubits, readoutqubit = setup(N, param, extra=False, full=False, cnot=False, firstOne=False, random=True, depth=10)\n",
    "inputs, labels = generate_data(qubits)\n",
    "\n",
    "ninp = len(inputs)\n",
    "split = int(ninp*1)\n",
    "\n",
    "train_excitations = inputs[:split]\n",
    "train_labels = labels[:split]\n",
    "#train_labels = tf.cast(train_labels, dtype=tf.float64)\n",
    "\n",
    "test_excitations = inputs[split:]\n",
    "test_labels = labels[split:]\n",
    "\n",
    "\n",
    "\n",
    "print(model.weights)\n",
    "\n",
    "\n",
    "\"\"\"batch_size = 16\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_excitations, train_labels))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\"\"\"\n",
    "\n",
    "\n",
    "loss_list = []\n",
    "\n",
    "epochs = 100\n",
    "train(model, train_excitations, train_labels, optimizer, loss_fn, loss_list, epochs=epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efaf5561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 0.27320945,  1.8422512 , -0.09350289], dtype=float32)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13b3749a0>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(model.get_weights())\n",
    "plt.plot(loss_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "01d7d829",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossQibo = [0.8134540832112808, 0.8004845937249053, 0.7901812498055115, 0.7819870147510053, 0.7752587399759246, 0.7695522037850754, 0.7646230684685612, 0.7603432877852007, 0.756635901099241, 0.7534420509637819, 0.750708179834802, 0.748382510650672, 0.746414989495453, 0.7447581684102412, 0.7433680880025803, 0.7422048789841038, 0.7412330506899176, 0.7404215167552599, 0.7397434266533349, 0.7391758677925437, 0.7386994919701643, 0.7382981079198171, 0.7379582705109862, 0.7376688875587532, 0.7374208573773592, 0.7372067441370928, 0.7370204936115126, 0.7368571888083588, 0.7367128430051665, 0.7365842266002967, 0.7364687237051988, 0.736364214344357, 0.7362689783376, 0.7361816172976794, 0.7361009916017273, 0.7360261696339826, 0.7359563870158335, 0.7358910139196445, 0.7358295288971546, 0.735771497939924, 0.7357165577307939, 0.7356644022458887, 0.735614772031505, 0.7355674456145271, 0.7355222326137257, 0.7354789682068363, 0.735437508678535, 0.735397727830555, 0.7353595140799772, 0.7353227681073529, 0.7352874009446607, 0.735253332415619, 0.7352204898587245, 0.7351888070775807, 0.735158223474331, 0.7351286833309401, 0.7351001352101635, 0.7350725314536736, 0.7350458277593005, 0.7350199828228978, 0.7349949580331908, 0.7349707172102277, 0.7349472263798533, 0.7349244535780843, 0.7349023686803988, 0.7348809432519077, 0.734860150415093, 0.7348399647324189, 0.7348203621015847, 0.734801319661602, 0.7347828157081698, 0.7347648296170929, 0.7347473417746969, 0.7347303335143556, 0.7347137870583897, 0.734697685464714, 0.7346820125776982, 0.7346667529827832, 0.7346518919644689, 0.7346374154673316, 0.7346233100597783, 0.7346095629002857, 0.7345961617058994, 0.7345830947227975, 0.7345703506987417, 0.7345579188572674, 0.7345457888734687, 0.7345339508512595, 0.7345223953019978, 0.7345111131243727, 0.7345000955854646, 0.7344893343028962, 0.7344788212279977, 0.7344685486299178, 0.734458509080621, 0.7344486954407062, 0.7344391008460024, 0.7344297186948858, 0.7344205426362757, 0.7344115665582648, 0.7344027845773506, 0.7343941910282258, 0.7343857804540964, 0.7343775475974983, 0.7343694873915794, 0.7343615949518238, 0.7343538655681909, 0.7343462946976443, 0.7343388779570539, 0.7343316111164415, 0.7343244900925618, 0.7343175109427892, 0.7343106698593005, 0.7343039631635386, 0.7342973873009342, 0.7342909388358814, 0.734284614446944, 0.7342784109222913, 0.7342723251553381, 0.7342663541405933, 0.734260494969689, 0.7342547448276008, 0.7342491009890294, 0.7342435608149492, 0.7342381217493126, 0.7342327813158949, 0.7342275371152847, 0.7342223868220015, 0.7342173281817411, 0.7342123590087404, 0.7342074771832533, 0.7342026806491397, 0.7341979674115516, 0.73419333553472, 0.7341887831398349, 0.7341843084030135, 0.7341799095533525, 0.7341755848710622, 0.7341713326856755, 0.7341671513743323, 0.734163039360132, 0.7341589951105534, 0.7341550171359377, 0.7341511039880315, 0.7341472542585907, 0.734143466578036, 0.7341397396141618, 0.7341360720708988, 0.7341324626871203, 0.7341289102354984, 0.7341254135214008, 0.7341219713818334, 0.7341185826844195, 0.7341152463264203, 0.7341119612337917, 0.7341087263602746, 0.7341055406865211, 0.7341024032192531, 0.7340993129904505, 0.7340962690565687, 0.7340932704977879, 0.7340903164172852, 0.7340874059405373, 0.7340845382146428, 0.7340817124076755, 0.7340789277080543, 0.7340761833239388, 0.7340734784826453, 0.7340708124300837, 0.734068184430212, 0.7340655937645125, 0.7340630397314841, 0.7340605216461519, 0.7340580388395939, 0.7340555906584855, 0.7340531764646553, 0.7340507956346595, 0.7340484475593682, 0.7340461316435668, 0.7340438473055706, 0.73404159397685, 0.7340393711016703, 0.734037178136742, 0.7340350145508828, 0.7340328798246902, 0.7340307734502247, 0.7340286949307028, 0.7340266437802008, 0.7340246195233662, 0.7340226216951391, 0.7340206498404831, 0.7340187035141237, 0.7340167822802925, 0.734014885712485, 0.7340130133932193, 0.7340111649138077, 0.734009339874131, 0.7340075378824209, 0.734005758555052, 0.734004001516334]\n",
    "\n",
    "#print(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "ca457883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.plot(np.abs(np.array(loss_list)-np.array(lossQibo)))\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "left, bottom, width, height = [0.385, 0.3, 0.5, 0.4]\n",
    "ax2 = fig.add_axes([left, bottom, width, height])\n",
    "\n",
    "ax1.plot(loss_list[:200], label='Qibo')\n",
    "ax1.plot(lossQibo[:200], '--', label='TF')\n",
    "\n",
    "ax2.plot(np.array(loss_list)-np.array(lossQibo), 'k')\n",
    "\n",
    "ax1.legend()\n",
    "\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"difference\")\n",
    "plt.savefig(\"compare.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "10592fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'parameters:0' shape=(18,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1.], dtype=float32)>]\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 2.5205\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 2.3512\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 2.1767\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 1.9995\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 1.8219\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 1.6464\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 1.4754\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 1.3112\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 1.1559\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 1.0112\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.8787\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.7592\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.6530\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.5602\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.4799\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.4113\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.3532\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.3041\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.2628\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.2280\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.1984\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.1731\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.1513\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.1323\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.1157\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.1010\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.0880\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.0765\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.0663\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.0574\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.0495\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.0427\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.0367\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.0316\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.0272\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.0234\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.0201\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.0174\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.0151\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.0131\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.0114\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.0100\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.0088\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.0078\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.0069\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.0061\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.0055\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.0050\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.0045\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.0041\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.0037\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.0034\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.0032\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.0029\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.0027\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.0025\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.0024\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.0022\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.0021\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.0020\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.0019\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.0018\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.0017\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.0016\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.0015\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.0014\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.0014\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.0013\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.0013\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.0012\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.0012\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.0011\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.0011\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.0010\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.0010\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 2.5205\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 2.3760\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 2.1743\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 1.9337\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 1.6691\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 1.3962\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 1.1310\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.8882\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.6794\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.5102\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.3805\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.2852\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.2170\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.1680\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.1316\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.1035\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.0810\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.0626\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.0475\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.0354\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.0258\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.0185\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.0130\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.0090\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.0061\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.0041\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.0028\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.0018\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.0012\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.0008\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.0006\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.0004\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.0003\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.0002\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.0002\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.0002\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.0002\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.0002\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.0001\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.0001\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.0001\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.0002\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.0002\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.0002\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.0002\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.0002\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.0002\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.0002\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.0002\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.0002\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.0002\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.0002\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.0002\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.0002\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.0002\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.0002\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.0002\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.0002\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.0002\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.0002\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.0002\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.0002\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.0002\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.0002\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.0002\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.0002\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.0002\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.0002\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.0002\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.0002\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.0002\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.0002\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.0002\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.0002\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.0002\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 2.6337\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 2.5215\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 2.3660\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 2.1796\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 1.9703\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 1.7455\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 1.5129\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 1.2801\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 1.0552\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.8453\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.6568\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.4939\n",
      "\n",
      "Start of epoch 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 12: 0.3589\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.2517\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.1702\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.1110\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.0698\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.0423\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.0247\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.0139\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.0075\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.0039\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.0019\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.0009\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.0004\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.0002\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.0001\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.0000\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.0000\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.0000\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.0000\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.0000\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.0000\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.0001\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.0001\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.0001\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.0002\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.0002\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.0003\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.0004\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.0004\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.0005\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.0006\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.0006\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.0007\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.0008\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.0008\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.0009\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.0009\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.0010\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.0010\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.0010\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.0010\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.0011\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.0011\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.0011\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.0011\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.0011\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.0011\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.0011\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.0011\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.0011\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.0010\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.0010\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.0010\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.0010\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.0010\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.0010\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.0009\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.0009\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.0009\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.0009\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.0008\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.0008\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.0008\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 2.6337\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 2.4985\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 2.3108\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 2.0856\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 1.8339\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 1.5670\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 1.2966\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 1.0348\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.7933\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.5817\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.4062\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.2691\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.1686\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.0996\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.0552\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.0286\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.0137\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.0060\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.0023\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.0008\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.0002\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.0000\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.0000\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.0000\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.0000\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.0001\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.0002\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.0003\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.0006\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.0009\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.0013\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.0018\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.0023\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.0028\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.0033\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.0038\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.0043\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.0047\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.0051\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.0054\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.0057\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.0059\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.0061\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.0061\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.0062\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.0061\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.0061\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.0059\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.0058\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.0056\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.0054\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.0052\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.0050\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.0047\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.0045\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.0043\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.0040\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.0038\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.0036\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.0034\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.0032\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.0030\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.0028\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.0026\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.0025\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.0023\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.0022\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.0020\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.0019\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.0018\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.0017\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.0016\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.0015\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.0014\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.0013\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 0.9691\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 0.7888\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.5762\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.3862\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.2523\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.1771\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.1391\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.1157\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.0957\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.0764\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.0590\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.0444\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.0332\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.0248\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.0186\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.0139\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.0102\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.0074\n",
      "\n",
      "Start of epoch 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 18: 0.0054\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.0039\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.0029\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.0022\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.0018\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.0016\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.0016\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.0016\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.0017\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.0019\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.0021\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.0023\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.0025\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.0026\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.0027\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.0027\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.0026\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.0025\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.0024\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.0022\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.0020\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.0018\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.0017\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.0015\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.0013\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.0012\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.0010\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.0009\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.0008\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.0008\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.0007\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.0007\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.0006\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.0006\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.0006\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.0005\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.0005\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.0005\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.0005\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.0005\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.0005\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.0005\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.0004\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.0004\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.0004\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.0004\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.0004\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.0004\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.0004\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.0003\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.0003\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.0003\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.0003\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.0003\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.0003\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.0003\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.0002\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 0.9691\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 0.7719\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.5442\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.3499\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.2238\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.1601\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.1288\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.1071\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.0866\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.0672\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.0505\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.0375\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.0278\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.0206\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.0152\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.0110\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.0078\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.0054\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.0039\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.0028\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.0022\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.0019\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.0019\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.0020\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.0022\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.0025\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.0029\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.0033\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.0036\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.0038\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.0039\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.0039\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.0038\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.0036\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.0033\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.0030\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.0027\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.0024\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.0022\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.0019\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.0017\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.0016\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.0015\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.0014\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.0013\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.0012\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.0012\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.0011\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.0011\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.0011\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.0010\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.0010\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.0009\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.0009\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.0009\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.0008\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.0008\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.0007\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.0007\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.0006\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.0006\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.0005\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.0005\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.0005\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.0004\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.0004\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.0004\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.0003\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.0003\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.0003\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.0003\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.0003\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.0003\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.0002\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.0002\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.3382\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 1.2501\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 1.1263\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.9769\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.8110\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.6390\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.4729\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.3248\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.2042\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.1157\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.0581\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.0253\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.0092\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.0026\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.0005\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.0001\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.0000\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.0000\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.0002\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.0006\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.0015\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.0030\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.0050\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.0073\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.0099\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.0126\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.0150\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.0170\n",
      "\n",
      "Start of epoch 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 28: 0.0185\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.0195\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.0198\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.0196\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.0189\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.0178\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.0164\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.0149\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.0133\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.0117\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.0102\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.0088\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.0075\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.0064\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.0054\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.0046\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.0039\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.0032\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.0027\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.0023\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.0020\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.0017\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.0014\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.0012\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.0010\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.0009\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.0008\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.0007\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.0006\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.0005\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.0005\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.0004\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.0004\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.0003\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.0003\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.0003\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.0003\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.0002\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.0002\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.0002\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.0002\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.0002\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.0002\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.0002\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.0001\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.0001\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.0001\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.3382\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 1.2446\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 1.1128\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.9539\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.7781\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.5980\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.4275\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.2799\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.1650\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.0858\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.0384\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.0143\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.0041\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.0008\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.0001\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.0000\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.0000\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.0002\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.0008\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.0021\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.0042\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.0070\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.0104\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.0140\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.0175\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.0206\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.0230\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.0246\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.0252\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.0251\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.0241\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.0226\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.0207\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.0185\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.0162\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.0140\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.0120\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.0101\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.0084\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.0070\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.0057\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.0047\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.0039\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.0032\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.0026\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.0021\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.0018\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.0015\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.0012\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.0010\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.0009\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.0007\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.0006\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.0005\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.0005\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.0004\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.0004\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.0003\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.0003\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.0002\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.0002\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.0002\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.0002\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.0002\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.0002\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.0001\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.0001\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.0001\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.0001\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.0001\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.0001\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.0001\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.0001\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.0001\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.0001\n",
      "[<tf.Variable 'parameters:0' shape=(18,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1.], dtype=float32)>]\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.6630\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 1.2862\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.8190\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.4880\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.3696\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.3760\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.4706\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.5655\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.5678\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.4962\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.4091\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.3389\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.2855\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.2427\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.2120\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.1989\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.2041\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.2193\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.2315\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.2319\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.2197\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.2002\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.1799\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.1626\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.1492\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.1391\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.1322\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.1283\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.1272\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.1276\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.1279\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.1268\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.1237\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.1192\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.1140\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.1090\n",
      "\n",
      "Start of epoch 36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 36: 0.1046\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.1011\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.0985\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.0966\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.0953\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.0945\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.0940\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.0937\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.0934\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.0930\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.0924\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.0917\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.0908\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.0899\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.0890\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.0881\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.0874\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.0870\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.0868\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.0869\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.0871\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.0873\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.0876\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.0877\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.0877\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.0876\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.0874\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.0871\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.0868\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.0866\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.0864\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.0863\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.0862\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.0862\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.0862\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.0862\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.0862\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.0862\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.0862\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.4688\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 1.0364\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.5889\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.3148\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.2281\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.2359\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.2696\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.3028\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.3144\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.2859\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.2195\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.1403\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.0760\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.0378\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.0204\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.0144\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.0140\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.0175\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.0231\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.0278\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.0287\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.0255\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.0201\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.0146\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.0101\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.0070\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.0052\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.0044\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.0044\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.0051\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.0064\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.0077\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.0089\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.0096\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.0095\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.0089\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.0077\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.0063\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.0049\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.0037\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.0027\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.0020\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.0014\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.0011\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.0008\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.0006\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.0005\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.0005\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.0004\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.0004\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.0004\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.0003\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.0003\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.0003\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.0003\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.0003\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.0003\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.0003\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.0003\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.0002\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.0002\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.0002\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.0002\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.0002\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.0002\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.0002\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.0001\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.0001\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.0001\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.0001\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.0001\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.0001\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.0001\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.0001\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.0001\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 0.3945\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 0.2956\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.1888\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.1024\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.0462\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.0166\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.0044\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.0007\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.0000\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.0000\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.0000\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.0002\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.0010\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.0026\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.0052\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.0085\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.0123\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.0158\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.0186\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.0202\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.0204\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.0194\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.0173\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.0147\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.0120\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.0093\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.0070\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.0051\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.0036\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.0025\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.0017\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.0011\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.0007\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.0005\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.0003\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.0002\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.0001\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.0001\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.0000\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.0000\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.0000\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.0000\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.0000\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.0000\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.0000\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.0000\n",
      "\n",
      "Start of epoch 46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 46: 0.0000\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.0000\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.0000\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.0000\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.0000\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.0000\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.0000\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.0000\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.0000\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.0000\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.0000\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.0000\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.0000\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.0000\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.0000\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.0000\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.0000\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.0000\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.0000\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.0000\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.0000\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.0000\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.0000\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.0000\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.0000\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.0000\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.0000\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.0000\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.0000\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.5420\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 1.3528\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 1.1372\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.9587\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.8427\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.7687\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.7139\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.6727\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.6452\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.6294\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.6204\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.6138\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.6073\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.6004\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.5935\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.5868\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.5800\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.5723\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.5629\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.5515\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.5385\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.5250\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.5122\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.5013\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.4932\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.4879\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.4855\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.4853\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.4866\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.4889\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.4914\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.4937\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.4954\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.4962\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.4962\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.4954\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.4939\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.4921\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.4900\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.4881\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.4862\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.4847\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.4834\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.4825\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.4819\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.4815\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.4814\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.4815\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.4817\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.4820\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.4824\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.4826\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.4828\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.4829\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.4829\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.4828\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.4826\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.4824\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.4821\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.4819\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.4817\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.4814\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.4813\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.4811\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.4810\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.4809\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.4809\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.4809\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.4809\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.4809\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.4809\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.4809\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.4810\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.4810\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.4810\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 2.0469\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 1.8120\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 1.4557\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 1.1437\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 1.0041\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.9597\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.9485\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.9553\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.9311\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.8633\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.7947\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.7489\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.7238\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.7049\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.6798\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.6424\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.5869\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.5116\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.4269\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.3531\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.3061\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.2830\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.2687\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.2511\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.2281\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.2069\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.1976\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.2006\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.2056\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.2037\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.1941\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.1814\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.1710\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.1654\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.1638\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.1624\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.1573\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.1467\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.1324\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.1191\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.1112\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.1104\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.1145\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.1188\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.1196\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.1161\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.1107\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.1060\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.1037\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.1029\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.1018\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.0991\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.0950\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.0911\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.0890\n",
      "\n",
      "Start of epoch 55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 55: 0.0889\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.0899\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.0907\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.0904\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.0893\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.0881\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.0875\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.0877\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.0883\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.0886\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.0884\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.0877\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.0871\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.0869\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.0870\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.0871\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.0871\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.0869\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.0865\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.0863\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.0749\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 0.8585\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.6586\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.5575\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.5493\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.5066\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.3986\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.2999\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.2469\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.2158\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.1868\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.1601\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.1448\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.1459\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.1567\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.1616\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.1491\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.1212\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.0896\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.0644\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.0484\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.0396\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.0345\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.0301\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.0252\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.0199\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.0151\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.0113\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.0088\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.0073\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.0066\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.0062\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.0059\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.0055\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.0048\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.0041\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.0033\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.0027\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.0021\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.0017\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.0014\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.0012\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.0011\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.0010\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.0009\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.0008\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.0007\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.0007\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.0006\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.0005\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.0005\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.0004\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.0003\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.0003\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.0002\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.0002\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.0002\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.0001\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.0001\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.0001\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.0001\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.0001\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.0001\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.0001\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.0001\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.0000\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.0000\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.0000\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.0000\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.0000\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.0000\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.0000\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.0000\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.0000\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.0000\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.5812\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 1.4345\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 1.1867\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.8769\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.5959\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.4316\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.4076\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.4868\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.5977\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.6772\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.7006\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.6706\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.6031\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.5213\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.4494\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.4047\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.3922\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.4053\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.4310\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.4555\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.4695\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.4692\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.4565\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.4365\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.4152\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.3973\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.3855\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.3801\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.3800\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.3831\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.3869\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.3894\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.3893\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.3862\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.3807\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.3737\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.3665\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.3598\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.3544\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.3504\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.3478\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.3461\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.3447\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.3429\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.3404\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.3368\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.3323\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.3273\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.3222\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.3173\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.3128\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.3089\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.3054\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.3022\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.2990\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.2958\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.2925\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.2892\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.2858\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.2824\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.2792\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.2760\n",
      "\n",
      "Start of epoch 62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 62: 0.2731\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.2704\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.2680\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.2658\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.2638\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.2621\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.2606\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.2592\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.2579\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.2567\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.2556\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.2546\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.2538\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 0.6096\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 0.5669\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.5404\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.5419\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.5565\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.5672\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.5656\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.5554\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.5449\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.5398\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.5410\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.5450\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.5475\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.5466\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.5434\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.5402\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.5386\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.5385\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.5390\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.5395\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.5396\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.5392\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.5386\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.5378\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.5370\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.5363\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.5359\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.5359\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.5364\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.5369\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.5370\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.5366\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.5358\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.5351\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.5348\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.5349\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.5353\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.5356\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.5357\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.5355\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.5351\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.5347\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.5346\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.5346\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.5348\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.5349\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.5348\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.5348\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.5346\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.5345\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.5345\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.5345\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.5345\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.5344\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.5344\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.5344\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.5344\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.5343\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.5343\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.5343\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.5342\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.5342\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.5342\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.5342\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.5342\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.5342\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.5341\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.5341\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.5341\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.5341\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.5341\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.5341\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.5340\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.5340\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.5340\n",
      "[<tf.Variable 'parameters:0' shape=(18,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1.], dtype=float32)>]\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.9678\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 1.7444\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 1.4763\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 1.2385\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.9946\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.8630\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.8922\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.9273\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.9109\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.8828\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.8618\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.8184\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.7432\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.6594\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.5867\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.5452\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.5399\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.5529\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.5700\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.5848\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.5904\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.5826\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.5637\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.5409\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.5211\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.5073\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.4986\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.4927\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.4877\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.4827\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.4780\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.4737\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.4697\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.4655\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.4603\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.4542\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.4479\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.4422\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.4374\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.4324\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.4257\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.4165\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.4054\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.3939\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.3831\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.3736\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.3652\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.3574\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.3494\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.3408\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.3317\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.3224\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.3135\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.3055\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.2984\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.2921\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.2867\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.2823\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.2788\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.2757\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.2724\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.2677\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.2608\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.2513\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.2394\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.2252\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.2088\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.1906\n",
      "\n",
      "Start of epoch 68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 68: 0.1720\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.1553\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.1429\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.1346\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.1284\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.1217\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.1140\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 0.5312\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 0.3666\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.3028\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.1362\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.0468\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.0326\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.0209\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.0072\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.0022\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.0028\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.0099\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.0266\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.0456\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.0527\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.0496\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.0472\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.0452\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.0385\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.0270\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.0157\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.0080\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.0039\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.0020\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.0012\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.0009\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.0008\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.0007\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.0006\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.0005\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.0005\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.0005\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.0005\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.0006\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.0007\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.0009\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.0012\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.0014\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.0016\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.0018\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.0019\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.0018\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.0017\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.0015\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.0013\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.0011\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.0009\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.0008\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.0007\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.0006\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.0005\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.0004\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.0003\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.0003\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.0002\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.0002\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.0001\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.0001\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.0001\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.0001\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.0001\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.0000\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.0000\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.0000\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.0000\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.0000\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.0000\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.0000\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.0000\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.0000\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.0000\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.0000\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.0000\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.0000\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.0000\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.0000\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.9287\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 1.7206\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 1.4784\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 1.2613\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 1.0847\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.9590\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.9183\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.9531\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.9899\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 1.0009\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.9949\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.9846\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.9778\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.9768\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.9806\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.9868\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.9934\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.9987\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 1.0023\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 1.0040\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 1.0043\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 1.0036\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 1.0026\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 1.0015\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 1.0006\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 1.0000\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.9998\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.9998\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.9999\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 1.0002\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 1.0005\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 1.0007\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 1.0009\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 1.0010\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 1.0010\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 1.0009\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 1.0008\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 1.0006\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 1.0005\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 1.0003\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 1.0002\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 1.0001\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 1.0000\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.9999\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.9999\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.9999\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 1.0000\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 1.0000\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 1.0000\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 1.0001\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 1.0001\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 1.0001\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 1.0001\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 1.0001\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 1.0001\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 1.0000\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 1.0000\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 1.0000\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 1.0000\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.9999\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.9999\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.9999\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.9999\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.9999\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.9999\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.9999\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.9999\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.9999\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.9999\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.9999\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.9999\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.9999\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.9999\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.9999\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.9999\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 0.5663\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 0.4770\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.3896\n",
      "\n",
      "Start of epoch 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 3: 0.3539\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.3588\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.3627\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.3535\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.3346\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.3161\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.3072\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.3110\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.3232\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.3355\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.3404\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.3362\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.3260\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.3154\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.3083\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.3062\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.3076\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.3098\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.3108\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.3097\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.3073\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.3049\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.3037\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.3039\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.3052\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.3064\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.3066\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.3055\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.3036\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.3016\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.3001\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.2996\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.2998\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.3004\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.3009\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.3010\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.3008\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.3003\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.2999\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.2998\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.2999\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.3001\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.3002\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.3002\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.2999\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.2996\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.2992\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.2991\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.2991\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.2992\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.2993\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.2994\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.2994\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.2993\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.2993\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.2992\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.2992\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.2992\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.2992\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.2992\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.2992\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.2991\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.2991\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.2990\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.2990\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.2990\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.2991\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.2991\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.2991\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.2991\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.2991\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.2991\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.0992\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 0.7088\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.3939\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.4505\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.4380\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.2594\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.1459\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.2237\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.2730\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.1995\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.1319\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.1593\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.2214\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.2304\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.1870\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.1470\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.1504\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.1802\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.1897\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.1643\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.1320\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.1241\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.1376\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.1438\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.1285\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.1065\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.0995\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.1082\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.1140\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.1065\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.0952\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.0935\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.1008\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.1051\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.1007\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.0939\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.0929\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.0967\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.0982\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.0946\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.0900\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.0894\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.0917\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.0926\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.0905\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.0884\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.0886\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.0903\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.0907\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.0895\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.0883\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.0885\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.0894\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.0895\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.0885\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.0879\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.0881\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.0886\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.0885\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.0879\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.0876\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.0878\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.0880\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.0879\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.0875\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.0873\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.0874\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.0876\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.0874\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.0872\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.0871\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.0872\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.0873\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.0872\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.0871\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.0925\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 0.9851\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.9465\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.8747\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.7725\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.7660\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.7921\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.7698\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.7150\n",
      "\n",
      "Start of epoch 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 9: 0.6192\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.4544\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.2630\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.1079\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.0293\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.0073\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.0041\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.0056\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.0122\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.0277\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.0431\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.0527\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.0562\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.0505\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.0421\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.0334\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.0254\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.0198\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.0167\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.0147\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.0130\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.0113\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.0095\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.0075\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.0053\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.0036\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.0023\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.0015\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.0009\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.0006\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.0004\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.0003\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.0003\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.0003\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.0003\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.0003\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.0004\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.0004\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.0005\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.0005\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.0006\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.0006\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.0007\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.0007\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.0007\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.0007\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.0007\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.0007\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.0007\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.0006\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.0006\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.0005\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.0005\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.0005\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.0004\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.0004\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.0003\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.0003\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.0003\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.0002\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.0002\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.0002\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.0002\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.0001\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.0001\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.0001\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.2151\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 1.1683\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 1.1240\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 1.0864\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 1.0525\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 1.0288\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 1.0146\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 1.0059\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 1.0019\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 1.0008\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 1.0005\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 1.0002\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 1.0001\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 1.0006\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 1.0016\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 1.0027\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 1.0030\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 1.0023\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.9999\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.9946\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.9855\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.9731\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.9601\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.9492\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.9399\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.9299\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.9182\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.9045\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.8910\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.8795\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.8709\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.8664\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.8664\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.8685\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.8702\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.8709\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.8715\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.8725\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.8739\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.8749\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.8753\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.8752\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.8748\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.8743\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.8738\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.8731\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.8720\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.8706\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.8694\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.8684\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.8675\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.8666\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.8656\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.8647\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.8641\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.8636\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.8632\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.8627\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.8624\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.8624\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.8623\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.8621\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.8617\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.8612\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.8609\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.8606\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.8601\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.8595\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.8588\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.8582\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.8577\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.8572\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.8568\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.8565\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.8563\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.0919\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 1.0264\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.9554\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.8921\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.8396\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.7939\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.7622\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.7507\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.7490\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.7459\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.7412\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.7381\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.7381\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.7403\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.7428\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.7438\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.7414\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.7337\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.7196\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.6986\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.6708\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.6365\n",
      "\n",
      "Start of epoch 22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 22: 0.5966\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.5536\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.5136\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.4869\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.4830\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.4995\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.5167\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.5181\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.5046\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.4870\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.4747\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.4712\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.4744\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.4796\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.4826\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.4813\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.4761\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.4686\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.4618\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.4580\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.4584\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.4620\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.4663\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.4690\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.4687\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.4659\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.4623\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.4594\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.4580\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.4582\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.4592\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.4603\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.4608\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.4605\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.4596\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.4585\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.4576\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.4572\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.4573\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.4576\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.4579\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.4580\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.4578\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.4574\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.4570\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.4567\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.4566\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.4566\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.4568\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.4569\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.4570\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.4569\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.4567\n",
      "[<tf.Variable 'parameters:0' shape=(18,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1.], dtype=float32)>]\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.6616\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 1.4440\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 1.1746\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.9688\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.9503\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 1.0253\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 1.0263\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.9517\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.8426\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.7752\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.7735\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.7315\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.6162\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.4755\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.3910\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.3456\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.3048\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.2789\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.2470\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.2370\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.2222\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.2231\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.2134\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.2171\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.2137\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.2177\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.2158\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.2180\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.2191\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.2201\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.2201\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.2149\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.2085\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.1970\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.1873\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.1766\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.1700\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.1649\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.1624\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.1599\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.1577\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.1559\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.1546\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.1550\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.1556\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.1570\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.1571\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.1568\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.1552\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.1537\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.1522\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.1514\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.1508\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.1502\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.1496\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.1487\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.1481\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.1475\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.1471\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.1466\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.1461\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.1455\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.1451\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.1447\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.1446\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.1446\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.1446\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.1447\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.1447\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.1448\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.1449\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.1450\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.1451\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.1451\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.1450\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.5404\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 1.2019\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.9124\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.8582\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.9375\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.9445\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.8816\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.8088\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.7429\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.7012\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.6483\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.5228\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.3241\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.1622\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.0898\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.0464\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.0169\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.0060\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.0063\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.0148\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.0333\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.0603\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.0869\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.1016\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.0992\n",
      "\n",
      "Start of epoch 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 25: 0.0834\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.0622\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.0425\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.0271\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.0162\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.0091\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.0049\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.0026\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.0015\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.0010\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.0009\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.0010\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.0013\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.0017\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.0022\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.0028\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.0034\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.0039\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.0042\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.0044\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.0043\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.0041\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.0037\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.0032\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.0027\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.0023\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.0018\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.0015\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.0012\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.0009\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.0007\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.0006\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.0004\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.0003\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.0003\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.0002\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.0002\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.0002\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.0001\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.0001\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.0001\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.0001\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.0001\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.0001\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.0001\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.0001\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.0001\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.0000\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.0000\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.0000\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 0.6292\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 0.4998\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.3293\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.1615\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.0505\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.0074\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.0002\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.0000\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.0021\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.0145\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.0416\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.0733\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.0931\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.0926\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.0754\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.0519\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.0309\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.0159\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.0069\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.0024\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.0006\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.0001\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.0000\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.0000\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.0000\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.0001\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.0003\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.0008\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.0014\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.0022\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.0031\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.0039\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.0044\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.0047\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.0047\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.0044\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.0039\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.0033\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.0027\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.0021\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.0016\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.0012\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.0008\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.0006\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.0004\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.0003\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.0002\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.0001\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.0001\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.0001\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.0000\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.0000\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.0000\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.0000\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.0000\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.0000\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.0000\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.0000\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.0000\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.0000\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.0000\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.0000\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.0000\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.0000\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.0000\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.0000\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.0000\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.0000\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.0000\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.0000\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.0000\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.0000\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.0000\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.0000\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.0000\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 0.8182\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 0.7882\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.7735\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.7527\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.7362\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.7373\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.7479\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.7543\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.7520\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.7460\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.7425\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.7435\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.7438\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.7405\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.7373\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.7377\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.7404\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.7422\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.7415\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.7388\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.7361\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.7347\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.7348\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.7356\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.7357\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.7351\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.7347\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.7349\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.7353\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.7356\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.7353\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.7347\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.7342\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.7341\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.7342\n",
      "\n",
      "Start of epoch 35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 35: 0.7344\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.7344\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.7343\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.7341\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.7341\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.7342\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.7343\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.7342\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.7341\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.7340\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.7339\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.7340\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.7340\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.7340\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.7340\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.7339\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.7339\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.7339\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.7339\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.7339\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.7339\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.7338\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.7338\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.7339\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.7339\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.7339\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.7339\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.7338\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.7338\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.7338\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.7338\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.7338\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.7338\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.7338\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.7338\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.7338\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.7338\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.7338\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.7338\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.7338\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.2639\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 0.8536\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.6506\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.7140\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.6636\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.3909\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.2750\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.4212\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.3446\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.1919\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.2573\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.3376\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.2643\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.2028\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.2491\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.2976\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.2714\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.2212\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.2218\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.2544\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.2474\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.2047\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.1873\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.2048\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.2080\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.1823\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.1652\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.1762\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.1856\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.1736\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.1620\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.1688\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.1783\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.1738\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.1642\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.1642\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.1695\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.1673\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.1597\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.1574\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.1603\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.1596\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.1546\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.1524\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.1548\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.1557\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.1531\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.1517\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.1533\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.1545\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.1532\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.1519\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.1524\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.1530\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.1520\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.1509\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.1510\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.1514\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.1509\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.1501\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.1501\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.1506\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.1504\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.1500\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.1500\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.1503\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.1503\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.1500\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.1500\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.1502\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.1501\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.1499\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.1498\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.1499\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.1499\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.0993\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 1.0335\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 1.0286\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.9692\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.9074\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.8815\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.7802\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.5541\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.2757\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.0808\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.0430\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.0537\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.0408\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.0363\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.0603\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.0904\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.0918\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.0669\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.0408\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.0229\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.0126\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.0081\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.0075\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.0087\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.0097\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.0098\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.0095\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.0098\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.0109\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.0122\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.0126\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.0113\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.0087\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.0058\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.0036\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.0022\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.0014\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.0010\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.0009\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.0009\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.0009\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.0010\n",
      "\n",
      "Start of epoch 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 42: 0.0010\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.0009\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.0008\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.0007\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.0006\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.0005\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.0004\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.0004\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.0003\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.0003\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.0003\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.0003\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.0003\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.0003\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.0003\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.0003\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.0003\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.0003\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.0003\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.0002\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.0002\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.0002\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.0002\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.0001\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.0001\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.0001\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.0001\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.0001\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.0001\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.0001\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.0001\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.0000\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.0000\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.1266\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 1.0830\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 1.0119\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.9046\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.7963\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.7659\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.8059\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.8357\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.8412\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.8311\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.8163\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.8036\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.7936\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.7846\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.7791\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.7800\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.7844\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.7862\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.7816\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.7716\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.7608\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.7542\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.7538\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.7576\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.7614\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.7630\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.7622\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.7605\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.7591\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.7583\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.7578\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.7574\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.7572\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.7570\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.7568\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.7560\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.7545\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.7528\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.7516\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.7513\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.7517\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.7524\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.7529\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.7531\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.7530\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.7528\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.7526\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.7524\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.7523\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.7522\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.7521\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.7521\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.7520\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.7518\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.7515\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.7514\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.7513\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.7513\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.7514\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.7515\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.7515\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.7515\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.7515\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.7514\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.7514\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.7514\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.7514\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.7514\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.7514\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.7514\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.7513\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.7513\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.7513\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.7512\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.7512\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 0.8135\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 0.7818\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.7681\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.7486\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.7354\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.7378\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.7477\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.7535\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.7509\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.7445\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.7418\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.7442\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.7440\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.7398\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.7371\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.7383\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.7409\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.7421\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.7409\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.7382\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.7355\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.7342\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.7346\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.7357\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.7361\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.7354\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.7347\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.7348\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.7352\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.7355\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.7352\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.7346\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.7341\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.7339\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.7341\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.7344\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.7345\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.7344\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.7342\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.7341\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.7342\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.7343\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.7342\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.7341\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.7340\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.7339\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.7340\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.7340\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.7341\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.7340\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.7339\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.7339\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.7339\n",
      "\n",
      "Start of epoch 53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 53: 0.7339\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.7339\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.7339\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.7339\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.7338\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.7338\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.7339\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.7339\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.7339\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.7338\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.7338\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.7338\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.7338\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.7338\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.7338\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.7338\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.7338\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.7338\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.7338\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.7338\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.7338\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.7338\n",
      "[<tf.Variable 'parameters:0' shape=(18,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1.], dtype=float32)>]\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.1792\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 0.8916\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.8163\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.8269\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.5589\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.5078\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.4649\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.2190\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.3085\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.3200\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.2435\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.3427\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.3469\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.2349\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.1984\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.2266\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.2032\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.1796\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.2088\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.2222\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.1910\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.1713\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.1816\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.1825\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.1660\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.1634\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.1762\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.1758\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.1623\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.1582\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.1623\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.1593\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.1532\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.1558\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.1624\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.1619\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.1562\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.1540\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.1543\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.1513\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.1478\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.1489\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.1520\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.1521\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.1503\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.1502\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.1503\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.1484\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.1467\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.1472\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.1482\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.1479\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.1474\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.1478\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.1479\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.1470\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.1464\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.1467\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.1470\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.1467\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.1466\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.1469\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.1468\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.1464\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.1463\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.1464\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.1464\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.1463\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.1464\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.1465\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.1464\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.1462\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.1462\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.1462\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.1462\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.0693\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 0.8004\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.7430\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.7049\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.2816\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.1245\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.1465\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.0361\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.0040\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.0260\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.1200\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.1691\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.1361\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.1070\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.1090\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.0894\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.0364\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.0081\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.0026\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.0043\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.0125\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.0206\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.0169\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.0086\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.0051\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.0079\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.0147\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.0190\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.0164\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.0106\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.0063\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.0042\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.0035\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.0036\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.0039\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.0037\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.0030\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.0019\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.0010\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.0005\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.0002\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.0001\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.0001\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.0001\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.0001\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.0002\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.0003\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.0004\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.0005\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.0006\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.0006\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.0005\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.0005\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.0004\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.0003\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.0002\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.0002\n",
      "\n",
      "Start of epoch 57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 57: 0.0002\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.0001\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.0001\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.0001\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.0001\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.0001\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.0001\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.0001\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.0001\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.0001\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.0001\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.0001\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.0001\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.0001\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.0001\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.0001\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.0000\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.0000\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.4568\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 1.3155\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 1.1835\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 1.0932\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 1.0414\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 1.0130\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 1.0012\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.9966\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.9976\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 1.0041\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 1.0079\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 1.0066\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 1.0036\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 1.0013\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 1.0003\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 1.0001\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 1.0000\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 1.0000\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 1.0000\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 1.0001\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 1.0003\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 1.0007\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 1.0012\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 1.0016\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 1.0018\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 1.0016\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 1.0012\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 1.0007\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 1.0002\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.9999\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.9998\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.9999\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 1.0001\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 1.0003\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 1.0004\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 1.0004\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 1.0004\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 1.0003\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 1.0001\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.9999\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.9998\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.9997\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.9996\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.9996\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.9996\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.9996\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.9996\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.9996\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.9995\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.9994\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.9993\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.9993\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.9992\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.9992\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.9992\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.9991\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.9991\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.9990\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.9989\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.9988\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.9987\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.9986\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.9985\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.9985\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.9984\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.9983\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.9982\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.9980\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.9979\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.9977\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.9976\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.9974\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.9972\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.9971\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.9969\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.2700\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 1.1633\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 1.0673\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 1.0018\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.9574\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.9314\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.9205\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.9134\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.9048\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.8965\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.8848\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.8705\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.8605\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.8594\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.8656\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.8735\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.8787\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.8799\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.8780\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.8743\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.8702\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.8664\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.8628\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.8591\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.8546\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.8496\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.8443\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.8390\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.8337\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.8285\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.8235\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.8189\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.8156\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.8142\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.8147\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.8165\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.8183\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.8187\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.8167\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.8124\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.8061\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.7981\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.7886\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.7770\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.7621\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.7427\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.7176\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.6856\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.6458\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.5988\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.5473\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.4989\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.4671\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.4662\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.4897\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.5078\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.5056\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.4921\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.4814\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.4781\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.4784\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.4778\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.4745\n",
      "\n",
      "Start of epoch 63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 63: 0.4690\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.4627\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.4573\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.4541\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.4535\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.4548\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.4565\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.4568\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.4549\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.4513\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.4475\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.4448\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.6153\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 1.3396\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 1.1001\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.9658\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.9444\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 1.0150\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 1.0480\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 1.0279\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.9604\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.8896\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.9150\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.9800\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.9493\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.8586\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.7965\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.7872\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.7867\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.7661\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.7186\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.6466\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.5729\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.5289\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.4860\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.4216\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.3894\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.3310\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.3298\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.2959\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.2795\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.2124\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.1961\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.1938\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.2007\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.2150\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.2199\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.2299\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.2274\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.2172\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.2085\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.2020\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.2024\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.1957\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.1940\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.1876\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.1893\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.1865\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.1876\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.1832\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.1832\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.1802\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.1802\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.1760\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.1735\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.1695\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.1691\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.1679\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.1689\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.1686\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.1697\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.1694\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.1699\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.1689\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.1687\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.1679\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.1682\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.1680\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.1680\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.1673\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.1670\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.1666\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.1668\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.1668\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.1670\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.1668\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.1668\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.1143\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 1.0729\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 1.0593\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 1.0684\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 1.0552\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 1.0078\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.9773\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.9728\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.9256\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.8758\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.8423\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.7568\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.6688\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.5543\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.3936\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.2889\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.1969\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.1616\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.1247\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.0772\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.0376\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.0189\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.0176\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.0292\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.0458\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.0542\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.0482\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.0334\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.0195\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.0110\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.0074\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.0068\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.0080\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.0102\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.0124\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.0136\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.0135\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.0124\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.0106\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.0083\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.0060\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.0041\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.0027\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.0017\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.0011\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.0008\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.0005\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.0004\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.0004\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.0003\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.0004\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.0004\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.0004\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.0005\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.0005\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.0006\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.0006\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.0006\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.0006\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.0006\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.0006\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.0005\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.0005\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.0005\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.0004\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.0004\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.0004\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.0003\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.0003\n",
      "\n",
      "Start of epoch 69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 69: 0.0003\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.0002\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.0002\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.0002\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.0002\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.0001\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.0972\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 1.0762\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 1.0553\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 1.0423\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 1.0281\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 1.0147\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 1.0055\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.9998\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.9982\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.9999\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 1.0017\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 1.0018\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 1.0008\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 1.0001\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 1.0006\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 1.0022\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 1.0032\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 1.0028\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 1.0015\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 1.0005\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 1.0002\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 1.0006\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 1.0010\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 1.0014\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 1.0014\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 1.0011\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 1.0008\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 1.0005\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 1.0002\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 1.0001\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 1.0001\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 1.0001\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 1.0001\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 1.0001\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 1.0000\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 1.0000\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.9999\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.9998\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.9997\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.9997\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.9996\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.9995\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.9994\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.9993\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.9992\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.9990\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.9989\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.9987\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.9985\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.9982\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.9979\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.9975\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.9971\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.9966\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.9961\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.9956\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.9952\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.9950\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.9950\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.9951\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.9954\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.9956\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.9957\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.9958\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.9956\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.9955\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.9953\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.9951\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.9950\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.9949\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.9950\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.9950\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.9951\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.9951\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.9952\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.0460\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 1.0169\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.9886\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.9664\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.9461\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.9230\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.8963\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.8745\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.8661\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.8637\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.8611\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.8623\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.8691\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.8777\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.8830\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.8832\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.8796\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.8745\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.8698\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.8656\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.8616\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.8584\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.8567\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.8566\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.8568\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.8558\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.8524\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.8466\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.8392\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.8307\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.8209\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.8086\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.7920\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.7688\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.7375\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.6982\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.6572\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.6293\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.6276\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.6297\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.6091\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.5811\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.5656\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.5658\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.5733\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.5793\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.5805\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.5784\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.5762\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.5766\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.5798\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.5831\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.5834\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.5799\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.5742\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.5693\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.5669\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.5666\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.5672\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.5671\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.5658\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.5637\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.5616\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.5604\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.5601\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.5605\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.5607\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.5606\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.5602\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.5601\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.5604\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.5609\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.5613\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.5614\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.5611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'parameters:0' shape=(18,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1.], dtype=float32)>]\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.2750\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 1.0307\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.9951\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.9297\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.7287\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.7442\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.7240\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.5394\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.6073\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.4415\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.4250\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.4663\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.3588\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.4719\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.4005\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.3463\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.3712\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.2812\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.2928\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.3222\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.2750\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.2907\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.2979\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.2438\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.2452\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.2441\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.2110\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.2315\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.2355\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.2195\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.2357\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.2230\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.2078\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.2150\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.2025\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.2009\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.2109\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.2040\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.2058\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.2095\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.2010\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.2016\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.2025\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.1972\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.2006\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.2013\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.1983\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.2008\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.1990\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.1966\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.1983\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.1967\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.1962\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.1978\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.1965\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.1963\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.1967\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.1951\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.1952\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.1955\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.1947\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.1953\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.1954\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.1948\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.1951\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.1947\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.1942\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.1945\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.1943\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.1942\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.1945\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.1943\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.1942\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.1943\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.1940\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 0.8981\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 0.7544\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.5451\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.3815\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.0825\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.0388\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.0123\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.0054\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.0295\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.1110\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.1507\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.1632\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.1469\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.0875\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.0542\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.0255\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.0060\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.0023\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.0028\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.0041\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.0049\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.0057\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.0084\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.0143\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.0201\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.0203\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.0176\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.0155\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.0131\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.0091\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.0052\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.0029\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.0019\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.0014\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.0012\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.0009\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.0006\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.0004\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.0003\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.0003\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.0004\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.0005\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.0006\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.0007\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.0007\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.0007\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.0007\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.0007\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.0006\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.0006\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.0006\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.0006\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.0006\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.0005\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.0004\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.0004\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.0003\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.0003\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.0002\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.0002\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.0002\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.0001\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.0001\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.0001\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.0001\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.0001\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.0001\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.0000\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.0000\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.0000\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.0000\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.0000\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.0000\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.0000\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.0000\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 0.8303\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 0.7016\n",
      "\n",
      "Start of epoch 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 2: 0.5030\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.2616\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.0746\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.0062\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.0000\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.0014\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.0219\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.0755\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.1330\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.1585\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.1443\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.1044\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.0596\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.0261\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.0083\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.0017\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.0002\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.0000\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.0001\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.0005\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.0019\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.0046\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.0084\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.0124\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.0156\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.0169\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.0161\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.0137\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.0105\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.0073\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.0047\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.0028\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.0015\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.0008\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.0004\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.0002\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.0001\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.0000\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.0000\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.0000\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.0000\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.0000\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.0000\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.0000\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.0000\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.0000\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.0001\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.0001\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.0001\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.0001\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.0001\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.0001\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.0002\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.0002\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.0002\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.0002\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.0002\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.0002\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.0002\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.0002\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.0002\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.0002\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.0002\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.0002\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.0001\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.0001\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.0001\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.0001\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.0001\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.0001\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.0001\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.0001\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.0001\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.1619\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 1.0962\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 1.0383\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.9894\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.9548\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.9536\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.9609\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.9509\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.9357\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.9227\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.9111\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.9036\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.8995\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.8953\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.8918\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.8910\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.8925\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.8942\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.8949\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.8942\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.8925\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.8896\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.8853\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.8796\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.8724\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.8638\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.8536\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.8415\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.8267\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.8086\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.7867\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.7619\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.7365\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.7145\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.6995\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.6916\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.6875\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.6851\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.6860\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.6912\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.6980\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.7026\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.7031\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.7001\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.6954\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.6907\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.6868\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.6838\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.6813\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.6792\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.6781\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.6785\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.6800\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.6818\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.6832\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.6837\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.6836\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.6830\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.6821\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.6811\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.6801\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.6790\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.6782\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.6776\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.6775\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.6777\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.6781\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.6784\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.6786\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.6787\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.6787\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.6786\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.6785\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.6782\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.6780\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 0.8750\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 0.8325\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.5036\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.6134\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.3173\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.4836\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.2641\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.3012\n",
      "\n",
      "Start of epoch 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 8: 0.3666\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.2539\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.3352\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.3575\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.2814\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.2981\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.3478\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.3021\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.2628\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.2912\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.2722\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.2237\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.2398\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.2500\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.2194\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.2247\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.2397\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.2202\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.2166\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.2347\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.2279\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.2175\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.2263\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.2236\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.2111\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.2143\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.2163\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.2067\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.2059\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.2090\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.2031\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.2024\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.2070\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.2042\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.2025\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.2054\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.2035\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.2015\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.2035\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.2024\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.2000\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.2007\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.2000\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.1981\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.1988\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.1988\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.1975\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.1980\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.1981\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.1972\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.1975\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.1977\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.1970\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.1970\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.1970\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.1964\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.1963\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.1964\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.1959\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.1959\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.1959\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.1956\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.1956\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.1957\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.1955\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.1954\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.1955\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.0711\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 1.0562\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 1.0326\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 1.0207\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 1.0191\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 1.0262\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 1.0197\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 1.0102\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 1.0038\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 1.0016\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 1.0010\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 1.0004\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 1.0001\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 1.0001\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 1.0007\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 1.0013\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 1.0015\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 1.0014\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 1.0013\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 1.0009\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 1.0002\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.9990\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.9972\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.9929\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.9790\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.9437\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.8774\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.7648\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.6209\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.4393\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.2287\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.0896\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.0195\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.0032\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.0018\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.0066\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.0200\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.0516\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.0847\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.1117\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.1114\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.1014\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.0756\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.0512\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.0278\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.0126\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.0055\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.0020\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.0006\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.0002\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.0001\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.0001\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.0003\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.0007\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.0011\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.0016\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.0021\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.0028\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.0037\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.0046\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.0053\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.0056\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.0055\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.0051\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.0045\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.0039\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.0033\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.0027\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.0022\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.0017\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.0013\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.0009\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.0007\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.0005\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.0003\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.0845\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 1.0640\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 1.0397\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 1.0200\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 1.0061\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 1.0008\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 1.0001\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 1.0000\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 1.0005\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 1.0016\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 1.0022\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 1.0015\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.9993\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.9948\n",
      "\n",
      "Start of epoch 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 14: 0.9861\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.9763\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.9757\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.9783\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.9750\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.9646\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.9493\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.9338\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.9190\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.9114\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.9151\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.9175\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.9153\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.9137\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.9135\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.9136\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.9150\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.9164\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.9155\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.9128\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.9104\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.9083\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.9061\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.9051\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.9057\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.9062\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.9058\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.9053\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.9051\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.9047\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.9045\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.9051\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.9056\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.9054\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.9048\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.9041\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.9035\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.9030\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.9029\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.9031\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.9033\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.9033\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.9033\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.9034\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.9033\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.9033\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.9033\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.9033\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.9031\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.9029\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.9028\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.9027\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.9027\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.9028\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.9029\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.9029\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.9029\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.9028\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.9028\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.9028\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.9028\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 0.9109\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 0.8672\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.8355\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.8418\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.8290\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.8174\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.8204\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.8311\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.8388\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.8384\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.8320\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.8237\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.8177\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.8164\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.8191\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.8209\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.8196\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.8179\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.8183\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.8196\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.8200\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.8188\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.8168\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.8148\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.8138\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.8137\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.8144\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.8153\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.8159\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.8158\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.8154\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.8150\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.8146\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.8143\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.8141\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.8138\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.8136\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.8136\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.8136\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.8138\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.8139\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.8139\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.8138\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.8136\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.8135\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.8134\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.8134\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.8135\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.8135\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.8135\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.8135\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.8134\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.8134\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.8134\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.8133\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.8133\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.8133\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.8132\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.8133\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.8133\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.8133\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.8133\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.8133\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.8133\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.8133\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.8132\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.8132\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.8132\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.8132\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.8132\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.8132\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.8132\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.8132\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.8132\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.8132\n"
     ]
    }
   ],
   "source": [
    "#qcnn_model.predict(train_excitations)\n",
    "\n",
    "N = 6\n",
    "\n",
    "lossp = []\n",
    "loss = []\n",
    "\n",
    "losspF = []\n",
    "lossF = []\n",
    "\n",
    "lossp_ = []\n",
    "loss_ = []\n",
    "\n",
    "losspF_ = []\n",
    "lossF_ = []\n",
    "\n",
    "loss_fn = tf.losses.mse\n",
    "\n",
    "#optimizer=tf.keras.optimizers.SGD(learning_rate=0.01*16, momentum=0.0, nesterov=False)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.02)\n",
    "    \n",
    "for n in range(1,N+1):\n",
    "    model, quantum_model_circuit, qubits, readoutqubit = setup(n, param, extra=False, full=True, cnot=True)\n",
    "    inputs, labels = generate_data(qubits)\n",
    "\n",
    "    ninp = len(inputs)\n",
    "    split = int(ninp*1)\n",
    "\n",
    "    train_excitations = inputs[:split]\n",
    "    train_labels = labels[:split]\n",
    "    #train_labels = tf.cast(train_labels, dtype=tf.float64)\n",
    "\n",
    "    test_excitations = inputs[split:]\n",
    "    test_labels = labels[split:]\n",
    "\n",
    "    print(model.weights)\n",
    "\n",
    "    \n",
    "\n",
    "    \"\"\"batch_size = 16\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train_excitations, train_labels))\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\"\"\"\n",
    "\n",
    "    \n",
    "    loss_list = []\n",
    "\n",
    "    epochs = 75\n",
    "    train(model, train_excitations, train_labels, optimizer, loss_fn, loss_list, epochs=epochs)\n",
    "    \n",
    "    loss.append(loss_list)\n",
    "    \n",
    "    loss_list = []\n",
    "    model, quantum_model_circuit, qubits, readoutqubit = setup(n, param, extra=False, full=True, cnot=True)\n",
    "    inputs, labels = generate_data_p(qubits)\n",
    "    train(model, inputs, labels, optimizer, loss_fn, loss_list, epochs=epochs)\n",
    "    lossp.append(loss_list)\n",
    "    \n",
    "    \n",
    "    loss_list = []\n",
    "    model, quantum_model_circuit, qubits, readoutqubit = setup(n, param, extra=False, full=False, cnot=True)\n",
    "    inputs, labels = generate_data_p(qubits)\n",
    "    train(model, inputs, labels, optimizer, loss_fn, loss_list, epochs=epochs)\n",
    "    losspF.append(loss_list)\n",
    "    \n",
    "    loss_list = []\n",
    "    model, quantum_model_circuit, qubits, readoutqubit = setup(n, param, extra=False, full=False, cnot=True)\n",
    "    inputs, labels = generate_data(qubits)\n",
    "    train(model, inputs, labels, optimizer, loss_fn, loss_list, epochs=epochs)\n",
    "    lossF.append(loss_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    loss_list = []\n",
    "\n",
    "    \n",
    "    model, quantum_model_circuit, qubits, readoutqubit = setup(n, param, extra=False, full=True, cnot=False)\n",
    "    train(model, train_excitations, train_labels, optimizer, loss_fn, loss_list, epochs=epochs)\n",
    "    \n",
    "    loss_.append(loss_list)\n",
    "    \n",
    "    loss_list = []\n",
    "    model, quantum_model_circuit, qubits, readoutqubit = setup(n, param, extra=False, full=True, cnot=False)\n",
    "    inputs, labels = generate_data_p(qubits)\n",
    "    train(model, inputs, labels, optimizer, loss_fn, loss_list, epochs=epochs)\n",
    "    lossp_.append(loss_list)\n",
    "    \n",
    "    \n",
    "    loss_list = []\n",
    "    model, quantum_model_circuit, qubits, readoutqubit = setup(n, param, extra=False, full=False, cnot=False)\n",
    "    inputs, labels = generate_data_p(qubits)\n",
    "    train(model, inputs, labels, optimizer, loss_fn, loss_list, epochs=epochs)\n",
    "    losspF_.append(loss_list)\n",
    "    \n",
    "    loss_list = []\n",
    "    model, quantum_model_circuit, qubits, readoutqubit = setup(n, param, extra=False, full=False, cnot=False)\n",
    "    inputs, labels = generate_data(qubits)\n",
    "    train(model, inputs, labels, optimizer, loss_fn, loss_list, epochs=epochs)\n",
    "    lossF_.append(loss_list)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "4c3d8c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_loss = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "f368bbf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAAsTAAALEwEAmpwYAABO6UlEQVR4nO2dd3wc1fW3n7Nd2lXvsizJFTds2ZYrxnQwxaYYCE7CDwgJvb0hjRQCJCRAAoEQQkIgoUMIJFQDoYZmbAs33HG3bEtW79K2+/4xKyPLKttsaaX78Blmd+bOnbOS9Z2z5557riil0Gg0Gk3sY+prAzQajUYTHbSgazQazQBBC7pGo9EMELSgazQazQBBC7pGo9EMELSgazQazQBBC7rmsCEib4rIJX1th0YzWNCCrjkIEdkhIi0i0igi5SLyuIi4wulLKXW6UuqJQL+XisgnIdhRKCJKRCwhXPOhiLQGbG/fZnXXV+Cz/bo3+wL9fjdYO6KFiEwXkcUiUisi1SKyTEQuC5w7PvCZ/tzpmk9E5NIO7/NE5BkRqRKRpkAfZwXO5Xf6WalAm/b3xx7RD6yJGC3omq6Yr5RyAVOAYuDnoVwsBn31b+s6pZSrw7akj+yICBGZBbwP/A8YCaQBVwOnd2jWBFwsIoXd9JEKfAK4gfFAOvAH4FkROV8ptavjzypw2aQOxz4+HJ9Nc/jQgq7pFqXUHuBNYIKIpIjI6yJSISI1gdd57W0DXuydIvIp0AwMb/dsRWQs8BdgVsDzqw1cc6aIrBSRehHZLSK3dbj9R4F9bbunfSQ+czQRkdtE5AUReVJEGkRknYgUdzg/NvAzqg2cW9Dh8t8BTyil7lZKVSqDL5RSF3ZoUws8DvyyGxP+H9AIXK6UKlNKtSilngPuBO4VEYnm59X0PVrQNd0iIkOBM4CVGP9W/gEUAPlAC/CnTpdcDFwBJAA72w8qpTYAVwFLAp5fcuBUE/B/QDJwJnC1iJwTODc3sE+OZU8bWAA8j/EZXyXwMxMRK/Aa8F8gE7geeEZEjhKReGAW8GIQ/d8JLBSRo7o4dwrwklLK3+n4Cxi/w9EhfxpNv0YLuqYrXg540Z9gfOX/jVKqSin1klKqWSnVgCEkx3W67nGl1DqllFcp5entJkqpD5VSXyql/EqpNcBzXfQZKn8MeLy1IrIiwr6iwSdKqcVKKR/wFDApcHwm4ALuUkq5lVLvA68Di4AUjL/Nfb11rpQqw/j2c0cXp9O76WNfh/OaAUTQA06aQcU5Sql3Ox4IeI1/AOZhCA5AgoiYA2IFsDuUm4jIDOAuYAJgA+zAvyIxHLhBKfVop2PewN7a4XX7+14fPBFS1uF1M+AIDM7mArs7ec87gSFADeAHcoCNQdzjbmCriEzqdLwy0Edncjqc1wwgtIeuCZabgaOAGUqpRL4OiXSMw/ZUurOrc89ihCGGKqWSMDxN6aF9uOzDEO7CTseH0SE0dITZCwztNHicD+xRSjUDS4CFwXSklKoC7gd+1enUu8B5XQxQX4jx8N0cht2afowWdE2wJGDEzWsD2RPdDcR1RzmQJyK2Tn1WK6VaRWQ68M0O5yowvNTh7Qc6pB8WhnLjwDeIl4A7RSRNRKwisggYhzHo2+EW4ui4dThn6XTOGrhgR8c0wRBYiuGx/yhgz/HAfIx4O8CPgEtF5Icikha41yQReb6rzoD7gNnA2A7H/gAkAY+JSHbA7kXAz4AfKl07e8ChBV0TLPcDcRhf0z8H3grx+veBdUCZiLR/1b8GuENEGoBbMQbrAAh4qXcCnwbi4TOBoRge9Z4w7L8GqAbWAPuB64AzlVLlHdrMxnhoHdg65K4/3OncPwIPpzSMn0dIKKXcGAJ+OsbP9M/A/ymlNgbOfwacGNi2iUg18AiwuJv+6oF7gNQOx6qAOYADWA9UAd8HLlZK/TNUmzX9H9EPaU2sICI/ByqUUn/ta1sARGQOcK1SalFf26LRgBZ0jUajGTDokItGo9EMELSgazQazQBBC7pGo9EMEPpsYlF6eroqLCzsq9trNBpNTPLFF19UKqUyujrXZ4JeWFhISUlJX91eo9FoYhIR6XYynA65aDQazQBBC7pGo9EMELSgazQazQBBV1vUaDSDDo/HQ2lpKa2trX1tSrc4HA7y8vKwWq1BX6MFXaPRDDpKS0tJSEigsLCQ/rhwk1KKqqoqSktLGTZsWNDX6ZCLRqMZdLS2tpKWltYvxRxAREhLSwv5G4QWdI1GMyjpr2LeTjj2xZygt27cyP5770MXFdNoNJqDiTlBb15eQtXf/kbjhx/2tSkajUYTFrt37+aEE05g3LhxjB8/ngceeCAq/cacoKdc9A2shYXs/93vUZ7DvRykRqPRRB+LxcK9997L+vXr+fzzz3nooYdYv359xP3GnKC/uP1lHp7ThHvbNmpeeKH3CzQajaafkZOTw5QpUwBISEhg7Nix7NkTzkJcBxNzaYtZNaX8N6+a/5s0mso/PUTS/PmYExP72iyNRhOj3P7aOtbvrY9qn+NyE/nl/PFBtd2xYwcrV65kxowZEd835jz0WeZEkv1+3jotEV9tLZV/7RerkWk0Gk3INDY2snDhQu6//34So+CYxpyHbs2bwalLmnkpeR2L5p9JzZNPkbJoEba8vL42TaPRxCDBetLRxuPxsHDhQr71rW9x3nnnRaXPmPPQlzZmcnKTosXvYf35k8FspuK++/raLI1GowkapRSXX345Y8eO5fvf/37U+o05QV/9eTnrd9/F2LphvFr/CWnf+Q71i99kz80/wFNefkh7f3MzjR9/jK+urg+s1Wg0mkP59NNPeeqpp3j//fcpKiqiqKiIxYsXR9xvzIVc0lIdlCknc9ffwLqaT/Bdu5B0FFWPPkbDBx+QfuWVpF56CW1fbaH2xX9R//ob+BsbMScnk37D9aRceCFiibmPrdFoBhBz5sw5LJMjY85DHzYhnbVJqxnqepvx++bwn7vX0XLStxi++A1cx8ym4g9/4KvZx7Dj/POpe/kVEk46iSH334999GjK7/gV2889l8ZPP+3rj6HRaDRRJ+YEPTvRwRdqGAtcj1BS9A+aVAOvPbiazduEvAcfJP/vj+E6bi5Zt/6CUR/9j9y77yJx3mnkP/E4Qx78I/7WNnZf/l2qn3q6rz+KRqPRRJWYiz1kJNipkBQabFkck1jFQ+N/xS8a/sr/nt2EySSMmzMb5+zZh1wnIiSecgqu445j9xVXUvnwwyQvPA9TfHwffAqNRqOJPjHnoVvNJjJcdnY4xnJ65R58Ji81c78kf3waHzyzkQ2f7evxepPNRsYN1+OrrtYzTTUazYAi5gQdIDvJwTrTaPKqdzEpdRyLd73BqVeMY+iYFN5/agOblpb1eH38lCnEz5hB1WOP4e/HK5ZoNBpNKMSmoCc6WOYZDsD8xKP4quYr5r44h1dG/Rl/TgPvPr6eD57eQEN192Kdfs01+CoqqX3xpSNltkaj0RxWYi6GDoaH/ta2ISBmLvCYSTj2blbuX8nayrU8kX8nxf7TYclcNn5exvg5Q5h6egHOJPtBfcRNK8Y97VSWvvwVDbuWYY+3kj8ujfwJqaTmOPt98XuNRhO7tLa2MnfuXNra2vB6vZx//vncfvvtEfcbk4Kelehgf6sZf8F4THu+4IyTf8kZw88AoM3Xxtkvn42Ya7iw6RrWfbSH9Z/sJSHNgT3egsNpxWo3U7atjkbn2RDvJ722hmZvMp/9ewuf/RtcKXaGT85g/JwhpOY6+/jTajSagYbdbuf999/H5XLh8XiYM2cOp59+OjNnzoyo314FXUT+DpwF7FdKTejivAAPAGcAzcClSqkVEVnVCzlJDgAa0yeR+NXL4PeByQyA3WznnJHn8NCqh/jpeT9kyqkzWfu/Uhpr2mhr9tBc76atxUtGfgLT5w9D/ngLli17GPHWmzQ2+Ni9vpqda6tY+9Ee1rxfSu6oZMbPzWVEUSZma0xGqDQaTT9DRHC5XIBR08Xj8UQlKhCMh/448CfgyW7Onw6MCmwzgIcD+8NGdqIh6OVJR5PofgoqN0Pm2APnzxl5Dg+vfpiXt7zM9ZOv55jzR3XbV4P7Mkqvupral18m5YILGDcnl3FzcmlpcLPhs32s+3gP7zy2ng8dm8g7KoX88Wnkj0slMT3ucH5EjUZzpHjzJ1D2ZXT7zD4aTr+rxyY+n4+pU6eyZcsWrr322qiUz+1V0JVSH4lIYQ9NzgaeVMY81s9FJFlEcpRSPecPRkB2wEPfbh/LKIDSkoMEPduZzTG5x/Dylpe5etLVWEzdf0zXcccRN3ky++++B+eMGdjy8wGIS7Ax5bQCJp+Sz+6N1WxdWcHuddVsX11pXJdix5lsJz7RRnyiDYfLisVqwmQ2YbaYMFtNmMxivLYYrw9sJkFMgaexAgWgFH6/wu9V+Hx+/D6Fz+s33nv9xmu/QvkVym8U92mfOdz+YBcx/idieAAixv3E9PV9zVbDHovVsNFqN2N1mLHazdgcFuxxlq9t02g0hw2z2cyqVauora3l3HPPZe3atUyYcEgQJCSiEUMfAuzu8L40cOywC/oWfzan2pNgTwlMufigNgtHLeSmD2/is72fMTdvbrd9iQhDfv87tp23kNKbbqLwuecw2b8eQBWTGIOl49JQSlFb3syuddVU7Gqgub6N+soWyrbV0dLoCShzbCMCDpcVh9OKw2UlOTOetDwX6YHNHm/taxM1mujSiyd9uElOTuaEE07grbfe6heCHjQicgVwBUB+wBMOh3ibhUSHhbJ6N+RNhdIvDmkzd+hcUh2pvLT5pR4FHcA6ZAi5d99F6VVXU37nb8i5o+vRZhEhJdtJSvahA6VKGd6zr6NH7VP4PH7D4/Yq/D4V8LKNc4FOEQABk7ndqxdMJhNmqwS8exNmS8DTDnj3YjI88QMefsAG1Nfeuwp49H5/4N4Br9/nMezzun142vy4W7142nx4Wn20NnloafTQ2uCmucHNji8rD5qsNXRsCsd+Y3SXPwONRhMcFRUVWK1WkpOTaWlp4Z133uHHP/5xxP1GQ9D3AEM7vM8LHDsEpdQjwCMAxcXFEfmz2UkOyupaIa8YPv49tDWAPeHAeavJytkjz+bJdU9S2VJJelx6j/0lHH88ad/7HlV/+xvxxVNJWrAgJHtEBDELJjNY7eawPlNYCEjHN1FGKUVzvZvK0kbKt9ez5v3dPP+rZRSdPJTiM4Yd2c+q0QwQ9u3bxyWXXILP58Pv93PhhRdy1llnRdxvNNI2XgX+TwxmAnWHM37eTlaig/L6Vhh5Eig/fP6XQ9qcN/I8fMrHq1tfDarPjBtvIL64mH2/vI2WL788LOUtYw0RwZlkp2B8GtPPGsY3b5vJ6OlZrHh7F8/e9jm71lf1tYkaTcwxceJEVq5cyZo1a1i7di233nprVPrtVdBF5DlgCXCUiJSKyOUicpWIXBVoshjYBmwB/gZcExXLeiEnycG+ulbInwnjzoaP74WanQe1KUwqZErmFP791b+DEmexWMi9715M8fHsuOBCvpo1m13fuZz9995L6/r1h+ujxBTxiTZOumQc5/1gClaHhbf+urbHGbkajebI0augK6UWKaVylFJWpVSeUuoxpdRflFJ/CZxXSqlrlVIjlFJHK6VKDr/ZRupiRWMbHp8fTvuNMZr39k8Pabdw9EJ21u+kpDw4s6yZmQz71wtk//JWEk45GV9tLVWPP8HOSy7F19AQ7Y8Rs+SMTOasayeigA+f3qi/zWg0/YCYnSmTnRSHUlDR0AZJeTD3h7Dxddj834PanVJwCk6rk1e2vBJ039bcXFIWLSLnV79i2L9fYtg/n8ff0EDN07qGekcS0+OYfe4Idq2vZuOSwx5l02g0vRDDgm6kFpbVB77uz7oO0kbBmz8Cz9chgDhLHPMK5/Hfnf+l2dMc1r0c48bhOv54qh9/Al9jU8S2DyQmzB1CzsgkPvnXFppq2/raHI1mUBOzgp4VmC1aVhcQb4sNzrgHarbDZ388qO3ZI8+mxdvCOzvfCft+6ddcja+ujprnng27j4GImIQTLx6Lz+vnw2c36dCLRtOHxKyg5yQZU+8PCDrAiBNh3DnGAGld6YHDRRlF5Cfk88rW4MMunYmbOBHnscdS/fd/4G8Oz9MfqCRnxTNjwXB2rKnkq5LyvjZHoxm0xKygp8RbsVlMRupiR06+Dbyt8OW/DhwSEc4eeTbLy5ZT2lBKuKRfczW+mhpqnv9n2H0MVCadNJTMwkQ+e3ELfr/20jWaYPD5fEyePDkqOegQw4IuImQnBlIXO5I6DHInw/qDc8/nD5+PILy29bWw7xk/eTLxs2ZS9fe/65WOOmEyCUUnD6Wpzs3ezTV9bY5GExM88MADjB07tveGQRKzgg5G6mJZZw8dYOwC2LsCar8uMZPjymFGzgxe2foKfuUP+54Z11yDr7KS2hf+1XvjQUbhxHSsdjObl+uwi0bTG6Wlpbzxxht897vfjVqfMbnARTtZSQ5W76499MTYBfDe7UYa48yrDxw+e+TZ3PLxLXxR/gXTsqeFdc/4adOInzaNqkcfJfmib2Cy2cK0fuBhtZkZXpTB1hUVHHfRUbp+vCYmuHvZ3Wys3hjVPsekjuHH03uuzXLTTTdxzz330BDF+S0x/ReXk2R46IdkVqSPhMxxh4RdTso/CafVyctbXo7ovmlXXol3/37qXw2upMBgYtS0LNwtXnau0yUBNJrueP3118nMzGTq1KlR7Te2PfREB26vn9pmDynOTp7y2AXwv7uhoRwSsoCvc9IXb1/Mz2b8jHhrfFj3dR4zG/u4sVQ99neSzjsPMcX0czGq5I1NweGy8tXycoYXZfS1ORpNr/TmSR8OPv30U1599VUWL15Ma2sr9fX1fPvb3+bpCCcvxrQStS9Fd8jAKMC4BYCCTW8cdLg9J/0/W/4T9n1FhLTLL8e9fTsN770Xdj8DEbPZxMipmexYU4m71dvX5mg0/ZLf/va3lJaWsmPHDp5//nlOPPHEiMUcYlzQ2ycXHZK6CEbIJXXEIWGXoowiZmTP4Pclv2fJ3iVh3zvxtNOw5uVR9eijejJNJ0ZNy8Lr8R9Y3Umj0RwZYlrQe/TQRWDsfNjxMTRXdzgs3HfCfQxLGsZNH9zEhqoNYd1bLBZSv3MZravX0Lx8eVh9DFRyhifhSrWzeZnOdtFoeuP444/n9ddfj0pfMS3oGQl2ROg6dRGMsIvfC5vfOuhwoi2Rh096mCR7Ele/e3XYk42SzzsPc2oqVX97NKzrBypiEkZPy2L3hmpaGtx9bY5GM2iIaUG3mk2ku+yU1bV03SB3CiTmHRJ2AchyZvGXk/+Cx+/hqnevorq1uosOesbkcJD6fxfT9PHHtG6MbtpTrDNqWhbKr9i6Yn9fm6LRDBpiWtChPXWxmyp/7WGXre8bS9R1YnjycP500p/Y17iPB1c+GNb9UxYtwhQfT9Wjj4V1/UAlbYiLlBynnmSk0RxBYl7QsxIdlHcVQ29n3ALwtcGWd7s8PTlzMrNzZ1NSFt66HOakJJIvvJD6N9+k5cu1YfUxEBERRkzJYN/WOtwtOttFozkSxLygG0vRdRNyAcibDlYn7Ow+o6Uos4gd9TuoaQ2vBkn61VdhSU9n749/rGu8dCB7eBIoqNilV3rSaI4EMS/oWYkO6lu9NLu78QLNFsibCruXdttHUWYRAKv2rwrLBnNSErm//Q3ubdvYf+99YfUxEMksSACgfGd9H1ui0QwOYl7Q21MXy3oKuwydAWVfgrvr1YbGp43HYrKwqmJV2HY4Z88m5eKLqXnqKZo++yzsfgYScS4bCWkOKnZqD12j6UxhYSFHH300RUVFFBcXR6XPASDoxkIXXeaitzN0Bigf7FnR5WmHxcG4tHFhe+jtZN78fWzDh7P3lp/iq6uLqK+BQmZBIvu1h67RdMkHH3zAqlWrKCkJbwyvMzEv6LnJhoe+p7anOHrg6ddT2CWjiLWVa3H7ws+bNjkc5N5zD96qKsp+9euw+xlIZBYmUF/ZSkujzkfXaA43MV2cCyC7fbZobQ8eelwKZIyB3cu6bTI5czJPrn+SDdUbmJQxKWx74iaMJ/3qq6h88E+kXnYpcePHh93XQCCzIBGA/TsbKBif1sfWaDSHUvab39C2IbrzSOxjx5D905/22EZEOPXUUxERrrzySq644oqI7xvzHrrdYiYjwc7enjx0gKHToXQZ+Lte3CLSgdGOpFx0EQBNn3wacV+xTma+MTBaocMuGs1BfPLJJ6xYsYI333yThx56iI8++ijiPmPeQwfITY5jb0+pi2DE0Vc8CVVbIGP0IafT49LJc+Wxcv9KLhl/SUT2WNLSsI8ZQ9Onn5J+ZeRP3VjGFmchOSue8h16YFTTP+nNkz5cDBkyBIDMzEzOPfdcli1bxty5cyPqM+Y9dIDcJEcQHvoMY99DHH1y5mRW7V8VleqJzmNm07xyJf7m5oj7inUyCxP0wKhG04GmpqYDKxU1NTXx3//+lwkTJkTc78AQ9OQ49tZ2sXJRR9JGGrH0XvLRq1qrwi7W1RHn7Nng8ehKjBhx9OY6N0213ZRo0GgGGeXl5cyZM4dJkyYxffp0zjzzTObNmxdxv0GFXERkHvAAYAYeVUrd1el8PvAEkBxo8xOl1OKIrQuS3OQ4Wjy+rlcu+tpIw0sPZoJRxSqGJg6NyKb4qVMRu52mzz7DddxxEfUV67QPjJbvqNerGGk0wPDhw1m9enXU++3VQxcRM/AQcDowDlgkIuM6Nfs58IJSajJwEfDnaBvaE7lJQaQugjEwWrn5oProHRmZPBKX1cXK/SsjtsnkcBA/daqeZASkD3UhJtFhF43mMBNMyGU6sEUptU0p5QaeB87u1EYBiYHXScDe6JnYO7nJQUwugq/j6KVdh0FMYmJSxqSoCDoYcfS2r7bgKR/cFQetNjOpuU49Y1SjOcwEI+hDgN0d3pcGjnXkNuDbIlIKLAau76ojEblCREpEpKSioiIMc7umXdB7HRjNnQJi7jXssrV2K/X710Vsl/OYYwBo+iz8pe4GCpkFCZTvrNfL9Wk0h5FoDYouAh5XSuUBZwBPicghfSulHlFKFSulijMyohdLTXPasJlNvQu6LR5yJvY4wajIkoxCsebp+T22Cwb76NGY09Jo+lTno2cWJNLW5KW+Ulej1GgOF8EI+h6g4whhXuBYRy4HXgBQSi0BHEB6NAwMBpNJyEl2sLe3kAvA0Jmw5wvweQ49V7ubiW/dhlkpVjpd8OQ5sP3jsO0Skwnn7Nk0LVmC6mZC02Ahq7B9xqiOo2s0h4tgBH05MEpEhomIDWPQs/OabruAkwBEZCyGoEcvphIEuUlxvXvoYAyMepqhvNNiFC018PRC4t3NjEocxrr8qZA8FJ45v9vFMYLBOXs2vqoq2jZvDruPgUBqrhOTRdiv4+gazWGjV0FXSnmB64C3gQ0Y2SzrROQOEVkQaHYz8D0RWQ08B1yqjnCw1MhFD0bQAwOjb/4Elj8GNTvA0wrPfRNqtsNFz5CbPJxydy1c+gakj4LnFsHG8LIwnbNnAQz6sIvZYiI9L4H9O7SHrtEA1NbWcv755zNmzBjGjh3LkiWRj7UFlYceyClf3OnYrR1erweOidiaCMhNdlBe34rX58di7uE5lTQETvw5fPEkvPF945gjGVpr4fy/w7BjySj/HyXlJeBMh0teM0Ivr1wDIzaANS4ku6xZWdhHjaTp089Iu/zycD/egCCrIIGNn5fh9ytMJulrczSaPuXGG29k3rx5vPjii7jdbpqjMKt8QMwUBcND9ysobwhiNuLcH8JNa+C6Eph3N+TPgrPuhwkLAciKz6LeXU+rt9WYXXranUZI5ssXw7LNOXs2zSUlg355uvT8BDxtPuorgvgmpdEMYOrq6vjoo4+4PODk2Ww2kpOTI+53QBTngoNTF4ckB+FFixjhlPRRMPOqg05lxBsZOBUtFQxNGAoFx0DmOFj2V5j8bePaEHDOnk31E0/S/MUXuI7p0y8yfUpqjhOAmrImkrPi+9gajcbg4xc2U7m7Map9pg91ceyFhxYBbGf79u1kZGRw2WWXsXr1aqZOncoDDzyA0+mM6L4Dx0MPzBYNKo7eC5lxmQDsb95vHBCB6VcYy9iFkcoYX1wMVivNn38esW2xTMoBQdcFyzSDG6/Xy4oVK7j66qtZuXIlTqeTu+66q/cLe2HAeOg5Bzz0yMMaBzz05g6JOhMvhHd+aXjp+TNC6s/kdBI3aaIxwejmiM2LWexxFpxJNqr3db22q0bTF/TkSR8u8vLyyMvLY8YMQ0vOP//8qAj6gPHQXXYLSXHW6Hjo8Z08dACb0wi3rH8FGspC7tM5axat69fjq62N2L5YJiXHSY0WdM0gJzs7m6FDh7Jp0yYA3nvvPcaN61wiK3QGjKCDEUff19tCF0GQaEvEbrZT0dIplX7a5eD3wRePh9ync9YsUIqmpZHNPo11UrKd1JQ36xIAmkHPgw8+yLe+9S0mTpzIqlWr+GkUFtoYMCEXMOLoe6IQchERMuIyKG/uVFQrbQSMOgVK/g5zvg+Wbkr1dkHc0Udjio+n6fMlJJ52asQ2xiqpOfF4Wn001bbhSnH0tTkaTZ9RVFRESUlJVPsccB56NEIuYIRdDoqhtzP9Cmgshw2dJ8v2jFitxE+bRvOSQT4wmm0MjOo4ukYTfQacoNe1eGhq80bcV2Z85qEhF4ARJ0HqcFj2t5D7jJ81E/eOHXj27YvYvljlQKbLPp3potFEmwEm6MZX+GjE0TPiM9jfvP/QWK/JBEXfhN2fQ1NVSH06Z80GoGkQe+lxCVbs8RZqyrSHrulb+vs4Tjj2DTBBN1IXoxFHz4zLpMXbQqOniwkHhcca+12h1V6wjx5llNONQs2GWEVESM1x6lx0TZ/icDioqqrqt6KulKKqqgqHI7RxpoE1KBrsQhdB0DEXPcGW0OlGk8HigJ2fwdizgu5TRHDOnEnT50tQSiEhzjgdKKRkx7NtdWVfm6EZxOTl5VFaWko0F9qJNg6Hg7y8vJCuGVCCnpVgxySwL5q56C37GZ48/OCTFjvkTYOdoVdQdM6aSf0bb+DesgX7qFER2xmLpOQ4af10Hy2NbuJcwWcKaTTRwmq1MmzYsL42I+oMqJCLxWwiKzE6qYvtgt5lpgtAwWwoWwOtoZWDjZ8ZKKc7iOPo7ZkuemBUo4kuA0rQIXqpixlxRsjlkFz0dgpmg/KHXNvFljcEa34+TYO4rktKjlGYSw+MajTRZUAKejSyXOKt8bisru499LxpYLKEF3aZOZPmZctQ3sjTK2ORhBQHFptJ56JrNFFm4Al6krG2qN8f+eh1RnxG17noYNR2yZ0ccqYLGKsY+RsbaV27tvfGAxAxiVECQGe6aDRRZeAJenIcbq+fqiZ3xH1lxmceXKCrMwWzjQWnPaF9I4ifPh2A5ihP+40lUnLidZEujSbKDEhBh+jVRe9Z0I8Bn9sQ9RCwpKZiHTKElnXrIrQwdknJdtJY04a7dXCGnTSaw8GAE/ThGUYGxaayyFeXbw+5+JW/6wZDZwBi5KOHiGPCBFrXDl5BT83Wi11oNNFm4Al6upPkeCslO6sj7iszPhOv30ttW23XDeKSIWtCWAOjjgnj8ezePWjro+tMF40m+gw4QRcRpuanULKzJuK+es1FByOOvnsZ+Dwh9R03YQLAoA27JGbEYTKLzkXXaKLIgBN0gKmFKWyraKI6woHRXnPRwRB0TzPsWx1S347A6iSt69aHbV8sYzabSMqM1x66RhNFBqSgFxekArAiQi89aA8dQg67mJOSsBbkD9rURYDU7Hidi67RRJEBKegT85KwmiXisEu7h76/pYdMF1cmpI0Ka2A0bvz4QS3oKTlO6ita8Hm6GXTWaDQhMSAF3WE1Mz43KWIP3Wq2kupI7dlDB8NL37nEWG80BBzjJ+DZuxdvdeQDuLFISk48SkHtfh1H12iiQVCCLiLzRGSTiGwRkZ900+ZCEVkvIutE5Nnomhk6xQUprC6txe2NzPvLiMvoORcdYMhUaKuDut0h9e0IDIy2DtKB0aQMI9OlvjI6ywZqNIOdXgVdRMzAQ8DpwDhgkYiM69RmFHALcIxSajxwU/RNDY3iwhTavH7W7q2LqJ/2lYt6JG2Esa/eFlLfjvGBgdFBGnZJTDOK99dXRl4dU6PRBOehTwe2KKW2KaXcwPPA2Z3afA94SClVA6CU6kUBDz9TClKA6AyMdlvPpZ3UQL30EAXd7HJhGzZs0KYuOlxWLHYz9VXaQ9dookEwgj4E6BhLKA0c68hoYLSIfCoin4vIvK46EpErRKREREoO90ohmQkO8lPjKdkRuaBXtVTh9fcwRd2VDZY4qN4ecv+DecaoiJCY5qChSnvoGk00iNagqAUYBRwPLAL+JiLJnRsppR5RShUrpYozMjKidOvuKS4wJhhFsm5gRlwGCkVlSw9LpplMkDosZA8dIG7CeLxlZXj78VJYh5PENIcOuWg0USIYQd8DDO3wPi9wrCOlwKtKKY9SajuwGUPg+5QpBSlUNraxuzr8r/RB5aKDEXYJQ9Ad48cDg3fGaEJ6HPVVLf12sV6NJpYIRtCXA6NEZJiI2ICLgFc7tXkZwztHRNIxQjChq1uUKS404uiR1HVpXyy6x1x0CHjo28EfWlaNY+xYEBm0YZfENAeeVh9tzbrqokYTKb0KulLKC1wHvA1sAF5QSq0TkTtEZEGg2dtAlYisBz4AfqiUqjpcRgfL6MwEEuyWiCYYZcVnAUF66L42aNgbUv8mpxPbiOGDONPFKHesUxc1msixBNNIKbUYWNzp2K0dXivg+4Gt32AyCZMLUiLKdEmxp2AWc++pix0zXZLyQrpH3PgJNH0W+kzTgUBC+tepi5kFiX1sjUYT2wzImaIdKS5IYVN5A3UtoVVDbMdsMpMWlxaaoIeIY8IEvBUVeMr7PNvziHMgF12nLmo0ETMoBF0p+ON7X1FaE94U88y4IHLRE4eA2RamoBsDo63rBl/YxR5vxR5v0amLGk0UGPCCPqUgheNGZ/DYJ9uZc/cHXPiXJTyzdCetnuDrrgQ1W9RkhpTC8AR9zBgwmQbtwGiCTl3UaKLCgBd0h9XME9+Zzsc/OoEfnDqa6mY3P/vPWm5/LXjxTHWkUt0aRKZM6vCwJheZ4uKw5ubi3rEj5GsHAonpcTTokItGEzEDXtDbGZoaz3UnjuKd/zeXS2cX8s/lu/mqPLh1R1MdqdS21Xa/tuiBhoFc9DByqm0FBbh37gz5uoFAQpqD+qpWnYuu0UTIoBH0dkSEG04ahdNm4e63NgV1TaojFb/yU9fWS6Gv1OHG6kWNPaxw1A3tgj4YRS0xLQ6fx09zfWQrTGk0g51BJ+gAqU4bVx0/gnc3lLNse++hlBSHMUGpprWX9MfUYcY+jDi6rbAAf2MjvprI10KNNRIDqYt6YFSjiYxBKegA3zlmGNmJDn775oZeveJUh7GkXa9x9AhSF20FBQC4dwy+sEuCTl3UaKLCoBX0OJuZ758ympW7anlrbVmPbYMW9KR8MFkiE/RBGEf/erao9tA1mkgYtIIOsHBqHqOzXNzz9iY8vu4HPIMOuZgtkJwflqBbhwwBsxn3zh0hXxvrWO1m4hKsNOjp/xpNRAxqQTebhB/PG8P2yiZeKOl++bgUuyHo1W3Bpi6GLuhitWLNGzIoPXSAhLQ46nUMXaOJiEEt6AAnjslkdJarx7CL1WwlwZZAdUsIueg6dTEkEtMdWtA1mggZ9IIuIkwtSGH17toeB0dTHanUtAWRgZI6HNrqoTn0YpO2/AI8OwZv6mJjdSt+/+D77BpNtBj0gg5QNDSZ+lYv2yubum2T6kjtPYYOEWe6+Jub8VX2sDrSACUhzYHfp2iqbetrUzSamEULOlA01IiRr9pd222bFHtK8NP/IexcdBikmS4HctH1wKhGEy5a0IGRmS6cNnPPgu4IUtCT80FMOnUxRHTqokYTOVrQMbJdJuYl9yjoQddzsdiNBS7CSV3MzQWLZXBOLkp1gOiVizSaSNCCHqAoP5kN++q7LasbdD0XCD910WLBlpc3KD10s9WEM8mup/9rNBGgBT1A0dBkPD7Fur31XZ4PenIRhC3ooFMXdeqiRhM+WtADTB6aDHQ/MBr09H8wBL2lBpqDaNsJW2EB7l27Bm3qog65aDThowU9QGaig9wkR3QEPSVQdbFmR8h2WAsKUC0tePcPvvVFE9IcNNa24fP2Mk6h0Wi6RAt6B4ryk1m1u+uQSkghl+Shxr6u+3IC3TGYqy4mpjtAQWONDrtoNOGgBb0DRUOT2V3dQlXjoZNbQqrnkhQQ9NpwBL0QAPeuQSjoOnVRo4kILegd6GmCUUj1XOJSwOYKy0O35mQjViueQTgw6koNTC6q1oKu0YSDFvQOHD0kCbNJeoyjB1XPRcTw0sPw0MVsxpqfPygzXVzJdgA9/V+jCRMt6B2Is5k5KiuhW0FPsacEF0MHI45etyssO2z5+YMyhm62mohLsNJYowVdowkHLeidMAZGa7us+pfqSA0uywXC9tAhkIu+axfKP/iyPVwpDi3oGk2YBCXoIjJPRDaJyBYR+UkP7RaKiBKR4uiZeGQpykumodXLti4qLwZdzwUMD721FtoaQrbBVliAamvDW14e8rWxjjPZTlOtjqFrNOHQq6CLiBl4CDgdGAcsEpFxXbRLAG4ElkbbyCNJUX4y0PXAaKojlbq2ut7ruUCEmS6Dt0iXK8WuPXSNJkyC8dCnA1uUUtuUUm7geeDsLtr9CrgbiGn3akSGC5fd0mU+eqojFZ/yUd/WdXmAg0jON/Y6Fz0kXCl22pq9eNq6rqmj0Wi6JxhBHwJ0VKXSwLEDiMgUYKhS6o2eOhKRK0SkRERKKioqQjb2SGA2CUVDk/liZ+0h59onFwUVdjngoYc+MGrJzkbs9kHqoRupi3pykUYTOhEPioqICbgPuLm3tkqpR5RSxUqp4oyMjEhvfdgoLkxhU1k99a2eg46HJOiuLDDbwvLQxWTCNmI4bZs2hnxtrNOeutioUxc1mpAJRtD3AEM7vM8LHGsnAZgAfCgiO4CZwKuxPDA6rTAVv4IVOw8Ou6Q50gCCy0U3mSBxSNiZLnGTJtGyeg3KN7hCD86UQC66jqNrNCETjKAvB0aJyDARsQEXAa+2n1RK1Sml0pVShUqpQuBzYIFSquSwWHwEKBqajNkklOw4WLgPeOjBzBaFQC56eIIeX1SEv6mJti1bw7o+VjngoWtB12hCpldBV0p5geuAt4ENwAtKqXUicoeILDjcBvYFTruF8bmJLN9xsHCHVM8FICk/fA+9qAiAllWrwro+VrHYzDhcVh1y0WjCIKgYulJqsVJqtFJqhFLqzsCxW5VSr3bR9vhY9s7bKS5IZdXuWtwdSrm213MJabZoYxl4Qxcna34+5pQUWlavDvnaWMdIXdSDohpNqOiZot0wrTCFNq+ftXsPXnIu5NmiAHWlId9fRIw4+iDz0MEIu+iQi0YTOlrQu6G40FjQoqSLsEtIHjqEHUePKyrCvW0bvtrasK6PVZwpDj0oqtGEgRb0bshIsDMs3cmy7YcOjIbsoYcdR58EQMuXX4Z1faziSrbT2uTB6x5cGT4aTaRoQe+B4oIUvthZfVChrpBCLolDAAnfQz/6aDCZaFm5KqzrYxVXqs5F12jCQQt6D0wrTKWm2cO2ysYDx0Kq52KxQUJO2B66yenEPnr0oIujH6iLrsMuGk1IaEHvgeJCI01xeYd89BRHSvD1XCCiXHQITDBas2ZQldLV0/81mvDQgt4Dw9KdpLtsB+WjpzqMwdLQ6qKHt9AFGAOj/sZG3FsHzwQjp57+r9GEhRb0HhARigtSD5oxGlI9FzA89Po94A9vgK99YLR5EIVdrHYz9niLTl3UaEJEC3ovFBemsKu6mfJ64+t/u4ceVD0XMDx0vxcaysK6v62wEHNS0uCLo+uVizSakNGC3gvTAvno7WGXAyGXoOu5hF8XHYxvCY6iSYNuxqgrxa4Xi9ZoQkQLei+My00kzmo+EHYJvZ5LZLnoYBTqcm/Ziq8+yIHYAYBTT//XaEJGC3ovWM0mJucn88mWSpRSRj0Xa4j1XADqIhsYBWhZvSbsPmINV7KdlgYPPs/gye7RaCJFC3oQLJiUy5b9jSzdHgi7xIUwucjmhLjUiDx0x9FHg8igCru4UnSmi0YTKlrQg+CcyUNIibfy90+2AyHWc4GIc9HNLhf2UaNoWbky7D5ijfZc9KZaHXbRaIJFC3oQOKxmvjkjn3c2lLOrqjm0ei4QyEUPX9AB4ouLaV65EuXx9N54AHDAQ9eZLhpN0GhBD5KLZxZiFuHxz3aEVs8FjEyXut2gVO9tuyF++nRUczMta9eG3Ucs4dQrF2k0IaMFPUiykxycOTGHF0p2k2RLpaa1Bo8vSG85aSh4mqE5hIdAJ+KnTwOgednysPuIJWwOC7Y4i46hazQhoAU9BC47ZhiNbV5277ejUJQ3lwd3YRQyXSypqdhHjaJ56dKw+4g1XCl2Gqt1DF2jCRYt6CFQNDSZqQUpLNlshE72Ne0L7sLkAmNfsyOi+8fPmGHE0d3uiPqJFfTkIo0mNLSgh8h3jhlGWbWRgRG0oKcON/ZVWyK6d/yM6aiWlkETR9dL0Wk0oaEFPUROG59FdlwWAHsb9wZ3kd0FCblQFVnFxPjiYhChedmyiPqJFZwpDpob3Pi8enKRRhMMWtBDxGI2cfXxY/F7XXy87avgL0wbEbGHbklJwX7UUTQNkji6K8UOCprqtJeu0QSDFvQw+PaMAlzmDFbt28HaPXXBXZQ2MmJBByPbpWXlKvyDII6uVy7SaEJDC3oYmEzCtLzhmG21XPvsChpag0hfTB8FLTXQVBXRvZ0zZqBaW2ldM/Druny9cpEWdI0mGLSgh0lB0hCs9jpKa5q55d9fonqbNJQ20thHOjAaiKM3DYI4evti0fVVLX1siUYTG2hBD5McZw5ufxtXn5jN62v28eyyXnLMoyTo5qQk7GPH0Lx04Au6zWHBlWKnZl9zX5ui0cQEQQm6iMwTkU0iskVEftLF+e+LyHoRWSMi74lIQfRN7V/kOHMAmDfJwdzRGdz+2nq+LO0hnp6cDyZLVOLozmnTaVm1Cn/bwA9FpOY4qd7X1NdmaDQxQa+CLiJm4CHgdGAcsEhExnVqthIoVkpNBF4E7om2of2NHJch6GXN+7j/G0VkuOxc+VQJlY3diKzZCinDoCqEzJhuiJ8xA9XWNijK6abkOKnZ14Tyh18HR6MZLATjoU8Htiiltiml3MDzwNkdGyilPlBKtX8v/hzIi66Z/Y92D31f0z5SnTb+evFUqprcXPvMCjy+bvKm00ZGnIsOEF88FUymQVHXJTXXidfjp75KlwDQaHojGEEfAnSs/VoaONYdlwNvdnVCRK4QkRIRKamoqAjeyn5Isj2ZOEvcgdmiE4YkcdfCo1m6vZrfLN7Q9UVpIwxB90c2UcacmIhj7FiaPvmk98HYGCc1xwmgwy4aTRBEdVBURL4NFAO/6+q8UuoRpVSxUqo4IyMjmrc+4ogI2c5s9jV+Pf3/3Ml5fOeYYfzj0x38e0XpoReljQRfG9R3cS5EEuefRcuqVTS8/XbEffVnUtoFfW9jH1ui0fR/ghH0PcDQDu/zAscOQkROBn4GLFBKDfzROiDXmXtIPZdbzhjDzOGp3PLvL1m5q9OqRumjjH1l5HH01G9/G8fRR1N2x6/w1oSwelKMYY/TmS4aTbAEI+jLgVEiMkxEbMBFwKsdG4jIZOCvGGK+P/pm9k+yndmHCLrVbOKhb04hK9HBd58oYVdVByE6kLoYeRxdLBZy7vw1voYGyn99Z8T99Wd0potGExy9CrpSygtcB7wNbABeUEqtE5E7RGRBoNnvABfwLxFZJSKvdtPdgCLXlUt1azWt3oMH7NJcdv5x2TS8fsWljy+jtjkwTd+VBTZXVFIXARyjR5N+9VXUv/EGDe+9F5U++yM600WjCY6gYuhKqcVKqdFKqRFKqTsDx25VSr0aeH2yUipLKVUU2Bb03OPAoGOmS2dGZLh45OKplFa3cMVTX9Dm9YFIVIp0dST9e9/DPmYMZbfdjq8uyLoyMYbOdNFogkPPFI2AngQdYMbwNH53wUSWba/mRy+uwe9XkDYqJEFv8/pYvbuWp5bs4J315YdktYjVSs6dv8ZbXU35XXeH/2H6MTrTRaMJDktfGxDLtE8u6pjp0pmzi4ZQWtPC797exP76Nv6SV0BS7UvgaQWro8tryutbeXLJDj7ZUsWGvfW4O+S1TxqazC2nj2Hm8LQDx+LGjyft8supeuQRkhbMxzlrVpQ+Yf+gY6bLsInpfWyNRtN/0YIeAZnxmZjE1OvKRdccP4JUp40739jAr0vd/M6k8Fdtw5R98ITbbRWNPPLRNv69Yg9ev5/iwlQuO6aQSUOTOXpIEku2VfGHdzZz0SOfc+KYTH56xhhGZiYAkH7N1dS//Rb7bruN4a+8gsnR9cMiFtGZLhpNcGhBjwCryUpGXEavgi4iLJqez9zRGTzy3H4oh3uff4PWkdDU5qXJ7aOqsY0l26qwmk1cOC2PK44dQX5a/EH9DE2NZ8GkXP7x6Q7+/OEWzn3oM/5z7TGMzHRhcjjIue02dl32HSr/+lcyb7zxcH70I47OdNFoekfH0CMk13VoLnp3DEmO47bLjPFie912nlu2i/c27mftnjrqWz1cfdwIPv3xifz6nKMPEfN2HFYzVx8/gjdvPBa71cR3n1h+IIvGOWsWSWcvoOrRx2jbEr2B1/6AznTRaHpHe+gRku3M5suKL4NuL44kcGVxw0jhhnPmhX3fvJR4/nrxVBY9spRrnlnBE9+ZjtVsIvPHP6bxw/+x79ZfUvD0U4hpYDyzO2a6JGXE9bU5Gk2/ZGD8tfchuc5cyprL8KsQ6rNEaTm6qQWp/Pa8o/lsaxW3v7YOAEtqKpk/+hEtK1ZQ++KLEd+jv6AzXTSa3tGCHiE5zhy8fi+VLZXBXxTFXPSFU/O48rjhPP35Lp5csgOApPPOJX76dPb//l58tbVRuU9fo2u6aDS9owU9QtpTF/c27g3+orRR0FxprDEaBX502hhOHpvJHa+tZ8WuGkSErJ/9DH99PdVPPR2Ve/Q1OtNFo+kdLegR0j65qKypLPiLoljTBcBsEu69sIjsJAc3PLeSuhYPjqNGk3DKyVQ/+SS+hoao3Kev6Q+ZLj6vn89f3sq7j6/nvSc38MFTG/jw2U1sWlqGzxNZWWSNJlK0oEdIb7NFu6Rd0Cs2Rc2OpDgrf1w0mbK6Vn4aWLQ67aqr8Dc0UPPMM1G7T1/S15kuSik+fGYjX7y1k72bayndUM3OtVVsKSnn3X+s54mffcay17bRVDcoio1q+iE6yyVCXDYXCbaEEEMuIyA+DbZ9CJO/FTVbpuSn8IPTjuKuNzdyzLJ0vjljPK7jjqP68SdIvfhiTE5n1O7VF/R1pssXb+5k45Iypp01jOlnDTtwXPkVuzdWs+aDUpa/sYMv3trJ1HkFTJ8//IjbqBncaA89CuQ4c0ILuZjMMOpU2PIO+H0h38/j81DdWo3H5znk3BXHDufYUenc/to6NpU1kH7N1fhqa6l5/vmQ79Pf6MtMl83Ly1j66jZGz8hi2pmFB50Tk5A/Lo2zrp3Et26fyYgpmSx/Ywcr39l1xO3UDG60oEeBXGcue5tC8NDBEPSWGijtfV1QpRS/Wfobjv/n8RQ/XcyUp6dw3D+PY/7L8w+pI2MyCfddWESCw8p1z67Ac9Q4nLNnU/X3f+BvaQnNxn5GX2W67NtSy3tPbCB3VDInfnssItJt2+SseE6+bBwjpmTy2Utb2LwshAe9RhMhWtCjQFcLXfTKiBPBZIHNb/Xa9OkNT/PcxueYmDGRRWMWcV3Rdfyg+AfUt9VzxTtXUNVSdVD7jAQ7f7yoiO2VTXzviRISr7gSX1UVtf/6V2g29jPscRZSsuPZvaH6iN2zobqVxQ9/SWJaHKdfdTRma+9/MiaTcPJlYxkyOpn3ntjA7vVHzl7N4EYLehTIS8ijwd3A1toQslbikiF/Fmz+b4/NVu5fyX0l93Hi0BN54IQHuLn4Zq6cdCWXjL+Eh05+iLKmMq5+92oa3Adnsswemc69F05i2Y5qfrjZRNy0aVQ9+hj+ttgesBsxJZO9m2tprncf9nspv+K9J9bj8/o585qJOJzWoK+1WM2cfvVEUrKdvPnXL9m/s/4wWqrRGGhBjwJnDT+LRFsidy6985B65T0y+jTYvw5qu461VrVU8YMPf0COK4dfzfnVIV/1J2dO5g8n/IGvar/iuveuo8V7cEjl7KIh3DZ/PO+sL+elCfPw7t9P9RNPhvz5+hMjpmSiFGxbVXHY77Xqvd3s2VTLnAtHkZzVdW2dnrDHWZh//SQcTiuv/2k1NWV6lqvm8KIFPQqkxaVx09SbWF62nNe3vR78haMDtVw2v33IKZ/fx48//jF17jr+cPwfSLQldtnFnCFz+O2c37Jy/0pu/vBmPP6DB0ovmV3IDSeN4sGaJPZOmE7lXx7GU14evI39jLQhTpKz4tm64vAuXVtZ2sjnr2xl2KR0xs7OCbsfZ7KdBTcWgQiv3L+K+srYHsfQ9G+0oEeJhaMWMjFjIr8v+T11bUEuBZc2ElKGwVeHhl0eWvUQS/ct5WczfsZRqUf12M28YfP4xaxf8PGej7ljyR2HfEv4fyeP4uKZBfws5yQ8bV5233VP0J+rvyEijJiSwZ5NNbQ0HJ6wi9fj491/rMMeb+WEb4/pcRA0GJKz4jn7xiK8bh+v3L+SptrYDntp+i9a0KOESUz8YuYvqG2r5YEVDxx0rsXbwpK9Sw4JiSBieOnbPwL311Pan1r/FH/78m8sHLWQc0edG9T9Lxh9AVdNuoqXt7zMw6sf7nQb4fYF4/nOBcfw71HH0fbmYj588R2o2AzrXoaPfgf/vhL+Pg9evgZWPgM1OyCE8JHy+Wj85FPqXnkFz94QM35CZOTUwxt2WfrKNqr2NHHixWOIS7BFpc+0IS7mX19ES4OHV+5fedgeRprBjZ5YFEXGpI7hm2O+yTMbnuGckeeQl5DH8xuf57mNz1HbVktmfCY3TL6B+SPmY5LAs3T0qbD0YUPUj5rHC5te4J7l93BKwSn8fObPQ7r/NZOuoaypjIdXP0xWfBYLRy88cM5kEq6YO4JN2TfTfNGnZN57I2rNHtrNIHEIJOfDpsWwKjCzNDEPjpoHEy+CvGLjAdQBpRRtGzZQ9+pr1L3xOr6KrwuUWQvycc6YievEE3Add1zEXm5H0oa4SMqIY+uK/Yw/dkjU+gXYvaGaVe/uZsLcIRQeHd3l7rKGJXLmtRN57cHVvPrHVZx90+SQBlo1mt6QkAbxokhxcbEqKSnpk3sfTpo8TSx4eQEoqHfX0+pr5fi84zm18FSe3fAsa6vWMiZ1DD8o/gHTs6cjPjfcMxyOvoD/jDmOWz+7lePzjue+4+/Dag79j93j93D9+9fz+d7P+eOJf2Ru3lzjRGMFfPx7WPUcdZvb2LsklWVTxvFC4YlkF45nwfRRnDY+G4dZoGIj7PwUtv8PvnoHvK2QOgImfgMmfQNSCvHs2cPen9xC8/LlYLXiOm4uSfMXYCvIp3npUpo+X0rzsmX4m5pwHjeXnF/+EmtubtR+zkte3srK/+7isnuOIc4VHS+6ud7NP3+9DHu8hQtumYbVbo5Kv53Zua6KxQ+vIS3XxYIbi7Soa0JCRL5QShV3eU4LevR5f9f7/OTjnzCvcB6Xjr+U4cnGFHC/8vPm9jd5YMUD7GvaR6ojlTGpYxhbvgVHQxl/jjczM2cmD570IHazPez7N3uaufStS9let51fzvolZ7W0wRs/gLYGGH8Oaup32PmzP9OydSsf/PgBntnUyJ7aFhIcFmYOT2NKfgqT85OZmJdEvL8J1r8Cq/8JOz8BoK65iLJ360AsZNx4A4nz52NJSTnEDuXxUPPcc+y/3whBZd50Iynf+hZijlwoK3Y18MJvlnPCxWMYd0zkDwrlV7z+p9Xs+aqWC35STNoQV8R99sSOLyt5869fkj7EEHV7vBZ1TXBoQe8DlFLdhhlava28tu011lSsYWP1RrZUb8aLn+KUsfz5jCeIs0Rep6SqpYrvv389Kyq/5Bv1DfzIMQzb2Q9D5hjDhg0b2PGNi7BkZJD74IOssmXwn5V7KNlZw/ZKI73ObBJGZboYm5PIuJxEJlv3k/nwr2hato24NDe5x7Zim34mTDgfRpwA3Xyj8OzZw77bb6fpo49xTJxI9i9vJW78+Ig+n1KKp2/9nOSMOObfUBRRXwAr/ruTJf/eynHfPIoJc6MbxumOHWsCoj40wRD1OB0B1fSOFvR+jrt2N6UPFZE/egGWhY8atV4iQSlY+xKexT/gj/EmHk90MiFtPPcefx+5rq+92ZY1ayi9/gZ8dXXk/uZOEs84A4DqJjerdtewclct6/bWs3l3FZPWfsw3Nr9Haks9bxXNw3ryROb5P2RE5XtY3PUQlwLjzoaxC2DoDLC7OpmkqH/9DcrvugtfdTUpiy4i48YbMSclhf0xl/xnC6ve2c1lv5sTUdiibHsd//ndCoYVpXPa9yZENd7fG9tXV/DWI2tJz3Nx6nfHk5QRer67ZnChBT0W+N898MGdMP48OO+Rbr3dXmncD6//P9j4OgwphnP+zHvNpfz8058jIlw89mIuPOpC0uLSAPBWVFB6w420rFxJ2ve+S/IFF2ByuTC5DEGue+klKv/6CN6yMjxjJ/DlWZfwkS2b1bvrKKtvxYaHE61r+ZazhBnuz7H5W1BiRnKLoGA25E2H1OGQOgxsTnz19VT88UFqnn0Wc1ISmTd/n8QFCzDZQo+D799Zz79+WxJR2KWl0c2/fmv8O/zGz6b1Sehj++oK3v3Hevw+xYyzhzPxxKGYTEfuoaKJLbSgxwqf/hHe+YWRynjBE2B1BH9twCtn8Q/B3QQn/BRmX3/A299Zv5N7lt/DR6UfYTPZmD9iPt8e+21GpoxEud2U/fpOal944eA+TSbw+4krKiL9+utwzp59kPdaVtfKyl01lOw0tq179jOFDUw3bWSOdTPj1RasfD3RSTkzkZQCcGbQWmuj7LWttGyrwuR0kDh3KknzTiRuyjRUfApemxMvCr/yY7fYsZoOFVqlFM/etpSWBjfHffMoRhVnddlGtbTga2zE39SEv6kZ1daK36/YtMHNyi/a8HgUZ16YQfbIFEzx8ZicTkz28McwwqGxpo3/PbuRHV9WkTUskRP/b+yB6pIaTUciFnQRmQc8AJiBR5VSd3U6bweeBKYCVcA3lFI7eupTC3o3LH8M3rgZhh1riHp8avdtvW7YtQS2vGts+9fDkKlwzsOQ0fVkpG1123h6/dO8uvVV2nxtZMRlGAOzaWOZuMdCQmULlhYP5lY3ppY2fEVjaS4aSZO3mebA1uptpcXbQou3BY/Pgwr85/H5qW50U9HoprLBQ1V9C5a2ahKliQRpIkGacZlbEZMbr3hw4yVnlzBmg4lxWwSbF8qT4atcYU+asDcN9qYKTQ4wmwWbxYLDaiND4hlCMjmSTKo7j/rNU2luTCQvsZrJtvVIdTneqkp8FZV4KytR7oNzvqtTjuKrkefT5MwlpWYTo7a8iKtTtUyJi8OSkoI5JQVzaiqW9HQsGRlfb5mZWDKN19ESf6UUm5eV8/ELm3E3e8kZmcywSekUTkwnOVOHYjQGEQm6iJiBzcApQCmwHFiklFrfoc01wESl1FUichFwrlLqGz31qwW9B1Y/Dy9fDcoPzgxjNmnqcLDGQWsttNQa+8qvwN0IJisUzDLi11MvA3Pvg2s1rTUs3r6YdZXr2FC9ge112/Gp0Gqzm8WM1WRFRBDkgPfuV36UMrxrhUIwASaUEpQygd+Oz2fD67Vg9luw+s0ktfiZtbWR4m11ZFe3kdzoJdigg19M7Myfx/bCedjctaRWvo3X3ITX5sFr9+G1J+K1FuA35eFX2eB3IZZm4tJ3EpfUhs1sw+YDu9+P1aOwud1YGxuwNtZjbqjDVFuL1FQh1dVd1q+XhARMqWmYAuJvSknBnJSEOTERc2ICpoQEzC4XZocDs9OJyeHAFOfAZLMjNititRl7sxlMJloaPHz5YSnbV1dStccoFZySHU/aEBfJWfEkZ8aRlBmPw2XFHmfBFmfBbDm8cwT9foXf58fvUx02Pz7vwXuvx48vsBmvfXjcfrxuH94Oe4/Hh9ftw+f24/P68fkUPo/Rv1LqwL6jPLV/OTSZBJNZkMDebDZhspgwWwSzxWRs1sDW/r7jOYsJk6XTtWb5em/udL79mFm+3kyCtO+P4JiL8XOITNBnAbcppU4LvL8FQCn12w5t3g60WSIiFqAMyFA9dK4FvRdKS4zJRjXboTqw+drAkQyOJKNaY3IBjDzZ8ObtCRHdrtXbyra6bTR5mvD4PHj8Htx+NzaTjXhrPPHWeOIsccRbvt6HkyffEbfXT2VjG/WtHupbvNS3eKhv9dDq8eNpasK0txTL3lJMLc0orwfxeMDtQZkUWHyYTW68pgaabQ00xNXToFy4Ss/E5k7r8n4N9ir2O3exN3ErG7OW4DN5g7LTpJTxcFGKhGZIaTS2pEZFShMkN0JSMyQ0Q1KzIrEZnK1gCXOJUa8J/ALKBM2ONKpTj6Y2eSytcVm02VNBDh00F58bk/IgyhfY/IZDAAgK6OpPUVBIQClNKBEUZhATSkwoMR/Yfz0DLUKUD7PPjcnvxuT3YPJ7EL8Hk/Iifi8m5QPUAfslYLdhZ8DmdvsI2Giy4BcLymRGiQW/yYIS64G9ijTJoNfP5O/CZj+iAj93pTr8DhSiFHFpq7n4d3eEdbueBD2YPKkhwO4O70uBGd21UUp5RaQOSAMqOzYSkSuAKwDy8/ODMn7QkldsbEcIh8XBuLRxR+x+ADaLidzkOHLpLk1zbMh9+nx+Gqtbcbf4aGvx0tbkxuOtxZ7aiBsPjS3ZNLXaaHHn0+ppprmtiVZPM16fF4/Pjcfnwev34vf78fu9+JXf+OailPG36fKDU0FmQCAVNCg/By25oQClMHsU1jaFpc2P1e3H7FGYPAqLR2H2KsSnMPkUJh+IXwU2EGW8R4GoVlDLcPiX4WgF1WLGZ0rFZ0rDL/EoceAXB0riUFhAzChMhuiLgApI4iFepGF/Z6EBH/iNveA33is/gg+FsUf5QPygfMZ7vKC8gTZeBC8oD6K8gAeTciPKg8ITaE+He3eDGFt7C+ngG0qH55NgmPh1V+rrNgeOCKIMsQeL8YDCbOyVOfCA7HzeFHhvwpBJ4+H29b7jZkYFHoqGRSYOPCyRDg9DOfCpbamHZ4zmiCa+KqUeAR4Bw0M/kvfWDA7MZlMXqX+HDpZqNAORYL5H7QGGdnifFzjWZZtAyCUJY3BUo9FoNEeIYAR9OTBKRIaJiA24CHi1U5tXgUsCr88H3u8pfq7RaDSa6NNryCUQE78OeBsjbfHvSql1InIHUKKUehV4DHhKRLYA1Riir9FoNJojSFAxdKXUYmBxp2O3dnjdClwQXdM0Go1GEwp6gQuNRqMZIGhB12g0mgGCFnSNRqMZIGhB12g0mgFCn1VbFJEKYGeYl6fTaRZqPyQWbITYsFPbGB20jdGhr20sUEpldHWizwQ9EkSkpLtaBv2FWLARYsNObWN00DZGh/5sow65aDQazQBBC7pGo9EMEGJV0B/pawOCIBZshNiwU9sYHbSN0aHf2hiTMXSNRqPRHEqseugajUaj6YQWdI1GoxkgxJygi8g8EdkkIltE5Cd9bQ+AiPxdRPaLyNoOx1JF5B0R+SqwT+ljG4eKyAcisl5E1onIjf3NThFxiMgyEVkdsPH2wPFhIrI08Dv/Z6CMc58iImYRWSkir/dHG0Vkh4h8KSKrRKQkcKzf/K472JksIi+KyEYR2SAis/qTnSJyVOBn2L7Vi8hN/cnGjsSUoAcWrH4IOB0YBywSkSO7blrXPA7M63TsJ8B7SqlRwHuB932JF7hZKTUOmAlcG/jZ9Sc724ATlVKTgCJgnojMBO4G/qCUGgnUAJf3nYkHuBHY0OF9f7TxBKVUUYec6f70u27nAeAtpdQYYBLGz7Tf2KmU2hT4GRYBU4Fm4D/9ycaDMFbWjo0NmAW83eH9LcAtfW1XwJZCYG2H95uAnMDrHGBTX9vYyd5XgFP6q51APLACY/3aSsDS1b+BPrItD+OP+ETgdYzFIvubjTuA9E7H+tXvGmNls+0EkjP6q50d7DoV+LQ/2xhTHjpdL1g9pI9s6Y0spdS+wOsy+tHCliJSCEwGltLP7AyEMlYB+4F3gK1ArVLKG2jSH37n9wM/AvyB92n0PxsV8F8R+SKwODv0s981MAyoAP4RCF89KiJO+p+d7VwEPBd43S9tjDVBj0mU8RjvF/mhIuICXgJuUkrVdzzXH+xUSvmU8fU2D5gOjOlLezojImcB+5VSX/S1Lb0wRyk1BSM8ea2IzO14sj/8rjEW2JkCPKyUmgw00Sl00U/sJDAmsgD4V+dz/cVGiD1BD2bB6v5CuYjkAAT2+/vYHkTEiiHmzyil/h043O/sBFBK1QIfYIQvkgOLj0Pf/86PARaIyA7geYywywP0LxtRSu0J7PdjxHyn0/9+16VAqVJqaeD9ixgC39/sBOPBuEIpVR543x9tjDlBD2bB6v5Cx4WzL8GIWfcZIiIYa79uUErd1+FUv7FTRDJEJDnwOg4jxr8BQ9jPDzTrUxuVUrcopfKUUoUY//7eV0p9i35ko4g4RSSh/TVG7Hct/eh3DaCUKgN2i8hRgUMnAevpZ3YGWMTX4RbonzbG1qBoYADiDGAzRmz1Z31tT8Cm54B9gAfD67gcI676HvAV8C6Q2sc2zsH4WrgGWBXYzuhPdgITgZUBG9cCtwaODweWAVswvvLa+/p3HrDreOD1/mZjwJbVgW1d+99Jf/pdd7C1CCgJ/M5fBlL6m52AE6gCkjoc61c2tm966r9Go9EMEGIt5KLRaDSabtCCrtFoNAMELegajUYzQNCCrtFoNAMELegajUYzQNCCrtFoNAMELegajUYzQPj/mqFe1if2Zy0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N=6\n",
    "\n",
    "plt.title(\"Paritat, FULL\")\n",
    "for n in range(1+1, N+1):\n",
    "    plt.plot(lossp[n-1], label=str(n))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"Paritat, NOFULL\")\n",
    "for n in range(1+1, N+1):\n",
    "    plt.plot(losspF[n-1], label=str(n))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"Excitat, FULL\")\n",
    "for n in range(1+1, N+1):\n",
    "    plt.plot(_loss[n-1], label=str(n))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"Excitat, NOFULL\")\n",
    "for n in range(1+1, N+1):\n",
    "    plt.plot(lossF[n-1], label=str(n))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.title(\"Paritat, FULL, noCNOT\")\n",
    "for n in range(1+1, N+1):\n",
    "    plt.plot(lossp_[n-1], label=str(n))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"Paritat, NOFULL, noCNOT\")\n",
    "for n in range(1+1, N+1):\n",
    "    plt.plot(losspF_[n-1], label=str(n))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"Excitat, FULL, noCNOT\")\n",
    "for n in range(1+1, N+1):\n",
    "    plt.plot(loss_[n-1], label=str(n))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"Excitat, NOFULL, noCNOT\")\n",
    "for n in range(1+1, N+1):\n",
    "    plt.plot(lossF_[n-1], label=str(n))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc95a58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "id": "42da35bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "styles = ['.', '^', 's', 'p', 'o']\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, sharex=True, sharey=True, figsize=(7,6))\n",
    "\n",
    "axs[1,0].set_ylim(0, 1.25)\n",
    "axs[1,1].set_ylim(0, 1.25)\n",
    "axs[0,0].set_ylim(0, 1.25)\n",
    "axs[0,1].set_ylim(0, 1.25)\n",
    "\n",
    "#plt.title(\"Paritat, FULL, noCNOT\")\n",
    "for n in range(1+1, N+1):\n",
    "    axs[1,0].plot(lossp_[n-1][::2], '-'+ styles[n-2], label=\"\", markersize=4)#str(n))\n",
    "\n",
    "#plt.title(\"Paritat, NOFULL, noCNOT\")\n",
    "\n",
    "axs[0,0].set_title(\"Parity\")\n",
    "axs[0,0].set_ylabel(\"Restricted 2-gate\")\n",
    "\n",
    "axs[1,0].set_ylabel(\"Full 2-gate\")\n",
    "\n",
    "for n in range(1+1, N+1):\n",
    "    axs[0,0].plot(losspF_[n-1][::2], '--'+ styles[n-2], label=\"\", markersize=4)#)str(n))\n",
    "\n",
    "#plt.title(\"Excitat, FULL, noCNOT\")\n",
    "for n in range(1+1, N+1):\n",
    "    axs[1,1].plot(loss_[n-1][::2], '-'+ styles[n-2], label=str(n), markersize=4)\n",
    "\n",
    "#plt.title(\"Excitat, NOFULL, noCNOT\")\n",
    "axs[0,1].set_title(\"Excitation\")\n",
    "for n in range(1+1, N+1):\n",
    "    axs[0,1].plot(lossF_[n-1][::2], '--'+ styles[n-2], label=\"\", markersize=4)#str(n))\n",
    "axs[1,1].legend()\n",
    "\n",
    "#plt.tight_layout()\n",
    "for ax in fig.get_axes():\n",
    "    ax.label_outer()\n",
    "    \n",
    "plt.tight_layout()\n",
    "\n",
    "for _ in axs:\n",
    "    for ax in _:\n",
    "        ax.label_outer()\n",
    "    \n",
    "plt.savefig('nqubits.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "dbc157ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x15996e490>"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"print(model(train_excitations))\n",
    "print(train_labels)\n",
    "\n",
    "print(loss_fn(train_labels, tf.squeeze(model(train_excitations))))\"\"\"\n",
    "\n",
    "plt.plot(loss_list, label=\"loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d01f2b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'parameters:0' shape=(6,) dtype=float32, numpy=\n",
      "array([ 0.95383805,  3.445206  ,  3.0512972 , -0.3224178 ,  2.4567301 ,\n",
      "       -0.28668672], dtype=float32)>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'parameters:0' shape=(6,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = model.trainable_weights\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8fb40dbb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer model_18 weight shape (6,) is not compatible with provided weight shape (3,).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-165-53ac3683819a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m   1849\u001b[0m         \u001b[0mref_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mref_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1851\u001b[0;31m           raise ValueError(\n\u001b[0m\u001b[1;32m   1852\u001b[0m               \u001b[0;34mf'Layer {self.name} weight shape {ref_shape} '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m               \u001b[0;34m'is not compatible with provided weight '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Layer model_18 weight shape (6,) is not compatible with provided weight shape (3,)."
     ]
    }
   ],
   "source": [
    "model.set_weights(np.array([[0.0,0,0]]))\n",
    "print(model.trainable_weights)\n",
    "\n",
    "\n",
    "pred = model(inputs)\n",
    "print(train_labels)\n",
    "print(pred)\n",
    "\n",
    "loss_value = tf.math.reduce_mean(loss_fn(train_labels, tf.squeeze(pred)))\n",
    "print(loss_value)\n",
    "\n",
    "SVGCircuit(quantum_model_circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "08421b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00\n",
      "\n",
      "01\n",
      "(0, 1): ───X───\n",
      "10\n",
      "(0, 0): ───X───\n",
      "11\n",
      "(0, 0): ───X───\n",
      "\n",
      "(0, 1): ───X───\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer \"add_circuit_54\" (type AddCircuit).\n\nprograms must be rank 1. Got rank 0. [Op:TfqAppendCircuit]\n\nCall arguments received:\n  • inputs=cirq.Circuit([\n    cirq.Moment(\n        cirq.CNOT(cirq.GridQubit(0, 0), cirq.GridQubit(-1, -1)),\n    ),\n    cirq.Moment(\n        cirq.CNOT(cirq.GridQubit(0, 1), cirq.GridQubit(-1, -1)),\n    ),\n])\n  • append=None\n  • prepend=tf.Tensor(shape=(), dtype=string)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-142-5f1a026e1b91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m print(el)\"\"\"\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAddCircuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquantum_model_circuit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow_quantum/python/layers/circuit_construction/elementary.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, append, prepend)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \" \".format(prepend))\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtfq_utility_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend_circuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow_quantum/core/ops/tfq_utility_ops.py\u001b[0m in \u001b[0;36mappend_circuit\u001b[0;34m(programs, programs_to_append)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mappended\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mprograms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \"\"\"\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mUTILITY_OP_MODULE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfq_append_circuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprograms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprograms_to_append\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36mtfq_append_circuit\u001b[0;34m(programs, programs_to_append, name)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer \"add_circuit_54\" (type AddCircuit).\n\nprograms must be rank 1. Got rank 0. [Op:TfqAppendCircuit]\n\nCall arguments received:\n  • inputs=cirq.Circuit([\n    cirq.Moment(\n        cirq.CNOT(cirq.GridQubit(0, 0), cirq.GridQubit(-1, -1)),\n    ),\n    cirq.Moment(\n        cirq.CNOT(cirq.GridQubit(0, 1), cirq.GridQubit(-1, -1)),\n    ),\n])\n  • append=None\n  • prepend=tf.Tensor(shape=(), dtype=string)"
     ]
    }
   ],
   "source": [
    "inputs, labels = generate_data_p(qubits)\n",
    "\n",
    "\"\"\"for el in inputs:\n",
    "    print(el)\"\"\"\n",
    "    \n",
    "    \n",
    "\"\"\"print()\n",
    "print(el)\"\"\"\n",
    "\n",
    "mod = tfq.layers.AddCircuit()(quantum_model_circuit, prepend=inputs[1])\n",
    "\n",
    "print(tfq.from_tensor(mod)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a44b00c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 1.],\n",
       "       [-1.],\n",
       "       [-1.]], dtype=float32)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(train_excitations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243c22a6",
   "metadata": {},
   "source": [
    "## Results\n",
    "After comparing and making sure we obtain the same as using qibo, everything being well controlled, we start analyzing more into detail the problems themselves rather than the implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd6cf76",
   "metadata": {},
   "source": [
    "Depth training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "id": "565e55b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'parameters:0' shape=(15,) dtype=float32, numpy=\n",
      "array([2.768021 , 2.8349156, 1.3637989, 1.8400033, 5.9047313, 1.706681 ,\n",
      "       1.4753548, 3.2054064, 3.3112376, 2.343164 , 4.4138837, 5.875032 ,\n",
      "       2.5824096, 0.6603046, 4.027665 ], dtype=float32)>]\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.3711\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 1.3255\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 1.2815\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 1.2400\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 1.2013\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 1.1657\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 1.1329\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 1.1026\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 1.0747\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 1.0491\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 1.0257\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 1.0043\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.9846\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.9664\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.9495\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.9337\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.9188\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.9049\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.8917\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.8794\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.8678\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.8569\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.8467\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.8370\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.8279\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.8193\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.8111\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.8033\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.7959\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.7889\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.7823\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.7763\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.7708\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.7659\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.7617\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.7581\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.7551\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.7526\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.7506\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.7488\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.7472\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.7458\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.7445\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.7433\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.7420\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.7407\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.7393\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.7378\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.7362\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.7346\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.7329\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.7311\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.7294\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.7278\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.7263\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.7248\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.7236\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.7224\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.7214\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.7204\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.7195\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.7186\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.7178\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.7169\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.7161\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.7152\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.7143\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.7135\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.7126\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.7117\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.7108\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.7098\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.7089\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.7079\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.7069\n",
      "\n",
      "Start of epoch 75\n",
      "Training loss at epoch 75: 0.7059\n",
      "\n",
      "Start of epoch 76\n",
      "Training loss at epoch 76: 0.7049\n",
      "\n",
      "Start of epoch 77\n",
      "Training loss at epoch 77: 0.7039\n",
      "\n",
      "Start of epoch 78\n",
      "Training loss at epoch 78: 0.7028\n",
      "\n",
      "Start of epoch 79\n",
      "Training loss at epoch 79: 0.7016\n",
      "\n",
      "Start of epoch 80\n",
      "Training loss at epoch 80: 0.7004\n",
      "\n",
      "Start of epoch 81\n",
      "Training loss at epoch 81: 0.6992\n",
      "\n",
      "Start of epoch 82\n",
      "Training loss at epoch 82: 0.6978\n",
      "\n",
      "Start of epoch 83\n",
      "Training loss at epoch 83: 0.6964\n",
      "\n",
      "Start of epoch 84\n",
      "Training loss at epoch 84: 0.6949\n",
      "\n",
      "Start of epoch 85\n",
      "Training loss at epoch 85: 0.6932\n",
      "\n",
      "Start of epoch 86\n",
      "Training loss at epoch 86: 0.6914\n",
      "\n",
      "Start of epoch 87\n",
      "Training loss at epoch 87: 0.6894\n",
      "\n",
      "Start of epoch 88\n",
      "Training loss at epoch 88: 0.6873\n",
      "\n",
      "Start of epoch 89\n",
      "Training loss at epoch 89: 0.6850\n",
      "\n",
      "Start of epoch 90\n",
      "Training loss at epoch 90: 0.6825\n",
      "\n",
      "Start of epoch 91\n",
      "Training loss at epoch 91: 0.6798\n",
      "\n",
      "Start of epoch 92\n",
      "Training loss at epoch 92: 0.6769\n",
      "\n",
      "Start of epoch 93\n",
      "Training loss at epoch 93: 0.6738\n",
      "\n",
      "Start of epoch 94\n",
      "Training loss at epoch 94: 0.6704\n",
      "\n",
      "Start of epoch 95\n",
      "Training loss at epoch 95: 0.6668\n",
      "\n",
      "Start of epoch 96\n",
      "Training loss at epoch 96: 0.6630\n",
      "\n",
      "Start of epoch 97\n",
      "Training loss at epoch 97: 0.6588\n",
      "\n",
      "Start of epoch 98\n",
      "Training loss at epoch 98: 0.6544\n",
      "\n",
      "Start of epoch 99\n",
      "Training loss at epoch 99: 0.6495\n",
      "\n",
      "Start of epoch 100\n",
      "Training loss at epoch 100: 0.6440\n",
      "\n",
      "Start of epoch 101\n",
      "Training loss at epoch 101: 0.6378\n",
      "\n",
      "Start of epoch 102\n",
      "Training loss at epoch 102: 0.6307\n",
      "\n",
      "Start of epoch 103\n",
      "Training loss at epoch 103: 0.6225\n",
      "\n",
      "Start of epoch 104\n",
      "Training loss at epoch 104: 0.6130\n",
      "\n",
      "Start of epoch 105\n",
      "Training loss at epoch 105: 0.6021\n",
      "\n",
      "Start of epoch 106\n",
      "Training loss at epoch 106: 0.5899\n",
      "\n",
      "Start of epoch 107\n",
      "Training loss at epoch 107: 0.5765\n",
      "\n",
      "Start of epoch 108\n",
      "Training loss at epoch 108: 0.5620\n",
      "\n",
      "Start of epoch 109\n",
      "Training loss at epoch 109: 0.5464\n",
      "\n",
      "Start of epoch 110\n",
      "Training loss at epoch 110: 0.5295\n",
      "\n",
      "Start of epoch 111\n",
      "Training loss at epoch 111: 0.5113\n",
      "\n",
      "Start of epoch 112\n",
      "Training loss at epoch 112: 0.4917\n",
      "\n",
      "Start of epoch 113\n",
      "Training loss at epoch 113: 0.4707\n",
      "\n",
      "Start of epoch 114\n",
      "Training loss at epoch 114: 0.4485\n",
      "\n",
      "Start of epoch 115\n",
      "Training loss at epoch 115: 0.4255\n",
      "\n",
      "Start of epoch 116\n",
      "Training loss at epoch 116: 0.4024\n",
      "\n",
      "Start of epoch 117\n",
      "Training loss at epoch 117: 0.3800\n",
      "\n",
      "Start of epoch 118\n",
      "Training loss at epoch 118: 0.3593\n",
      "\n",
      "Start of epoch 119\n",
      "Training loss at epoch 119: 0.3407\n",
      "\n",
      "Start of epoch 120\n",
      "Training loss at epoch 120: 0.3240\n",
      "\n",
      "Start of epoch 121\n",
      "Training loss at epoch 121: 0.3086\n",
      "\n",
      "Start of epoch 122\n",
      "Training loss at epoch 122: 0.2938\n",
      "\n",
      "Start of epoch 123\n",
      "Training loss at epoch 123: 0.2797\n",
      "\n",
      "Start of epoch 124\n",
      "Training loss at epoch 124: 0.2668\n",
      "\n",
      "Start of epoch 125\n",
      "Training loss at epoch 125: 0.2556\n",
      "\n",
      "Start of epoch 126\n",
      "Training loss at epoch 126: 0.2461\n",
      "\n",
      "Start of epoch 127\n",
      "Training loss at epoch 127: 0.2386\n",
      "\n",
      "Start of epoch 128\n",
      "Training loss at epoch 128: 0.2328\n",
      "\n",
      "Start of epoch 129\n",
      "Training loss at epoch 129: 0.2282\n",
      "\n",
      "Start of epoch 130\n",
      "Training loss at epoch 130: 0.2240\n",
      "\n",
      "Start of epoch 131\n",
      "Training loss at epoch 131: 0.2198\n",
      "\n",
      "Start of epoch 132\n",
      "Training loss at epoch 132: 0.2151\n",
      "\n",
      "Start of epoch 133\n",
      "Training loss at epoch 133: 0.2101\n",
      "\n",
      "Start of epoch 134\n",
      "Training loss at epoch 134: 0.2050\n",
      "\n",
      "Start of epoch 135\n",
      "Training loss at epoch 135: 0.2002\n",
      "\n",
      "Start of epoch 136\n",
      "Training loss at epoch 136: 0.1962\n",
      "\n",
      "Start of epoch 137\n",
      "Training loss at epoch 137: 0.1929\n",
      "\n",
      "Start of epoch 138\n",
      "Training loss at epoch 138: 0.1902\n",
      "\n",
      "Start of epoch 139\n",
      "Training loss at epoch 139: 0.1879\n",
      "\n",
      "Start of epoch 140\n",
      "Training loss at epoch 140: 0.1857\n",
      "\n",
      "Start of epoch 141\n",
      "Training loss at epoch 141: 0.1835\n",
      "\n",
      "Start of epoch 142\n",
      "Training loss at epoch 142: 0.1814\n",
      "\n",
      "Start of epoch 143\n",
      "Training loss at epoch 143: 0.1796\n",
      "\n",
      "Start of epoch 144\n",
      "Training loss at epoch 144: 0.1780\n",
      "\n",
      "Start of epoch 145\n",
      "Training loss at epoch 145: 0.1768\n",
      "\n",
      "Start of epoch 146\n",
      "Training loss at epoch 146: 0.1759\n",
      "\n",
      "Start of epoch 147\n",
      "Training loss at epoch 147: 0.1751\n",
      "\n",
      "Start of epoch 148\n",
      "Training loss at epoch 148: 0.1743\n",
      "\n",
      "Start of epoch 149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 149: 0.1734\n",
      "\n",
      "Start of epoch 150\n",
      "Training loss at epoch 150: 0.1724\n",
      "\n",
      "Start of epoch 151\n",
      "Training loss at epoch 151: 0.1715\n",
      "\n",
      "Start of epoch 152\n",
      "Training loss at epoch 152: 0.1707\n",
      "\n",
      "Start of epoch 153\n",
      "Training loss at epoch 153: 0.1699\n",
      "\n",
      "Start of epoch 154\n",
      "Training loss at epoch 154: 0.1693\n",
      "\n",
      "Start of epoch 155\n",
      "Training loss at epoch 155: 0.1688\n",
      "\n",
      "Start of epoch 156\n",
      "Training loss at epoch 156: 0.1682\n",
      "\n",
      "Start of epoch 157\n",
      "Training loss at epoch 157: 0.1676\n",
      "\n",
      "Start of epoch 158\n",
      "Training loss at epoch 158: 0.1671\n",
      "\n",
      "Start of epoch 159\n",
      "Training loss at epoch 159: 0.1666\n",
      "\n",
      "Start of epoch 160\n",
      "Training loss at epoch 160: 0.1661\n",
      "\n",
      "Start of epoch 161\n",
      "Training loss at epoch 161: 0.1658\n",
      "\n",
      "Start of epoch 162\n",
      "Training loss at epoch 162: 0.1656\n",
      "\n",
      "Start of epoch 163\n",
      "Training loss at epoch 163: 0.1654\n",
      "\n",
      "Start of epoch 164\n",
      "Training loss at epoch 164: 0.1653\n",
      "\n",
      "Start of epoch 165\n",
      "Training loss at epoch 165: 0.1651\n",
      "\n",
      "Start of epoch 166\n",
      "Training loss at epoch 166: 0.1650\n",
      "\n",
      "Start of epoch 167\n",
      "Training loss at epoch 167: 0.1650\n",
      "\n",
      "Start of epoch 168\n",
      "Training loss at epoch 168: 0.1649\n",
      "\n",
      "Start of epoch 169\n",
      "Training loss at epoch 169: 0.1649\n",
      "\n",
      "Start of epoch 170\n",
      "Training loss at epoch 170: 0.1649\n",
      "\n",
      "Start of epoch 171\n",
      "Training loss at epoch 171: 0.1649\n",
      "\n",
      "Start of epoch 172\n",
      "Training loss at epoch 172: 0.1649\n",
      "\n",
      "Start of epoch 173\n",
      "Training loss at epoch 173: 0.1649\n",
      "\n",
      "Start of epoch 174\n",
      "Training loss at epoch 174: 0.1648\n",
      "\n",
      "Start of epoch 175\n",
      "Training loss at epoch 175: 0.1648\n",
      "\n",
      "Start of epoch 176\n",
      "Training loss at epoch 176: 0.1647\n",
      "\n",
      "Start of epoch 177\n",
      "Training loss at epoch 177: 0.1647\n",
      "\n",
      "Start of epoch 178\n",
      "Training loss at epoch 178: 0.1646\n",
      "\n",
      "Start of epoch 179\n",
      "Training loss at epoch 179: 0.1646\n",
      "\n",
      "Start of epoch 180\n",
      "Training loss at epoch 180: 0.1645\n",
      "\n",
      "Start of epoch 181\n",
      "Training loss at epoch 181: 0.1645\n",
      "\n",
      "Start of epoch 182\n",
      "Training loss at epoch 182: 0.1645\n",
      "\n",
      "Start of epoch 183\n",
      "Training loss at epoch 183: 0.1644\n",
      "\n",
      "Start of epoch 184\n",
      "Training loss at epoch 184: 0.1644\n",
      "\n",
      "Start of epoch 185\n",
      "Training loss at epoch 185: 0.1644\n",
      "\n",
      "Start of epoch 186\n",
      "Training loss at epoch 186: 0.1645\n",
      "\n",
      "Start of epoch 187\n",
      "Training loss at epoch 187: 0.1645\n",
      "\n",
      "Start of epoch 188\n",
      "Training loss at epoch 188: 0.1645\n",
      "\n",
      "Start of epoch 189\n",
      "Training loss at epoch 189: 0.1645\n",
      "\n",
      "Start of epoch 190\n",
      "Training loss at epoch 190: 0.1644\n",
      "\n",
      "Start of epoch 191\n",
      "Training loss at epoch 191: 0.1643\n",
      "\n",
      "Start of epoch 192\n",
      "Training loss at epoch 192: 0.1644\n",
      "\n",
      "Start of epoch 193\n",
      "Training loss at epoch 193: 0.1644\n",
      "\n",
      "Start of epoch 194\n",
      "Training loss at epoch 194: 0.1644\n",
      "\n",
      "Start of epoch 195\n",
      "Training loss at epoch 195: 0.1643\n",
      "\n",
      "Start of epoch 196\n",
      "Training loss at epoch 196: 0.1643\n",
      "\n",
      "Start of epoch 197\n",
      "Training loss at epoch 197: 0.1643\n",
      "\n",
      "Start of epoch 198\n",
      "Training loss at epoch 198: 0.1643\n",
      "\n",
      "Start of epoch 199\n",
      "Training loss at epoch 199: 0.1643\n",
      "\n",
      "Start of epoch 200\n",
      "Training loss at epoch 200: 0.1642\n",
      "\n",
      "Start of epoch 201\n",
      "Training loss at epoch 201: 0.1643\n",
      "\n",
      "Start of epoch 202\n",
      "Training loss at epoch 202: 0.1643\n",
      "\n",
      "Start of epoch 203\n",
      "Training loss at epoch 203: 0.1642\n",
      "\n",
      "Start of epoch 204\n",
      "Training loss at epoch 204: 0.1642\n",
      "\n",
      "Start of epoch 205\n",
      "Training loss at epoch 205: 0.1642\n",
      "\n",
      "Start of epoch 206\n",
      "Training loss at epoch 206: 0.1642\n",
      "\n",
      "Start of epoch 207\n",
      "Training loss at epoch 207: 0.1642\n",
      "\n",
      "Start of epoch 208\n",
      "Training loss at epoch 208: 0.1642\n",
      "\n",
      "Start of epoch 209\n",
      "Training loss at epoch 209: 0.1642\n",
      "\n",
      "Start of epoch 210\n",
      "Training loss at epoch 210: 0.1642\n",
      "\n",
      "Start of epoch 211\n",
      "Training loss at epoch 211: 0.1642\n",
      "\n",
      "Start of epoch 212\n",
      "Training loss at epoch 212: 0.1642\n",
      "\n",
      "Start of epoch 213\n",
      "Training loss at epoch 213: 0.1642\n",
      "\n",
      "Start of epoch 214\n",
      "Training loss at epoch 214: 0.1642\n",
      "\n",
      "Start of epoch 215\n",
      "Training loss at epoch 215: 0.1642\n",
      "\n",
      "Start of epoch 216\n",
      "Training loss at epoch 216: 0.1642\n",
      "\n",
      "Start of epoch 217\n",
      "Training loss at epoch 217: 0.1642\n",
      "\n",
      "Start of epoch 218\n",
      "Training loss at epoch 218: 0.1642\n",
      "\n",
      "Start of epoch 219\n",
      "Training loss at epoch 219: 0.1642\n",
      "\n",
      "Start of epoch 220\n",
      "Training loss at epoch 220: 0.1642\n",
      "\n",
      "Start of epoch 221\n",
      "Training loss at epoch 221: 0.1641\n",
      "\n",
      "Start of epoch 222\n",
      "Training loss at epoch 222: 0.1641\n",
      "\n",
      "Start of epoch 223\n",
      "Training loss at epoch 223: 0.1641\n",
      "\n",
      "Start of epoch 224\n",
      "Training loss at epoch 224: 0.1641\n",
      "\n",
      "Start of epoch 225\n",
      "Training loss at epoch 225: 0.1641\n",
      "\n",
      "Start of epoch 226\n",
      "Training loss at epoch 226: 0.1641\n",
      "\n",
      "Start of epoch 227\n",
      "Training loss at epoch 227: 0.1641\n",
      "\n",
      "Start of epoch 228\n",
      "Training loss at epoch 228: 0.1641\n",
      "\n",
      "Start of epoch 229\n",
      "Training loss at epoch 229: 0.1641\n",
      "\n",
      "Start of epoch 230\n",
      "Training loss at epoch 230: 0.1641\n",
      "\n",
      "Start of epoch 231\n",
      "Training loss at epoch 231: 0.1641\n",
      "\n",
      "Start of epoch 232\n",
      "Training loss at epoch 232: 0.1641\n",
      "\n",
      "Start of epoch 233\n",
      "Training loss at epoch 233: 0.1641\n",
      "\n",
      "Start of epoch 234\n",
      "Training loss at epoch 234: 0.1641\n",
      "\n",
      "Start of epoch 235\n",
      "Training loss at epoch 235: 0.1641\n",
      "\n",
      "Start of epoch 236\n",
      "Training loss at epoch 236: 0.1641\n",
      "\n",
      "Start of epoch 237\n",
      "Training loss at epoch 237: 0.1641\n",
      "\n",
      "Start of epoch 238\n",
      "Training loss at epoch 238: 0.1641\n",
      "\n",
      "Start of epoch 239\n",
      "Training loss at epoch 239: 0.1641\n",
      "\n",
      "Start of epoch 240\n",
      "Training loss at epoch 240: 0.1641\n",
      "\n",
      "Start of epoch 241\n",
      "Training loss at epoch 241: 0.1641\n",
      "\n",
      "Start of epoch 242\n",
      "Training loss at epoch 242: 0.1641\n",
      "\n",
      "Start of epoch 243\n",
      "Training loss at epoch 243: 0.1641\n",
      "\n",
      "Start of epoch 244\n",
      "Training loss at epoch 244: 0.1641\n",
      "\n",
      "Start of epoch 245\n",
      "Training loss at epoch 245: 0.1641\n",
      "\n",
      "Start of epoch 246\n",
      "Training loss at epoch 246: 0.1641\n",
      "\n",
      "Start of epoch 247\n",
      "Training loss at epoch 247: 0.1641\n",
      "\n",
      "Start of epoch 248\n",
      "Training loss at epoch 248: 0.1641\n",
      "\n",
      "Start of epoch 249\n",
      "Training loss at epoch 249: 0.1641\n",
      "\n",
      "Start of epoch 250\n",
      "Training loss at epoch 250: 0.1641\n",
      "\n",
      "Start of epoch 251\n",
      "Training loss at epoch 251: 0.1641\n",
      "\n",
      "Start of epoch 252\n",
      "Training loss at epoch 252: 0.1640\n",
      "\n",
      "Start of epoch 253\n",
      "Training loss at epoch 253: 0.1640\n",
      "\n",
      "Start of epoch 254\n",
      "Training loss at epoch 254: 0.1640\n",
      "\n",
      "Start of epoch 255\n",
      "Training loss at epoch 255: 0.1640\n",
      "\n",
      "Start of epoch 256\n",
      "Training loss at epoch 256: 0.1640\n",
      "\n",
      "Start of epoch 257\n",
      "Training loss at epoch 257: 0.1640\n",
      "\n",
      "Start of epoch 258\n",
      "Training loss at epoch 258: 0.1640\n",
      "\n",
      "Start of epoch 259\n",
      "Training loss at epoch 259: 0.1640\n",
      "\n",
      "Start of epoch 260\n",
      "Training loss at epoch 260: 0.1640\n",
      "\n",
      "Start of epoch 261\n",
      "Training loss at epoch 261: 0.1640\n",
      "\n",
      "Start of epoch 262\n",
      "Training loss at epoch 262: 0.1640\n",
      "\n",
      "Start of epoch 263\n",
      "Training loss at epoch 263: 0.1640\n",
      "\n",
      "Start of epoch 264\n",
      "Training loss at epoch 264: 0.1640\n",
      "\n",
      "Start of epoch 265\n",
      "Training loss at epoch 265: 0.1640\n",
      "\n",
      "Start of epoch 266\n",
      "Training loss at epoch 266: 0.1640\n",
      "\n",
      "Start of epoch 267\n",
      "Training loss at epoch 267: 0.1640\n",
      "\n",
      "Start of epoch 268\n",
      "Training loss at epoch 268: 0.1640\n",
      "\n",
      "Start of epoch 269\n",
      "Training loss at epoch 269: 0.1640\n",
      "\n",
      "Start of epoch 270\n",
      "Training loss at epoch 270: 0.1640\n",
      "\n",
      "Start of epoch 271\n",
      "Training loss at epoch 271: 0.1640\n",
      "\n",
      "Start of epoch 272\n",
      "Training loss at epoch 272: 0.1640\n",
      "\n",
      "Start of epoch 273\n",
      "Training loss at epoch 273: 0.1640\n",
      "\n",
      "Start of epoch 274\n",
      "Training loss at epoch 274: 0.1640\n",
      "\n",
      "Start of epoch 275\n",
      "Training loss at epoch 275: 0.1641\n",
      "\n",
      "Start of epoch 276\n",
      "Training loss at epoch 276: 0.1641\n",
      "\n",
      "Start of epoch 277\n",
      "Training loss at epoch 277: 0.1641\n",
      "\n",
      "Start of epoch 278\n",
      "Training loss at epoch 278: 0.1642\n",
      "\n",
      "Start of epoch 279\n",
      "Training loss at epoch 279: 0.1642\n",
      "\n",
      "Start of epoch 280\n",
      "Training loss at epoch 280: 0.1641\n",
      "\n",
      "Start of epoch 281\n",
      "Training loss at epoch 281: 0.1640\n",
      "\n",
      "Start of epoch 282\n",
      "Training loss at epoch 282: 0.1640\n",
      "\n",
      "Start of epoch 283\n",
      "Training loss at epoch 283: 0.1640\n",
      "\n",
      "Start of epoch 284\n",
      "Training loss at epoch 284: 0.1641\n",
      "\n",
      "Start of epoch 285\n",
      "Training loss at epoch 285: 0.1641\n",
      "\n",
      "Start of epoch 286\n",
      "Training loss at epoch 286: 0.1640\n",
      "\n",
      "Start of epoch 287\n",
      "Training loss at epoch 287: 0.1640\n",
      "\n",
      "Start of epoch 288\n",
      "Training loss at epoch 288: 0.1640\n",
      "\n",
      "Start of epoch 289\n",
      "Training loss at epoch 289: 0.1640\n",
      "\n",
      "Start of epoch 290\n",
      "Training loss at epoch 290: 0.1640\n",
      "\n",
      "Start of epoch 291\n",
      "Training loss at epoch 291: 0.1640\n",
      "\n",
      "Start of epoch 292\n",
      "Training loss at epoch 292: 0.1640\n",
      "\n",
      "Start of epoch 293\n",
      "Training loss at epoch 293: 0.1640\n",
      "\n",
      "Start of epoch 294\n",
      "Training loss at epoch 294: 0.1640\n",
      "\n",
      "Start of epoch 295\n",
      "Training loss at epoch 295: 0.1640\n",
      "\n",
      "Start of epoch 296\n",
      "Training loss at epoch 296: 0.1640\n",
      "\n",
      "Start of epoch 297\n",
      "Training loss at epoch 297: 0.1640\n",
      "\n",
      "Start of epoch 298\n",
      "Training loss at epoch 298: 0.1640\n",
      "\n",
      "Start of epoch 299\n",
      "Training loss at epoch 299: 0.1640\n",
      "\n",
      "Start of epoch 300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 300: 0.1640\n",
      "\n",
      "Start of epoch 301\n",
      "Training loss at epoch 301: 0.1640\n",
      "\n",
      "Start of epoch 302\n",
      "Training loss at epoch 302: 0.1640\n",
      "\n",
      "Start of epoch 303\n",
      "Training loss at epoch 303: 0.1640\n",
      "\n",
      "Start of epoch 304\n",
      "Training loss at epoch 304: 0.1640\n",
      "\n",
      "Start of epoch 305\n",
      "Training loss at epoch 305: 0.1640\n",
      "\n",
      "Start of epoch 306\n",
      "Training loss at epoch 306: 0.1640\n",
      "\n",
      "Start of epoch 307\n",
      "Training loss at epoch 307: 0.1640\n",
      "\n",
      "Start of epoch 308\n",
      "Training loss at epoch 308: 0.1640\n",
      "\n",
      "Start of epoch 309\n",
      "Training loss at epoch 309: 0.1640\n",
      "\n",
      "Start of epoch 310\n",
      "Training loss at epoch 310: 0.1640\n",
      "\n",
      "Start of epoch 311\n",
      "Training loss at epoch 311: 0.1640\n",
      "\n",
      "Start of epoch 312\n",
      "Training loss at epoch 312: 0.1640\n",
      "\n",
      "Start of epoch 313\n",
      "Training loss at epoch 313: 0.1640\n",
      "\n",
      "Start of epoch 314\n",
      "Training loss at epoch 314: 0.1640\n",
      "\n",
      "Start of epoch 315\n",
      "Training loss at epoch 315: 0.1640\n",
      "\n",
      "Start of epoch 316\n",
      "Training loss at epoch 316: 0.1640\n",
      "\n",
      "Start of epoch 317\n",
      "Training loss at epoch 317: 0.1640\n",
      "\n",
      "Start of epoch 318\n",
      "Training loss at epoch 318: 0.1640\n",
      "\n",
      "Start of epoch 319\n",
      "Training loss at epoch 319: 0.1639\n",
      "\n",
      "Start of epoch 320\n",
      "Training loss at epoch 320: 0.1639\n",
      "\n",
      "Start of epoch 321\n",
      "Training loss at epoch 321: 0.1639\n",
      "\n",
      "Start of epoch 322\n",
      "Training loss at epoch 322: 0.1639\n",
      "\n",
      "Start of epoch 323\n",
      "Training loss at epoch 323: 0.1639\n",
      "\n",
      "Start of epoch 324\n",
      "Training loss at epoch 324: 0.1639\n",
      "\n",
      "Start of epoch 325\n",
      "Training loss at epoch 325: 0.1639\n",
      "\n",
      "Start of epoch 326\n",
      "Training loss at epoch 326: 0.1639\n",
      "\n",
      "Start of epoch 327\n",
      "Training loss at epoch 327: 0.1639\n",
      "\n",
      "Start of epoch 328\n",
      "Training loss at epoch 328: 0.1639\n",
      "\n",
      "Start of epoch 329\n",
      "Training loss at epoch 329: 0.1639\n",
      "\n",
      "Start of epoch 330\n",
      "Training loss at epoch 330: 0.1639\n",
      "\n",
      "Start of epoch 331\n",
      "Training loss at epoch 331: 0.1639\n",
      "\n",
      "Start of epoch 332\n",
      "Training loss at epoch 332: 0.1639\n",
      "\n",
      "Start of epoch 333\n",
      "Training loss at epoch 333: 0.1639\n",
      "\n",
      "Start of epoch 334\n",
      "Training loss at epoch 334: 0.1639\n",
      "\n",
      "Start of epoch 335\n",
      "Training loss at epoch 335: 0.1639\n",
      "\n",
      "Start of epoch 336\n",
      "Training loss at epoch 336: 0.1639\n",
      "\n",
      "Start of epoch 337\n",
      "Training loss at epoch 337: 0.1639\n",
      "\n",
      "Start of epoch 338\n",
      "Training loss at epoch 338: 0.1639\n",
      "\n",
      "Start of epoch 339\n",
      "Training loss at epoch 339: 0.1639\n",
      "\n",
      "Start of epoch 340\n",
      "Training loss at epoch 340: 0.1639\n",
      "\n",
      "Start of epoch 341\n",
      "Training loss at epoch 341: 0.1639\n",
      "\n",
      "Start of epoch 342\n",
      "Training loss at epoch 342: 0.1639\n",
      "\n",
      "Start of epoch 343\n",
      "Training loss at epoch 343: 0.1639\n",
      "\n",
      "Start of epoch 344\n",
      "Training loss at epoch 344: 0.1639\n",
      "\n",
      "Start of epoch 345\n",
      "Training loss at epoch 345: 0.1639\n",
      "\n",
      "Start of epoch 346\n",
      "Training loss at epoch 346: 0.1639\n",
      "\n",
      "Start of epoch 347\n",
      "Training loss at epoch 347: 0.1639\n",
      "\n",
      "Start of epoch 348\n",
      "Training loss at epoch 348: 0.1639\n",
      "\n",
      "Start of epoch 349\n",
      "Training loss at epoch 349: 0.1639\n",
      "\n",
      "Start of epoch 350\n",
      "Training loss at epoch 350: 0.1639\n",
      "\n",
      "Start of epoch 351\n",
      "Training loss at epoch 351: 0.1639\n",
      "\n",
      "Start of epoch 352\n",
      "Training loss at epoch 352: 0.1639\n",
      "\n",
      "Start of epoch 353\n",
      "Training loss at epoch 353: 0.1639\n",
      "\n",
      "Start of epoch 354\n",
      "Training loss at epoch 354: 0.1639\n",
      "\n",
      "Start of epoch 355\n",
      "Training loss at epoch 355: 0.1639\n",
      "\n",
      "Start of epoch 356\n",
      "Training loss at epoch 356: 0.1639\n",
      "\n",
      "Start of epoch 357\n",
      "Training loss at epoch 357: 0.1639\n",
      "\n",
      "Start of epoch 358\n",
      "Training loss at epoch 358: 0.1639\n",
      "\n",
      "Start of epoch 359\n",
      "Training loss at epoch 359: 0.1639\n",
      "\n",
      "Start of epoch 360\n",
      "Training loss at epoch 360: 0.1639\n",
      "\n",
      "Start of epoch 361\n",
      "Training loss at epoch 361: 0.1639\n",
      "\n",
      "Start of epoch 362\n",
      "Training loss at epoch 362: 0.1639\n",
      "\n",
      "Start of epoch 363\n",
      "Training loss at epoch 363: 0.1639\n",
      "\n",
      "Start of epoch 364\n",
      "Training loss at epoch 364: 0.1639\n",
      "\n",
      "Start of epoch 365\n",
      "Training loss at epoch 365: 0.1639\n",
      "\n",
      "Start of epoch 366\n",
      "Training loss at epoch 366: 0.1639\n",
      "\n",
      "Start of epoch 367\n",
      "Training loss at epoch 367: 0.1639\n",
      "\n",
      "Start of epoch 368\n",
      "Training loss at epoch 368: 0.1639\n",
      "\n",
      "Start of epoch 369\n",
      "Training loss at epoch 369: 0.1639\n",
      "\n",
      "Start of epoch 370\n",
      "Training loss at epoch 370: 0.1639\n",
      "\n",
      "Start of epoch 371\n",
      "Training loss at epoch 371: 0.1640\n",
      "\n",
      "Start of epoch 372\n",
      "Training loss at epoch 372: 0.1640\n",
      "\n",
      "Start of epoch 373\n",
      "Training loss at epoch 373: 0.1640\n",
      "\n",
      "Start of epoch 374\n",
      "Training loss at epoch 374: 0.1641\n",
      "\n",
      "Start of epoch 375\n",
      "Training loss at epoch 375: 0.1641\n",
      "\n",
      "Start of epoch 376\n",
      "Training loss at epoch 376: 0.1640\n",
      "\n",
      "Start of epoch 377\n",
      "Training loss at epoch 377: 0.1640\n",
      "\n",
      "Start of epoch 378\n",
      "Training loss at epoch 378: 0.1639\n",
      "\n",
      "Start of epoch 379\n",
      "Training loss at epoch 379: 0.1639\n",
      "\n",
      "Start of epoch 380\n",
      "Training loss at epoch 380: 0.1639\n",
      "\n",
      "Start of epoch 381\n",
      "Training loss at epoch 381: 0.1640\n",
      "\n",
      "Start of epoch 382\n",
      "Training loss at epoch 382: 0.1640\n",
      "\n",
      "Start of epoch 383\n",
      "Training loss at epoch 383: 0.1639\n",
      "\n",
      "Start of epoch 384\n",
      "Training loss at epoch 384: 0.1639\n",
      "\n",
      "Start of epoch 385\n",
      "Training loss at epoch 385: 0.1639\n",
      "\n",
      "Start of epoch 386\n",
      "Training loss at epoch 386: 0.1639\n",
      "\n",
      "Start of epoch 387\n",
      "Training loss at epoch 387: 0.1639\n",
      "\n",
      "Start of epoch 388\n",
      "Training loss at epoch 388: 0.1639\n",
      "\n",
      "Start of epoch 389\n",
      "Training loss at epoch 389: 0.1639\n",
      "\n",
      "Start of epoch 390\n",
      "Training loss at epoch 390: 0.1639\n",
      "\n",
      "Start of epoch 391\n",
      "Training loss at epoch 391: 0.1639\n",
      "\n",
      "Start of epoch 392\n",
      "Training loss at epoch 392: 0.1639\n",
      "\n",
      "Start of epoch 393\n",
      "Training loss at epoch 393: 0.1639\n",
      "\n",
      "Start of epoch 394\n",
      "Training loss at epoch 394: 0.1639\n",
      "\n",
      "Start of epoch 395\n",
      "Training loss at epoch 395: 0.1639\n",
      "\n",
      "Start of epoch 396\n",
      "Training loss at epoch 396: 0.1639\n",
      "\n",
      "Start of epoch 397\n",
      "Training loss at epoch 397: 0.1639\n",
      "\n",
      "Start of epoch 398\n",
      "Training loss at epoch 398: 0.1639\n",
      "\n",
      "Start of epoch 399\n",
      "Training loss at epoch 399: 0.1639\n",
      "\n",
      "Start of epoch 400\n",
      "Training loss at epoch 400: 0.1639\n",
      "\n",
      "Start of epoch 401\n",
      "Training loss at epoch 401: 0.1639\n",
      "\n",
      "Start of epoch 402\n",
      "Training loss at epoch 402: 0.1639\n",
      "\n",
      "Start of epoch 403\n",
      "Training loss at epoch 403: 0.1639\n",
      "\n",
      "Start of epoch 404\n",
      "Training loss at epoch 404: 0.1639\n",
      "\n",
      "Start of epoch 405\n",
      "Training loss at epoch 405: 0.1639\n",
      "\n",
      "Start of epoch 406\n",
      "Training loss at epoch 406: 0.1639\n",
      "\n",
      "Start of epoch 407\n",
      "Training loss at epoch 407: 0.1639\n",
      "\n",
      "Start of epoch 408\n",
      "Training loss at epoch 408: 0.1639\n",
      "\n",
      "Start of epoch 409\n",
      "Training loss at epoch 409: 0.1639\n",
      "\n",
      "Start of epoch 410\n",
      "Training loss at epoch 410: 0.1639\n",
      "\n",
      "Start of epoch 411\n",
      "Training loss at epoch 411: 0.1639\n",
      "\n",
      "Start of epoch 412\n",
      "Training loss at epoch 412: 0.1639\n",
      "\n",
      "Start of epoch 413\n",
      "Training loss at epoch 413: 0.1639\n",
      "\n",
      "Start of epoch 414\n",
      "Training loss at epoch 414: 0.1639\n",
      "\n",
      "Start of epoch 415\n",
      "Training loss at epoch 415: 0.1639\n",
      "\n",
      "Start of epoch 416\n",
      "Training loss at epoch 416: 0.1639\n",
      "\n",
      "Start of epoch 417\n",
      "Training loss at epoch 417: 0.1639\n",
      "\n",
      "Start of epoch 418\n",
      "Training loss at epoch 418: 0.1639\n",
      "\n",
      "Start of epoch 419\n",
      "Training loss at epoch 419: 0.1639\n",
      "\n",
      "Start of epoch 420\n",
      "Training loss at epoch 420: 0.1639\n",
      "\n",
      "Start of epoch 421\n",
      "Training loss at epoch 421: 0.1639\n",
      "\n",
      "Start of epoch 422\n",
      "Training loss at epoch 422: 0.1639\n",
      "\n",
      "Start of epoch 423\n",
      "Training loss at epoch 423: 0.1639\n",
      "\n",
      "Start of epoch 424\n",
      "Training loss at epoch 424: 0.1639\n",
      "\n",
      "Start of epoch 425\n",
      "Training loss at epoch 425: 0.1639\n",
      "\n",
      "Start of epoch 426\n",
      "Training loss at epoch 426: 0.1639\n",
      "\n",
      "Start of epoch 427\n",
      "Training loss at epoch 427: 0.1639\n",
      "\n",
      "Start of epoch 428\n",
      "Training loss at epoch 428: 0.1639\n",
      "\n",
      "Start of epoch 429\n",
      "Training loss at epoch 429: 0.1639\n",
      "\n",
      "Start of epoch 430\n",
      "Training loss at epoch 430: 0.1639\n",
      "\n",
      "Start of epoch 431\n",
      "Training loss at epoch 431: 0.1639\n",
      "\n",
      "Start of epoch 432\n",
      "Training loss at epoch 432: 0.1639\n",
      "\n",
      "Start of epoch 433\n",
      "Training loss at epoch 433: 0.1639\n",
      "\n",
      "Start of epoch 434\n",
      "Training loss at epoch 434: 0.1639\n",
      "\n",
      "Start of epoch 435\n",
      "Training loss at epoch 435: 0.1639\n",
      "\n",
      "Start of epoch 436\n",
      "Training loss at epoch 436: 0.1639\n",
      "\n",
      "Start of epoch 437\n",
      "Training loss at epoch 437: 0.1639\n",
      "\n",
      "Start of epoch 438\n",
      "Training loss at epoch 438: 0.1639\n",
      "\n",
      "Start of epoch 439\n",
      "Training loss at epoch 439: 0.1639\n",
      "\n",
      "Start of epoch 440\n",
      "Training loss at epoch 440: 0.1639\n",
      "\n",
      "Start of epoch 441\n",
      "Training loss at epoch 441: 0.1639\n",
      "\n",
      "Start of epoch 442\n",
      "Training loss at epoch 442: 0.1639\n",
      "\n",
      "Start of epoch 443\n",
      "Training loss at epoch 443: 0.1639\n",
      "\n",
      "Start of epoch 444\n",
      "Training loss at epoch 444: 0.1639\n",
      "\n",
      "Start of epoch 445\n",
      "Training loss at epoch 445: 0.1639\n",
      "\n",
      "Start of epoch 446\n",
      "Training loss at epoch 446: 0.1639\n",
      "\n",
      "Start of epoch 447\n",
      "Training loss at epoch 447: 0.1639\n",
      "\n",
      "Start of epoch 448\n",
      "Training loss at epoch 448: 0.1639\n",
      "\n",
      "Start of epoch 449\n",
      "Training loss at epoch 449: 0.1639\n",
      "\n",
      "Start of epoch 450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 450: 0.1639\n",
      "\n",
      "Start of epoch 451\n",
      "Training loss at epoch 451: 0.1639\n",
      "\n",
      "Start of epoch 452\n",
      "Training loss at epoch 452: 0.1639\n",
      "\n",
      "Start of epoch 453\n",
      "Training loss at epoch 453: 0.1639\n",
      "\n",
      "Start of epoch 454\n",
      "Training loss at epoch 454: 0.1639\n",
      "\n",
      "Start of epoch 455\n",
      "Training loss at epoch 455: 0.1639\n",
      "\n",
      "Start of epoch 456\n",
      "Training loss at epoch 456: 0.1639\n",
      "\n",
      "Start of epoch 457\n",
      "Training loss at epoch 457: 0.1639\n",
      "\n",
      "Start of epoch 458\n",
      "Training loss at epoch 458: 0.1639\n",
      "\n",
      "Start of epoch 459\n",
      "Training loss at epoch 459: 0.1639\n",
      "\n",
      "Start of epoch 460\n",
      "Training loss at epoch 460: 0.1639\n",
      "\n",
      "Start of epoch 461\n",
      "Training loss at epoch 461: 0.1639\n",
      "\n",
      "Start of epoch 462\n",
      "Training loss at epoch 462: 0.1639\n",
      "\n",
      "Start of epoch 463\n",
      "Training loss at epoch 463: 0.1639\n",
      "\n",
      "Start of epoch 464\n",
      "Training loss at epoch 464: 0.1639\n",
      "\n",
      "Start of epoch 465\n",
      "Training loss at epoch 465: 0.1639\n",
      "\n",
      "Start of epoch 466\n",
      "Training loss at epoch 466: 0.1639\n",
      "\n",
      "Start of epoch 467\n",
      "Training loss at epoch 467: 0.1639\n",
      "\n",
      "Start of epoch 468\n",
      "Training loss at epoch 468: 0.1639\n",
      "\n",
      "Start of epoch 469\n",
      "Training loss at epoch 469: 0.1640\n",
      "\n",
      "Start of epoch 470\n",
      "Training loss at epoch 470: 0.1640\n",
      "\n",
      "Start of epoch 471\n",
      "Training loss at epoch 471: 0.1640\n",
      "\n",
      "Start of epoch 472\n",
      "Training loss at epoch 472: 0.1640\n",
      "\n",
      "Start of epoch 473\n",
      "Training loss at epoch 473: 0.1640\n",
      "\n",
      "Start of epoch 474\n",
      "Training loss at epoch 474: 0.1640\n",
      "\n",
      "Start of epoch 475\n",
      "Training loss at epoch 475: 0.1639\n",
      "\n",
      "Start of epoch 476\n",
      "Training loss at epoch 476: 0.1639\n",
      "\n",
      "Start of epoch 477\n",
      "Training loss at epoch 477: 0.1639\n",
      "\n",
      "Start of epoch 478\n",
      "Training loss at epoch 478: 0.1639\n",
      "\n",
      "Start of epoch 479\n",
      "Training loss at epoch 479: 0.1639\n",
      "\n",
      "Start of epoch 480\n",
      "Training loss at epoch 480: 0.1639\n",
      "\n",
      "Start of epoch 481\n",
      "Training loss at epoch 481: 0.1639\n",
      "\n",
      "Start of epoch 482\n",
      "Training loss at epoch 482: 0.1639\n",
      "\n",
      "Start of epoch 483\n",
      "Training loss at epoch 483: 0.1639\n",
      "\n",
      "Start of epoch 484\n",
      "Training loss at epoch 484: 0.1639\n",
      "\n",
      "Start of epoch 485\n",
      "Training loss at epoch 485: 0.1639\n",
      "\n",
      "Start of epoch 486\n",
      "Training loss at epoch 486: 0.1639\n",
      "\n",
      "Start of epoch 487\n",
      "Training loss at epoch 487: 0.1639\n",
      "\n",
      "Start of epoch 488\n",
      "Training loss at epoch 488: 0.1639\n",
      "\n",
      "Start of epoch 489\n",
      "Training loss at epoch 489: 0.1639\n",
      "\n",
      "Start of epoch 490\n",
      "Training loss at epoch 490: 0.1639\n",
      "\n",
      "Start of epoch 491\n",
      "Training loss at epoch 491: 0.1639\n",
      "\n",
      "Start of epoch 492\n",
      "Training loss at epoch 492: 0.1639\n",
      "\n",
      "Start of epoch 493\n",
      "Training loss at epoch 493: 0.1639\n",
      "\n",
      "Start of epoch 494\n",
      "Training loss at epoch 494: 0.1639\n",
      "\n",
      "Start of epoch 495\n",
      "Training loss at epoch 495: 0.1639\n",
      "\n",
      "Start of epoch 496\n",
      "Training loss at epoch 496: 0.1639\n",
      "\n",
      "Start of epoch 497\n",
      "Training loss at epoch 497: 0.1639\n",
      "\n",
      "Start of epoch 498\n",
      "Training loss at epoch 498: 0.1639\n",
      "\n",
      "Start of epoch 499\n",
      "Training loss at epoch 499: 0.1639\n",
      "[<tf.Variable 'parameters:0' shape=(15,) dtype=float32, numpy=\n",
      "array([4.9481773 , 0.89366066, 2.728925  , 0.67799634, 5.1459875 ,\n",
      "       5.631921  , 0.783262  , 0.5567796 , 2.8036427 , 5.9432955 ,\n",
      "       1.545079  , 4.1814256 , 3.696559  , 3.2284043 , 2.0800152 ],\n",
      "      dtype=float32)>]\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.4693\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 1.3847\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 1.3023\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 1.2246\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 1.1539\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 1.0919\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 1.0387\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.9942\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.9584\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.9305\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.9086\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.8905\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.8740\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.8576\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.8401\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.8209\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.7996\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.7757\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.7491\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.7197\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.6874\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.6529\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.6168\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.5802\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.5445\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.5108\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.4804\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.4537\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.4308\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.4112\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.3941\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.3787\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.3645\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.3515\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.3401\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.3309\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.3245\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.3210\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.3198\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.3195\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.3189\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.3170\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.3137\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.3094\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.3051\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.3016\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.2992\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.2976\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.2960\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.2940\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.2914\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.2885\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.2859\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.2840\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.2827\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.2814\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.2796\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.2771\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.2741\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.2709\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.2679\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.2653\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.2626\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.2597\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.2565\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.2534\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.2504\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.2479\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.2455\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.2431\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.2406\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.2380\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.2354\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.2330\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.2307\n",
      "\n",
      "Start of epoch 75\n",
      "Training loss at epoch 75: 0.2283\n",
      "\n",
      "Start of epoch 76\n",
      "Training loss at epoch 76: 0.2258\n",
      "\n",
      "Start of epoch 77\n",
      "Training loss at epoch 77: 0.2233\n",
      "\n",
      "Start of epoch 78\n",
      "Training loss at epoch 78: 0.2210\n",
      "\n",
      "Start of epoch 79\n",
      "Training loss at epoch 79: 0.2188\n",
      "\n",
      "Start of epoch 80\n",
      "Training loss at epoch 80: 0.2167\n",
      "\n",
      "Start of epoch 81\n",
      "Training loss at epoch 81: 0.2146\n",
      "\n",
      "Start of epoch 82\n",
      "Training loss at epoch 82: 0.2125\n",
      "\n",
      "Start of epoch 83\n",
      "Training loss at epoch 83: 0.2104\n",
      "\n",
      "Start of epoch 84\n",
      "Training loss at epoch 84: 0.2085\n",
      "\n",
      "Start of epoch 85\n",
      "Training loss at epoch 85: 0.2066\n",
      "\n",
      "Start of epoch 86\n",
      "Training loss at epoch 86: 0.2047\n",
      "\n",
      "Start of epoch 87\n",
      "Training loss at epoch 87: 0.2028\n",
      "\n",
      "Start of epoch 88\n",
      "Training loss at epoch 88: 0.2009\n",
      "\n",
      "Start of epoch 89\n",
      "Training loss at epoch 89: 0.1990\n",
      "\n",
      "Start of epoch 90\n",
      "Training loss at epoch 90: 0.1973\n",
      "\n",
      "Start of epoch 91\n",
      "Training loss at epoch 91: 0.1955\n",
      "\n",
      "Start of epoch 92\n",
      "Training loss at epoch 92: 0.1938\n",
      "\n",
      "Start of epoch 93\n",
      "Training loss at epoch 93: 0.1922\n",
      "\n",
      "Start of epoch 94\n",
      "Training loss at epoch 94: 0.1906\n",
      "\n",
      "Start of epoch 95\n",
      "Training loss at epoch 95: 0.1890\n",
      "\n",
      "Start of epoch 96\n",
      "Training loss at epoch 96: 0.1875\n",
      "\n",
      "Start of epoch 97\n",
      "Training loss at epoch 97: 0.1860\n",
      "\n",
      "Start of epoch 98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 98: 0.1846\n",
      "\n",
      "Start of epoch 99\n",
      "Training loss at epoch 99: 0.1832\n",
      "\n",
      "Start of epoch 100\n",
      "Training loss at epoch 100: 0.1818\n",
      "\n",
      "Start of epoch 101\n",
      "Training loss at epoch 101: 0.1805\n",
      "\n",
      "Start of epoch 102\n",
      "Training loss at epoch 102: 0.1792\n",
      "\n",
      "Start of epoch 103\n",
      "Training loss at epoch 103: 0.1779\n",
      "\n",
      "Start of epoch 104\n",
      "Training loss at epoch 104: 0.1767\n",
      "\n",
      "Start of epoch 105\n",
      "Training loss at epoch 105: 0.1756\n",
      "\n",
      "Start of epoch 106\n",
      "Training loss at epoch 106: 0.1744\n",
      "\n",
      "Start of epoch 107\n",
      "Training loss at epoch 107: 0.1733\n",
      "\n",
      "Start of epoch 108\n",
      "Training loss at epoch 108: 0.1722\n",
      "\n",
      "Start of epoch 109\n",
      "Training loss at epoch 109: 0.1712\n",
      "\n",
      "Start of epoch 110\n",
      "Training loss at epoch 110: 0.1702\n",
      "\n",
      "Start of epoch 111\n",
      "Training loss at epoch 111: 0.1692\n",
      "\n",
      "Start of epoch 112\n",
      "Training loss at epoch 112: 0.1682\n",
      "\n",
      "Start of epoch 113\n",
      "Training loss at epoch 113: 0.1673\n",
      "\n",
      "Start of epoch 114\n",
      "Training loss at epoch 114: 0.1664\n",
      "\n",
      "Start of epoch 115\n",
      "Training loss at epoch 115: 0.1655\n",
      "\n",
      "Start of epoch 116\n",
      "Training loss at epoch 116: 0.1647\n",
      "\n",
      "Start of epoch 117\n",
      "Training loss at epoch 117: 0.1639\n",
      "\n",
      "Start of epoch 118\n",
      "Training loss at epoch 118: 0.1631\n",
      "\n",
      "Start of epoch 119\n",
      "Training loss at epoch 119: 0.1623\n",
      "\n",
      "Start of epoch 120\n",
      "Training loss at epoch 120: 0.1616\n",
      "\n",
      "Start of epoch 121\n",
      "Training loss at epoch 121: 0.1609\n",
      "\n",
      "Start of epoch 122\n",
      "Training loss at epoch 122: 0.1602\n",
      "\n",
      "Start of epoch 123\n",
      "Training loss at epoch 123: 0.1596\n",
      "\n",
      "Start of epoch 124\n",
      "Training loss at epoch 124: 0.1590\n",
      "\n",
      "Start of epoch 125\n",
      "Training loss at epoch 125: 0.1584\n",
      "\n",
      "Start of epoch 126\n",
      "Training loss at epoch 126: 0.1579\n",
      "\n",
      "Start of epoch 127\n",
      "Training loss at epoch 127: 0.1574\n",
      "\n",
      "Start of epoch 128\n",
      "Training loss at epoch 128: 0.1569\n",
      "\n",
      "Start of epoch 129\n",
      "Training loss at epoch 129: 0.1565\n",
      "\n",
      "Start of epoch 130\n",
      "Training loss at epoch 130: 0.1561\n",
      "\n",
      "Start of epoch 131\n",
      "Training loss at epoch 131: 0.1558\n",
      "\n",
      "Start of epoch 132\n",
      "Training loss at epoch 132: 0.1554\n",
      "\n",
      "Start of epoch 133\n",
      "Training loss at epoch 133: 0.1551\n",
      "\n",
      "Start of epoch 134\n",
      "Training loss at epoch 134: 0.1548\n",
      "\n",
      "Start of epoch 135\n",
      "Training loss at epoch 135: 0.1546\n",
      "\n",
      "Start of epoch 136\n",
      "Training loss at epoch 136: 0.1543\n",
      "\n",
      "Start of epoch 137\n",
      "Training loss at epoch 137: 0.1541\n",
      "\n",
      "Start of epoch 138\n",
      "Training loss at epoch 138: 0.1539\n",
      "\n",
      "Start of epoch 139\n",
      "Training loss at epoch 139: 0.1537\n",
      "\n",
      "Start of epoch 140\n",
      "Training loss at epoch 140: 0.1535\n",
      "\n",
      "Start of epoch 141\n",
      "Training loss at epoch 141: 0.1533\n",
      "\n",
      "Start of epoch 142\n",
      "Training loss at epoch 142: 0.1531\n",
      "\n",
      "Start of epoch 143\n",
      "Training loss at epoch 143: 0.1529\n",
      "\n",
      "Start of epoch 144\n",
      "Training loss at epoch 144: 0.1528\n",
      "\n",
      "Start of epoch 145\n",
      "Training loss at epoch 145: 0.1526\n",
      "\n",
      "Start of epoch 146\n",
      "Training loss at epoch 146: 0.1524\n",
      "\n",
      "Start of epoch 147\n",
      "Training loss at epoch 147: 0.1523\n",
      "\n",
      "Start of epoch 148\n",
      "Training loss at epoch 148: 0.1521\n",
      "\n",
      "Start of epoch 149\n",
      "Training loss at epoch 149: 0.1520\n",
      "\n",
      "Start of epoch 150\n",
      "Training loss at epoch 150: 0.1518\n",
      "\n",
      "Start of epoch 151\n",
      "Training loss at epoch 151: 0.1517\n",
      "\n",
      "Start of epoch 152\n",
      "Training loss at epoch 152: 0.1516\n",
      "\n",
      "Start of epoch 153\n",
      "Training loss at epoch 153: 0.1515\n",
      "\n",
      "Start of epoch 154\n",
      "Training loss at epoch 154: 0.1514\n",
      "\n",
      "Start of epoch 155\n",
      "Training loss at epoch 155: 0.1513\n",
      "\n",
      "Start of epoch 156\n",
      "Training loss at epoch 156: 0.1512\n",
      "\n",
      "Start of epoch 157\n",
      "Training loss at epoch 157: 0.1511\n",
      "\n",
      "Start of epoch 158\n",
      "Training loss at epoch 158: 0.1510\n",
      "\n",
      "Start of epoch 159\n",
      "Training loss at epoch 159: 0.1509\n",
      "\n",
      "Start of epoch 160\n",
      "Training loss at epoch 160: 0.1508\n",
      "\n",
      "Start of epoch 161\n",
      "Training loss at epoch 161: 0.1508\n",
      "\n",
      "Start of epoch 162\n",
      "Training loss at epoch 162: 0.1507\n",
      "\n",
      "Start of epoch 163\n",
      "Training loss at epoch 163: 0.1506\n",
      "\n",
      "Start of epoch 164\n",
      "Training loss at epoch 164: 0.1506\n",
      "\n",
      "Start of epoch 165\n",
      "Training loss at epoch 165: 0.1505\n",
      "\n",
      "Start of epoch 166\n",
      "Training loss at epoch 166: 0.1505\n",
      "\n",
      "Start of epoch 167\n",
      "Training loss at epoch 167: 0.1504\n",
      "\n",
      "Start of epoch 168\n",
      "Training loss at epoch 168: 0.1504\n",
      "\n",
      "Start of epoch 169\n",
      "Training loss at epoch 169: 0.1503\n",
      "\n",
      "Start of epoch 170\n",
      "Training loss at epoch 170: 0.1503\n",
      "\n",
      "Start of epoch 171\n",
      "Training loss at epoch 171: 0.1502\n",
      "\n",
      "Start of epoch 172\n",
      "Training loss at epoch 172: 0.1502\n",
      "\n",
      "Start of epoch 173\n",
      "Training loss at epoch 173: 0.1502\n",
      "\n",
      "Start of epoch 174\n",
      "Training loss at epoch 174: 0.1501\n",
      "\n",
      "Start of epoch 175\n",
      "Training loss at epoch 175: 0.1501\n",
      "\n",
      "Start of epoch 176\n",
      "Training loss at epoch 176: 0.1501\n",
      "\n",
      "Start of epoch 177\n",
      "Training loss at epoch 177: 0.1500\n",
      "\n",
      "Start of epoch 178\n",
      "Training loss at epoch 178: 0.1500\n",
      "\n",
      "Start of epoch 179\n",
      "Training loss at epoch 179: 0.1500\n",
      "\n",
      "Start of epoch 180\n",
      "Training loss at epoch 180: 0.1500\n",
      "\n",
      "Start of epoch 181\n",
      "Training loss at epoch 181: 0.1499\n",
      "\n",
      "Start of epoch 182\n",
      "Training loss at epoch 182: 0.1499\n",
      "\n",
      "Start of epoch 183\n",
      "Training loss at epoch 183: 0.1499\n",
      "\n",
      "Start of epoch 184\n",
      "Training loss at epoch 184: 0.1499\n",
      "\n",
      "Start of epoch 185\n",
      "Training loss at epoch 185: 0.1499\n",
      "\n",
      "Start of epoch 186\n",
      "Training loss at epoch 186: 0.1499\n",
      "\n",
      "Start of epoch 187\n",
      "Training loss at epoch 187: 0.1498\n",
      "\n",
      "Start of epoch 188\n",
      "Training loss at epoch 188: 0.1498\n",
      "\n",
      "Start of epoch 189\n",
      "Training loss at epoch 189: 0.1498\n",
      "\n",
      "Start of epoch 190\n",
      "Training loss at epoch 190: 0.1498\n",
      "\n",
      "Start of epoch 191\n",
      "Training loss at epoch 191: 0.1498\n",
      "\n",
      "Start of epoch 192\n",
      "Training loss at epoch 192: 0.1498\n",
      "\n",
      "Start of epoch 193\n",
      "Training loss at epoch 193: 0.1498\n",
      "\n",
      "Start of epoch 194\n",
      "Training loss at epoch 194: 0.1498\n",
      "\n",
      "Start of epoch 195\n",
      "Training loss at epoch 195: 0.1497\n",
      "\n",
      "Start of epoch 196\n",
      "Training loss at epoch 196: 0.1497\n",
      "\n",
      "Start of epoch 197\n",
      "Training loss at epoch 197: 0.1497\n",
      "\n",
      "Start of epoch 198\n",
      "Training loss at epoch 198: 0.1497\n",
      "\n",
      "Start of epoch 199\n",
      "Training loss at epoch 199: 0.1497\n",
      "\n",
      "Start of epoch 200\n",
      "Training loss at epoch 200: 0.1497\n",
      "\n",
      "Start of epoch 201\n",
      "Training loss at epoch 201: 0.1497\n",
      "\n",
      "Start of epoch 202\n",
      "Training loss at epoch 202: 0.1497\n",
      "\n",
      "Start of epoch 203\n",
      "Training loss at epoch 203: 0.1497\n",
      "\n",
      "Start of epoch 204\n",
      "Training loss at epoch 204: 0.1497\n",
      "\n",
      "Start of epoch 205\n",
      "Training loss at epoch 205: 0.1497\n",
      "\n",
      "Start of epoch 206\n",
      "Training loss at epoch 206: 0.1497\n",
      "\n",
      "Start of epoch 207\n",
      "Training loss at epoch 207: 0.1497\n",
      "\n",
      "Start of epoch 208\n",
      "Training loss at epoch 208: 0.1497\n",
      "\n",
      "Start of epoch 209\n",
      "Training loss at epoch 209: 0.1497\n",
      "\n",
      "Start of epoch 210\n",
      "Training loss at epoch 210: 0.1497\n",
      "\n",
      "Start of epoch 211\n",
      "Training loss at epoch 211: 0.1497\n",
      "\n",
      "Start of epoch 212\n",
      "Training loss at epoch 212: 0.1496\n",
      "\n",
      "Start of epoch 213\n",
      "Training loss at epoch 213: 0.1496\n",
      "\n",
      "Start of epoch 214\n",
      "Training loss at epoch 214: 0.1496\n",
      "\n",
      "Start of epoch 215\n",
      "Training loss at epoch 215: 0.1496\n",
      "\n",
      "Start of epoch 216\n",
      "Training loss at epoch 216: 0.1496\n",
      "\n",
      "Start of epoch 217\n",
      "Training loss at epoch 217: 0.1496\n",
      "\n",
      "Start of epoch 218\n",
      "Training loss at epoch 218: 0.1496\n",
      "\n",
      "Start of epoch 219\n",
      "Training loss at epoch 219: 0.1496\n",
      "\n",
      "Start of epoch 220\n",
      "Training loss at epoch 220: 0.1496\n",
      "\n",
      "Start of epoch 221\n",
      "Training loss at epoch 221: 0.1496\n",
      "\n",
      "Start of epoch 222\n",
      "Training loss at epoch 222: 0.1496\n",
      "\n",
      "Start of epoch 223\n",
      "Training loss at epoch 223: 0.1496\n",
      "\n",
      "Start of epoch 224\n",
      "Training loss at epoch 224: 0.1496\n",
      "\n",
      "Start of epoch 225\n",
      "Training loss at epoch 225: 0.1496\n",
      "\n",
      "Start of epoch 226\n",
      "Training loss at epoch 226: 0.1496\n",
      "\n",
      "Start of epoch 227\n",
      "Training loss at epoch 227: 0.1496\n",
      "\n",
      "Start of epoch 228\n",
      "Training loss at epoch 228: 0.1496\n",
      "\n",
      "Start of epoch 229\n",
      "Training loss at epoch 229: 0.1496\n",
      "\n",
      "Start of epoch 230\n",
      "Training loss at epoch 230: 0.1496\n",
      "\n",
      "Start of epoch 231\n",
      "Training loss at epoch 231: 0.1496\n",
      "\n",
      "Start of epoch 232\n",
      "Training loss at epoch 232: 0.1496\n",
      "\n",
      "Start of epoch 233\n",
      "Training loss at epoch 233: 0.1496\n",
      "\n",
      "Start of epoch 234\n",
      "Training loss at epoch 234: 0.1496\n",
      "\n",
      "Start of epoch 235\n",
      "Training loss at epoch 235: 0.1496\n",
      "\n",
      "Start of epoch 236\n",
      "Training loss at epoch 236: 0.1496\n",
      "\n",
      "Start of epoch 237\n",
      "Training loss at epoch 237: 0.1496\n",
      "\n",
      "Start of epoch 238\n",
      "Training loss at epoch 238: 0.1496\n",
      "\n",
      "Start of epoch 239\n",
      "Training loss at epoch 239: 0.1496\n",
      "\n",
      "Start of epoch 240\n",
      "Training loss at epoch 240: 0.1496\n",
      "\n",
      "Start of epoch 241\n",
      "Training loss at epoch 241: 0.1496\n",
      "\n",
      "Start of epoch 242\n",
      "Training loss at epoch 242: 0.1496\n",
      "\n",
      "Start of epoch 243\n",
      "Training loss at epoch 243: 0.1496\n",
      "\n",
      "Start of epoch 244\n",
      "Training loss at epoch 244: 0.1496\n",
      "\n",
      "Start of epoch 245\n",
      "Training loss at epoch 245: 0.1496\n",
      "\n",
      "Start of epoch 246\n",
      "Training loss at epoch 246: 0.1496\n",
      "\n",
      "Start of epoch 247\n",
      "Training loss at epoch 247: 0.1496\n",
      "\n",
      "Start of epoch 248\n",
      "Training loss at epoch 248: 0.1496\n",
      "\n",
      "Start of epoch 249\n",
      "Training loss at epoch 249: 0.1496\n",
      "\n",
      "Start of epoch 250\n",
      "Training loss at epoch 250: 0.1496\n",
      "\n",
      "Start of epoch 251\n",
      "Training loss at epoch 251: 0.1496\n",
      "\n",
      "Start of epoch 252\n",
      "Training loss at epoch 252: 0.1496\n",
      "\n",
      "Start of epoch 253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 253: 0.1496\n",
      "\n",
      "Start of epoch 254\n",
      "Training loss at epoch 254: 0.1496\n",
      "\n",
      "Start of epoch 255\n",
      "Training loss at epoch 255: 0.1496\n",
      "\n",
      "Start of epoch 256\n",
      "Training loss at epoch 256: 0.1496\n",
      "\n",
      "Start of epoch 257\n",
      "Training loss at epoch 257: 0.1496\n",
      "\n",
      "Start of epoch 258\n",
      "Training loss at epoch 258: 0.1496\n",
      "\n",
      "Start of epoch 259\n",
      "Training loss at epoch 259: 0.1496\n",
      "\n",
      "Start of epoch 260\n",
      "Training loss at epoch 260: 0.1496\n",
      "\n",
      "Start of epoch 261\n",
      "Training loss at epoch 261: 0.1496\n",
      "\n",
      "Start of epoch 262\n",
      "Training loss at epoch 262: 0.1496\n",
      "\n",
      "Start of epoch 263\n",
      "Training loss at epoch 263: 0.1496\n",
      "\n",
      "Start of epoch 264\n",
      "Training loss at epoch 264: 0.1496\n",
      "\n",
      "Start of epoch 265\n",
      "Training loss at epoch 265: 0.1496\n",
      "\n",
      "Start of epoch 266\n",
      "Training loss at epoch 266: 0.1496\n",
      "\n",
      "Start of epoch 267\n",
      "Training loss at epoch 267: 0.1496\n",
      "\n",
      "Start of epoch 268\n",
      "Training loss at epoch 268: 0.1496\n",
      "\n",
      "Start of epoch 269\n",
      "Training loss at epoch 269: 0.1496\n",
      "\n",
      "Start of epoch 270\n",
      "Training loss at epoch 270: 0.1496\n",
      "\n",
      "Start of epoch 271\n",
      "Training loss at epoch 271: 0.1496\n",
      "\n",
      "Start of epoch 272\n",
      "Training loss at epoch 272: 0.1496\n",
      "\n",
      "Start of epoch 273\n",
      "Training loss at epoch 273: 0.1496\n",
      "\n",
      "Start of epoch 274\n",
      "Training loss at epoch 274: 0.1496\n",
      "\n",
      "Start of epoch 275\n",
      "Training loss at epoch 275: 0.1496\n",
      "\n",
      "Start of epoch 276\n",
      "Training loss at epoch 276: 0.1496\n",
      "\n",
      "Start of epoch 277\n",
      "Training loss at epoch 277: 0.1496\n",
      "\n",
      "Start of epoch 278\n",
      "Training loss at epoch 278: 0.1496\n",
      "\n",
      "Start of epoch 279\n",
      "Training loss at epoch 279: 0.1496\n",
      "\n",
      "Start of epoch 280\n",
      "Training loss at epoch 280: 0.1496\n",
      "\n",
      "Start of epoch 281\n",
      "Training loss at epoch 281: 0.1496\n",
      "\n",
      "Start of epoch 282\n",
      "Training loss at epoch 282: 0.1496\n",
      "\n",
      "Start of epoch 283\n",
      "Training loss at epoch 283: 0.1496\n",
      "\n",
      "Start of epoch 284\n",
      "Training loss at epoch 284: 0.1496\n",
      "\n",
      "Start of epoch 285\n",
      "Training loss at epoch 285: 0.1496\n",
      "\n",
      "Start of epoch 286\n",
      "Training loss at epoch 286: 0.1496\n",
      "\n",
      "Start of epoch 287\n",
      "Training loss at epoch 287: 0.1496\n",
      "\n",
      "Start of epoch 288\n",
      "Training loss at epoch 288: 0.1496\n",
      "\n",
      "Start of epoch 289\n",
      "Training loss at epoch 289: 0.1496\n",
      "\n",
      "Start of epoch 290\n",
      "Training loss at epoch 290: 0.1496\n",
      "\n",
      "Start of epoch 291\n",
      "Training loss at epoch 291: 0.1496\n",
      "\n",
      "Start of epoch 292\n",
      "Training loss at epoch 292: 0.1496\n",
      "\n",
      "Start of epoch 293\n",
      "Training loss at epoch 293: 0.1496\n",
      "\n",
      "Start of epoch 294\n",
      "Training loss at epoch 294: 0.1496\n",
      "\n",
      "Start of epoch 295\n",
      "Training loss at epoch 295: 0.1496\n",
      "\n",
      "Start of epoch 296\n",
      "Training loss at epoch 296: 0.1496\n",
      "\n",
      "Start of epoch 297\n",
      "Training loss at epoch 297: 0.1496\n",
      "\n",
      "Start of epoch 298\n",
      "Training loss at epoch 298: 0.1496\n",
      "\n",
      "Start of epoch 299\n",
      "Training loss at epoch 299: 0.1496\n",
      "\n",
      "Start of epoch 300\n",
      "Training loss at epoch 300: 0.1496\n",
      "\n",
      "Start of epoch 301\n",
      "Training loss at epoch 301: 0.1496\n",
      "\n",
      "Start of epoch 302\n",
      "Training loss at epoch 302: 0.1496\n",
      "\n",
      "Start of epoch 303\n",
      "Training loss at epoch 303: 0.1496\n",
      "\n",
      "Start of epoch 304\n",
      "Training loss at epoch 304: 0.1496\n",
      "\n",
      "Start of epoch 305\n",
      "Training loss at epoch 305: 0.1496\n",
      "\n",
      "Start of epoch 306\n",
      "Training loss at epoch 306: 0.1496\n",
      "\n",
      "Start of epoch 307\n",
      "Training loss at epoch 307: 0.1496\n",
      "\n",
      "Start of epoch 308\n",
      "Training loss at epoch 308: 0.1496\n",
      "\n",
      "Start of epoch 309\n",
      "Training loss at epoch 309: 0.1496\n",
      "\n",
      "Start of epoch 310\n",
      "Training loss at epoch 310: 0.1496\n",
      "\n",
      "Start of epoch 311\n",
      "Training loss at epoch 311: 0.1496\n",
      "\n",
      "Start of epoch 312\n",
      "Training loss at epoch 312: 0.1496\n",
      "\n",
      "Start of epoch 313\n",
      "Training loss at epoch 313: 0.1496\n",
      "\n",
      "Start of epoch 314\n",
      "Training loss at epoch 314: 0.1496\n",
      "\n",
      "Start of epoch 315\n",
      "Training loss at epoch 315: 0.1496\n",
      "\n",
      "Start of epoch 316\n",
      "Training loss at epoch 316: 0.1496\n",
      "\n",
      "Start of epoch 317\n",
      "Training loss at epoch 317: 0.1496\n",
      "\n",
      "Start of epoch 318\n",
      "Training loss at epoch 318: 0.1496\n",
      "\n",
      "Start of epoch 319\n",
      "Training loss at epoch 319: 0.1496\n",
      "\n",
      "Start of epoch 320\n",
      "Training loss at epoch 320: 0.1496\n",
      "\n",
      "Start of epoch 321\n",
      "Training loss at epoch 321: 0.1496\n",
      "\n",
      "Start of epoch 322\n",
      "Training loss at epoch 322: 0.1496\n",
      "\n",
      "Start of epoch 323\n",
      "Training loss at epoch 323: 0.1496\n",
      "\n",
      "Start of epoch 324\n",
      "Training loss at epoch 324: 0.1496\n",
      "\n",
      "Start of epoch 325\n",
      "Training loss at epoch 325: 0.1496\n",
      "\n",
      "Start of epoch 326\n",
      "Training loss at epoch 326: 0.1496\n",
      "\n",
      "Start of epoch 327\n",
      "Training loss at epoch 327: 0.1496\n",
      "\n",
      "Start of epoch 328\n",
      "Training loss at epoch 328: 0.1496\n",
      "\n",
      "Start of epoch 329\n",
      "Training loss at epoch 329: 0.1496\n",
      "\n",
      "Start of epoch 330\n",
      "Training loss at epoch 330: 0.1496\n",
      "\n",
      "Start of epoch 331\n",
      "Training loss at epoch 331: 0.1496\n",
      "\n",
      "Start of epoch 332\n",
      "Training loss at epoch 332: 0.1496\n",
      "\n",
      "Start of epoch 333\n",
      "Training loss at epoch 333: 0.1496\n",
      "\n",
      "Start of epoch 334\n",
      "Training loss at epoch 334: 0.1496\n",
      "\n",
      "Start of epoch 335\n",
      "Training loss at epoch 335: 0.1496\n",
      "\n",
      "Start of epoch 336\n",
      "Training loss at epoch 336: 0.1496\n",
      "\n",
      "Start of epoch 337\n",
      "Training loss at epoch 337: 0.1496\n",
      "\n",
      "Start of epoch 338\n",
      "Training loss at epoch 338: 0.1496\n",
      "\n",
      "Start of epoch 339\n",
      "Training loss at epoch 339: 0.1496\n",
      "\n",
      "Start of epoch 340\n",
      "Training loss at epoch 340: 0.1496\n",
      "\n",
      "Start of epoch 341\n",
      "Training loss at epoch 341: 0.1496\n",
      "\n",
      "Start of epoch 342\n",
      "Training loss at epoch 342: 0.1496\n",
      "\n",
      "Start of epoch 343\n",
      "Training loss at epoch 343: 0.1496\n",
      "\n",
      "Start of epoch 344\n",
      "Training loss at epoch 344: 0.1496\n",
      "\n",
      "Start of epoch 345\n",
      "Training loss at epoch 345: 0.1496\n",
      "\n",
      "Start of epoch 346\n",
      "Training loss at epoch 346: 0.1496\n",
      "\n",
      "Start of epoch 347\n",
      "Training loss at epoch 347: 0.1496\n",
      "\n",
      "Start of epoch 348\n",
      "Training loss at epoch 348: 0.1496\n",
      "\n",
      "Start of epoch 349\n",
      "Training loss at epoch 349: 0.1496\n",
      "\n",
      "Start of epoch 350\n",
      "Training loss at epoch 350: 0.1496\n",
      "\n",
      "Start of epoch 351\n",
      "Training loss at epoch 351: 0.1496\n",
      "\n",
      "Start of epoch 352\n",
      "Training loss at epoch 352: 0.1496\n",
      "\n",
      "Start of epoch 353\n",
      "Training loss at epoch 353: 0.1496\n",
      "\n",
      "Start of epoch 354\n",
      "Training loss at epoch 354: 0.1496\n",
      "\n",
      "Start of epoch 355\n",
      "Training loss at epoch 355: 0.1496\n",
      "\n",
      "Start of epoch 356\n",
      "Training loss at epoch 356: 0.1496\n",
      "\n",
      "Start of epoch 357\n",
      "Training loss at epoch 357: 0.1496\n",
      "\n",
      "Start of epoch 358\n",
      "Training loss at epoch 358: 0.1496\n",
      "\n",
      "Start of epoch 359\n",
      "Training loss at epoch 359: 0.1496\n",
      "\n",
      "Start of epoch 360\n",
      "Training loss at epoch 360: 0.1496\n",
      "\n",
      "Start of epoch 361\n",
      "Training loss at epoch 361: 0.1496\n",
      "\n",
      "Start of epoch 362\n",
      "Training loss at epoch 362: 0.1496\n",
      "\n",
      "Start of epoch 363\n",
      "Training loss at epoch 363: 0.1496\n",
      "\n",
      "Start of epoch 364\n",
      "Training loss at epoch 364: 0.1496\n",
      "\n",
      "Start of epoch 365\n",
      "Training loss at epoch 365: 0.1496\n",
      "\n",
      "Start of epoch 366\n",
      "Training loss at epoch 366: 0.1496\n",
      "\n",
      "Start of epoch 367\n",
      "Training loss at epoch 367: 0.1496\n",
      "\n",
      "Start of epoch 368\n",
      "Training loss at epoch 368: 0.1496\n",
      "\n",
      "Start of epoch 369\n",
      "Training loss at epoch 369: 0.1496\n",
      "\n",
      "Start of epoch 370\n",
      "Training loss at epoch 370: 0.1496\n",
      "\n",
      "Start of epoch 371\n",
      "Training loss at epoch 371: 0.1496\n",
      "\n",
      "Start of epoch 372\n",
      "Training loss at epoch 372: 0.1496\n",
      "\n",
      "Start of epoch 373\n",
      "Training loss at epoch 373: 0.1496\n",
      "\n",
      "Start of epoch 374\n",
      "Training loss at epoch 374: 0.1496\n",
      "\n",
      "Start of epoch 375\n",
      "Training loss at epoch 375: 0.1496\n",
      "\n",
      "Start of epoch 376\n",
      "Training loss at epoch 376: 0.1496\n",
      "\n",
      "Start of epoch 377\n",
      "Training loss at epoch 377: 0.1496\n",
      "\n",
      "Start of epoch 378\n",
      "Training loss at epoch 378: 0.1496\n",
      "\n",
      "Start of epoch 379\n",
      "Training loss at epoch 379: 0.1496\n",
      "\n",
      "Start of epoch 380\n",
      "Training loss at epoch 380: 0.1496\n",
      "\n",
      "Start of epoch 381\n",
      "Training loss at epoch 381: 0.1496\n",
      "\n",
      "Start of epoch 382\n",
      "Training loss at epoch 382: 0.1496\n",
      "\n",
      "Start of epoch 383\n",
      "Training loss at epoch 383: 0.1496\n",
      "\n",
      "Start of epoch 384\n",
      "Training loss at epoch 384: 0.1496\n",
      "\n",
      "Start of epoch 385\n",
      "Training loss at epoch 385: 0.1496\n",
      "\n",
      "Start of epoch 386\n",
      "Training loss at epoch 386: 0.1496\n",
      "\n",
      "Start of epoch 387\n",
      "Training loss at epoch 387: 0.1496\n",
      "\n",
      "Start of epoch 388\n",
      "Training loss at epoch 388: 0.1496\n",
      "\n",
      "Start of epoch 389\n",
      "Training loss at epoch 389: 0.1496\n",
      "\n",
      "Start of epoch 390\n",
      "Training loss at epoch 390: 0.1496\n",
      "\n",
      "Start of epoch 391\n",
      "Training loss at epoch 391: 0.1496\n",
      "\n",
      "Start of epoch 392\n",
      "Training loss at epoch 392: 0.1496\n",
      "\n",
      "Start of epoch 393\n",
      "Training loss at epoch 393: 0.1496\n",
      "\n",
      "Start of epoch 394\n",
      "Training loss at epoch 394: 0.1496\n",
      "\n",
      "Start of epoch 395\n",
      "Training loss at epoch 395: 0.1496\n",
      "\n",
      "Start of epoch 396\n",
      "Training loss at epoch 396: 0.1496\n",
      "\n",
      "Start of epoch 397\n",
      "Training loss at epoch 397: 0.1496\n",
      "\n",
      "Start of epoch 398\n",
      "Training loss at epoch 398: 0.1496\n",
      "\n",
      "Start of epoch 399\n",
      "Training loss at epoch 399: 0.1496\n",
      "\n",
      "Start of epoch 400\n",
      "Training loss at epoch 400: 0.1496\n",
      "\n",
      "Start of epoch 401\n",
      "Training loss at epoch 401: 0.1496\n",
      "\n",
      "Start of epoch 402\n",
      "Training loss at epoch 402: 0.1496\n",
      "\n",
      "Start of epoch 403\n",
      "Training loss at epoch 403: 0.1496\n",
      "\n",
      "Start of epoch 404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 404: 0.1496\n",
      "\n",
      "Start of epoch 405\n",
      "Training loss at epoch 405: 0.1496\n",
      "\n",
      "Start of epoch 406\n",
      "Training loss at epoch 406: 0.1496\n",
      "\n",
      "Start of epoch 407\n",
      "Training loss at epoch 407: 0.1496\n",
      "\n",
      "Start of epoch 408\n",
      "Training loss at epoch 408: 0.1496\n",
      "\n",
      "Start of epoch 409\n",
      "Training loss at epoch 409: 0.1496\n",
      "\n",
      "Start of epoch 410\n",
      "Training loss at epoch 410: 0.1496\n",
      "\n",
      "Start of epoch 411\n",
      "Training loss at epoch 411: 0.1496\n",
      "\n",
      "Start of epoch 412\n",
      "Training loss at epoch 412: 0.1496\n",
      "\n",
      "Start of epoch 413\n",
      "Training loss at epoch 413: 0.1496\n",
      "\n",
      "Start of epoch 414\n",
      "Training loss at epoch 414: 0.1496\n",
      "\n",
      "Start of epoch 415\n",
      "Training loss at epoch 415: 0.1496\n",
      "\n",
      "Start of epoch 416\n",
      "Training loss at epoch 416: 0.1496\n",
      "\n",
      "Start of epoch 417\n",
      "Training loss at epoch 417: 0.1496\n",
      "\n",
      "Start of epoch 418\n",
      "Training loss at epoch 418: 0.1496\n",
      "\n",
      "Start of epoch 419\n",
      "Training loss at epoch 419: 0.1496\n",
      "\n",
      "Start of epoch 420\n",
      "Training loss at epoch 420: 0.1496\n",
      "\n",
      "Start of epoch 421\n",
      "Training loss at epoch 421: 0.1496\n",
      "\n",
      "Start of epoch 422\n",
      "Training loss at epoch 422: 0.1496\n",
      "\n",
      "Start of epoch 423\n",
      "Training loss at epoch 423: 0.1496\n",
      "\n",
      "Start of epoch 424\n",
      "Training loss at epoch 424: 0.1496\n",
      "\n",
      "Start of epoch 425\n",
      "Training loss at epoch 425: 0.1496\n",
      "\n",
      "Start of epoch 426\n",
      "Training loss at epoch 426: 0.1496\n",
      "\n",
      "Start of epoch 427\n",
      "Training loss at epoch 427: 0.1496\n",
      "\n",
      "Start of epoch 428\n",
      "Training loss at epoch 428: 0.1496\n",
      "\n",
      "Start of epoch 429\n",
      "Training loss at epoch 429: 0.1496\n",
      "\n",
      "Start of epoch 430\n",
      "Training loss at epoch 430: 0.1496\n",
      "\n",
      "Start of epoch 431\n",
      "Training loss at epoch 431: 0.1496\n",
      "\n",
      "Start of epoch 432\n",
      "Training loss at epoch 432: 0.1496\n",
      "\n",
      "Start of epoch 433\n",
      "Training loss at epoch 433: 0.1496\n",
      "\n",
      "Start of epoch 434\n",
      "Training loss at epoch 434: 0.1496\n",
      "\n",
      "Start of epoch 435\n",
      "Training loss at epoch 435: 0.1496\n",
      "\n",
      "Start of epoch 436\n",
      "Training loss at epoch 436: 0.1496\n",
      "\n",
      "Start of epoch 437\n",
      "Training loss at epoch 437: 0.1496\n",
      "\n",
      "Start of epoch 438\n",
      "Training loss at epoch 438: 0.1496\n",
      "\n",
      "Start of epoch 439\n",
      "Training loss at epoch 439: 0.1496\n",
      "\n",
      "Start of epoch 440\n",
      "Training loss at epoch 440: 0.1496\n",
      "\n",
      "Start of epoch 441\n",
      "Training loss at epoch 441: 0.1496\n",
      "\n",
      "Start of epoch 442\n",
      "Training loss at epoch 442: 0.1496\n",
      "\n",
      "Start of epoch 443\n",
      "Training loss at epoch 443: 0.1496\n",
      "\n",
      "Start of epoch 444\n",
      "Training loss at epoch 444: 0.1496\n",
      "\n",
      "Start of epoch 445\n",
      "Training loss at epoch 445: 0.1496\n",
      "\n",
      "Start of epoch 446\n",
      "Training loss at epoch 446: 0.1496\n",
      "\n",
      "Start of epoch 447\n",
      "Training loss at epoch 447: 0.1496\n",
      "\n",
      "Start of epoch 448\n",
      "Training loss at epoch 448: 0.1496\n",
      "\n",
      "Start of epoch 449\n",
      "Training loss at epoch 449: 0.1496\n",
      "\n",
      "Start of epoch 450\n",
      "Training loss at epoch 450: 0.1496\n",
      "\n",
      "Start of epoch 451\n",
      "Training loss at epoch 451: 0.1496\n",
      "\n",
      "Start of epoch 452\n",
      "Training loss at epoch 452: 0.1496\n",
      "\n",
      "Start of epoch 453\n",
      "Training loss at epoch 453: 0.1496\n",
      "\n",
      "Start of epoch 454\n",
      "Training loss at epoch 454: 0.1496\n",
      "\n",
      "Start of epoch 455\n",
      "Training loss at epoch 455: 0.1496\n",
      "\n",
      "Start of epoch 456\n",
      "Training loss at epoch 456: 0.1496\n",
      "\n",
      "Start of epoch 457\n",
      "Training loss at epoch 457: 0.1496\n",
      "\n",
      "Start of epoch 458\n",
      "Training loss at epoch 458: 0.1496\n",
      "\n",
      "Start of epoch 459\n",
      "Training loss at epoch 459: 0.1496\n",
      "\n",
      "Start of epoch 460\n",
      "Training loss at epoch 460: 0.1496\n",
      "\n",
      "Start of epoch 461\n",
      "Training loss at epoch 461: 0.1496\n",
      "\n",
      "Start of epoch 462\n",
      "Training loss at epoch 462: 0.1496\n",
      "\n",
      "Start of epoch 463\n",
      "Training loss at epoch 463: 0.1496\n",
      "\n",
      "Start of epoch 464\n",
      "Training loss at epoch 464: 0.1496\n",
      "\n",
      "Start of epoch 465\n",
      "Training loss at epoch 465: 0.1496\n",
      "\n",
      "Start of epoch 466\n",
      "Training loss at epoch 466: 0.1496\n",
      "\n",
      "Start of epoch 467\n",
      "Training loss at epoch 467: 0.1496\n",
      "\n",
      "Start of epoch 468\n",
      "Training loss at epoch 468: 0.1496\n",
      "\n",
      "Start of epoch 469\n",
      "Training loss at epoch 469: 0.1496\n",
      "\n",
      "Start of epoch 470\n",
      "Training loss at epoch 470: 0.1496\n",
      "\n",
      "Start of epoch 471\n",
      "Training loss at epoch 471: 0.1496\n",
      "\n",
      "Start of epoch 472\n",
      "Training loss at epoch 472: 0.1496\n",
      "\n",
      "Start of epoch 473\n",
      "Training loss at epoch 473: 0.1496\n",
      "\n",
      "Start of epoch 474\n",
      "Training loss at epoch 474: 0.1496\n",
      "\n",
      "Start of epoch 475\n",
      "Training loss at epoch 475: 0.1496\n",
      "\n",
      "Start of epoch 476\n",
      "Training loss at epoch 476: 0.1496\n",
      "\n",
      "Start of epoch 477\n",
      "Training loss at epoch 477: 0.1496\n",
      "\n",
      "Start of epoch 478\n",
      "Training loss at epoch 478: 0.1496\n",
      "\n",
      "Start of epoch 479\n",
      "Training loss at epoch 479: 0.1496\n",
      "\n",
      "Start of epoch 480\n",
      "Training loss at epoch 480: 0.1496\n",
      "\n",
      "Start of epoch 481\n",
      "Training loss at epoch 481: 0.1496\n",
      "\n",
      "Start of epoch 482\n",
      "Training loss at epoch 482: 0.1496\n",
      "\n",
      "Start of epoch 483\n",
      "Training loss at epoch 483: 0.1496\n",
      "\n",
      "Start of epoch 484\n",
      "Training loss at epoch 484: 0.1496\n",
      "\n",
      "Start of epoch 485\n",
      "Training loss at epoch 485: 0.1496\n",
      "\n",
      "Start of epoch 486\n",
      "Training loss at epoch 486: 0.1496\n",
      "\n",
      "Start of epoch 487\n",
      "Training loss at epoch 487: 0.1496\n",
      "\n",
      "Start of epoch 488\n",
      "Training loss at epoch 488: 0.1496\n",
      "\n",
      "Start of epoch 489\n",
      "Training loss at epoch 489: 0.1496\n",
      "\n",
      "Start of epoch 490\n",
      "Training loss at epoch 490: 0.1496\n",
      "\n",
      "Start of epoch 491\n",
      "Training loss at epoch 491: 0.1496\n",
      "\n",
      "Start of epoch 492\n",
      "Training loss at epoch 492: 0.1496\n",
      "\n",
      "Start of epoch 493\n",
      "Training loss at epoch 493: 0.1496\n",
      "\n",
      "Start of epoch 494\n",
      "Training loss at epoch 494: 0.1496\n",
      "\n",
      "Start of epoch 495\n",
      "Training loss at epoch 495: 0.1496\n",
      "\n",
      "Start of epoch 496\n",
      "Training loss at epoch 496: 0.1496\n",
      "\n",
      "Start of epoch 497\n",
      "Training loss at epoch 497: 0.1496\n",
      "\n",
      "Start of epoch 498\n",
      "Training loss at epoch 498: 0.1496\n",
      "\n",
      "Start of epoch 499\n",
      "Training loss at epoch 499: 0.1496\n",
      "[<tf.Variable 'parameters:0' shape=(15,) dtype=float32, numpy=\n",
      "array([2.3167903e+00, 4.2521530e-03, 3.5308974e+00, 8.1289971e-01,\n",
      "       2.4721651e+00, 2.9670606e+00, 5.0760093e+00, 4.9826139e-01,\n",
      "       4.3356404e+00, 2.0091569e+00, 5.9720407e+00, 3.0488985e+00,\n",
      "       4.0673013e+00, 1.4985667e+00, 2.7154419e+00], dtype=float32)>]\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 0.9539\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 0.9172\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.8905\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.8726\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.8614\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.8549\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.8515\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.8495\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.8477\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.8450\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.8408\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.8346\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.8263\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.8159\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.8037\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.7904\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.7766\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.7631\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.7507\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.7399\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.7312\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.7244\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.7190\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.7142\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.7090\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.7025\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.6947\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.6855\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.6756\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.6656\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.6561\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.6473\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.6395\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.6324\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.6256\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.6188\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.6112\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.6023\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.5914\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.5780\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.5616\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.5423\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.5207\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.4981\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.4760\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.4558\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.4372\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.4189\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.4001\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.3816\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.3654\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.3528\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.3440\n",
      "\n",
      "Start of epoch 53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 53: 0.3372\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.3308\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.3242\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.3179\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.3120\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.3054\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.2975\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.2888\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.2799\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.2706\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.2605\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.2499\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.2397\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.2301\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.2205\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.2114\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.2034\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.1965\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.1902\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.1848\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.1804\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.1765\n",
      "\n",
      "Start of epoch 75\n",
      "Training loss at epoch 75: 0.1731\n",
      "\n",
      "Start of epoch 76\n",
      "Training loss at epoch 76: 0.1709\n",
      "\n",
      "Start of epoch 77\n",
      "Training loss at epoch 77: 0.1696\n",
      "\n",
      "Start of epoch 78\n",
      "Training loss at epoch 78: 0.1689\n",
      "\n",
      "Start of epoch 79\n",
      "Training loss at epoch 79: 0.1690\n",
      "\n",
      "Start of epoch 80\n",
      "Training loss at epoch 80: 0.1696\n",
      "\n",
      "Start of epoch 81\n",
      "Training loss at epoch 81: 0.1701\n",
      "\n",
      "Start of epoch 82\n",
      "Training loss at epoch 82: 0.1707\n",
      "\n",
      "Start of epoch 83\n",
      "Training loss at epoch 83: 0.1712\n",
      "\n",
      "Start of epoch 84\n",
      "Training loss at epoch 84: 0.1715\n",
      "\n",
      "Start of epoch 85\n",
      "Training loss at epoch 85: 0.1716\n",
      "\n",
      "Start of epoch 86\n",
      "Training loss at epoch 86: 0.1717\n",
      "\n",
      "Start of epoch 87\n",
      "Training loss at epoch 87: 0.1717\n",
      "\n",
      "Start of epoch 88\n",
      "Training loss at epoch 88: 0.1716\n",
      "\n",
      "Start of epoch 89\n",
      "Training loss at epoch 89: 0.1715\n",
      "\n",
      "Start of epoch 90\n",
      "Training loss at epoch 90: 0.1713\n",
      "\n",
      "Start of epoch 91\n",
      "Training loss at epoch 91: 0.1709\n",
      "\n",
      "Start of epoch 92\n",
      "Training loss at epoch 92: 0.1705\n",
      "\n",
      "Start of epoch 93\n",
      "Training loss at epoch 93: 0.1700\n",
      "\n",
      "Start of epoch 94\n",
      "Training loss at epoch 94: 0.1694\n",
      "\n",
      "Start of epoch 95\n",
      "Training loss at epoch 95: 0.1688\n",
      "\n",
      "Start of epoch 96\n",
      "Training loss at epoch 96: 0.1683\n",
      "\n",
      "Start of epoch 97\n",
      "Training loss at epoch 97: 0.1678\n",
      "\n",
      "Start of epoch 98\n",
      "Training loss at epoch 98: 0.1674\n",
      "\n",
      "Start of epoch 99\n",
      "Training loss at epoch 99: 0.1671\n",
      "\n",
      "Start of epoch 100\n",
      "Training loss at epoch 100: 0.1668\n",
      "\n",
      "Start of epoch 101\n",
      "Training loss at epoch 101: 0.1666\n",
      "\n",
      "Start of epoch 102\n",
      "Training loss at epoch 102: 0.1664\n",
      "\n",
      "Start of epoch 103\n",
      "Training loss at epoch 103: 0.1662\n",
      "\n",
      "Start of epoch 104\n",
      "Training loss at epoch 104: 0.1660\n",
      "\n",
      "Start of epoch 105\n",
      "Training loss at epoch 105: 0.1659\n",
      "\n",
      "Start of epoch 106\n",
      "Training loss at epoch 106: 0.1658\n",
      "\n",
      "Start of epoch 107\n",
      "Training loss at epoch 107: 0.1657\n",
      "\n",
      "Start of epoch 108\n",
      "Training loss at epoch 108: 0.1656\n",
      "\n",
      "Start of epoch 109\n",
      "Training loss at epoch 109: 0.1656\n",
      "\n",
      "Start of epoch 110\n",
      "Training loss at epoch 110: 0.1655\n",
      "\n",
      "Start of epoch 111\n",
      "Training loss at epoch 111: 0.1655\n",
      "\n",
      "Start of epoch 112\n",
      "Training loss at epoch 112: 0.1654\n",
      "\n",
      "Start of epoch 113\n",
      "Training loss at epoch 113: 0.1653\n",
      "\n",
      "Start of epoch 114\n",
      "Training loss at epoch 114: 0.1652\n",
      "\n",
      "Start of epoch 115\n",
      "Training loss at epoch 115: 0.1651\n",
      "\n",
      "Start of epoch 116\n",
      "Training loss at epoch 116: 0.1650\n",
      "\n",
      "Start of epoch 117\n",
      "Training loss at epoch 117: 0.1650\n",
      "\n",
      "Start of epoch 118\n",
      "Training loss at epoch 118: 0.1649\n",
      "\n",
      "Start of epoch 119\n",
      "Training loss at epoch 119: 0.1648\n",
      "\n",
      "Start of epoch 120\n",
      "Training loss at epoch 120: 0.1648\n",
      "\n",
      "Start of epoch 121\n",
      "Training loss at epoch 121: 0.1647\n",
      "\n",
      "Start of epoch 122\n",
      "Training loss at epoch 122: 0.1647\n",
      "\n",
      "Start of epoch 123\n",
      "Training loss at epoch 123: 0.1646\n",
      "\n",
      "Start of epoch 124\n",
      "Training loss at epoch 124: 0.1646\n",
      "\n",
      "Start of epoch 125\n",
      "Training loss at epoch 125: 0.1646\n",
      "\n",
      "Start of epoch 126\n",
      "Training loss at epoch 126: 0.1645\n",
      "\n",
      "Start of epoch 127\n",
      "Training loss at epoch 127: 0.1645\n",
      "\n",
      "Start of epoch 128\n",
      "Training loss at epoch 128: 0.1645\n",
      "\n",
      "Start of epoch 129\n",
      "Training loss at epoch 129: 0.1645\n",
      "\n",
      "Start of epoch 130\n",
      "Training loss at epoch 130: 0.1645\n",
      "\n",
      "Start of epoch 131\n",
      "Training loss at epoch 131: 0.1644\n",
      "\n",
      "Start of epoch 132\n",
      "Training loss at epoch 132: 0.1644\n",
      "\n",
      "Start of epoch 133\n",
      "Training loss at epoch 133: 0.1644\n",
      "\n",
      "Start of epoch 134\n",
      "Training loss at epoch 134: 0.1644\n",
      "\n",
      "Start of epoch 135\n",
      "Training loss at epoch 135: 0.1644\n",
      "\n",
      "Start of epoch 136\n",
      "Training loss at epoch 136: 0.1644\n",
      "\n",
      "Start of epoch 137\n",
      "Training loss at epoch 137: 0.1643\n",
      "\n",
      "Start of epoch 138\n",
      "Training loss at epoch 138: 0.1643\n",
      "\n",
      "Start of epoch 139\n",
      "Training loss at epoch 139: 0.1643\n",
      "\n",
      "Start of epoch 140\n",
      "Training loss at epoch 140: 0.1643\n",
      "\n",
      "Start of epoch 141\n",
      "Training loss at epoch 141: 0.1643\n",
      "\n",
      "Start of epoch 142\n",
      "Training loss at epoch 142: 0.1643\n",
      "\n",
      "Start of epoch 143\n",
      "Training loss at epoch 143: 0.1642\n",
      "\n",
      "Start of epoch 144\n",
      "Training loss at epoch 144: 0.1642\n",
      "\n",
      "Start of epoch 145\n",
      "Training loss at epoch 145: 0.1642\n",
      "\n",
      "Start of epoch 146\n",
      "Training loss at epoch 146: 0.1642\n",
      "\n",
      "Start of epoch 147\n",
      "Training loss at epoch 147: 0.1642\n",
      "\n",
      "Start of epoch 148\n",
      "Training loss at epoch 148: 0.1642\n",
      "\n",
      "Start of epoch 149\n",
      "Training loss at epoch 149: 0.1642\n",
      "\n",
      "Start of epoch 150\n",
      "Training loss at epoch 150: 0.1642\n",
      "\n",
      "Start of epoch 151\n",
      "Training loss at epoch 151: 0.1642\n",
      "\n",
      "Start of epoch 152\n",
      "Training loss at epoch 152: 0.1642\n",
      "\n",
      "Start of epoch 153\n",
      "Training loss at epoch 153: 0.1641\n",
      "\n",
      "Start of epoch 154\n",
      "Training loss at epoch 154: 0.1641\n",
      "\n",
      "Start of epoch 155\n",
      "Training loss at epoch 155: 0.1641\n",
      "\n",
      "Start of epoch 156\n",
      "Training loss at epoch 156: 0.1641\n",
      "\n",
      "Start of epoch 157\n",
      "Training loss at epoch 157: 0.1641\n",
      "\n",
      "Start of epoch 158\n",
      "Training loss at epoch 158: 0.1641\n",
      "\n",
      "Start of epoch 159\n",
      "Training loss at epoch 159: 0.1641\n",
      "\n",
      "Start of epoch 160\n",
      "Training loss at epoch 160: 0.1641\n",
      "\n",
      "Start of epoch 161\n",
      "Training loss at epoch 161: 0.1641\n",
      "\n",
      "Start of epoch 162\n",
      "Training loss at epoch 162: 0.1641\n",
      "\n",
      "Start of epoch 163\n",
      "Training loss at epoch 163: 0.1641\n",
      "\n",
      "Start of epoch 164\n",
      "Training loss at epoch 164: 0.1641\n",
      "\n",
      "Start of epoch 165\n",
      "Training loss at epoch 165: 0.1641\n",
      "\n",
      "Start of epoch 166\n",
      "Training loss at epoch 166: 0.1641\n",
      "\n",
      "Start of epoch 167\n",
      "Training loss at epoch 167: 0.1641\n",
      "\n",
      "Start of epoch 168\n",
      "Training loss at epoch 168: 0.1641\n",
      "\n",
      "Start of epoch 169\n",
      "Training loss at epoch 169: 0.1641\n",
      "\n",
      "Start of epoch 170\n",
      "Training loss at epoch 170: 0.1640\n",
      "\n",
      "Start of epoch 171\n",
      "Training loss at epoch 171: 0.1640\n",
      "\n",
      "Start of epoch 172\n",
      "Training loss at epoch 172: 0.1640\n",
      "\n",
      "Start of epoch 173\n",
      "Training loss at epoch 173: 0.1640\n",
      "\n",
      "Start of epoch 174\n",
      "Training loss at epoch 174: 0.1640\n",
      "\n",
      "Start of epoch 175\n",
      "Training loss at epoch 175: 0.1640\n",
      "\n",
      "Start of epoch 176\n",
      "Training loss at epoch 176: 0.1640\n",
      "\n",
      "Start of epoch 177\n",
      "Training loss at epoch 177: 0.1640\n",
      "\n",
      "Start of epoch 178\n",
      "Training loss at epoch 178: 0.1640\n",
      "\n",
      "Start of epoch 179\n",
      "Training loss at epoch 179: 0.1640\n",
      "\n",
      "Start of epoch 180\n",
      "Training loss at epoch 180: 0.1640\n",
      "\n",
      "Start of epoch 181\n",
      "Training loss at epoch 181: 0.1640\n",
      "\n",
      "Start of epoch 182\n",
      "Training loss at epoch 182: 0.1640\n",
      "\n",
      "Start of epoch 183\n",
      "Training loss at epoch 183: 0.1640\n",
      "\n",
      "Start of epoch 184\n",
      "Training loss at epoch 184: 0.1640\n",
      "\n",
      "Start of epoch 185\n",
      "Training loss at epoch 185: 0.1640\n",
      "\n",
      "Start of epoch 186\n",
      "Training loss at epoch 186: 0.1640\n",
      "\n",
      "Start of epoch 187\n",
      "Training loss at epoch 187: 0.1640\n",
      "\n",
      "Start of epoch 188\n",
      "Training loss at epoch 188: 0.1640\n",
      "\n",
      "Start of epoch 189\n",
      "Training loss at epoch 189: 0.1640\n",
      "\n",
      "Start of epoch 190\n",
      "Training loss at epoch 190: 0.1640\n",
      "\n",
      "Start of epoch 191\n",
      "Training loss at epoch 191: 0.1640\n",
      "\n",
      "Start of epoch 192\n",
      "Training loss at epoch 192: 0.1640\n",
      "\n",
      "Start of epoch 193\n",
      "Training loss at epoch 193: 0.1640\n",
      "\n",
      "Start of epoch 194\n",
      "Training loss at epoch 194: 0.1640\n",
      "\n",
      "Start of epoch 195\n",
      "Training loss at epoch 195: 0.1640\n",
      "\n",
      "Start of epoch 196\n",
      "Training loss at epoch 196: 0.1640\n",
      "\n",
      "Start of epoch 197\n",
      "Training loss at epoch 197: 0.1640\n",
      "\n",
      "Start of epoch 198\n",
      "Training loss at epoch 198: 0.1640\n",
      "\n",
      "Start of epoch 199\n",
      "Training loss at epoch 199: 0.1640\n",
      "\n",
      "Start of epoch 200\n",
      "Training loss at epoch 200: 0.1640\n",
      "\n",
      "Start of epoch 201\n",
      "Training loss at epoch 201: 0.1640\n",
      "\n",
      "Start of epoch 202\n",
      "Training loss at epoch 202: 0.1640\n",
      "\n",
      "Start of epoch 203\n",
      "Training loss at epoch 203: 0.1640\n",
      "\n",
      "Start of epoch 204\n",
      "Training loss at epoch 204: 0.1640\n",
      "\n",
      "Start of epoch 205\n",
      "Training loss at epoch 205: 0.1639\n",
      "\n",
      "Start of epoch 206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 206: 0.1639\n",
      "\n",
      "Start of epoch 207\n",
      "Training loss at epoch 207: 0.1639\n",
      "\n",
      "Start of epoch 208\n",
      "Training loss at epoch 208: 0.1639\n",
      "\n",
      "Start of epoch 209\n",
      "Training loss at epoch 209: 0.1639\n",
      "\n",
      "Start of epoch 210\n",
      "Training loss at epoch 210: 0.1639\n",
      "\n",
      "Start of epoch 211\n",
      "Training loss at epoch 211: 0.1639\n",
      "\n",
      "Start of epoch 212\n",
      "Training loss at epoch 212: 0.1639\n",
      "\n",
      "Start of epoch 213\n",
      "Training loss at epoch 213: 0.1639\n",
      "\n",
      "Start of epoch 214\n",
      "Training loss at epoch 214: 0.1639\n",
      "\n",
      "Start of epoch 215\n",
      "Training loss at epoch 215: 0.1639\n",
      "\n",
      "Start of epoch 216\n",
      "Training loss at epoch 216: 0.1639\n",
      "\n",
      "Start of epoch 217\n",
      "Training loss at epoch 217: 0.1639\n",
      "\n",
      "Start of epoch 218\n",
      "Training loss at epoch 218: 0.1639\n",
      "\n",
      "Start of epoch 219\n",
      "Training loss at epoch 219: 0.1639\n",
      "\n",
      "Start of epoch 220\n",
      "Training loss at epoch 220: 0.1639\n",
      "\n",
      "Start of epoch 221\n",
      "Training loss at epoch 221: 0.1639\n",
      "\n",
      "Start of epoch 222\n",
      "Training loss at epoch 222: 0.1639\n",
      "\n",
      "Start of epoch 223\n",
      "Training loss at epoch 223: 0.1639\n",
      "\n",
      "Start of epoch 224\n",
      "Training loss at epoch 224: 0.1639\n",
      "\n",
      "Start of epoch 225\n",
      "Training loss at epoch 225: 0.1639\n",
      "\n",
      "Start of epoch 226\n",
      "Training loss at epoch 226: 0.1639\n",
      "\n",
      "Start of epoch 227\n",
      "Training loss at epoch 227: 0.1639\n",
      "\n",
      "Start of epoch 228\n",
      "Training loss at epoch 228: 0.1639\n",
      "\n",
      "Start of epoch 229\n",
      "Training loss at epoch 229: 0.1639\n",
      "\n",
      "Start of epoch 230\n",
      "Training loss at epoch 230: 0.1639\n",
      "\n",
      "Start of epoch 231\n",
      "Training loss at epoch 231: 0.1639\n",
      "\n",
      "Start of epoch 232\n",
      "Training loss at epoch 232: 0.1639\n",
      "\n",
      "Start of epoch 233\n",
      "Training loss at epoch 233: 0.1639\n",
      "\n",
      "Start of epoch 234\n",
      "Training loss at epoch 234: 0.1639\n",
      "\n",
      "Start of epoch 235\n",
      "Training loss at epoch 235: 0.1639\n",
      "\n",
      "Start of epoch 236\n",
      "Training loss at epoch 236: 0.1639\n",
      "\n",
      "Start of epoch 237\n",
      "Training loss at epoch 237: 0.1639\n",
      "\n",
      "Start of epoch 238\n",
      "Training loss at epoch 238: 0.1639\n",
      "\n",
      "Start of epoch 239\n",
      "Training loss at epoch 239: 0.1639\n",
      "\n",
      "Start of epoch 240\n",
      "Training loss at epoch 240: 0.1639\n",
      "\n",
      "Start of epoch 241\n",
      "Training loss at epoch 241: 0.1639\n",
      "\n",
      "Start of epoch 242\n",
      "Training loss at epoch 242: 0.1639\n",
      "\n",
      "Start of epoch 243\n",
      "Training loss at epoch 243: 0.1639\n",
      "\n",
      "Start of epoch 244\n",
      "Training loss at epoch 244: 0.1639\n",
      "\n",
      "Start of epoch 245\n",
      "Training loss at epoch 245: 0.1639\n",
      "\n",
      "Start of epoch 246\n",
      "Training loss at epoch 246: 0.1639\n",
      "\n",
      "Start of epoch 247\n",
      "Training loss at epoch 247: 0.1639\n",
      "\n",
      "Start of epoch 248\n",
      "Training loss at epoch 248: 0.1639\n",
      "\n",
      "Start of epoch 249\n",
      "Training loss at epoch 249: 0.1639\n",
      "\n",
      "Start of epoch 250\n",
      "Training loss at epoch 250: 0.1639\n",
      "\n",
      "Start of epoch 251\n",
      "Training loss at epoch 251: 0.1639\n",
      "\n",
      "Start of epoch 252\n",
      "Training loss at epoch 252: 0.1639\n",
      "\n",
      "Start of epoch 253\n",
      "Training loss at epoch 253: 0.1639\n",
      "\n",
      "Start of epoch 254\n",
      "Training loss at epoch 254: 0.1639\n",
      "\n",
      "Start of epoch 255\n",
      "Training loss at epoch 255: 0.1639\n",
      "\n",
      "Start of epoch 256\n",
      "Training loss at epoch 256: 0.1639\n",
      "\n",
      "Start of epoch 257\n",
      "Training loss at epoch 257: 0.1639\n",
      "\n",
      "Start of epoch 258\n",
      "Training loss at epoch 258: 0.1639\n",
      "\n",
      "Start of epoch 259\n",
      "Training loss at epoch 259: 0.1639\n",
      "\n",
      "Start of epoch 260\n",
      "Training loss at epoch 260: 0.1639\n",
      "\n",
      "Start of epoch 261\n",
      "Training loss at epoch 261: 0.1639\n",
      "\n",
      "Start of epoch 262\n",
      "Training loss at epoch 262: 0.1639\n",
      "\n",
      "Start of epoch 263\n",
      "Training loss at epoch 263: 0.1639\n",
      "\n",
      "Start of epoch 264\n",
      "Training loss at epoch 264: 0.1639\n",
      "\n",
      "Start of epoch 265\n",
      "Training loss at epoch 265: 0.1639\n",
      "\n",
      "Start of epoch 266\n",
      "Training loss at epoch 266: 0.1639\n",
      "\n",
      "Start of epoch 267\n",
      "Training loss at epoch 267: 0.1639\n",
      "\n",
      "Start of epoch 268\n",
      "Training loss at epoch 268: 0.1639\n",
      "\n",
      "Start of epoch 269\n",
      "Training loss at epoch 269: 0.1639\n",
      "\n",
      "Start of epoch 270\n",
      "Training loss at epoch 270: 0.1639\n",
      "\n",
      "Start of epoch 271\n",
      "Training loss at epoch 271: 0.1639\n",
      "\n",
      "Start of epoch 272\n",
      "Training loss at epoch 272: 0.1639\n",
      "\n",
      "Start of epoch 273\n",
      "Training loss at epoch 273: 0.1639\n",
      "\n",
      "Start of epoch 274\n",
      "Training loss at epoch 274: 0.1639\n",
      "\n",
      "Start of epoch 275\n",
      "Training loss at epoch 275: 0.1639\n",
      "\n",
      "Start of epoch 276\n",
      "Training loss at epoch 276: 0.1639\n",
      "\n",
      "Start of epoch 277\n",
      "Training loss at epoch 277: 0.1639\n",
      "\n",
      "Start of epoch 278\n",
      "Training loss at epoch 278: 0.1639\n",
      "\n",
      "Start of epoch 279\n",
      "Training loss at epoch 279: 0.1639\n",
      "\n",
      "Start of epoch 280\n",
      "Training loss at epoch 280: 0.1639\n",
      "\n",
      "Start of epoch 281\n",
      "Training loss at epoch 281: 0.1639\n",
      "\n",
      "Start of epoch 282\n",
      "Training loss at epoch 282: 0.1639\n",
      "\n",
      "Start of epoch 283\n",
      "Training loss at epoch 283: 0.1639\n",
      "\n",
      "Start of epoch 284\n",
      "Training loss at epoch 284: 0.1639\n",
      "\n",
      "Start of epoch 285\n",
      "Training loss at epoch 285: 0.1639\n",
      "\n",
      "Start of epoch 286\n",
      "Training loss at epoch 286: 0.1639\n",
      "\n",
      "Start of epoch 287\n",
      "Training loss at epoch 287: 0.1639\n",
      "\n",
      "Start of epoch 288\n",
      "Training loss at epoch 288: 0.1639\n",
      "\n",
      "Start of epoch 289\n",
      "Training loss at epoch 289: 0.1639\n",
      "\n",
      "Start of epoch 290\n",
      "Training loss at epoch 290: 0.1639\n",
      "\n",
      "Start of epoch 291\n",
      "Training loss at epoch 291: 0.1639\n",
      "\n",
      "Start of epoch 292\n",
      "Training loss at epoch 292: 0.1639\n",
      "\n",
      "Start of epoch 293\n",
      "Training loss at epoch 293: 0.1639\n",
      "\n",
      "Start of epoch 294\n",
      "Training loss at epoch 294: 0.1639\n",
      "\n",
      "Start of epoch 295\n",
      "Training loss at epoch 295: 0.1639\n",
      "\n",
      "Start of epoch 296\n",
      "Training loss at epoch 296: 0.1639\n",
      "\n",
      "Start of epoch 297\n",
      "Training loss at epoch 297: 0.1639\n",
      "\n",
      "Start of epoch 298\n",
      "Training loss at epoch 298: 0.1639\n",
      "\n",
      "Start of epoch 299\n",
      "Training loss at epoch 299: 0.1639\n",
      "\n",
      "Start of epoch 300\n",
      "Training loss at epoch 300: 0.1639\n",
      "\n",
      "Start of epoch 301\n",
      "Training loss at epoch 301: 0.1639\n",
      "\n",
      "Start of epoch 302\n",
      "Training loss at epoch 302: 0.1639\n",
      "\n",
      "Start of epoch 303\n",
      "Training loss at epoch 303: 0.1639\n",
      "\n",
      "Start of epoch 304\n",
      "Training loss at epoch 304: 0.1639\n",
      "\n",
      "Start of epoch 305\n",
      "Training loss at epoch 305: 0.1639\n",
      "\n",
      "Start of epoch 306\n",
      "Training loss at epoch 306: 0.1639\n",
      "\n",
      "Start of epoch 307\n",
      "Training loss at epoch 307: 0.1639\n",
      "\n",
      "Start of epoch 308\n",
      "Training loss at epoch 308: 0.1639\n",
      "\n",
      "Start of epoch 309\n",
      "Training loss at epoch 309: 0.1639\n",
      "\n",
      "Start of epoch 310\n",
      "Training loss at epoch 310: 0.1639\n",
      "\n",
      "Start of epoch 311\n",
      "Training loss at epoch 311: 0.1639\n",
      "\n",
      "Start of epoch 312\n",
      "Training loss at epoch 312: 0.1639\n",
      "\n",
      "Start of epoch 313\n",
      "Training loss at epoch 313: 0.1639\n",
      "\n",
      "Start of epoch 314\n",
      "Training loss at epoch 314: 0.1639\n",
      "\n",
      "Start of epoch 315\n",
      "Training loss at epoch 315: 0.1639\n",
      "\n",
      "Start of epoch 316\n",
      "Training loss at epoch 316: 0.1639\n",
      "\n",
      "Start of epoch 317\n",
      "Training loss at epoch 317: 0.1639\n",
      "\n",
      "Start of epoch 318\n",
      "Training loss at epoch 318: 0.1639\n",
      "\n",
      "Start of epoch 319\n",
      "Training loss at epoch 319: 0.1639\n",
      "\n",
      "Start of epoch 320\n",
      "Training loss at epoch 320: 0.1639\n",
      "\n",
      "Start of epoch 321\n",
      "Training loss at epoch 321: 0.1639\n",
      "\n",
      "Start of epoch 322\n",
      "Training loss at epoch 322: 0.1639\n",
      "\n",
      "Start of epoch 323\n",
      "Training loss at epoch 323: 0.1639\n",
      "\n",
      "Start of epoch 324\n",
      "Training loss at epoch 324: 0.1639\n",
      "\n",
      "Start of epoch 325\n",
      "Training loss at epoch 325: 0.1639\n",
      "\n",
      "Start of epoch 326\n",
      "Training loss at epoch 326: 0.1639\n",
      "\n",
      "Start of epoch 327\n",
      "Training loss at epoch 327: 0.1639\n",
      "\n",
      "Start of epoch 328\n",
      "Training loss at epoch 328: 0.1639\n",
      "\n",
      "Start of epoch 329\n",
      "Training loss at epoch 329: 0.1639\n",
      "\n",
      "Start of epoch 330\n",
      "Training loss at epoch 330: 0.1639\n",
      "\n",
      "Start of epoch 331\n",
      "Training loss at epoch 331: 0.1639\n",
      "\n",
      "Start of epoch 332\n",
      "Training loss at epoch 332: 0.1639\n",
      "\n",
      "Start of epoch 333\n",
      "Training loss at epoch 333: 0.1639\n",
      "\n",
      "Start of epoch 334\n",
      "Training loss at epoch 334: 0.1639\n",
      "\n",
      "Start of epoch 335\n",
      "Training loss at epoch 335: 0.1639\n",
      "\n",
      "Start of epoch 336\n",
      "Training loss at epoch 336: 0.1639\n",
      "\n",
      "Start of epoch 337\n",
      "Training loss at epoch 337: 0.1639\n",
      "\n",
      "Start of epoch 338\n",
      "Training loss at epoch 338: 0.1639\n",
      "\n",
      "Start of epoch 339\n",
      "Training loss at epoch 339: 0.1639\n",
      "\n",
      "Start of epoch 340\n",
      "Training loss at epoch 340: 0.1639\n",
      "\n",
      "Start of epoch 341\n",
      "Training loss at epoch 341: 0.1639\n",
      "\n",
      "Start of epoch 342\n",
      "Training loss at epoch 342: 0.1639\n",
      "\n",
      "Start of epoch 343\n",
      "Training loss at epoch 343: 0.1639\n",
      "\n",
      "Start of epoch 344\n",
      "Training loss at epoch 344: 0.1639\n",
      "\n",
      "Start of epoch 345\n",
      "Training loss at epoch 345: 0.1639\n",
      "\n",
      "Start of epoch 346\n",
      "Training loss at epoch 346: 0.1639\n",
      "\n",
      "Start of epoch 347\n",
      "Training loss at epoch 347: 0.1639\n",
      "\n",
      "Start of epoch 348\n",
      "Training loss at epoch 348: 0.1639\n",
      "\n",
      "Start of epoch 349\n",
      "Training loss at epoch 349: 0.1639\n",
      "\n",
      "Start of epoch 350\n",
      "Training loss at epoch 350: 0.1639\n",
      "\n",
      "Start of epoch 351\n",
      "Training loss at epoch 351: 0.1639\n",
      "\n",
      "Start of epoch 352\n",
      "Training loss at epoch 352: 0.1639\n",
      "\n",
      "Start of epoch 353\n",
      "Training loss at epoch 353: 0.1639\n",
      "\n",
      "Start of epoch 354\n",
      "Training loss at epoch 354: 0.1639\n",
      "\n",
      "Start of epoch 355\n",
      "Training loss at epoch 355: 0.1639\n",
      "\n",
      "Start of epoch 356\n",
      "Training loss at epoch 356: 0.1639\n",
      "\n",
      "Start of epoch 357\n",
      "Training loss at epoch 357: 0.1639\n",
      "\n",
      "Start of epoch 358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 358: 0.1639\n",
      "\n",
      "Start of epoch 359\n",
      "Training loss at epoch 359: 0.1639\n",
      "\n",
      "Start of epoch 360\n",
      "Training loss at epoch 360: 0.1639\n",
      "\n",
      "Start of epoch 361\n",
      "Training loss at epoch 361: 0.1639\n",
      "\n",
      "Start of epoch 362\n",
      "Training loss at epoch 362: 0.1639\n",
      "\n",
      "Start of epoch 363\n",
      "Training loss at epoch 363: 0.1639\n",
      "\n",
      "Start of epoch 364\n",
      "Training loss at epoch 364: 0.1639\n",
      "\n",
      "Start of epoch 365\n",
      "Training loss at epoch 365: 0.1639\n",
      "\n",
      "Start of epoch 366\n",
      "Training loss at epoch 366: 0.1639\n",
      "\n",
      "Start of epoch 367\n",
      "Training loss at epoch 367: 0.1639\n",
      "\n",
      "Start of epoch 368\n",
      "Training loss at epoch 368: 0.1639\n",
      "\n",
      "Start of epoch 369\n",
      "Training loss at epoch 369: 0.1639\n",
      "\n",
      "Start of epoch 370\n",
      "Training loss at epoch 370: 0.1639\n",
      "\n",
      "Start of epoch 371\n",
      "Training loss at epoch 371: 0.1639\n",
      "\n",
      "Start of epoch 372\n",
      "Training loss at epoch 372: 0.1639\n",
      "\n",
      "Start of epoch 373\n",
      "Training loss at epoch 373: 0.1639\n",
      "\n",
      "Start of epoch 374\n",
      "Training loss at epoch 374: 0.1639\n",
      "\n",
      "Start of epoch 375\n",
      "Training loss at epoch 375: 0.1639\n",
      "\n",
      "Start of epoch 376\n",
      "Training loss at epoch 376: 0.1639\n",
      "\n",
      "Start of epoch 377\n",
      "Training loss at epoch 377: 0.1639\n",
      "\n",
      "Start of epoch 378\n",
      "Training loss at epoch 378: 0.1639\n",
      "\n",
      "Start of epoch 379\n",
      "Training loss at epoch 379: 0.1639\n",
      "\n",
      "Start of epoch 380\n",
      "Training loss at epoch 380: 0.1639\n",
      "\n",
      "Start of epoch 381\n",
      "Training loss at epoch 381: 0.1639\n",
      "\n",
      "Start of epoch 382\n",
      "Training loss at epoch 382: 0.1639\n",
      "\n",
      "Start of epoch 383\n",
      "Training loss at epoch 383: 0.1639\n",
      "\n",
      "Start of epoch 384\n",
      "Training loss at epoch 384: 0.1639\n",
      "\n",
      "Start of epoch 385\n",
      "Training loss at epoch 385: 0.1639\n",
      "\n",
      "Start of epoch 386\n",
      "Training loss at epoch 386: 0.1639\n",
      "\n",
      "Start of epoch 387\n",
      "Training loss at epoch 387: 0.1639\n",
      "\n",
      "Start of epoch 388\n",
      "Training loss at epoch 388: 0.1639\n",
      "\n",
      "Start of epoch 389\n",
      "Training loss at epoch 389: 0.1639\n",
      "\n",
      "Start of epoch 390\n",
      "Training loss at epoch 390: 0.1639\n",
      "\n",
      "Start of epoch 391\n",
      "Training loss at epoch 391: 0.1639\n",
      "\n",
      "Start of epoch 392\n",
      "Training loss at epoch 392: 0.1639\n",
      "\n",
      "Start of epoch 393\n",
      "Training loss at epoch 393: 0.1639\n",
      "\n",
      "Start of epoch 394\n",
      "Training loss at epoch 394: 0.1639\n",
      "\n",
      "Start of epoch 395\n",
      "Training loss at epoch 395: 0.1639\n",
      "\n",
      "Start of epoch 396\n",
      "Training loss at epoch 396: 0.1639\n",
      "\n",
      "Start of epoch 397\n",
      "Training loss at epoch 397: 0.1639\n",
      "\n",
      "Start of epoch 398\n",
      "Training loss at epoch 398: 0.1639\n",
      "\n",
      "Start of epoch 399\n",
      "Training loss at epoch 399: 0.1639\n",
      "\n",
      "Start of epoch 400\n",
      "Training loss at epoch 400: 0.1639\n",
      "\n",
      "Start of epoch 401\n",
      "Training loss at epoch 401: 0.1639\n",
      "\n",
      "Start of epoch 402\n",
      "Training loss at epoch 402: 0.1639\n",
      "\n",
      "Start of epoch 403\n",
      "Training loss at epoch 403: 0.1639\n",
      "\n",
      "Start of epoch 404\n",
      "Training loss at epoch 404: 0.1639\n",
      "\n",
      "Start of epoch 405\n",
      "Training loss at epoch 405: 0.1639\n",
      "\n",
      "Start of epoch 406\n",
      "Training loss at epoch 406: 0.1639\n",
      "\n",
      "Start of epoch 407\n",
      "Training loss at epoch 407: 0.1639\n",
      "\n",
      "Start of epoch 408\n",
      "Training loss at epoch 408: 0.1639\n",
      "\n",
      "Start of epoch 409\n",
      "Training loss at epoch 409: 0.1639\n",
      "\n",
      "Start of epoch 410\n",
      "Training loss at epoch 410: 0.1639\n",
      "\n",
      "Start of epoch 411\n",
      "Training loss at epoch 411: 0.1639\n",
      "\n",
      "Start of epoch 412\n",
      "Training loss at epoch 412: 0.1639\n",
      "\n",
      "Start of epoch 413\n",
      "Training loss at epoch 413: 0.1639\n",
      "\n",
      "Start of epoch 414\n",
      "Training loss at epoch 414: 0.1639\n",
      "\n",
      "Start of epoch 415\n",
      "Training loss at epoch 415: 0.1639\n",
      "\n",
      "Start of epoch 416\n",
      "Training loss at epoch 416: 0.1639\n",
      "\n",
      "Start of epoch 417\n",
      "Training loss at epoch 417: 0.1639\n",
      "\n",
      "Start of epoch 418\n",
      "Training loss at epoch 418: 0.1639\n",
      "\n",
      "Start of epoch 419\n",
      "Training loss at epoch 419: 0.1639\n",
      "\n",
      "Start of epoch 420\n",
      "Training loss at epoch 420: 0.1639\n",
      "\n",
      "Start of epoch 421\n",
      "Training loss at epoch 421: 0.1639\n",
      "\n",
      "Start of epoch 422\n",
      "Training loss at epoch 422: 0.1639\n",
      "\n",
      "Start of epoch 423\n",
      "Training loss at epoch 423: 0.1639\n",
      "\n",
      "Start of epoch 424\n",
      "Training loss at epoch 424: 0.1639\n",
      "\n",
      "Start of epoch 425\n",
      "Training loss at epoch 425: 0.1639\n",
      "\n",
      "Start of epoch 426\n",
      "Training loss at epoch 426: 0.1639\n",
      "\n",
      "Start of epoch 427\n",
      "Training loss at epoch 427: 0.1639\n",
      "\n",
      "Start of epoch 428\n",
      "Training loss at epoch 428: 0.1639\n",
      "\n",
      "Start of epoch 429\n",
      "Training loss at epoch 429: 0.1639\n",
      "\n",
      "Start of epoch 430\n",
      "Training loss at epoch 430: 0.1639\n",
      "\n",
      "Start of epoch 431\n",
      "Training loss at epoch 431: 0.1639\n",
      "\n",
      "Start of epoch 432\n",
      "Training loss at epoch 432: 0.1639\n",
      "\n",
      "Start of epoch 433\n",
      "Training loss at epoch 433: 0.1639\n",
      "\n",
      "Start of epoch 434\n",
      "Training loss at epoch 434: 0.1639\n",
      "\n",
      "Start of epoch 435\n",
      "Training loss at epoch 435: 0.1639\n",
      "\n",
      "Start of epoch 436\n",
      "Training loss at epoch 436: 0.1639\n",
      "\n",
      "Start of epoch 437\n",
      "Training loss at epoch 437: 0.1639\n",
      "\n",
      "Start of epoch 438\n",
      "Training loss at epoch 438: 0.1639\n",
      "\n",
      "Start of epoch 439\n",
      "Training loss at epoch 439: 0.1639\n",
      "\n",
      "Start of epoch 440\n",
      "Training loss at epoch 440: 0.1639\n",
      "\n",
      "Start of epoch 441\n",
      "Training loss at epoch 441: 0.1639\n",
      "\n",
      "Start of epoch 442\n",
      "Training loss at epoch 442: 0.1639\n",
      "\n",
      "Start of epoch 443\n",
      "Training loss at epoch 443: 0.1639\n",
      "\n",
      "Start of epoch 444\n",
      "Training loss at epoch 444: 0.1639\n",
      "\n",
      "Start of epoch 445\n",
      "Training loss at epoch 445: 0.1639\n",
      "\n",
      "Start of epoch 446\n",
      "Training loss at epoch 446: 0.1639\n",
      "\n",
      "Start of epoch 447\n",
      "Training loss at epoch 447: 0.1639\n",
      "\n",
      "Start of epoch 448\n",
      "Training loss at epoch 448: 0.1639\n",
      "\n",
      "Start of epoch 449\n",
      "Training loss at epoch 449: 0.1639\n",
      "\n",
      "Start of epoch 450\n",
      "Training loss at epoch 450: 0.1639\n",
      "\n",
      "Start of epoch 451\n",
      "Training loss at epoch 451: 0.1639\n",
      "\n",
      "Start of epoch 452\n",
      "Training loss at epoch 452: 0.1639\n",
      "\n",
      "Start of epoch 453\n",
      "Training loss at epoch 453: 0.1639\n",
      "\n",
      "Start of epoch 454\n",
      "Training loss at epoch 454: 0.1639\n",
      "\n",
      "Start of epoch 455\n",
      "Training loss at epoch 455: 0.1639\n",
      "\n",
      "Start of epoch 456\n",
      "Training loss at epoch 456: 0.1639\n",
      "\n",
      "Start of epoch 457\n",
      "Training loss at epoch 457: 0.1639\n",
      "\n",
      "Start of epoch 458\n",
      "Training loss at epoch 458: 0.1639\n",
      "\n",
      "Start of epoch 459\n",
      "Training loss at epoch 459: 0.1639\n",
      "\n",
      "Start of epoch 460\n",
      "Training loss at epoch 460: 0.1639\n",
      "\n",
      "Start of epoch 461\n",
      "Training loss at epoch 461: 0.1639\n",
      "\n",
      "Start of epoch 462\n",
      "Training loss at epoch 462: 0.1639\n",
      "\n",
      "Start of epoch 463\n",
      "Training loss at epoch 463: 0.1639\n",
      "\n",
      "Start of epoch 464\n",
      "Training loss at epoch 464: 0.1639\n",
      "\n",
      "Start of epoch 465\n",
      "Training loss at epoch 465: 0.1639\n",
      "\n",
      "Start of epoch 466\n",
      "Training loss at epoch 466: 0.1639\n",
      "\n",
      "Start of epoch 467\n",
      "Training loss at epoch 467: 0.1639\n",
      "\n",
      "Start of epoch 468\n",
      "Training loss at epoch 468: 0.1639\n",
      "\n",
      "Start of epoch 469\n",
      "Training loss at epoch 469: 0.1639\n",
      "\n",
      "Start of epoch 470\n",
      "Training loss at epoch 470: 0.1639\n",
      "\n",
      "Start of epoch 471\n",
      "Training loss at epoch 471: 0.1639\n",
      "\n",
      "Start of epoch 472\n",
      "Training loss at epoch 472: 0.1639\n",
      "\n",
      "Start of epoch 473\n",
      "Training loss at epoch 473: 0.1639\n",
      "\n",
      "Start of epoch 474\n",
      "Training loss at epoch 474: 0.1639\n",
      "\n",
      "Start of epoch 475\n",
      "Training loss at epoch 475: 0.1639\n",
      "\n",
      "Start of epoch 476\n",
      "Training loss at epoch 476: 0.1639\n",
      "\n",
      "Start of epoch 477\n",
      "Training loss at epoch 477: 0.1639\n",
      "\n",
      "Start of epoch 478\n",
      "Training loss at epoch 478: 0.1639\n",
      "\n",
      "Start of epoch 479\n",
      "Training loss at epoch 479: 0.1639\n",
      "\n",
      "Start of epoch 480\n",
      "Training loss at epoch 480: 0.1639\n",
      "\n",
      "Start of epoch 481\n",
      "Training loss at epoch 481: 0.1639\n",
      "\n",
      "Start of epoch 482\n",
      "Training loss at epoch 482: 0.1639\n",
      "\n",
      "Start of epoch 483\n",
      "Training loss at epoch 483: 0.1639\n",
      "\n",
      "Start of epoch 484\n",
      "Training loss at epoch 484: 0.1639\n",
      "\n",
      "Start of epoch 485\n",
      "Training loss at epoch 485: 0.1639\n",
      "\n",
      "Start of epoch 486\n",
      "Training loss at epoch 486: 0.1639\n",
      "\n",
      "Start of epoch 487\n",
      "Training loss at epoch 487: 0.1639\n",
      "\n",
      "Start of epoch 488\n",
      "Training loss at epoch 488: 0.1639\n",
      "\n",
      "Start of epoch 489\n",
      "Training loss at epoch 489: 0.1639\n",
      "\n",
      "Start of epoch 490\n",
      "Training loss at epoch 490: 0.1639\n",
      "\n",
      "Start of epoch 491\n",
      "Training loss at epoch 491: 0.1639\n",
      "\n",
      "Start of epoch 492\n",
      "Training loss at epoch 492: 0.1639\n",
      "\n",
      "Start of epoch 493\n",
      "Training loss at epoch 493: 0.1639\n",
      "\n",
      "Start of epoch 494\n",
      "Training loss at epoch 494: 0.1639\n",
      "\n",
      "Start of epoch 495\n",
      "Training loss at epoch 495: 0.1639\n",
      "\n",
      "Start of epoch 496\n",
      "Training loss at epoch 496: 0.1639\n",
      "\n",
      "Start of epoch 497\n",
      "Training loss at epoch 497: 0.1639\n",
      "\n",
      "Start of epoch 498\n",
      "Training loss at epoch 498: 0.1639\n",
      "\n",
      "Start of epoch 499\n",
      "Training loss at epoch 499: 0.1639\n",
      "[<tf.Variable 'parameters:0' shape=(15,) dtype=float32, numpy=\n",
      "array([4.488917  , 4.200594  , 3.3812315 , 0.65364134, 4.9857583 ,\n",
      "       3.912875  , 2.877999  , 3.7420542 , 0.5935487 , 0.11952018,\n",
      "       5.9849706 , 1.8513539 , 1.4850748 , 1.1053215 , 5.0125437 ],\n",
      "      dtype=float32)>]\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 0.6995\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 0.5831\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.5045\n",
      "\n",
      "Start of epoch 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 3: 0.4732\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.4737\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.4715\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.4526\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.4212\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.3864\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.3563\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.3357\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.3249\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.3203\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.3163\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.3091\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.2983\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.2867\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.2777\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.2738\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.2750\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.2786\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.2813\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.2811\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.2780\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.2740\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.2709\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.2697\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.2696\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.2689\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.2664\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.2619\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.2567\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.2521\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.2487\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.2464\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.2440\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.2409\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.2371\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.2333\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.2303\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.2280\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.2261\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.2238\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.2209\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.2177\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.2146\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.2121\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.2097\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.2071\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.2043\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.2013\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.1987\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.1964\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.1944\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.1923\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.1901\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.1880\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.1862\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.1847\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.1833\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.1819\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.1804\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.1792\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.1781\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.1771\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.1762\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.1753\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.1744\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.1738\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.1732\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.1727\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.1722\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.1717\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.1714\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.1711\n",
      "\n",
      "Start of epoch 75\n",
      "Training loss at epoch 75: 0.1708\n",
      "\n",
      "Start of epoch 76\n",
      "Training loss at epoch 76: 0.1705\n",
      "\n",
      "Start of epoch 77\n",
      "Training loss at epoch 77: 0.1703\n",
      "\n",
      "Start of epoch 78\n",
      "Training loss at epoch 78: 0.1700\n",
      "\n",
      "Start of epoch 79\n",
      "Training loss at epoch 79: 0.1698\n",
      "\n",
      "Start of epoch 80\n",
      "Training loss at epoch 80: 0.1696\n",
      "\n",
      "Start of epoch 81\n",
      "Training loss at epoch 81: 0.1694\n",
      "\n",
      "Start of epoch 82\n",
      "Training loss at epoch 82: 0.1692\n",
      "\n",
      "Start of epoch 83\n",
      "Training loss at epoch 83: 0.1690\n",
      "\n",
      "Start of epoch 84\n",
      "Training loss at epoch 84: 0.1688\n",
      "\n",
      "Start of epoch 85\n",
      "Training loss at epoch 85: 0.1687\n",
      "\n",
      "Start of epoch 86\n",
      "Training loss at epoch 86: 0.1685\n",
      "\n",
      "Start of epoch 87\n",
      "Training loss at epoch 87: 0.1683\n",
      "\n",
      "Start of epoch 88\n",
      "Training loss at epoch 88: 0.1682\n",
      "\n",
      "Start of epoch 89\n",
      "Training loss at epoch 89: 0.1681\n",
      "\n",
      "Start of epoch 90\n",
      "Training loss at epoch 90: 0.1680\n",
      "\n",
      "Start of epoch 91\n",
      "Training loss at epoch 91: 0.1679\n",
      "\n",
      "Start of epoch 92\n",
      "Training loss at epoch 92: 0.1677\n",
      "\n",
      "Start of epoch 93\n",
      "Training loss at epoch 93: 0.1676\n",
      "\n",
      "Start of epoch 94\n",
      "Training loss at epoch 94: 0.1675\n",
      "\n",
      "Start of epoch 95\n",
      "Training loss at epoch 95: 0.1674\n",
      "\n",
      "Start of epoch 96\n",
      "Training loss at epoch 96: 0.1674\n",
      "\n",
      "Start of epoch 97\n",
      "Training loss at epoch 97: 0.1673\n",
      "\n",
      "Start of epoch 98\n",
      "Training loss at epoch 98: 0.1672\n",
      "\n",
      "Start of epoch 99\n",
      "Training loss at epoch 99: 0.1671\n",
      "\n",
      "Start of epoch 100\n",
      "Training loss at epoch 100: 0.1670\n",
      "\n",
      "Start of epoch 101\n",
      "Training loss at epoch 101: 0.1670\n",
      "\n",
      "Start of epoch 102\n",
      "Training loss at epoch 102: 0.1669\n",
      "\n",
      "Start of epoch 103\n",
      "Training loss at epoch 103: 0.1668\n",
      "\n",
      "Start of epoch 104\n",
      "Training loss at epoch 104: 0.1668\n",
      "\n",
      "Start of epoch 105\n",
      "Training loss at epoch 105: 0.1667\n",
      "\n",
      "Start of epoch 106\n",
      "Training loss at epoch 106: 0.1666\n",
      "\n",
      "Start of epoch 107\n",
      "Training loss at epoch 107: 0.1666\n",
      "\n",
      "Start of epoch 108\n",
      "Training loss at epoch 108: 0.1665\n",
      "\n",
      "Start of epoch 109\n",
      "Training loss at epoch 109: 0.1665\n",
      "\n",
      "Start of epoch 110\n",
      "Training loss at epoch 110: 0.1664\n",
      "\n",
      "Start of epoch 111\n",
      "Training loss at epoch 111: 0.1663\n",
      "\n",
      "Start of epoch 112\n",
      "Training loss at epoch 112: 0.1663\n",
      "\n",
      "Start of epoch 113\n",
      "Training loss at epoch 113: 0.1662\n",
      "\n",
      "Start of epoch 114\n",
      "Training loss at epoch 114: 0.1662\n",
      "\n",
      "Start of epoch 115\n",
      "Training loss at epoch 115: 0.1661\n",
      "\n",
      "Start of epoch 116\n",
      "Training loss at epoch 116: 0.1661\n",
      "\n",
      "Start of epoch 117\n",
      "Training loss at epoch 117: 0.1661\n",
      "\n",
      "Start of epoch 118\n",
      "Training loss at epoch 118: 0.1660\n",
      "\n",
      "Start of epoch 119\n",
      "Training loss at epoch 119: 0.1660\n",
      "\n",
      "Start of epoch 120\n",
      "Training loss at epoch 120: 0.1659\n",
      "\n",
      "Start of epoch 121\n",
      "Training loss at epoch 121: 0.1659\n",
      "\n",
      "Start of epoch 122\n",
      "Training loss at epoch 122: 0.1659\n",
      "\n",
      "Start of epoch 123\n",
      "Training loss at epoch 123: 0.1658\n",
      "\n",
      "Start of epoch 124\n",
      "Training loss at epoch 124: 0.1658\n",
      "\n",
      "Start of epoch 125\n",
      "Training loss at epoch 125: 0.1657\n",
      "\n",
      "Start of epoch 126\n",
      "Training loss at epoch 126: 0.1657\n",
      "\n",
      "Start of epoch 127\n",
      "Training loss at epoch 127: 0.1657\n",
      "\n",
      "Start of epoch 128\n",
      "Training loss at epoch 128: 0.1657\n",
      "\n",
      "Start of epoch 129\n",
      "Training loss at epoch 129: 0.1656\n",
      "\n",
      "Start of epoch 130\n",
      "Training loss at epoch 130: 0.1656\n",
      "\n",
      "Start of epoch 131\n",
      "Training loss at epoch 131: 0.1656\n",
      "\n",
      "Start of epoch 132\n",
      "Training loss at epoch 132: 0.1655\n",
      "\n",
      "Start of epoch 133\n",
      "Training loss at epoch 133: 0.1655\n",
      "\n",
      "Start of epoch 134\n",
      "Training loss at epoch 134: 0.1655\n",
      "\n",
      "Start of epoch 135\n",
      "Training loss at epoch 135: 0.1655\n",
      "\n",
      "Start of epoch 136\n",
      "Training loss at epoch 136: 0.1654\n",
      "\n",
      "Start of epoch 137\n",
      "Training loss at epoch 137: 0.1654\n",
      "\n",
      "Start of epoch 138\n",
      "Training loss at epoch 138: 0.1654\n",
      "\n",
      "Start of epoch 139\n",
      "Training loss at epoch 139: 0.1654\n",
      "\n",
      "Start of epoch 140\n",
      "Training loss at epoch 140: 0.1653\n",
      "\n",
      "Start of epoch 141\n",
      "Training loss at epoch 141: 0.1653\n",
      "\n",
      "Start of epoch 142\n",
      "Training loss at epoch 142: 0.1653\n",
      "\n",
      "Start of epoch 143\n",
      "Training loss at epoch 143: 0.1653\n",
      "\n",
      "Start of epoch 144\n",
      "Training loss at epoch 144: 0.1653\n",
      "\n",
      "Start of epoch 145\n",
      "Training loss at epoch 145: 0.1652\n",
      "\n",
      "Start of epoch 146\n",
      "Training loss at epoch 146: 0.1652\n",
      "\n",
      "Start of epoch 147\n",
      "Training loss at epoch 147: 0.1652\n",
      "\n",
      "Start of epoch 148\n",
      "Training loss at epoch 148: 0.1652\n",
      "\n",
      "Start of epoch 149\n",
      "Training loss at epoch 149: 0.1652\n",
      "\n",
      "Start of epoch 150\n",
      "Training loss at epoch 150: 0.1651\n",
      "\n",
      "Start of epoch 151\n",
      "Training loss at epoch 151: 0.1651\n",
      "\n",
      "Start of epoch 152\n",
      "Training loss at epoch 152: 0.1651\n",
      "\n",
      "Start of epoch 153\n",
      "Training loss at epoch 153: 0.1651\n",
      "\n",
      "Start of epoch 154\n",
      "Training loss at epoch 154: 0.1651\n",
      "\n",
      "Start of epoch 155\n",
      "Training loss at epoch 155: 0.1651\n",
      "\n",
      "Start of epoch 156\n",
      "Training loss at epoch 156: 0.1650\n",
      "\n",
      "Start of epoch 157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 157: 0.1650\n",
      "\n",
      "Start of epoch 158\n",
      "Training loss at epoch 158: 0.1650\n",
      "\n",
      "Start of epoch 159\n",
      "Training loss at epoch 159: 0.1650\n",
      "\n",
      "Start of epoch 160\n",
      "Training loss at epoch 160: 0.1650\n",
      "\n",
      "Start of epoch 161\n",
      "Training loss at epoch 161: 0.1650\n",
      "\n",
      "Start of epoch 162\n",
      "Training loss at epoch 162: 0.1650\n",
      "\n",
      "Start of epoch 163\n",
      "Training loss at epoch 163: 0.1649\n",
      "\n",
      "Start of epoch 164\n",
      "Training loss at epoch 164: 0.1649\n",
      "\n",
      "Start of epoch 165\n",
      "Training loss at epoch 165: 0.1649\n",
      "\n",
      "Start of epoch 166\n",
      "Training loss at epoch 166: 0.1649\n",
      "\n",
      "Start of epoch 167\n",
      "Training loss at epoch 167: 0.1649\n",
      "\n",
      "Start of epoch 168\n",
      "Training loss at epoch 168: 0.1649\n",
      "\n",
      "Start of epoch 169\n",
      "Training loss at epoch 169: 0.1649\n",
      "\n",
      "Start of epoch 170\n",
      "Training loss at epoch 170: 0.1649\n",
      "\n",
      "Start of epoch 171\n",
      "Training loss at epoch 171: 0.1649\n",
      "\n",
      "Start of epoch 172\n",
      "Training loss at epoch 172: 0.1648\n",
      "\n",
      "Start of epoch 173\n",
      "Training loss at epoch 173: 0.1648\n",
      "\n",
      "Start of epoch 174\n",
      "Training loss at epoch 174: 0.1648\n",
      "\n",
      "Start of epoch 175\n",
      "Training loss at epoch 175: 0.1648\n",
      "\n",
      "Start of epoch 176\n",
      "Training loss at epoch 176: 0.1648\n",
      "\n",
      "Start of epoch 177\n",
      "Training loss at epoch 177: 0.1648\n",
      "\n",
      "Start of epoch 178\n",
      "Training loss at epoch 178: 0.1648\n",
      "\n",
      "Start of epoch 179\n",
      "Training loss at epoch 179: 0.1648\n",
      "\n",
      "Start of epoch 180\n",
      "Training loss at epoch 180: 0.1648\n",
      "\n",
      "Start of epoch 181\n",
      "Training loss at epoch 181: 0.1648\n",
      "\n",
      "Start of epoch 182\n",
      "Training loss at epoch 182: 0.1647\n",
      "\n",
      "Start of epoch 183\n",
      "Training loss at epoch 183: 0.1647\n",
      "\n",
      "Start of epoch 184\n",
      "Training loss at epoch 184: 0.1647\n",
      "\n",
      "Start of epoch 185\n",
      "Training loss at epoch 185: 0.1647\n",
      "\n",
      "Start of epoch 186\n",
      "Training loss at epoch 186: 0.1647\n",
      "\n",
      "Start of epoch 187\n",
      "Training loss at epoch 187: 0.1647\n",
      "\n",
      "Start of epoch 188\n",
      "Training loss at epoch 188: 0.1647\n",
      "\n",
      "Start of epoch 189\n",
      "Training loss at epoch 189: 0.1647\n",
      "\n",
      "Start of epoch 190\n",
      "Training loss at epoch 190: 0.1647\n",
      "\n",
      "Start of epoch 191\n",
      "Training loss at epoch 191: 0.1647\n",
      "\n",
      "Start of epoch 192\n",
      "Training loss at epoch 192: 0.1647\n",
      "\n",
      "Start of epoch 193\n",
      "Training loss at epoch 193: 0.1647\n",
      "\n",
      "Start of epoch 194\n",
      "Training loss at epoch 194: 0.1646\n",
      "\n",
      "Start of epoch 195\n",
      "Training loss at epoch 195: 0.1646\n",
      "\n",
      "Start of epoch 196\n",
      "Training loss at epoch 196: 0.1646\n",
      "\n",
      "Start of epoch 197\n",
      "Training loss at epoch 197: 0.1646\n",
      "\n",
      "Start of epoch 198\n",
      "Training loss at epoch 198: 0.1646\n",
      "\n",
      "Start of epoch 199\n",
      "Training loss at epoch 199: 0.1646\n",
      "\n",
      "Start of epoch 200\n",
      "Training loss at epoch 200: 0.1646\n",
      "\n",
      "Start of epoch 201\n",
      "Training loss at epoch 201: 0.1646\n",
      "\n",
      "Start of epoch 202\n",
      "Training loss at epoch 202: 0.1646\n",
      "\n",
      "Start of epoch 203\n",
      "Training loss at epoch 203: 0.1646\n",
      "\n",
      "Start of epoch 204\n",
      "Training loss at epoch 204: 0.1646\n",
      "\n",
      "Start of epoch 205\n",
      "Training loss at epoch 205: 0.1646\n",
      "\n",
      "Start of epoch 206\n",
      "Training loss at epoch 206: 0.1646\n",
      "\n",
      "Start of epoch 207\n",
      "Training loss at epoch 207: 0.1646\n",
      "\n",
      "Start of epoch 208\n",
      "Training loss at epoch 208: 0.1646\n",
      "\n",
      "Start of epoch 209\n",
      "Training loss at epoch 209: 0.1646\n",
      "\n",
      "Start of epoch 210\n",
      "Training loss at epoch 210: 0.1645\n",
      "\n",
      "Start of epoch 211\n",
      "Training loss at epoch 211: 0.1645\n",
      "\n",
      "Start of epoch 212\n",
      "Training loss at epoch 212: 0.1645\n",
      "\n",
      "Start of epoch 213\n",
      "Training loss at epoch 213: 0.1645\n",
      "\n",
      "Start of epoch 214\n",
      "Training loss at epoch 214: 0.1645\n",
      "\n",
      "Start of epoch 215\n",
      "Training loss at epoch 215: 0.1645\n",
      "\n",
      "Start of epoch 216\n",
      "Training loss at epoch 216: 0.1645\n",
      "\n",
      "Start of epoch 217\n",
      "Training loss at epoch 217: 0.1645\n",
      "\n",
      "Start of epoch 218\n",
      "Training loss at epoch 218: 0.1645\n",
      "\n",
      "Start of epoch 219\n",
      "Training loss at epoch 219: 0.1645\n",
      "\n",
      "Start of epoch 220\n",
      "Training loss at epoch 220: 0.1645\n",
      "\n",
      "Start of epoch 221\n",
      "Training loss at epoch 221: 0.1645\n",
      "\n",
      "Start of epoch 222\n",
      "Training loss at epoch 222: 0.1645\n",
      "\n",
      "Start of epoch 223\n",
      "Training loss at epoch 223: 0.1645\n",
      "\n",
      "Start of epoch 224\n",
      "Training loss at epoch 224: 0.1645\n",
      "\n",
      "Start of epoch 225\n",
      "Training loss at epoch 225: 0.1645\n",
      "\n",
      "Start of epoch 226\n",
      "Training loss at epoch 226: 0.1645\n",
      "\n",
      "Start of epoch 227\n",
      "Training loss at epoch 227: 0.1645\n",
      "\n",
      "Start of epoch 228\n",
      "Training loss at epoch 228: 0.1645\n",
      "\n",
      "Start of epoch 229\n",
      "Training loss at epoch 229: 0.1645\n",
      "\n",
      "Start of epoch 230\n",
      "Training loss at epoch 230: 0.1644\n",
      "\n",
      "Start of epoch 231\n",
      "Training loss at epoch 231: 0.1644\n",
      "\n",
      "Start of epoch 232\n",
      "Training loss at epoch 232: 0.1644\n",
      "\n",
      "Start of epoch 233\n",
      "Training loss at epoch 233: 0.1644\n",
      "\n",
      "Start of epoch 234\n",
      "Training loss at epoch 234: 0.1644\n",
      "\n",
      "Start of epoch 235\n",
      "Training loss at epoch 235: 0.1644\n",
      "\n",
      "Start of epoch 236\n",
      "Training loss at epoch 236: 0.1644\n",
      "\n",
      "Start of epoch 237\n",
      "Training loss at epoch 237: 0.1644\n",
      "\n",
      "Start of epoch 238\n",
      "Training loss at epoch 238: 0.1644\n",
      "\n",
      "Start of epoch 239\n",
      "Training loss at epoch 239: 0.1644\n",
      "\n",
      "Start of epoch 240\n",
      "Training loss at epoch 240: 0.1644\n",
      "\n",
      "Start of epoch 241\n",
      "Training loss at epoch 241: 0.1644\n",
      "\n",
      "Start of epoch 242\n",
      "Training loss at epoch 242: 0.1644\n",
      "\n",
      "Start of epoch 243\n",
      "Training loss at epoch 243: 0.1644\n",
      "\n",
      "Start of epoch 244\n",
      "Training loss at epoch 244: 0.1644\n",
      "\n",
      "Start of epoch 245\n",
      "Training loss at epoch 245: 0.1644\n",
      "\n",
      "Start of epoch 246\n",
      "Training loss at epoch 246: 0.1644\n",
      "\n",
      "Start of epoch 247\n",
      "Training loss at epoch 247: 0.1644\n",
      "\n",
      "Start of epoch 248\n",
      "Training loss at epoch 248: 0.1644\n",
      "\n",
      "Start of epoch 249\n",
      "Training loss at epoch 249: 0.1644\n",
      "\n",
      "Start of epoch 250\n",
      "Training loss at epoch 250: 0.1644\n",
      "\n",
      "Start of epoch 251\n",
      "Training loss at epoch 251: 0.1644\n",
      "\n",
      "Start of epoch 252\n",
      "Training loss at epoch 252: 0.1644\n",
      "\n",
      "Start of epoch 253\n",
      "Training loss at epoch 253: 0.1644\n",
      "\n",
      "Start of epoch 254\n",
      "Training loss at epoch 254: 0.1644\n",
      "\n",
      "Start of epoch 255\n",
      "Training loss at epoch 255: 0.1644\n",
      "\n",
      "Start of epoch 256\n",
      "Training loss at epoch 256: 0.1644\n",
      "\n",
      "Start of epoch 257\n",
      "Training loss at epoch 257: 0.1644\n",
      "\n",
      "Start of epoch 258\n",
      "Training loss at epoch 258: 0.1644\n",
      "\n",
      "Start of epoch 259\n",
      "Training loss at epoch 259: 0.1643\n",
      "\n",
      "Start of epoch 260\n",
      "Training loss at epoch 260: 0.1643\n",
      "\n",
      "Start of epoch 261\n",
      "Training loss at epoch 261: 0.1643\n",
      "\n",
      "Start of epoch 262\n",
      "Training loss at epoch 262: 0.1643\n",
      "\n",
      "Start of epoch 263\n",
      "Training loss at epoch 263: 0.1643\n",
      "\n",
      "Start of epoch 264\n",
      "Training loss at epoch 264: 0.1643\n",
      "\n",
      "Start of epoch 265\n",
      "Training loss at epoch 265: 0.1643\n",
      "\n",
      "Start of epoch 266\n",
      "Training loss at epoch 266: 0.1643\n",
      "\n",
      "Start of epoch 267\n",
      "Training loss at epoch 267: 0.1643\n",
      "\n",
      "Start of epoch 268\n",
      "Training loss at epoch 268: 0.1643\n",
      "\n",
      "Start of epoch 269\n",
      "Training loss at epoch 269: 0.1643\n",
      "\n",
      "Start of epoch 270\n",
      "Training loss at epoch 270: 0.1643\n",
      "\n",
      "Start of epoch 271\n",
      "Training loss at epoch 271: 0.1643\n",
      "\n",
      "Start of epoch 272\n",
      "Training loss at epoch 272: 0.1643\n",
      "\n",
      "Start of epoch 273\n",
      "Training loss at epoch 273: 0.1643\n",
      "\n",
      "Start of epoch 274\n",
      "Training loss at epoch 274: 0.1643\n",
      "\n",
      "Start of epoch 275\n",
      "Training loss at epoch 275: 0.1643\n",
      "\n",
      "Start of epoch 276\n",
      "Training loss at epoch 276: 0.1643\n",
      "\n",
      "Start of epoch 277\n",
      "Training loss at epoch 277: 0.1643\n",
      "\n",
      "Start of epoch 278\n",
      "Training loss at epoch 278: 0.1643\n",
      "\n",
      "Start of epoch 279\n",
      "Training loss at epoch 279: 0.1643\n",
      "\n",
      "Start of epoch 280\n",
      "Training loss at epoch 280: 0.1643\n",
      "\n",
      "Start of epoch 281\n",
      "Training loss at epoch 281: 0.1643\n",
      "\n",
      "Start of epoch 282\n",
      "Training loss at epoch 282: 0.1643\n",
      "\n",
      "Start of epoch 283\n",
      "Training loss at epoch 283: 0.1643\n",
      "\n",
      "Start of epoch 284\n",
      "Training loss at epoch 284: 0.1643\n",
      "\n",
      "Start of epoch 285\n",
      "Training loss at epoch 285: 0.1643\n",
      "\n",
      "Start of epoch 286\n",
      "Training loss at epoch 286: 0.1643\n",
      "\n",
      "Start of epoch 287\n",
      "Training loss at epoch 287: 0.1643\n",
      "\n",
      "Start of epoch 288\n",
      "Training loss at epoch 288: 0.1643\n",
      "\n",
      "Start of epoch 289\n",
      "Training loss at epoch 289: 0.1643\n",
      "\n",
      "Start of epoch 290\n",
      "Training loss at epoch 290: 0.1643\n",
      "\n",
      "Start of epoch 291\n",
      "Training loss at epoch 291: 0.1643\n",
      "\n",
      "Start of epoch 292\n",
      "Training loss at epoch 292: 0.1643\n",
      "\n",
      "Start of epoch 293\n",
      "Training loss at epoch 293: 0.1643\n",
      "\n",
      "Start of epoch 294\n",
      "Training loss at epoch 294: 0.1643\n",
      "\n",
      "Start of epoch 295\n",
      "Training loss at epoch 295: 0.1643\n",
      "\n",
      "Start of epoch 296\n",
      "Training loss at epoch 296: 0.1643\n",
      "\n",
      "Start of epoch 297\n",
      "Training loss at epoch 297: 0.1643\n",
      "\n",
      "Start of epoch 298\n",
      "Training loss at epoch 298: 0.1643\n",
      "\n",
      "Start of epoch 299\n",
      "Training loss at epoch 299: 0.1643\n",
      "\n",
      "Start of epoch 300\n",
      "Training loss at epoch 300: 0.1642\n",
      "\n",
      "Start of epoch 301\n",
      "Training loss at epoch 301: 0.1642\n",
      "\n",
      "Start of epoch 302\n",
      "Training loss at epoch 302: 0.1642\n",
      "\n",
      "Start of epoch 303\n",
      "Training loss at epoch 303: 0.1642\n",
      "\n",
      "Start of epoch 304\n",
      "Training loss at epoch 304: 0.1642\n",
      "\n",
      "Start of epoch 305\n",
      "Training loss at epoch 305: 0.1642\n",
      "\n",
      "Start of epoch 306\n",
      "Training loss at epoch 306: 0.1642\n",
      "\n",
      "Start of epoch 307\n",
      "Training loss at epoch 307: 0.1642\n",
      "\n",
      "Start of epoch 308\n",
      "Training loss at epoch 308: 0.1642\n",
      "\n",
      "Start of epoch 309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 309: 0.1642\n",
      "\n",
      "Start of epoch 310\n",
      "Training loss at epoch 310: 0.1642\n",
      "\n",
      "Start of epoch 311\n",
      "Training loss at epoch 311: 0.1642\n",
      "\n",
      "Start of epoch 312\n",
      "Training loss at epoch 312: 0.1642\n",
      "\n",
      "Start of epoch 313\n",
      "Training loss at epoch 313: 0.1642\n",
      "\n",
      "Start of epoch 314\n",
      "Training loss at epoch 314: 0.1642\n",
      "\n",
      "Start of epoch 315\n",
      "Training loss at epoch 315: 0.1642\n",
      "\n",
      "Start of epoch 316\n",
      "Training loss at epoch 316: 0.1642\n",
      "\n",
      "Start of epoch 317\n",
      "Training loss at epoch 317: 0.1642\n",
      "\n",
      "Start of epoch 318\n",
      "Training loss at epoch 318: 0.1642\n",
      "\n",
      "Start of epoch 319\n",
      "Training loss at epoch 319: 0.1642\n",
      "\n",
      "Start of epoch 320\n",
      "Training loss at epoch 320: 0.1642\n",
      "\n",
      "Start of epoch 321\n",
      "Training loss at epoch 321: 0.1642\n",
      "\n",
      "Start of epoch 322\n",
      "Training loss at epoch 322: 0.1642\n",
      "\n",
      "Start of epoch 323\n",
      "Training loss at epoch 323: 0.1642\n",
      "\n",
      "Start of epoch 324\n",
      "Training loss at epoch 324: 0.1642\n",
      "\n",
      "Start of epoch 325\n",
      "Training loss at epoch 325: 0.1642\n",
      "\n",
      "Start of epoch 326\n",
      "Training loss at epoch 326: 0.1642\n",
      "\n",
      "Start of epoch 327\n",
      "Training loss at epoch 327: 0.1642\n",
      "\n",
      "Start of epoch 328\n",
      "Training loss at epoch 328: 0.1642\n",
      "\n",
      "Start of epoch 329\n",
      "Training loss at epoch 329: 0.1642\n",
      "\n",
      "Start of epoch 330\n",
      "Training loss at epoch 330: 0.1642\n",
      "\n",
      "Start of epoch 331\n",
      "Training loss at epoch 331: 0.1642\n",
      "\n",
      "Start of epoch 332\n",
      "Training loss at epoch 332: 0.1642\n",
      "\n",
      "Start of epoch 333\n",
      "Training loss at epoch 333: 0.1642\n",
      "\n",
      "Start of epoch 334\n",
      "Training loss at epoch 334: 0.1642\n",
      "\n",
      "Start of epoch 335\n",
      "Training loss at epoch 335: 0.1642\n",
      "\n",
      "Start of epoch 336\n",
      "Training loss at epoch 336: 0.1642\n",
      "\n",
      "Start of epoch 337\n",
      "Training loss at epoch 337: 0.1642\n",
      "\n",
      "Start of epoch 338\n",
      "Training loss at epoch 338: 0.1642\n",
      "\n",
      "Start of epoch 339\n",
      "Training loss at epoch 339: 0.1642\n",
      "\n",
      "Start of epoch 340\n",
      "Training loss at epoch 340: 0.1642\n",
      "\n",
      "Start of epoch 341\n",
      "Training loss at epoch 341: 0.1642\n",
      "\n",
      "Start of epoch 342\n",
      "Training loss at epoch 342: 0.1642\n",
      "\n",
      "Start of epoch 343\n",
      "Training loss at epoch 343: 0.1642\n",
      "\n",
      "Start of epoch 344\n",
      "Training loss at epoch 344: 0.1642\n",
      "\n",
      "Start of epoch 345\n",
      "Training loss at epoch 345: 0.1642\n",
      "\n",
      "Start of epoch 346\n",
      "Training loss at epoch 346: 0.1642\n",
      "\n",
      "Start of epoch 347\n",
      "Training loss at epoch 347: 0.1642\n",
      "\n",
      "Start of epoch 348\n",
      "Training loss at epoch 348: 0.1642\n",
      "\n",
      "Start of epoch 349\n",
      "Training loss at epoch 349: 0.1642\n",
      "\n",
      "Start of epoch 350\n",
      "Training loss at epoch 350: 0.1642\n",
      "\n",
      "Start of epoch 351\n",
      "Training loss at epoch 351: 0.1642\n",
      "\n",
      "Start of epoch 352\n",
      "Training loss at epoch 352: 0.1642\n",
      "\n",
      "Start of epoch 353\n",
      "Training loss at epoch 353: 0.1642\n",
      "\n",
      "Start of epoch 354\n",
      "Training loss at epoch 354: 0.1642\n",
      "\n",
      "Start of epoch 355\n",
      "Training loss at epoch 355: 0.1642\n",
      "\n",
      "Start of epoch 356\n",
      "Training loss at epoch 356: 0.1642\n",
      "\n",
      "Start of epoch 357\n",
      "Training loss at epoch 357: 0.1642\n",
      "\n",
      "Start of epoch 358\n",
      "Training loss at epoch 358: 0.1642\n",
      "\n",
      "Start of epoch 359\n",
      "Training loss at epoch 359: 0.1642\n",
      "\n",
      "Start of epoch 360\n",
      "Training loss at epoch 360: 0.1642\n",
      "\n",
      "Start of epoch 361\n",
      "Training loss at epoch 361: 0.1642\n",
      "\n",
      "Start of epoch 362\n",
      "Training loss at epoch 362: 0.1641\n",
      "\n",
      "Start of epoch 363\n",
      "Training loss at epoch 363: 0.1641\n",
      "\n",
      "Start of epoch 364\n",
      "Training loss at epoch 364: 0.1641\n",
      "\n",
      "Start of epoch 365\n",
      "Training loss at epoch 365: 0.1641\n",
      "\n",
      "Start of epoch 366\n",
      "Training loss at epoch 366: 0.1641\n",
      "\n",
      "Start of epoch 367\n",
      "Training loss at epoch 367: 0.1641\n",
      "\n",
      "Start of epoch 368\n",
      "Training loss at epoch 368: 0.1641\n",
      "\n",
      "Start of epoch 369\n",
      "Training loss at epoch 369: 0.1641\n",
      "\n",
      "Start of epoch 370\n",
      "Training loss at epoch 370: 0.1641\n",
      "\n",
      "Start of epoch 371\n",
      "Training loss at epoch 371: 0.1641\n",
      "\n",
      "Start of epoch 372\n",
      "Training loss at epoch 372: 0.1641\n",
      "\n",
      "Start of epoch 373\n",
      "Training loss at epoch 373: 0.1641\n",
      "\n",
      "Start of epoch 374\n",
      "Training loss at epoch 374: 0.1641\n",
      "\n",
      "Start of epoch 375\n",
      "Training loss at epoch 375: 0.1641\n",
      "\n",
      "Start of epoch 376\n",
      "Training loss at epoch 376: 0.1641\n",
      "\n",
      "Start of epoch 377\n",
      "Training loss at epoch 377: 0.1641\n",
      "\n",
      "Start of epoch 378\n",
      "Training loss at epoch 378: 0.1641\n",
      "\n",
      "Start of epoch 379\n",
      "Training loss at epoch 379: 0.1641\n",
      "\n",
      "Start of epoch 380\n",
      "Training loss at epoch 380: 0.1641\n",
      "\n",
      "Start of epoch 381\n",
      "Training loss at epoch 381: 0.1641\n",
      "\n",
      "Start of epoch 382\n",
      "Training loss at epoch 382: 0.1641\n",
      "\n",
      "Start of epoch 383\n",
      "Training loss at epoch 383: 0.1641\n",
      "\n",
      "Start of epoch 384\n",
      "Training loss at epoch 384: 0.1641\n",
      "\n",
      "Start of epoch 385\n",
      "Training loss at epoch 385: 0.1641\n",
      "\n",
      "Start of epoch 386\n",
      "Training loss at epoch 386: 0.1641\n",
      "\n",
      "Start of epoch 387\n",
      "Training loss at epoch 387: 0.1641\n",
      "\n",
      "Start of epoch 388\n",
      "Training loss at epoch 388: 0.1641\n",
      "\n",
      "Start of epoch 389\n",
      "Training loss at epoch 389: 0.1641\n",
      "\n",
      "Start of epoch 390\n",
      "Training loss at epoch 390: 0.1641\n",
      "\n",
      "Start of epoch 391\n",
      "Training loss at epoch 391: 0.1641\n",
      "\n",
      "Start of epoch 392\n",
      "Training loss at epoch 392: 0.1641\n",
      "\n",
      "Start of epoch 393\n",
      "Training loss at epoch 393: 0.1641\n",
      "\n",
      "Start of epoch 394\n",
      "Training loss at epoch 394: 0.1641\n",
      "\n",
      "Start of epoch 395\n",
      "Training loss at epoch 395: 0.1641\n",
      "\n",
      "Start of epoch 396\n",
      "Training loss at epoch 396: 0.1641\n",
      "\n",
      "Start of epoch 397\n",
      "Training loss at epoch 397: 0.1641\n",
      "\n",
      "Start of epoch 398\n",
      "Training loss at epoch 398: 0.1641\n",
      "\n",
      "Start of epoch 399\n",
      "Training loss at epoch 399: 0.1641\n",
      "\n",
      "Start of epoch 400\n",
      "Training loss at epoch 400: 0.1641\n",
      "\n",
      "Start of epoch 401\n",
      "Training loss at epoch 401: 0.1641\n",
      "\n",
      "Start of epoch 402\n",
      "Training loss at epoch 402: 0.1641\n",
      "\n",
      "Start of epoch 403\n",
      "Training loss at epoch 403: 0.1641\n",
      "\n",
      "Start of epoch 404\n",
      "Training loss at epoch 404: 0.1641\n",
      "\n",
      "Start of epoch 405\n",
      "Training loss at epoch 405: 0.1641\n",
      "\n",
      "Start of epoch 406\n",
      "Training loss at epoch 406: 0.1641\n",
      "\n",
      "Start of epoch 407\n",
      "Training loss at epoch 407: 0.1641\n",
      "\n",
      "Start of epoch 408\n",
      "Training loss at epoch 408: 0.1641\n",
      "\n",
      "Start of epoch 409\n",
      "Training loss at epoch 409: 0.1641\n",
      "\n",
      "Start of epoch 410\n",
      "Training loss at epoch 410: 0.1641\n",
      "\n",
      "Start of epoch 411\n",
      "Training loss at epoch 411: 0.1641\n",
      "\n",
      "Start of epoch 412\n",
      "Training loss at epoch 412: 0.1641\n",
      "\n",
      "Start of epoch 413\n",
      "Training loss at epoch 413: 0.1641\n",
      "\n",
      "Start of epoch 414\n",
      "Training loss at epoch 414: 0.1641\n",
      "\n",
      "Start of epoch 415\n",
      "Training loss at epoch 415: 0.1641\n",
      "\n",
      "Start of epoch 416\n",
      "Training loss at epoch 416: 0.1641\n",
      "\n",
      "Start of epoch 417\n",
      "Training loss at epoch 417: 0.1641\n",
      "\n",
      "Start of epoch 418\n",
      "Training loss at epoch 418: 0.1641\n",
      "\n",
      "Start of epoch 419\n",
      "Training loss at epoch 419: 0.1641\n",
      "\n",
      "Start of epoch 420\n",
      "Training loss at epoch 420: 0.1641\n",
      "\n",
      "Start of epoch 421\n",
      "Training loss at epoch 421: 0.1641\n",
      "\n",
      "Start of epoch 422\n",
      "Training loss at epoch 422: 0.1641\n",
      "\n",
      "Start of epoch 423\n",
      "Training loss at epoch 423: 0.1641\n",
      "\n",
      "Start of epoch 424\n",
      "Training loss at epoch 424: 0.1641\n",
      "\n",
      "Start of epoch 425\n",
      "Training loss at epoch 425: 0.1641\n",
      "\n",
      "Start of epoch 426\n",
      "Training loss at epoch 426: 0.1641\n",
      "\n",
      "Start of epoch 427\n",
      "Training loss at epoch 427: 0.1641\n",
      "\n",
      "Start of epoch 428\n",
      "Training loss at epoch 428: 0.1641\n",
      "\n",
      "Start of epoch 429\n",
      "Training loss at epoch 429: 0.1641\n",
      "\n",
      "Start of epoch 430\n",
      "Training loss at epoch 430: 0.1641\n",
      "\n",
      "Start of epoch 431\n",
      "Training loss at epoch 431: 0.1641\n",
      "\n",
      "Start of epoch 432\n",
      "Training loss at epoch 432: 0.1641\n",
      "\n",
      "Start of epoch 433\n",
      "Training loss at epoch 433: 0.1641\n",
      "\n",
      "Start of epoch 434\n",
      "Training loss at epoch 434: 0.1641\n",
      "\n",
      "Start of epoch 435\n",
      "Training loss at epoch 435: 0.1641\n",
      "\n",
      "Start of epoch 436\n",
      "Training loss at epoch 436: 0.1641\n",
      "\n",
      "Start of epoch 437\n",
      "Training loss at epoch 437: 0.1641\n",
      "\n",
      "Start of epoch 438\n",
      "Training loss at epoch 438: 0.1641\n",
      "\n",
      "Start of epoch 439\n",
      "Training loss at epoch 439: 0.1641\n",
      "\n",
      "Start of epoch 440\n",
      "Training loss at epoch 440: 0.1641\n",
      "\n",
      "Start of epoch 441\n",
      "Training loss at epoch 441: 0.1641\n",
      "\n",
      "Start of epoch 442\n",
      "Training loss at epoch 442: 0.1641\n",
      "\n",
      "Start of epoch 443\n",
      "Training loss at epoch 443: 0.1641\n",
      "\n",
      "Start of epoch 444\n",
      "Training loss at epoch 444: 0.1641\n",
      "\n",
      "Start of epoch 445\n",
      "Training loss at epoch 445: 0.1641\n",
      "\n",
      "Start of epoch 446\n",
      "Training loss at epoch 446: 0.1641\n",
      "\n",
      "Start of epoch 447\n",
      "Training loss at epoch 447: 0.1641\n",
      "\n",
      "Start of epoch 448\n",
      "Training loss at epoch 448: 0.1641\n",
      "\n",
      "Start of epoch 449\n",
      "Training loss at epoch 449: 0.1641\n",
      "\n",
      "Start of epoch 450\n",
      "Training loss at epoch 450: 0.1641\n",
      "\n",
      "Start of epoch 451\n",
      "Training loss at epoch 451: 0.1641\n",
      "\n",
      "Start of epoch 452\n",
      "Training loss at epoch 452: 0.1641\n",
      "\n",
      "Start of epoch 453\n",
      "Training loss at epoch 453: 0.1641\n",
      "\n",
      "Start of epoch 454\n",
      "Training loss at epoch 454: 0.1641\n",
      "\n",
      "Start of epoch 455\n",
      "Training loss at epoch 455: 0.1641\n",
      "\n",
      "Start of epoch 456\n",
      "Training loss at epoch 456: 0.1641\n",
      "\n",
      "Start of epoch 457\n",
      "Training loss at epoch 457: 0.1641\n",
      "\n",
      "Start of epoch 458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 458: 0.1641\n",
      "\n",
      "Start of epoch 459\n",
      "Training loss at epoch 459: 0.1640\n",
      "\n",
      "Start of epoch 460\n",
      "Training loss at epoch 460: 0.1640\n",
      "\n",
      "Start of epoch 461\n",
      "Training loss at epoch 461: 0.1640\n",
      "\n",
      "Start of epoch 462\n",
      "Training loss at epoch 462: 0.1640\n",
      "\n",
      "Start of epoch 463\n",
      "Training loss at epoch 463: 0.1640\n",
      "\n",
      "Start of epoch 464\n",
      "Training loss at epoch 464: 0.1640\n",
      "\n",
      "Start of epoch 465\n",
      "Training loss at epoch 465: 0.1640\n",
      "\n",
      "Start of epoch 466\n",
      "Training loss at epoch 466: 0.1640\n",
      "\n",
      "Start of epoch 467\n",
      "Training loss at epoch 467: 0.1640\n",
      "\n",
      "Start of epoch 468\n",
      "Training loss at epoch 468: 0.1640\n",
      "\n",
      "Start of epoch 469\n",
      "Training loss at epoch 469: 0.1640\n",
      "\n",
      "Start of epoch 470\n",
      "Training loss at epoch 470: 0.1640\n",
      "\n",
      "Start of epoch 471\n",
      "Training loss at epoch 471: 0.1640\n",
      "\n",
      "Start of epoch 472\n",
      "Training loss at epoch 472: 0.1640\n",
      "\n",
      "Start of epoch 473\n",
      "Training loss at epoch 473: 0.1640\n",
      "\n",
      "Start of epoch 474\n",
      "Training loss at epoch 474: 0.1640\n",
      "\n",
      "Start of epoch 475\n",
      "Training loss at epoch 475: 0.1640\n",
      "\n",
      "Start of epoch 476\n",
      "Training loss at epoch 476: 0.1640\n",
      "\n",
      "Start of epoch 477\n",
      "Training loss at epoch 477: 0.1640\n",
      "\n",
      "Start of epoch 478\n",
      "Training loss at epoch 478: 0.1640\n",
      "\n",
      "Start of epoch 479\n",
      "Training loss at epoch 479: 0.1640\n",
      "\n",
      "Start of epoch 480\n",
      "Training loss at epoch 480: 0.1640\n",
      "\n",
      "Start of epoch 481\n",
      "Training loss at epoch 481: 0.1640\n",
      "\n",
      "Start of epoch 482\n",
      "Training loss at epoch 482: 0.1640\n",
      "\n",
      "Start of epoch 483\n",
      "Training loss at epoch 483: 0.1640\n",
      "\n",
      "Start of epoch 484\n",
      "Training loss at epoch 484: 0.1640\n",
      "\n",
      "Start of epoch 485\n",
      "Training loss at epoch 485: 0.1640\n",
      "\n",
      "Start of epoch 486\n",
      "Training loss at epoch 486: 0.1640\n",
      "\n",
      "Start of epoch 487\n",
      "Training loss at epoch 487: 0.1640\n",
      "\n",
      "Start of epoch 488\n",
      "Training loss at epoch 488: 0.1640\n",
      "\n",
      "Start of epoch 489\n",
      "Training loss at epoch 489: 0.1640\n",
      "\n",
      "Start of epoch 490\n",
      "Training loss at epoch 490: 0.1640\n",
      "\n",
      "Start of epoch 491\n",
      "Training loss at epoch 491: 0.1640\n",
      "\n",
      "Start of epoch 492\n",
      "Training loss at epoch 492: 0.1640\n",
      "\n",
      "Start of epoch 493\n",
      "Training loss at epoch 493: 0.1640\n",
      "\n",
      "Start of epoch 494\n",
      "Training loss at epoch 494: 0.1640\n",
      "\n",
      "Start of epoch 495\n",
      "Training loss at epoch 495: 0.1640\n",
      "\n",
      "Start of epoch 496\n",
      "Training loss at epoch 496: 0.1640\n",
      "\n",
      "Start of epoch 497\n",
      "Training loss at epoch 497: 0.1640\n",
      "\n",
      "Start of epoch 498\n",
      "Training loss at epoch 498: 0.1640\n",
      "\n",
      "Start of epoch 499\n",
      "Training loss at epoch 499: 0.1640\n",
      "[<tf.Variable 'parameters:0' shape=(15,) dtype=float32, numpy=\n",
      "array([3.2224674 , 1.027448  , 4.6830516 , 0.59412545, 5.976449  ,\n",
      "       6.047775  , 4.1740165 , 2.647325  , 4.533346  , 2.217821  ,\n",
      "       5.2809544 , 3.1913228 , 5.1876497 , 1.3863862 , 0.02792324],\n",
      "      dtype=float32)>]\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 0.8933\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 0.8779\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.8647\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.8537\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.8449\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.8376\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.8312\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.8249\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.8181\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.8105\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.8019\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.7922\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.7817\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.7704\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.7584\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.7461\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.7337\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.7217\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.7107\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.7010\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.6925\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.6846\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.6762\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.6667\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.6563\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.6452\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.6338\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.6224\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.6108\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.5989\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.5863\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.5733\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.5600\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.5465\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.5332\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.5202\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.5079\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.4963\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.4856\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.4758\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.4669\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.4590\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.4520\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.4459\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.4403\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.4352\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.4303\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.4257\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.4216\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.4181\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.4152\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.4129\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.4110\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.4093\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.4075\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.4057\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.4038\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.4016\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.3991\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.3961\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.3925\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.3882\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.3833\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.3776\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.3712\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.3640\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.3560\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.3472\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.3377\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.3275\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.3169\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.3058\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.2945\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.2833\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.2725\n",
      "\n",
      "Start of epoch 75\n",
      "Training loss at epoch 75: 0.2626\n",
      "\n",
      "Start of epoch 76\n",
      "Training loss at epoch 76: 0.2538\n",
      "\n",
      "Start of epoch 77\n",
      "Training loss at epoch 77: 0.2463\n",
      "\n",
      "Start of epoch 78\n",
      "Training loss at epoch 78: 0.2400\n",
      "\n",
      "Start of epoch 79\n",
      "Training loss at epoch 79: 0.2345\n",
      "\n",
      "Start of epoch 80\n",
      "Training loss at epoch 80: 0.2294\n",
      "\n",
      "Start of epoch 81\n",
      "Training loss at epoch 81: 0.2240\n",
      "\n",
      "Start of epoch 82\n",
      "Training loss at epoch 82: 0.2183\n",
      "\n",
      "Start of epoch 83\n",
      "Training loss at epoch 83: 0.2121\n",
      "\n",
      "Start of epoch 84\n",
      "Training loss at epoch 84: 0.2059\n",
      "\n",
      "Start of epoch 85\n",
      "Training loss at epoch 85: 0.2000\n",
      "\n",
      "Start of epoch 86\n",
      "Training loss at epoch 86: 0.1948\n",
      "\n",
      "Start of epoch 87\n",
      "Training loss at epoch 87: 0.1906\n",
      "\n",
      "Start of epoch 88\n",
      "Training loss at epoch 88: 0.1876\n",
      "\n",
      "Start of epoch 89\n",
      "Training loss at epoch 89: 0.1854\n",
      "\n",
      "Start of epoch 90\n",
      "Training loss at epoch 90: 0.1839\n",
      "\n",
      "Start of epoch 91\n",
      "Training loss at epoch 91: 0.1826\n",
      "\n",
      "Start of epoch 92\n",
      "Training loss at epoch 92: 0.1812\n",
      "\n",
      "Start of epoch 93\n",
      "Training loss at epoch 93: 0.1795\n",
      "\n",
      "Start of epoch 94\n",
      "Training loss at epoch 94: 0.1778\n",
      "\n",
      "Start of epoch 95\n",
      "Training loss at epoch 95: 0.1761\n",
      "\n",
      "Start of epoch 96\n",
      "Training loss at epoch 96: 0.1745\n",
      "\n",
      "Start of epoch 97\n",
      "Training loss at epoch 97: 0.1733\n",
      "\n",
      "Start of epoch 98\n",
      "Training loss at epoch 98: 0.1724\n",
      "\n",
      "Start of epoch 99\n",
      "Training loss at epoch 99: 0.1718\n",
      "\n",
      "Start of epoch 100\n",
      "Training loss at epoch 100: 0.1714\n",
      "\n",
      "Start of epoch 101\n",
      "Training loss at epoch 101: 0.1711\n",
      "\n",
      "Start of epoch 102\n",
      "Training loss at epoch 102: 0.1707\n",
      "\n",
      "Start of epoch 103\n",
      "Training loss at epoch 103: 0.1702\n",
      "\n",
      "Start of epoch 104\n",
      "Training loss at epoch 104: 0.1697\n",
      "\n",
      "Start of epoch 105\n",
      "Training loss at epoch 105: 0.1691\n",
      "\n",
      "Start of epoch 106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 106: 0.1685\n",
      "\n",
      "Start of epoch 107\n",
      "Training loss at epoch 107: 0.1681\n",
      "\n",
      "Start of epoch 108\n",
      "Training loss at epoch 108: 0.1678\n",
      "\n",
      "Start of epoch 109\n",
      "Training loss at epoch 109: 0.1676\n",
      "\n",
      "Start of epoch 110\n",
      "Training loss at epoch 110: 0.1674\n",
      "\n",
      "Start of epoch 111\n",
      "Training loss at epoch 111: 0.1673\n",
      "\n",
      "Start of epoch 112\n",
      "Training loss at epoch 112: 0.1671\n",
      "\n",
      "Start of epoch 113\n",
      "Training loss at epoch 113: 0.1667\n",
      "\n",
      "Start of epoch 114\n",
      "Training loss at epoch 114: 0.1665\n",
      "\n",
      "Start of epoch 115\n",
      "Training loss at epoch 115: 0.1663\n",
      "\n",
      "Start of epoch 116\n",
      "Training loss at epoch 116: 0.1661\n",
      "\n",
      "Start of epoch 117\n",
      "Training loss at epoch 117: 0.1658\n",
      "\n",
      "Start of epoch 118\n",
      "Training loss at epoch 118: 0.1657\n",
      "\n",
      "Start of epoch 119\n",
      "Training loss at epoch 119: 0.1656\n",
      "\n",
      "Start of epoch 120\n",
      "Training loss at epoch 120: 0.1655\n",
      "\n",
      "Start of epoch 121\n",
      "Training loss at epoch 121: 0.1653\n",
      "\n",
      "Start of epoch 122\n",
      "Training loss at epoch 122: 0.1652\n",
      "\n",
      "Start of epoch 123\n",
      "Training loss at epoch 123: 0.1652\n",
      "\n",
      "Start of epoch 124\n",
      "Training loss at epoch 124: 0.1650\n",
      "\n",
      "Start of epoch 125\n",
      "Training loss at epoch 125: 0.1649\n",
      "\n",
      "Start of epoch 126\n",
      "Training loss at epoch 126: 0.1648\n",
      "\n",
      "Start of epoch 127\n",
      "Training loss at epoch 127: 0.1647\n",
      "\n",
      "Start of epoch 128\n",
      "Training loss at epoch 128: 0.1646\n",
      "\n",
      "Start of epoch 129\n",
      "Training loss at epoch 129: 0.1645\n",
      "\n",
      "Start of epoch 130\n",
      "Training loss at epoch 130: 0.1645\n",
      "\n",
      "Start of epoch 131\n",
      "Training loss at epoch 131: 0.1645\n",
      "\n",
      "Start of epoch 132\n",
      "Training loss at epoch 132: 0.1644\n",
      "\n",
      "Start of epoch 133\n",
      "Training loss at epoch 133: 0.1643\n",
      "\n",
      "Start of epoch 134\n",
      "Training loss at epoch 134: 0.1643\n",
      "\n",
      "Start of epoch 135\n",
      "Training loss at epoch 135: 0.1642\n",
      "\n",
      "Start of epoch 136\n",
      "Training loss at epoch 136: 0.1642\n",
      "\n",
      "Start of epoch 137\n",
      "Training loss at epoch 137: 0.1642\n",
      "\n",
      "Start of epoch 138\n",
      "Training loss at epoch 138: 0.1641\n",
      "\n",
      "Start of epoch 139\n",
      "Training loss at epoch 139: 0.1641\n",
      "\n",
      "Start of epoch 140\n",
      "Training loss at epoch 140: 0.1641\n",
      "\n",
      "Start of epoch 141\n",
      "Training loss at epoch 141: 0.1641\n",
      "\n",
      "Start of epoch 142\n",
      "Training loss at epoch 142: 0.1641\n",
      "\n",
      "Start of epoch 143\n",
      "Training loss at epoch 143: 0.1640\n",
      "\n",
      "Start of epoch 144\n",
      "Training loss at epoch 144: 0.1640\n",
      "\n",
      "Start of epoch 145\n",
      "Training loss at epoch 145: 0.1640\n",
      "\n",
      "Start of epoch 146\n",
      "Training loss at epoch 146: 0.1640\n",
      "\n",
      "Start of epoch 147\n",
      "Training loss at epoch 147: 0.1640\n",
      "\n",
      "Start of epoch 148\n",
      "Training loss at epoch 148: 0.1640\n",
      "\n",
      "Start of epoch 149\n",
      "Training loss at epoch 149: 0.1640\n",
      "\n",
      "Start of epoch 150\n",
      "Training loss at epoch 150: 0.1640\n",
      "\n",
      "Start of epoch 151\n",
      "Training loss at epoch 151: 0.1640\n",
      "\n",
      "Start of epoch 152\n",
      "Training loss at epoch 152: 0.1639\n",
      "\n",
      "Start of epoch 153\n",
      "Training loss at epoch 153: 0.1639\n",
      "\n",
      "Start of epoch 154\n",
      "Training loss at epoch 154: 0.1639\n",
      "\n",
      "Start of epoch 155\n",
      "Training loss at epoch 155: 0.1639\n",
      "\n",
      "Start of epoch 156\n",
      "Training loss at epoch 156: 0.1639\n",
      "\n",
      "Start of epoch 157\n",
      "Training loss at epoch 157: 0.1639\n",
      "\n",
      "Start of epoch 158\n",
      "Training loss at epoch 158: 0.1639\n",
      "\n",
      "Start of epoch 159\n",
      "Training loss at epoch 159: 0.1639\n",
      "\n",
      "Start of epoch 160\n",
      "Training loss at epoch 160: 0.1639\n",
      "\n",
      "Start of epoch 161\n",
      "Training loss at epoch 161: 0.1639\n",
      "\n",
      "Start of epoch 162\n",
      "Training loss at epoch 162: 0.1639\n",
      "\n",
      "Start of epoch 163\n",
      "Training loss at epoch 163: 0.1639\n",
      "\n",
      "Start of epoch 164\n",
      "Training loss at epoch 164: 0.1639\n",
      "\n",
      "Start of epoch 165\n",
      "Training loss at epoch 165: 0.1639\n",
      "\n",
      "Start of epoch 166\n",
      "Training loss at epoch 166: 0.1639\n",
      "\n",
      "Start of epoch 167\n",
      "Training loss at epoch 167: 0.1639\n",
      "\n",
      "Start of epoch 168\n",
      "Training loss at epoch 168: 0.1639\n",
      "\n",
      "Start of epoch 169\n",
      "Training loss at epoch 169: 0.1639\n",
      "\n",
      "Start of epoch 170\n",
      "Training loss at epoch 170: 0.1639\n",
      "\n",
      "Start of epoch 171\n",
      "Training loss at epoch 171: 0.1639\n",
      "\n",
      "Start of epoch 172\n",
      "Training loss at epoch 172: 0.1639\n",
      "\n",
      "Start of epoch 173\n",
      "Training loss at epoch 173: 0.1639\n",
      "\n",
      "Start of epoch 174\n",
      "Training loss at epoch 174: 0.1639\n",
      "\n",
      "Start of epoch 175\n",
      "Training loss at epoch 175: 0.1639\n",
      "\n",
      "Start of epoch 176\n",
      "Training loss at epoch 176: 0.1639\n",
      "\n",
      "Start of epoch 177\n",
      "Training loss at epoch 177: 0.1639\n",
      "\n",
      "Start of epoch 178\n",
      "Training loss at epoch 178: 0.1639\n",
      "\n",
      "Start of epoch 179\n",
      "Training loss at epoch 179: 0.1639\n",
      "\n",
      "Start of epoch 180\n",
      "Training loss at epoch 180: 0.1639\n",
      "\n",
      "Start of epoch 181\n",
      "Training loss at epoch 181: 0.1639\n",
      "\n",
      "Start of epoch 182\n",
      "Training loss at epoch 182: 0.1639\n",
      "\n",
      "Start of epoch 183\n",
      "Training loss at epoch 183: 0.1639\n",
      "\n",
      "Start of epoch 184\n",
      "Training loss at epoch 184: 0.1639\n",
      "\n",
      "Start of epoch 185\n",
      "Training loss at epoch 185: 0.1639\n",
      "\n",
      "Start of epoch 186\n",
      "Training loss at epoch 186: 0.1639\n",
      "\n",
      "Start of epoch 187\n",
      "Training loss at epoch 187: 0.1639\n",
      "\n",
      "Start of epoch 188\n",
      "Training loss at epoch 188: 0.1639\n",
      "\n",
      "Start of epoch 189\n",
      "Training loss at epoch 189: 0.1639\n",
      "\n",
      "Start of epoch 190\n",
      "Training loss at epoch 190: 0.1639\n",
      "\n",
      "Start of epoch 191\n",
      "Training loss at epoch 191: 0.1639\n",
      "\n",
      "Start of epoch 192\n",
      "Training loss at epoch 192: 0.1639\n",
      "\n",
      "Start of epoch 193\n",
      "Training loss at epoch 193: 0.1639\n",
      "\n",
      "Start of epoch 194\n",
      "Training loss at epoch 194: 0.1639\n",
      "\n",
      "Start of epoch 195\n",
      "Training loss at epoch 195: 0.1639\n",
      "\n",
      "Start of epoch 196\n",
      "Training loss at epoch 196: 0.1639\n",
      "\n",
      "Start of epoch 197\n",
      "Training loss at epoch 197: 0.1639\n",
      "\n",
      "Start of epoch 198\n",
      "Training loss at epoch 198: 0.1639\n",
      "\n",
      "Start of epoch 199\n",
      "Training loss at epoch 199: 0.1639\n",
      "\n",
      "Start of epoch 200\n",
      "Training loss at epoch 200: 0.1639\n",
      "\n",
      "Start of epoch 201\n",
      "Training loss at epoch 201: 0.1639\n",
      "\n",
      "Start of epoch 202\n",
      "Training loss at epoch 202: 0.1639\n",
      "\n",
      "Start of epoch 203\n",
      "Training loss at epoch 203: 0.1639\n",
      "\n",
      "Start of epoch 204\n",
      "Training loss at epoch 204: 0.1639\n",
      "\n",
      "Start of epoch 205\n",
      "Training loss at epoch 205: 0.1639\n",
      "\n",
      "Start of epoch 206\n",
      "Training loss at epoch 206: 0.1639\n",
      "\n",
      "Start of epoch 207\n",
      "Training loss at epoch 207: 0.1639\n",
      "\n",
      "Start of epoch 208\n",
      "Training loss at epoch 208: 0.1640\n",
      "\n",
      "Start of epoch 209\n",
      "Training loss at epoch 209: 0.1640\n",
      "\n",
      "Start of epoch 210\n",
      "Training loss at epoch 210: 0.1641\n",
      "\n",
      "Start of epoch 211\n",
      "Training loss at epoch 211: 0.1640\n",
      "\n",
      "Start of epoch 212\n",
      "Training loss at epoch 212: 0.1640\n",
      "\n",
      "Start of epoch 213\n",
      "Training loss at epoch 213: 0.1639\n",
      "\n",
      "Start of epoch 214\n",
      "Training loss at epoch 214: 0.1639\n",
      "\n",
      "Start of epoch 215\n",
      "Training loss at epoch 215: 0.1639\n",
      "\n",
      "Start of epoch 216\n",
      "Training loss at epoch 216: 0.1640\n",
      "\n",
      "Start of epoch 217\n",
      "Training loss at epoch 217: 0.1640\n",
      "\n",
      "Start of epoch 218\n",
      "Training loss at epoch 218: 0.1639\n",
      "\n",
      "Start of epoch 219\n",
      "Training loss at epoch 219: 0.1639\n",
      "\n",
      "Start of epoch 220\n",
      "Training loss at epoch 220: 0.1639\n",
      "\n",
      "Start of epoch 221\n",
      "Training loss at epoch 221: 0.1640\n",
      "\n",
      "Start of epoch 222\n",
      "Training loss at epoch 222: 0.1639\n",
      "\n",
      "Start of epoch 223\n",
      "Training loss at epoch 223: 0.1639\n",
      "\n",
      "Start of epoch 224\n",
      "Training loss at epoch 224: 0.1639\n",
      "\n",
      "Start of epoch 225\n",
      "Training loss at epoch 225: 0.1639\n",
      "\n",
      "Start of epoch 226\n",
      "Training loss at epoch 226: 0.1639\n",
      "\n",
      "Start of epoch 227\n",
      "Training loss at epoch 227: 0.1639\n",
      "\n",
      "Start of epoch 228\n",
      "Training loss at epoch 228: 0.1639\n",
      "\n",
      "Start of epoch 229\n",
      "Training loss at epoch 229: 0.1639\n",
      "\n",
      "Start of epoch 230\n",
      "Training loss at epoch 230: 0.1639\n",
      "\n",
      "Start of epoch 231\n",
      "Training loss at epoch 231: 0.1639\n",
      "\n",
      "Start of epoch 232\n",
      "Training loss at epoch 232: 0.1639\n",
      "\n",
      "Start of epoch 233\n",
      "Training loss at epoch 233: 0.1639\n",
      "\n",
      "Start of epoch 234\n",
      "Training loss at epoch 234: 0.1639\n",
      "\n",
      "Start of epoch 235\n",
      "Training loss at epoch 235: 0.1639\n",
      "\n",
      "Start of epoch 236\n",
      "Training loss at epoch 236: 0.1639\n",
      "\n",
      "Start of epoch 237\n",
      "Training loss at epoch 237: 0.1639\n",
      "\n",
      "Start of epoch 238\n",
      "Training loss at epoch 238: 0.1639\n",
      "\n",
      "Start of epoch 239\n",
      "Training loss at epoch 239: 0.1639\n",
      "\n",
      "Start of epoch 240\n",
      "Training loss at epoch 240: 0.1639\n",
      "\n",
      "Start of epoch 241\n",
      "Training loss at epoch 241: 0.1639\n",
      "\n",
      "Start of epoch 242\n",
      "Training loss at epoch 242: 0.1639\n",
      "\n",
      "Start of epoch 243\n",
      "Training loss at epoch 243: 0.1639\n",
      "\n",
      "Start of epoch 244\n",
      "Training loss at epoch 244: 0.1639\n",
      "\n",
      "Start of epoch 245\n",
      "Training loss at epoch 245: 0.1639\n",
      "\n",
      "Start of epoch 246\n",
      "Training loss at epoch 246: 0.1639\n",
      "\n",
      "Start of epoch 247\n",
      "Training loss at epoch 247: 0.1639\n",
      "\n",
      "Start of epoch 248\n",
      "Training loss at epoch 248: 0.1639\n",
      "\n",
      "Start of epoch 249\n",
      "Training loss at epoch 249: 0.1639\n",
      "\n",
      "Start of epoch 250\n",
      "Training loss at epoch 250: 0.1639\n",
      "\n",
      "Start of epoch 251\n",
      "Training loss at epoch 251: 0.1639\n",
      "\n",
      "Start of epoch 252\n",
      "Training loss at epoch 252: 0.1639\n",
      "\n",
      "Start of epoch 253\n",
      "Training loss at epoch 253: 0.1639\n",
      "\n",
      "Start of epoch 254\n",
      "Training loss at epoch 254: 0.1639\n",
      "\n",
      "Start of epoch 255\n",
      "Training loss at epoch 255: 0.1639\n",
      "\n",
      "Start of epoch 256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 256: 0.1639\n",
      "\n",
      "Start of epoch 257\n",
      "Training loss at epoch 257: 0.1639\n",
      "\n",
      "Start of epoch 258\n",
      "Training loss at epoch 258: 0.1639\n",
      "\n",
      "Start of epoch 259\n",
      "Training loss at epoch 259: 0.1639\n",
      "\n",
      "Start of epoch 260\n",
      "Training loss at epoch 260: 0.1639\n",
      "\n",
      "Start of epoch 261\n",
      "Training loss at epoch 261: 0.1639\n",
      "\n",
      "Start of epoch 262\n",
      "Training loss at epoch 262: 0.1639\n",
      "\n",
      "Start of epoch 263\n",
      "Training loss at epoch 263: 0.1639\n",
      "\n",
      "Start of epoch 264\n",
      "Training loss at epoch 264: 0.1639\n",
      "\n",
      "Start of epoch 265\n",
      "Training loss at epoch 265: 0.1639\n",
      "\n",
      "Start of epoch 266\n",
      "Training loss at epoch 266: 0.1639\n",
      "\n",
      "Start of epoch 267\n",
      "Training loss at epoch 267: 0.1639\n",
      "\n",
      "Start of epoch 268\n",
      "Training loss at epoch 268: 0.1639\n",
      "\n",
      "Start of epoch 269\n",
      "Training loss at epoch 269: 0.1639\n",
      "\n",
      "Start of epoch 270\n",
      "Training loss at epoch 270: 0.1639\n",
      "\n",
      "Start of epoch 271\n",
      "Training loss at epoch 271: 0.1639\n",
      "\n",
      "Start of epoch 272\n",
      "Training loss at epoch 272: 0.1639\n",
      "\n",
      "Start of epoch 273\n",
      "Training loss at epoch 273: 0.1639\n",
      "\n",
      "Start of epoch 274\n",
      "Training loss at epoch 274: 0.1639\n",
      "\n",
      "Start of epoch 275\n",
      "Training loss at epoch 275: 0.1639\n",
      "\n",
      "Start of epoch 276\n",
      "Training loss at epoch 276: 0.1639\n",
      "\n",
      "Start of epoch 277\n",
      "Training loss at epoch 277: 0.1639\n",
      "\n",
      "Start of epoch 278\n",
      "Training loss at epoch 278: 0.1639\n",
      "\n",
      "Start of epoch 279\n",
      "Training loss at epoch 279: 0.1639\n",
      "\n",
      "Start of epoch 280\n",
      "Training loss at epoch 280: 0.1639\n",
      "\n",
      "Start of epoch 281\n",
      "Training loss at epoch 281: 0.1639\n",
      "\n",
      "Start of epoch 282\n",
      "Training loss at epoch 282: 0.1639\n",
      "\n",
      "Start of epoch 283\n",
      "Training loss at epoch 283: 0.1639\n",
      "\n",
      "Start of epoch 284\n",
      "Training loss at epoch 284: 0.1639\n",
      "\n",
      "Start of epoch 285\n",
      "Training loss at epoch 285: 0.1639\n",
      "\n",
      "Start of epoch 286\n",
      "Training loss at epoch 286: 0.1639\n",
      "\n",
      "Start of epoch 287\n",
      "Training loss at epoch 287: 0.1639\n",
      "\n",
      "Start of epoch 288\n",
      "Training loss at epoch 288: 0.1639\n",
      "\n",
      "Start of epoch 289\n",
      "Training loss at epoch 289: 0.1639\n",
      "\n",
      "Start of epoch 290\n",
      "Training loss at epoch 290: 0.1639\n",
      "\n",
      "Start of epoch 291\n",
      "Training loss at epoch 291: 0.1639\n",
      "\n",
      "Start of epoch 292\n",
      "Training loss at epoch 292: 0.1639\n",
      "\n",
      "Start of epoch 293\n",
      "Training loss at epoch 293: 0.1639\n",
      "\n",
      "Start of epoch 294\n",
      "Training loss at epoch 294: 0.1639\n",
      "\n",
      "Start of epoch 295\n",
      "Training loss at epoch 295: 0.1639\n",
      "\n",
      "Start of epoch 296\n",
      "Training loss at epoch 296: 0.1639\n",
      "\n",
      "Start of epoch 297\n",
      "Training loss at epoch 297: 0.1639\n",
      "\n",
      "Start of epoch 298\n",
      "Training loss at epoch 298: 0.1639\n",
      "\n",
      "Start of epoch 299\n",
      "Training loss at epoch 299: 0.1639\n",
      "\n",
      "Start of epoch 300\n",
      "Training loss at epoch 300: 0.1639\n",
      "\n",
      "Start of epoch 301\n",
      "Training loss at epoch 301: 0.1639\n",
      "\n",
      "Start of epoch 302\n",
      "Training loss at epoch 302: 0.1639\n",
      "\n",
      "Start of epoch 303\n",
      "Training loss at epoch 303: 0.1639\n",
      "\n",
      "Start of epoch 304\n",
      "Training loss at epoch 304: 0.1639\n",
      "\n",
      "Start of epoch 305\n",
      "Training loss at epoch 305: 0.1639\n",
      "\n",
      "Start of epoch 306\n",
      "Training loss at epoch 306: 0.1639\n",
      "\n",
      "Start of epoch 307\n",
      "Training loss at epoch 307: 0.1639\n",
      "\n",
      "Start of epoch 308\n",
      "Training loss at epoch 308: 0.1639\n",
      "\n",
      "Start of epoch 309\n",
      "Training loss at epoch 309: 0.1640\n",
      "\n",
      "Start of epoch 310\n",
      "Training loss at epoch 310: 0.1640\n",
      "\n",
      "Start of epoch 311\n",
      "Training loss at epoch 311: 0.1641\n",
      "\n",
      "Start of epoch 312\n",
      "Training loss at epoch 312: 0.1641\n",
      "\n",
      "Start of epoch 313\n",
      "Training loss at epoch 313: 0.1641\n",
      "\n",
      "Start of epoch 314\n",
      "Training loss at epoch 314: 0.1640\n",
      "\n",
      "Start of epoch 315\n",
      "Training loss at epoch 315: 0.1639\n",
      "\n",
      "Start of epoch 316\n",
      "Training loss at epoch 316: 0.1639\n",
      "\n",
      "Start of epoch 317\n",
      "Training loss at epoch 317: 0.1640\n",
      "\n",
      "Start of epoch 318\n",
      "Training loss at epoch 318: 0.1640\n",
      "\n",
      "Start of epoch 319\n",
      "Training loss at epoch 319: 0.1640\n",
      "\n",
      "Start of epoch 320\n",
      "Training loss at epoch 320: 0.1639\n",
      "\n",
      "Start of epoch 321\n",
      "Training loss at epoch 321: 0.1639\n",
      "\n",
      "Start of epoch 322\n",
      "Training loss at epoch 322: 0.1639\n",
      "\n",
      "Start of epoch 323\n",
      "Training loss at epoch 323: 0.1640\n",
      "\n",
      "Start of epoch 324\n",
      "Training loss at epoch 324: 0.1639\n",
      "\n",
      "Start of epoch 325\n",
      "Training loss at epoch 325: 0.1639\n",
      "\n",
      "Start of epoch 326\n",
      "Training loss at epoch 326: 0.1639\n",
      "\n",
      "Start of epoch 327\n",
      "Training loss at epoch 327: 0.1639\n",
      "\n",
      "Start of epoch 328\n",
      "Training loss at epoch 328: 0.1639\n",
      "\n",
      "Start of epoch 329\n",
      "Training loss at epoch 329: 0.1639\n",
      "\n",
      "Start of epoch 330\n",
      "Training loss at epoch 330: 0.1639\n",
      "\n",
      "Start of epoch 331\n",
      "Training loss at epoch 331: 0.1639\n",
      "\n",
      "Start of epoch 332\n",
      "Training loss at epoch 332: 0.1639\n",
      "\n",
      "Start of epoch 333\n",
      "Training loss at epoch 333: 0.1639\n",
      "\n",
      "Start of epoch 334\n",
      "Training loss at epoch 334: 0.1639\n",
      "\n",
      "Start of epoch 335\n",
      "Training loss at epoch 335: 0.1639\n",
      "\n",
      "Start of epoch 336\n",
      "Training loss at epoch 336: 0.1639\n",
      "\n",
      "Start of epoch 337\n",
      "Training loss at epoch 337: 0.1639\n",
      "\n",
      "Start of epoch 338\n",
      "Training loss at epoch 338: 0.1639\n",
      "\n",
      "Start of epoch 339\n",
      "Training loss at epoch 339: 0.1639\n",
      "\n",
      "Start of epoch 340\n",
      "Training loss at epoch 340: 0.1639\n",
      "\n",
      "Start of epoch 341\n",
      "Training loss at epoch 341: 0.1639\n",
      "\n",
      "Start of epoch 342\n",
      "Training loss at epoch 342: 0.1639\n",
      "\n",
      "Start of epoch 343\n",
      "Training loss at epoch 343: 0.1639\n",
      "\n",
      "Start of epoch 344\n",
      "Training loss at epoch 344: 0.1639\n",
      "\n",
      "Start of epoch 345\n",
      "Training loss at epoch 345: 0.1639\n",
      "\n",
      "Start of epoch 346\n",
      "Training loss at epoch 346: 0.1639\n",
      "\n",
      "Start of epoch 347\n",
      "Training loss at epoch 347: 0.1639\n",
      "\n",
      "Start of epoch 348\n",
      "Training loss at epoch 348: 0.1639\n",
      "\n",
      "Start of epoch 349\n",
      "Training loss at epoch 349: 0.1639\n",
      "\n",
      "Start of epoch 350\n",
      "Training loss at epoch 350: 0.1639\n",
      "\n",
      "Start of epoch 351\n",
      "Training loss at epoch 351: 0.1639\n",
      "\n",
      "Start of epoch 352\n",
      "Training loss at epoch 352: 0.1639\n",
      "\n",
      "Start of epoch 353\n",
      "Training loss at epoch 353: 0.1639\n",
      "\n",
      "Start of epoch 354\n",
      "Training loss at epoch 354: 0.1639\n",
      "\n",
      "Start of epoch 355\n",
      "Training loss at epoch 355: 0.1639\n",
      "\n",
      "Start of epoch 356\n",
      "Training loss at epoch 356: 0.1639\n",
      "\n",
      "Start of epoch 357\n",
      "Training loss at epoch 357: 0.1639\n",
      "\n",
      "Start of epoch 358\n",
      "Training loss at epoch 358: 0.1639\n",
      "\n",
      "Start of epoch 359\n",
      "Training loss at epoch 359: 0.1639\n",
      "\n",
      "Start of epoch 360\n",
      "Training loss at epoch 360: 0.1639\n",
      "\n",
      "Start of epoch 361\n",
      "Training loss at epoch 361: 0.1639\n",
      "\n",
      "Start of epoch 362\n",
      "Training loss at epoch 362: 0.1639\n",
      "\n",
      "Start of epoch 363\n",
      "Training loss at epoch 363: 0.1639\n",
      "\n",
      "Start of epoch 364\n",
      "Training loss at epoch 364: 0.1639\n",
      "\n",
      "Start of epoch 365\n",
      "Training loss at epoch 365: 0.1639\n",
      "\n",
      "Start of epoch 366\n",
      "Training loss at epoch 366: 0.1639\n",
      "\n",
      "Start of epoch 367\n",
      "Training loss at epoch 367: 0.1639\n",
      "\n",
      "Start of epoch 368\n",
      "Training loss at epoch 368: 0.1639\n",
      "\n",
      "Start of epoch 369\n",
      "Training loss at epoch 369: 0.1639\n",
      "\n",
      "Start of epoch 370\n",
      "Training loss at epoch 370: 0.1639\n",
      "\n",
      "Start of epoch 371\n",
      "Training loss at epoch 371: 0.1639\n",
      "\n",
      "Start of epoch 372\n",
      "Training loss at epoch 372: 0.1639\n",
      "\n",
      "Start of epoch 373\n",
      "Training loss at epoch 373: 0.1639\n",
      "\n",
      "Start of epoch 374\n",
      "Training loss at epoch 374: 0.1639\n",
      "\n",
      "Start of epoch 375\n",
      "Training loss at epoch 375: 0.1639\n",
      "\n",
      "Start of epoch 376\n",
      "Training loss at epoch 376: 0.1639\n",
      "\n",
      "Start of epoch 377\n",
      "Training loss at epoch 377: 0.1639\n",
      "\n",
      "Start of epoch 378\n",
      "Training loss at epoch 378: 0.1639\n",
      "\n",
      "Start of epoch 379\n",
      "Training loss at epoch 379: 0.1639\n",
      "\n",
      "Start of epoch 380\n",
      "Training loss at epoch 380: 0.1639\n",
      "\n",
      "Start of epoch 381\n",
      "Training loss at epoch 381: 0.1639\n",
      "\n",
      "Start of epoch 382\n",
      "Training loss at epoch 382: 0.1639\n",
      "\n",
      "Start of epoch 383\n",
      "Training loss at epoch 383: 0.1639\n",
      "\n",
      "Start of epoch 384\n",
      "Training loss at epoch 384: 0.1639\n",
      "\n",
      "Start of epoch 385\n",
      "Training loss at epoch 385: 0.1639\n",
      "\n",
      "Start of epoch 386\n",
      "Training loss at epoch 386: 0.1639\n",
      "\n",
      "Start of epoch 387\n",
      "Training loss at epoch 387: 0.1639\n",
      "\n",
      "Start of epoch 388\n",
      "Training loss at epoch 388: 0.1639\n",
      "\n",
      "Start of epoch 389\n",
      "Training loss at epoch 389: 0.1639\n",
      "\n",
      "Start of epoch 390\n",
      "Training loss at epoch 390: 0.1639\n",
      "\n",
      "Start of epoch 391\n",
      "Training loss at epoch 391: 0.1639\n",
      "\n",
      "Start of epoch 392\n",
      "Training loss at epoch 392: 0.1639\n",
      "\n",
      "Start of epoch 393\n",
      "Training loss at epoch 393: 0.1639\n",
      "\n",
      "Start of epoch 394\n",
      "Training loss at epoch 394: 0.1639\n",
      "\n",
      "Start of epoch 395\n",
      "Training loss at epoch 395: 0.1639\n",
      "\n",
      "Start of epoch 396\n",
      "Training loss at epoch 396: 0.1639\n",
      "\n",
      "Start of epoch 397\n",
      "Training loss at epoch 397: 0.1639\n",
      "\n",
      "Start of epoch 398\n",
      "Training loss at epoch 398: 0.1639\n",
      "\n",
      "Start of epoch 399\n",
      "Training loss at epoch 399: 0.1639\n",
      "\n",
      "Start of epoch 400\n",
      "Training loss at epoch 400: 0.1639\n",
      "\n",
      "Start of epoch 401\n",
      "Training loss at epoch 401: 0.1639\n",
      "\n",
      "Start of epoch 402\n",
      "Training loss at epoch 402: 0.1639\n",
      "\n",
      "Start of epoch 403\n",
      "Training loss at epoch 403: 0.1639\n",
      "\n",
      "Start of epoch 404\n",
      "Training loss at epoch 404: 0.1639\n",
      "\n",
      "Start of epoch 405\n",
      "Training loss at epoch 405: 0.1639\n",
      "\n",
      "Start of epoch 406\n",
      "Training loss at epoch 406: 0.1639\n",
      "\n",
      "Start of epoch 407\n",
      "Training loss at epoch 407: 0.1639\n",
      "\n",
      "Start of epoch 408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 408: 0.1639\n",
      "\n",
      "Start of epoch 409\n",
      "Training loss at epoch 409: 0.1639\n",
      "\n",
      "Start of epoch 410\n",
      "Training loss at epoch 410: 0.1639\n",
      "\n",
      "Start of epoch 411\n",
      "Training loss at epoch 411: 0.1639\n",
      "\n",
      "Start of epoch 412\n",
      "Training loss at epoch 412: 0.1639\n",
      "\n",
      "Start of epoch 413\n",
      "Training loss at epoch 413: 0.1639\n",
      "\n",
      "Start of epoch 414\n",
      "Training loss at epoch 414: 0.1639\n",
      "\n",
      "Start of epoch 415\n",
      "Training loss at epoch 415: 0.1639\n",
      "\n",
      "Start of epoch 416\n",
      "Training loss at epoch 416: 0.1639\n",
      "\n",
      "Start of epoch 417\n",
      "Training loss at epoch 417: 0.1639\n",
      "\n",
      "Start of epoch 418\n",
      "Training loss at epoch 418: 0.1639\n",
      "\n",
      "Start of epoch 419\n",
      "Training loss at epoch 419: 0.1639\n",
      "\n",
      "Start of epoch 420\n",
      "Training loss at epoch 420: 0.1639\n",
      "\n",
      "Start of epoch 421\n",
      "Training loss at epoch 421: 0.1639\n",
      "\n",
      "Start of epoch 422\n",
      "Training loss at epoch 422: 0.1639\n",
      "\n",
      "Start of epoch 423\n",
      "Training loss at epoch 423: 0.1639\n",
      "\n",
      "Start of epoch 424\n",
      "Training loss at epoch 424: 0.1639\n",
      "\n",
      "Start of epoch 425\n",
      "Training loss at epoch 425: 0.1639\n",
      "\n",
      "Start of epoch 426\n",
      "Training loss at epoch 426: 0.1639\n",
      "\n",
      "Start of epoch 427\n",
      "Training loss at epoch 427: 0.1639\n",
      "\n",
      "Start of epoch 428\n",
      "Training loss at epoch 428: 0.1639\n",
      "\n",
      "Start of epoch 429\n",
      "Training loss at epoch 429: 0.1639\n",
      "\n",
      "Start of epoch 430\n",
      "Training loss at epoch 430: 0.1639\n",
      "\n",
      "Start of epoch 431\n",
      "Training loss at epoch 431: 0.1639\n",
      "\n",
      "Start of epoch 432\n",
      "Training loss at epoch 432: 0.1639\n",
      "\n",
      "Start of epoch 433\n",
      "Training loss at epoch 433: 0.1639\n",
      "\n",
      "Start of epoch 434\n",
      "Training loss at epoch 434: 0.1639\n",
      "\n",
      "Start of epoch 435\n",
      "Training loss at epoch 435: 0.1639\n",
      "\n",
      "Start of epoch 436\n",
      "Training loss at epoch 436: 0.1639\n",
      "\n",
      "Start of epoch 437\n",
      "Training loss at epoch 437: 0.1639\n",
      "\n",
      "Start of epoch 438\n",
      "Training loss at epoch 438: 0.1639\n",
      "\n",
      "Start of epoch 439\n",
      "Training loss at epoch 439: 0.1639\n",
      "\n",
      "Start of epoch 440\n",
      "Training loss at epoch 440: 0.1639\n",
      "\n",
      "Start of epoch 441\n",
      "Training loss at epoch 441: 0.1639\n",
      "\n",
      "Start of epoch 442\n",
      "Training loss at epoch 442: 0.1639\n",
      "\n",
      "Start of epoch 443\n",
      "Training loss at epoch 443: 0.1639\n",
      "\n",
      "Start of epoch 444\n",
      "Training loss at epoch 444: 0.1640\n",
      "\n",
      "Start of epoch 445\n",
      "Training loss at epoch 445: 0.1640\n",
      "\n",
      "Start of epoch 446\n",
      "Training loss at epoch 446: 0.1641\n",
      "\n",
      "Start of epoch 447\n",
      "Training loss at epoch 447: 0.1642\n",
      "\n",
      "Start of epoch 448\n",
      "Training loss at epoch 448: 0.1642\n",
      "\n",
      "Start of epoch 449\n",
      "Training loss at epoch 449: 0.1641\n",
      "\n",
      "Start of epoch 450\n",
      "Training loss at epoch 450: 0.1640\n",
      "\n",
      "Start of epoch 451\n",
      "Training loss at epoch 451: 0.1639\n",
      "\n",
      "Start of epoch 452\n",
      "Training loss at epoch 452: 0.1640\n",
      "\n",
      "Start of epoch 453\n",
      "Training loss at epoch 453: 0.1641\n",
      "\n",
      "Start of epoch 454\n",
      "Training loss at epoch 454: 0.1640\n",
      "\n",
      "Start of epoch 455\n",
      "Training loss at epoch 455: 0.1639\n",
      "\n",
      "Start of epoch 456\n",
      "Training loss at epoch 456: 0.1639\n",
      "\n",
      "Start of epoch 457\n",
      "Training loss at epoch 457: 0.1640\n",
      "\n",
      "Start of epoch 458\n",
      "Training loss at epoch 458: 0.1640\n",
      "\n",
      "Start of epoch 459\n",
      "Training loss at epoch 459: 0.1640\n",
      "\n",
      "Start of epoch 460\n",
      "Training loss at epoch 460: 0.1639\n",
      "\n",
      "Start of epoch 461\n",
      "Training loss at epoch 461: 0.1639\n",
      "\n",
      "Start of epoch 462\n",
      "Training loss at epoch 462: 0.1640\n",
      "\n",
      "Start of epoch 463\n",
      "Training loss at epoch 463: 0.1640\n",
      "\n",
      "Start of epoch 464\n",
      "Training loss at epoch 464: 0.1639\n",
      "\n",
      "Start of epoch 465\n",
      "Training loss at epoch 465: 0.1639\n",
      "\n",
      "Start of epoch 466\n",
      "Training loss at epoch 466: 0.1639\n",
      "\n",
      "Start of epoch 467\n",
      "Training loss at epoch 467: 0.1639\n",
      "\n",
      "Start of epoch 468\n",
      "Training loss at epoch 468: 0.1639\n",
      "\n",
      "Start of epoch 469\n",
      "Training loss at epoch 469: 0.1639\n",
      "\n",
      "Start of epoch 470\n",
      "Training loss at epoch 470: 0.1639\n",
      "\n",
      "Start of epoch 471\n",
      "Training loss at epoch 471: 0.1639\n",
      "\n",
      "Start of epoch 472\n",
      "Training loss at epoch 472: 0.1639\n",
      "\n",
      "Start of epoch 473\n",
      "Training loss at epoch 473: 0.1639\n",
      "\n",
      "Start of epoch 474\n",
      "Training loss at epoch 474: 0.1639\n",
      "\n",
      "Start of epoch 475\n",
      "Training loss at epoch 475: 0.1639\n",
      "\n",
      "Start of epoch 476\n",
      "Training loss at epoch 476: 0.1639\n",
      "\n",
      "Start of epoch 477\n",
      "Training loss at epoch 477: 0.1639\n",
      "\n",
      "Start of epoch 478\n",
      "Training loss at epoch 478: 0.1639\n",
      "\n",
      "Start of epoch 479\n",
      "Training loss at epoch 479: 0.1639\n",
      "\n",
      "Start of epoch 480\n",
      "Training loss at epoch 480: 0.1639\n",
      "\n",
      "Start of epoch 481\n",
      "Training loss at epoch 481: 0.1639\n",
      "\n",
      "Start of epoch 482\n",
      "Training loss at epoch 482: 0.1639\n",
      "\n",
      "Start of epoch 483\n",
      "Training loss at epoch 483: 0.1639\n",
      "\n",
      "Start of epoch 484\n",
      "Training loss at epoch 484: 0.1639\n",
      "\n",
      "Start of epoch 485\n",
      "Training loss at epoch 485: 0.1639\n",
      "\n",
      "Start of epoch 486\n",
      "Training loss at epoch 486: 0.1639\n",
      "\n",
      "Start of epoch 487\n",
      "Training loss at epoch 487: 0.1639\n",
      "\n",
      "Start of epoch 488\n",
      "Training loss at epoch 488: 0.1639\n",
      "\n",
      "Start of epoch 489\n",
      "Training loss at epoch 489: 0.1639\n",
      "\n",
      "Start of epoch 490\n",
      "Training loss at epoch 490: 0.1639\n",
      "\n",
      "Start of epoch 491\n",
      "Training loss at epoch 491: 0.1639\n",
      "\n",
      "Start of epoch 492\n",
      "Training loss at epoch 492: 0.1639\n",
      "\n",
      "Start of epoch 493\n",
      "Training loss at epoch 493: 0.1639\n",
      "\n",
      "Start of epoch 494\n",
      "Training loss at epoch 494: 0.1639\n",
      "\n",
      "Start of epoch 495\n",
      "Training loss at epoch 495: 0.1639\n",
      "\n",
      "Start of epoch 496\n",
      "Training loss at epoch 496: 0.1639\n",
      "\n",
      "Start of epoch 497\n",
      "Training loss at epoch 497: 0.1639\n",
      "\n",
      "Start of epoch 498\n",
      "Training loss at epoch 498: 0.1639\n",
      "\n",
      "Start of epoch 499\n",
      "Training loss at epoch 499: 0.1639\n",
      "[<tf.Variable 'parameters:0' shape=(30,) dtype=float32, numpy=\n",
      "array([3.2374694 , 6.1548095 , 5.2833953 , 0.10679817, 4.2552876 ,\n",
      "       5.0679483 , 0.90879   , 5.734416  , 4.6492667 , 4.3159766 ,\n",
      "       0.5409417 , 3.7673147 , 0.2410215 , 6.0250354 , 1.9939654 ,\n",
      "       1.7838737 , 0.06162289, 5.77807   , 2.4128335 , 1.5852164 ,\n",
      "       3.7259526 , 0.7299494 , 6.062289  , 6.0249496 , 0.2568047 ,\n",
      "       0.23578739, 5.5760126 , 4.955564  , 3.0994675 , 3.529761  ],\n",
      "      dtype=float32)>]\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.0074\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 0.9483\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.9056\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.8756\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.8522\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.8311\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.8108\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.7913\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.7729\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.7555\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.7389\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.7223\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.7053\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.6875\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.6689\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.6500\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.6310\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.6125\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.5946\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.5775\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.5614\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.5465\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.5332\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.5215\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.5114\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.5025\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.4944\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.4870\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.4805\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.4749\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.4700\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.4655\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.4613\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.4572\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.4531\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.4491\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.4452\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.4413\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.4376\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.4341\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.4311\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.4284\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.4260\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.4239\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.4220\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.4201\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.4184\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.4167\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.4151\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.4135\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.4120\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.4105\n",
      "\n",
      "Start of epoch 52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 52: 0.4092\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.4079\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.4067\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.4055\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.4043\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.4030\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.4015\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.3999\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.3981\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.3961\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.3940\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.3917\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.3893\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.3867\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.3841\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.3814\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.3785\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.3756\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.3727\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.3696\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.3666\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.3635\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.3604\n",
      "\n",
      "Start of epoch 75\n",
      "Training loss at epoch 75: 0.3572\n",
      "\n",
      "Start of epoch 76\n",
      "Training loss at epoch 76: 0.3540\n",
      "\n",
      "Start of epoch 77\n",
      "Training loss at epoch 77: 0.3505\n",
      "\n",
      "Start of epoch 78\n",
      "Training loss at epoch 78: 0.3470\n",
      "\n",
      "Start of epoch 79\n",
      "Training loss at epoch 79: 0.3434\n",
      "\n",
      "Start of epoch 80\n",
      "Training loss at epoch 80: 0.3399\n",
      "\n",
      "Start of epoch 81\n",
      "Training loss at epoch 81: 0.3363\n",
      "\n",
      "Start of epoch 82\n",
      "Training loss at epoch 82: 0.3328\n",
      "\n",
      "Start of epoch 83\n",
      "Training loss at epoch 83: 0.3294\n",
      "\n",
      "Start of epoch 84\n",
      "Training loss at epoch 84: 0.3261\n",
      "\n",
      "Start of epoch 85\n",
      "Training loss at epoch 85: 0.3229\n",
      "\n",
      "Start of epoch 86\n",
      "Training loss at epoch 86: 0.3198\n",
      "\n",
      "Start of epoch 87\n",
      "Training loss at epoch 87: 0.3168\n",
      "\n",
      "Start of epoch 88\n",
      "Training loss at epoch 88: 0.3140\n",
      "\n",
      "Start of epoch 89\n",
      "Training loss at epoch 89: 0.3114\n",
      "\n",
      "Start of epoch 90\n",
      "Training loss at epoch 90: 0.3090\n",
      "\n",
      "Start of epoch 91\n",
      "Training loss at epoch 91: 0.3068\n",
      "\n",
      "Start of epoch 92\n",
      "Training loss at epoch 92: 0.3048\n",
      "\n",
      "Start of epoch 93\n",
      "Training loss at epoch 93: 0.3029\n",
      "\n",
      "Start of epoch 94\n",
      "Training loss at epoch 94: 0.3013\n",
      "\n",
      "Start of epoch 95\n",
      "Training loss at epoch 95: 0.2997\n",
      "\n",
      "Start of epoch 96\n",
      "Training loss at epoch 96: 0.2984\n",
      "\n",
      "Start of epoch 97\n",
      "Training loss at epoch 97: 0.2971\n",
      "\n",
      "Start of epoch 98\n",
      "Training loss at epoch 98: 0.2960\n",
      "\n",
      "Start of epoch 99\n",
      "Training loss at epoch 99: 0.2950\n",
      "\n",
      "Start of epoch 100\n",
      "Training loss at epoch 100: 0.2941\n",
      "\n",
      "Start of epoch 101\n",
      "Training loss at epoch 101: 0.2934\n",
      "\n",
      "Start of epoch 102\n",
      "Training loss at epoch 102: 0.2927\n",
      "\n",
      "Start of epoch 103\n",
      "Training loss at epoch 103: 0.2921\n",
      "\n",
      "Start of epoch 104\n",
      "Training loss at epoch 104: 0.2915\n",
      "\n",
      "Start of epoch 105\n",
      "Training loss at epoch 105: 0.2909\n",
      "\n",
      "Start of epoch 106\n",
      "Training loss at epoch 106: 0.2902\n",
      "\n",
      "Start of epoch 107\n",
      "Training loss at epoch 107: 0.2895\n",
      "\n",
      "Start of epoch 108\n",
      "Training loss at epoch 108: 0.2887\n",
      "\n",
      "Start of epoch 109\n",
      "Training loss at epoch 109: 0.2878\n",
      "\n",
      "Start of epoch 110\n",
      "Training loss at epoch 110: 0.2869\n",
      "\n",
      "Start of epoch 111\n",
      "Training loss at epoch 111: 0.2859\n",
      "\n",
      "Start of epoch 112\n",
      "Training loss at epoch 112: 0.2850\n",
      "\n",
      "Start of epoch 113\n",
      "Training loss at epoch 113: 0.2840\n",
      "\n",
      "Start of epoch 114\n",
      "Training loss at epoch 114: 0.2831\n",
      "\n",
      "Start of epoch 115\n",
      "Training loss at epoch 115: 0.2823\n",
      "\n",
      "Start of epoch 116\n",
      "Training loss at epoch 116: 0.2815\n",
      "\n",
      "Start of epoch 117\n",
      "Training loss at epoch 117: 0.2807\n",
      "\n",
      "Start of epoch 118\n",
      "Training loss at epoch 118: 0.2800\n",
      "\n",
      "Start of epoch 119\n",
      "Training loss at epoch 119: 0.2793\n",
      "\n",
      "Start of epoch 120\n",
      "Training loss at epoch 120: 0.2786\n",
      "\n",
      "Start of epoch 121\n",
      "Training loss at epoch 121: 0.2780\n",
      "\n",
      "Start of epoch 122\n",
      "Training loss at epoch 122: 0.2773\n",
      "\n",
      "Start of epoch 123\n",
      "Training loss at epoch 123: 0.2768\n",
      "\n",
      "Start of epoch 124\n",
      "Training loss at epoch 124: 0.2762\n",
      "\n",
      "Start of epoch 125\n",
      "Training loss at epoch 125: 0.2757\n",
      "\n",
      "Start of epoch 126\n",
      "Training loss at epoch 126: 0.2751\n",
      "\n",
      "Start of epoch 127\n",
      "Training loss at epoch 127: 0.2747\n",
      "\n",
      "Start of epoch 128\n",
      "Training loss at epoch 128: 0.2742\n",
      "\n",
      "Start of epoch 129\n",
      "Training loss at epoch 129: 0.2737\n",
      "\n",
      "Start of epoch 130\n",
      "Training loss at epoch 130: 0.2733\n",
      "\n",
      "Start of epoch 131\n",
      "Training loss at epoch 131: 0.2729\n",
      "\n",
      "Start of epoch 132\n",
      "Training loss at epoch 132: 0.2724\n",
      "\n",
      "Start of epoch 133\n",
      "Training loss at epoch 133: 0.2720\n",
      "\n",
      "Start of epoch 134\n",
      "Training loss at epoch 134: 0.2716\n",
      "\n",
      "Start of epoch 135\n",
      "Training loss at epoch 135: 0.2711\n",
      "\n",
      "Start of epoch 136\n",
      "Training loss at epoch 136: 0.2707\n",
      "\n",
      "Start of epoch 137\n",
      "Training loss at epoch 137: 0.2702\n",
      "\n",
      "Start of epoch 138\n",
      "Training loss at epoch 138: 0.2698\n",
      "\n",
      "Start of epoch 139\n",
      "Training loss at epoch 139: 0.2693\n",
      "\n",
      "Start of epoch 140\n",
      "Training loss at epoch 140: 0.2689\n",
      "\n",
      "Start of epoch 141\n",
      "Training loss at epoch 141: 0.2684\n",
      "\n",
      "Start of epoch 142\n",
      "Training loss at epoch 142: 0.2679\n",
      "\n",
      "Start of epoch 143\n",
      "Training loss at epoch 143: 0.2674\n",
      "\n",
      "Start of epoch 144\n",
      "Training loss at epoch 144: 0.2669\n",
      "\n",
      "Start of epoch 145\n",
      "Training loss at epoch 145: 0.2664\n",
      "\n",
      "Start of epoch 146\n",
      "Training loss at epoch 146: 0.2659\n",
      "\n",
      "Start of epoch 147\n",
      "Training loss at epoch 147: 0.2654\n",
      "\n",
      "Start of epoch 148\n",
      "Training loss at epoch 148: 0.2649\n",
      "\n",
      "Start of epoch 149\n",
      "Training loss at epoch 149: 0.2643\n",
      "\n",
      "Start of epoch 150\n",
      "Training loss at epoch 150: 0.2638\n",
      "\n",
      "Start of epoch 151\n",
      "Training loss at epoch 151: 0.2632\n",
      "\n",
      "Start of epoch 152\n",
      "Training loss at epoch 152: 0.2627\n",
      "\n",
      "Start of epoch 153\n",
      "Training loss at epoch 153: 0.2621\n",
      "\n",
      "Start of epoch 154\n",
      "Training loss at epoch 154: 0.2616\n",
      "\n",
      "Start of epoch 155\n",
      "Training loss at epoch 155: 0.2610\n",
      "\n",
      "Start of epoch 156\n",
      "Training loss at epoch 156: 0.2604\n",
      "\n",
      "Start of epoch 157\n",
      "Training loss at epoch 157: 0.2599\n",
      "\n",
      "Start of epoch 158\n",
      "Training loss at epoch 158: 0.2593\n",
      "\n",
      "Start of epoch 159\n",
      "Training loss at epoch 159: 0.2588\n",
      "\n",
      "Start of epoch 160\n",
      "Training loss at epoch 160: 0.2582\n",
      "\n",
      "Start of epoch 161\n",
      "Training loss at epoch 161: 0.2577\n",
      "\n",
      "Start of epoch 162\n",
      "Training loss at epoch 162: 0.2572\n",
      "\n",
      "Start of epoch 163\n",
      "Training loss at epoch 163: 0.2567\n",
      "\n",
      "Start of epoch 164\n",
      "Training loss at epoch 164: 0.2562\n",
      "\n",
      "Start of epoch 165\n",
      "Training loss at epoch 165: 0.2557\n",
      "\n",
      "Start of epoch 166\n",
      "Training loss at epoch 166: 0.2552\n",
      "\n",
      "Start of epoch 167\n",
      "Training loss at epoch 167: 0.2548\n",
      "\n",
      "Start of epoch 168\n",
      "Training loss at epoch 168: 0.2543\n",
      "\n",
      "Start of epoch 169\n",
      "Training loss at epoch 169: 0.2539\n",
      "\n",
      "Start of epoch 170\n",
      "Training loss at epoch 170: 0.2535\n",
      "\n",
      "Start of epoch 171\n",
      "Training loss at epoch 171: 0.2531\n",
      "\n",
      "Start of epoch 172\n",
      "Training loss at epoch 172: 0.2527\n",
      "\n",
      "Start of epoch 173\n",
      "Training loss at epoch 173: 0.2523\n",
      "\n",
      "Start of epoch 174\n",
      "Training loss at epoch 174: 0.2519\n",
      "\n",
      "Start of epoch 175\n",
      "Training loss at epoch 175: 0.2516\n",
      "\n",
      "Start of epoch 176\n",
      "Training loss at epoch 176: 0.2512\n",
      "\n",
      "Start of epoch 177\n",
      "Training loss at epoch 177: 0.2509\n",
      "\n",
      "Start of epoch 178\n",
      "Training loss at epoch 178: 0.2505\n",
      "\n",
      "Start of epoch 179\n",
      "Training loss at epoch 179: 0.2502\n",
      "\n",
      "Start of epoch 180\n",
      "Training loss at epoch 180: 0.2499\n",
      "\n",
      "Start of epoch 181\n",
      "Training loss at epoch 181: 0.2496\n",
      "\n",
      "Start of epoch 182\n",
      "Training loss at epoch 182: 0.2493\n",
      "\n",
      "Start of epoch 183\n",
      "Training loss at epoch 183: 0.2490\n",
      "\n",
      "Start of epoch 184\n",
      "Training loss at epoch 184: 0.2488\n",
      "\n",
      "Start of epoch 185\n",
      "Training loss at epoch 185: 0.2485\n",
      "\n",
      "Start of epoch 186\n",
      "Training loss at epoch 186: 0.2482\n",
      "\n",
      "Start of epoch 187\n",
      "Training loss at epoch 187: 0.2479\n",
      "\n",
      "Start of epoch 188\n",
      "Training loss at epoch 188: 0.2477\n",
      "\n",
      "Start of epoch 189\n",
      "Training loss at epoch 189: 0.2474\n",
      "\n",
      "Start of epoch 190\n",
      "Training loss at epoch 190: 0.2472\n",
      "\n",
      "Start of epoch 191\n",
      "Training loss at epoch 191: 0.2469\n",
      "\n",
      "Start of epoch 192\n",
      "Training loss at epoch 192: 0.2467\n",
      "\n",
      "Start of epoch 193\n",
      "Training loss at epoch 193: 0.2464\n",
      "\n",
      "Start of epoch 194\n",
      "Training loss at epoch 194: 0.2461\n",
      "\n",
      "Start of epoch 195\n",
      "Training loss at epoch 195: 0.2459\n",
      "\n",
      "Start of epoch 196\n",
      "Training loss at epoch 196: 0.2456\n",
      "\n",
      "Start of epoch 197\n",
      "Training loss at epoch 197: 0.2454\n",
      "\n",
      "Start of epoch 198\n",
      "Training loss at epoch 198: 0.2451\n",
      "\n",
      "Start of epoch 199\n",
      "Training loss at epoch 199: 0.2449\n",
      "\n",
      "Start of epoch 200\n",
      "Training loss at epoch 200: 0.2446\n",
      "\n",
      "Start of epoch 201\n",
      "Training loss at epoch 201: 0.2443\n",
      "\n",
      "Start of epoch 202\n",
      "Training loss at epoch 202: 0.2441\n",
      "\n",
      "Start of epoch 203\n",
      "Training loss at epoch 203: 0.2438\n",
      "\n",
      "Start of epoch 204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 204: 0.2435\n",
      "\n",
      "Start of epoch 205\n",
      "Training loss at epoch 205: 0.2432\n",
      "\n",
      "Start of epoch 206\n",
      "Training loss at epoch 206: 0.2429\n",
      "\n",
      "Start of epoch 207\n",
      "Training loss at epoch 207: 0.2426\n",
      "\n",
      "Start of epoch 208\n",
      "Training loss at epoch 208: 0.2422\n",
      "\n",
      "Start of epoch 209\n",
      "Training loss at epoch 209: 0.2419\n",
      "\n",
      "Start of epoch 210\n",
      "Training loss at epoch 210: 0.2415\n",
      "\n",
      "Start of epoch 211\n",
      "Training loss at epoch 211: 0.2411\n",
      "\n",
      "Start of epoch 212\n",
      "Training loss at epoch 212: 0.2407\n",
      "\n",
      "Start of epoch 213\n",
      "Training loss at epoch 213: 0.2403\n",
      "\n",
      "Start of epoch 214\n",
      "Training loss at epoch 214: 0.2398\n",
      "\n",
      "Start of epoch 215\n",
      "Training loss at epoch 215: 0.2393\n",
      "\n",
      "Start of epoch 216\n",
      "Training loss at epoch 216: 0.2388\n",
      "\n",
      "Start of epoch 217\n",
      "Training loss at epoch 217: 0.2382\n",
      "\n",
      "Start of epoch 218\n",
      "Training loss at epoch 218: 0.2376\n",
      "\n",
      "Start of epoch 219\n",
      "Training loss at epoch 219: 0.2369\n",
      "\n",
      "Start of epoch 220\n",
      "Training loss at epoch 220: 0.2362\n",
      "\n",
      "Start of epoch 221\n",
      "Training loss at epoch 221: 0.2353\n",
      "\n",
      "Start of epoch 222\n",
      "Training loss at epoch 222: 0.2344\n",
      "\n",
      "Start of epoch 223\n",
      "Training loss at epoch 223: 0.2333\n",
      "\n",
      "Start of epoch 224\n",
      "Training loss at epoch 224: 0.2321\n",
      "\n",
      "Start of epoch 225\n",
      "Training loss at epoch 225: 0.2308\n",
      "\n",
      "Start of epoch 226\n",
      "Training loss at epoch 226: 0.2292\n",
      "\n",
      "Start of epoch 227\n",
      "Training loss at epoch 227: 0.2273\n",
      "\n",
      "Start of epoch 228\n",
      "Training loss at epoch 228: 0.2252\n",
      "\n",
      "Start of epoch 229\n",
      "Training loss at epoch 229: 0.2227\n",
      "\n",
      "Start of epoch 230\n",
      "Training loss at epoch 230: 0.2197\n",
      "\n",
      "Start of epoch 231\n",
      "Training loss at epoch 231: 0.2164\n",
      "\n",
      "Start of epoch 232\n",
      "Training loss at epoch 232: 0.2127\n",
      "\n",
      "Start of epoch 233\n",
      "Training loss at epoch 233: 0.2086\n",
      "\n",
      "Start of epoch 234\n",
      "Training loss at epoch 234: 0.2042\n",
      "\n",
      "Start of epoch 235\n",
      "Training loss at epoch 235: 0.1998\n",
      "\n",
      "Start of epoch 236\n",
      "Training loss at epoch 236: 0.1953\n",
      "\n",
      "Start of epoch 237\n",
      "Training loss at epoch 237: 0.1909\n",
      "\n",
      "Start of epoch 238\n",
      "Training loss at epoch 238: 0.1868\n",
      "\n",
      "Start of epoch 239\n",
      "Training loss at epoch 239: 0.1831\n",
      "\n",
      "Start of epoch 240\n",
      "Training loss at epoch 240: 0.1797\n",
      "\n",
      "Start of epoch 241\n",
      "Training loss at epoch 241: 0.1766\n",
      "\n",
      "Start of epoch 242\n",
      "Training loss at epoch 242: 0.1740\n",
      "\n",
      "Start of epoch 243\n",
      "Training loss at epoch 243: 0.1716\n",
      "\n",
      "Start of epoch 244\n",
      "Training loss at epoch 244: 0.1694\n",
      "\n",
      "Start of epoch 245\n",
      "Training loss at epoch 245: 0.1673\n",
      "\n",
      "Start of epoch 246\n",
      "Training loss at epoch 246: 0.1654\n",
      "\n",
      "Start of epoch 247\n",
      "Training loss at epoch 247: 0.1635\n",
      "\n",
      "Start of epoch 248\n",
      "Training loss at epoch 248: 0.1618\n",
      "\n",
      "Start of epoch 249\n",
      "Training loss at epoch 249: 0.1601\n",
      "\n",
      "Start of epoch 250\n",
      "Training loss at epoch 250: 0.1585\n",
      "\n",
      "Start of epoch 251\n",
      "Training loss at epoch 251: 0.1568\n",
      "\n",
      "Start of epoch 252\n",
      "Training loss at epoch 252: 0.1550\n",
      "\n",
      "Start of epoch 253\n",
      "Training loss at epoch 253: 0.1528\n",
      "\n",
      "Start of epoch 254\n",
      "Training loss at epoch 254: 0.1502\n",
      "\n",
      "Start of epoch 255\n",
      "Training loss at epoch 255: 0.1471\n",
      "\n",
      "Start of epoch 256\n",
      "Training loss at epoch 256: 0.1434\n",
      "\n",
      "Start of epoch 257\n",
      "Training loss at epoch 257: 0.1391\n",
      "\n",
      "Start of epoch 258\n",
      "Training loss at epoch 258: 0.1344\n",
      "\n",
      "Start of epoch 259\n",
      "Training loss at epoch 259: 0.1293\n",
      "\n",
      "Start of epoch 260\n",
      "Training loss at epoch 260: 0.1242\n",
      "\n",
      "Start of epoch 261\n",
      "Training loss at epoch 261: 0.1194\n",
      "\n",
      "Start of epoch 262\n",
      "Training loss at epoch 262: 0.1151\n",
      "\n",
      "Start of epoch 263\n",
      "Training loss at epoch 263: 0.1112\n",
      "\n",
      "Start of epoch 264\n",
      "Training loss at epoch 264: 0.1077\n",
      "\n",
      "Start of epoch 265\n",
      "Training loss at epoch 265: 0.1042\n",
      "\n",
      "Start of epoch 266\n",
      "Training loss at epoch 266: 0.1007\n",
      "\n",
      "Start of epoch 267\n",
      "Training loss at epoch 267: 0.0971\n",
      "\n",
      "Start of epoch 268\n",
      "Training loss at epoch 268: 0.0935\n",
      "\n",
      "Start of epoch 269\n",
      "Training loss at epoch 269: 0.0898\n",
      "\n",
      "Start of epoch 270\n",
      "Training loss at epoch 270: 0.0861\n",
      "\n",
      "Start of epoch 271\n",
      "Training loss at epoch 271: 0.0823\n",
      "\n",
      "Start of epoch 272\n",
      "Training loss at epoch 272: 0.0785\n",
      "\n",
      "Start of epoch 273\n",
      "Training loss at epoch 273: 0.0748\n",
      "\n",
      "Start of epoch 274\n",
      "Training loss at epoch 274: 0.0715\n",
      "\n",
      "Start of epoch 275\n",
      "Training loss at epoch 275: 0.0685\n",
      "\n",
      "Start of epoch 276\n",
      "Training loss at epoch 276: 0.0661\n",
      "\n",
      "Start of epoch 277\n",
      "Training loss at epoch 277: 0.0641\n",
      "\n",
      "Start of epoch 278\n",
      "Training loss at epoch 278: 0.0626\n",
      "\n",
      "Start of epoch 279\n",
      "Training loss at epoch 279: 0.0613\n",
      "\n",
      "Start of epoch 280\n",
      "Training loss at epoch 280: 0.0602\n",
      "\n",
      "Start of epoch 281\n",
      "Training loss at epoch 281: 0.0592\n",
      "\n",
      "Start of epoch 282\n",
      "Training loss at epoch 282: 0.0583\n",
      "\n",
      "Start of epoch 283\n",
      "Training loss at epoch 283: 0.0576\n",
      "\n",
      "Start of epoch 284\n",
      "Training loss at epoch 284: 0.0573\n",
      "\n",
      "Start of epoch 285\n",
      "Training loss at epoch 285: 0.0579\n",
      "\n",
      "Start of epoch 286\n",
      "Training loss at epoch 286: 0.0584\n",
      "\n",
      "Start of epoch 287\n",
      "Training loss at epoch 287: 0.0566\n",
      "\n",
      "Start of epoch 288\n",
      "Training loss at epoch 288: 0.0550\n",
      "\n",
      "Start of epoch 289\n",
      "Training loss at epoch 289: 0.0561\n",
      "\n",
      "Start of epoch 290\n",
      "Training loss at epoch 290: 0.0545\n",
      "\n",
      "Start of epoch 291\n",
      "Training loss at epoch 291: 0.0539\n",
      "\n",
      "Start of epoch 292\n",
      "Training loss at epoch 292: 0.0539\n",
      "\n",
      "Start of epoch 293\n",
      "Training loss at epoch 293: 0.0522\n",
      "\n",
      "Start of epoch 294\n",
      "Training loss at epoch 294: 0.0523\n",
      "\n",
      "Start of epoch 295\n",
      "Training loss at epoch 295: 0.0508\n",
      "\n",
      "Start of epoch 296\n",
      "Training loss at epoch 296: 0.0504\n",
      "\n",
      "Start of epoch 297\n",
      "Training loss at epoch 297: 0.0495\n",
      "\n",
      "Start of epoch 298\n",
      "Training loss at epoch 298: 0.0487\n",
      "\n",
      "Start of epoch 299\n",
      "Training loss at epoch 299: 0.0480\n",
      "\n",
      "Start of epoch 300\n",
      "Training loss at epoch 300: 0.0470\n",
      "\n",
      "Start of epoch 301\n",
      "Training loss at epoch 301: 0.0465\n",
      "\n",
      "Start of epoch 302\n",
      "Training loss at epoch 302: 0.0454\n",
      "\n",
      "Start of epoch 303\n",
      "Training loss at epoch 303: 0.0448\n",
      "\n",
      "Start of epoch 304\n",
      "Training loss at epoch 304: 0.0438\n",
      "\n",
      "Start of epoch 305\n",
      "Training loss at epoch 305: 0.0431\n",
      "\n",
      "Start of epoch 306\n",
      "Training loss at epoch 306: 0.0421\n",
      "\n",
      "Start of epoch 307\n",
      "Training loss at epoch 307: 0.0413\n",
      "\n",
      "Start of epoch 308\n",
      "Training loss at epoch 308: 0.0404\n",
      "\n",
      "Start of epoch 309\n",
      "Training loss at epoch 309: 0.0395\n",
      "\n",
      "Start of epoch 310\n",
      "Training loss at epoch 310: 0.0387\n",
      "\n",
      "Start of epoch 311\n",
      "Training loss at epoch 311: 0.0378\n",
      "\n",
      "Start of epoch 312\n",
      "Training loss at epoch 312: 0.0370\n",
      "\n",
      "Start of epoch 313\n",
      "Training loss at epoch 313: 0.0361\n",
      "\n",
      "Start of epoch 314\n",
      "Training loss at epoch 314: 0.0354\n",
      "\n",
      "Start of epoch 315\n",
      "Training loss at epoch 315: 0.0345\n",
      "\n",
      "Start of epoch 316\n",
      "Training loss at epoch 316: 0.0338\n",
      "\n",
      "Start of epoch 317\n",
      "Training loss at epoch 317: 0.0331\n",
      "\n",
      "Start of epoch 318\n",
      "Training loss at epoch 318: 0.0325\n",
      "\n",
      "Start of epoch 319\n",
      "Training loss at epoch 319: 0.0318\n",
      "\n",
      "Start of epoch 320\n",
      "Training loss at epoch 320: 0.0313\n",
      "\n",
      "Start of epoch 321\n",
      "Training loss at epoch 321: 0.0308\n",
      "\n",
      "Start of epoch 322\n",
      "Training loss at epoch 322: 0.0303\n",
      "\n",
      "Start of epoch 323\n",
      "Training loss at epoch 323: 0.0299\n",
      "\n",
      "Start of epoch 324\n",
      "Training loss at epoch 324: 0.0295\n",
      "\n",
      "Start of epoch 325\n",
      "Training loss at epoch 325: 0.0291\n",
      "\n",
      "Start of epoch 326\n",
      "Training loss at epoch 326: 0.0288\n",
      "\n",
      "Start of epoch 327\n",
      "Training loss at epoch 327: 0.0285\n",
      "\n",
      "Start of epoch 328\n",
      "Training loss at epoch 328: 0.0282\n",
      "\n",
      "Start of epoch 329\n",
      "Training loss at epoch 329: 0.0279\n",
      "\n",
      "Start of epoch 330\n",
      "Training loss at epoch 330: 0.0277\n",
      "\n",
      "Start of epoch 331\n",
      "Training loss at epoch 331: 0.0274\n",
      "\n",
      "Start of epoch 332\n",
      "Training loss at epoch 332: 0.0272\n",
      "\n",
      "Start of epoch 333\n",
      "Training loss at epoch 333: 0.0270\n",
      "\n",
      "Start of epoch 334\n",
      "Training loss at epoch 334: 0.0268\n",
      "\n",
      "Start of epoch 335\n",
      "Training loss at epoch 335: 0.0266\n",
      "\n",
      "Start of epoch 336\n",
      "Training loss at epoch 336: 0.0264\n",
      "\n",
      "Start of epoch 337\n",
      "Training loss at epoch 337: 0.0263\n",
      "\n",
      "Start of epoch 338\n",
      "Training loss at epoch 338: 0.0261\n",
      "\n",
      "Start of epoch 339\n",
      "Training loss at epoch 339: 0.0260\n",
      "\n",
      "Start of epoch 340\n",
      "Training loss at epoch 340: 0.0259\n",
      "\n",
      "Start of epoch 341\n",
      "Training loss at epoch 341: 0.0258\n",
      "\n",
      "Start of epoch 342\n",
      "Training loss at epoch 342: 0.0257\n",
      "\n",
      "Start of epoch 343\n",
      "Training loss at epoch 343: 0.0256\n",
      "\n",
      "Start of epoch 344\n",
      "Training loss at epoch 344: 0.0255\n",
      "\n",
      "Start of epoch 345\n",
      "Training loss at epoch 345: 0.0254\n",
      "\n",
      "Start of epoch 346\n",
      "Training loss at epoch 346: 0.0253\n",
      "\n",
      "Start of epoch 347\n",
      "Training loss at epoch 347: 0.0252\n",
      "\n",
      "Start of epoch 348\n",
      "Training loss at epoch 348: 0.0251\n",
      "\n",
      "Start of epoch 349\n",
      "Training loss at epoch 349: 0.0250\n",
      "\n",
      "Start of epoch 350\n",
      "Training loss at epoch 350: 0.0249\n",
      "\n",
      "Start of epoch 351\n",
      "Training loss at epoch 351: 0.0248\n",
      "\n",
      "Start of epoch 352\n",
      "Training loss at epoch 352: 0.0247\n",
      "\n",
      "Start of epoch 353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 353: 0.0246\n",
      "\n",
      "Start of epoch 354\n",
      "Training loss at epoch 354: 0.0245\n",
      "\n",
      "Start of epoch 355\n",
      "Training loss at epoch 355: 0.0244\n",
      "\n",
      "Start of epoch 356\n",
      "Training loss at epoch 356: 0.0243\n",
      "\n",
      "Start of epoch 357\n",
      "Training loss at epoch 357: 0.0241\n",
      "\n",
      "Start of epoch 358\n",
      "Training loss at epoch 358: 0.0240\n",
      "\n",
      "Start of epoch 359\n",
      "Training loss at epoch 359: 0.0239\n",
      "\n",
      "Start of epoch 360\n",
      "Training loss at epoch 360: 0.0238\n",
      "\n",
      "Start of epoch 361\n",
      "Training loss at epoch 361: 0.0237\n",
      "\n",
      "Start of epoch 362\n",
      "Training loss at epoch 362: 0.0236\n",
      "\n",
      "Start of epoch 363\n",
      "Training loss at epoch 363: 0.0235\n",
      "\n",
      "Start of epoch 364\n",
      "Training loss at epoch 364: 0.0234\n",
      "\n",
      "Start of epoch 365\n",
      "Training loss at epoch 365: 0.0233\n",
      "\n",
      "Start of epoch 366\n",
      "Training loss at epoch 366: 0.0232\n",
      "\n",
      "Start of epoch 367\n",
      "Training loss at epoch 367: 0.0231\n",
      "\n",
      "Start of epoch 368\n",
      "Training loss at epoch 368: 0.0230\n",
      "\n",
      "Start of epoch 369\n",
      "Training loss at epoch 369: 0.0229\n",
      "\n",
      "Start of epoch 370\n",
      "Training loss at epoch 370: 0.0228\n",
      "\n",
      "Start of epoch 371\n",
      "Training loss at epoch 371: 0.0227\n",
      "\n",
      "Start of epoch 372\n",
      "Training loss at epoch 372: 0.0226\n",
      "\n",
      "Start of epoch 373\n",
      "Training loss at epoch 373: 0.0225\n",
      "\n",
      "Start of epoch 374\n",
      "Training loss at epoch 374: 0.0224\n",
      "\n",
      "Start of epoch 375\n",
      "Training loss at epoch 375: 0.0224\n",
      "\n",
      "Start of epoch 376\n",
      "Training loss at epoch 376: 0.0223\n",
      "\n",
      "Start of epoch 377\n",
      "Training loss at epoch 377: 0.0222\n",
      "\n",
      "Start of epoch 378\n",
      "Training loss at epoch 378: 0.0221\n",
      "\n",
      "Start of epoch 379\n",
      "Training loss at epoch 379: 0.0220\n",
      "\n",
      "Start of epoch 380\n",
      "Training loss at epoch 380: 0.0219\n",
      "\n",
      "Start of epoch 381\n",
      "Training loss at epoch 381: 0.0219\n",
      "\n",
      "Start of epoch 382\n",
      "Training loss at epoch 382: 0.0218\n",
      "\n",
      "Start of epoch 383\n",
      "Training loss at epoch 383: 0.0217\n",
      "\n",
      "Start of epoch 384\n",
      "Training loss at epoch 384: 0.0216\n",
      "\n",
      "Start of epoch 385\n",
      "Training loss at epoch 385: 0.0215\n",
      "\n",
      "Start of epoch 386\n",
      "Training loss at epoch 386: 0.0215\n",
      "\n",
      "Start of epoch 387\n",
      "Training loss at epoch 387: 0.0214\n",
      "\n",
      "Start of epoch 388\n",
      "Training loss at epoch 388: 0.0213\n",
      "\n",
      "Start of epoch 389\n",
      "Training loss at epoch 389: 0.0213\n",
      "\n",
      "Start of epoch 390\n",
      "Training loss at epoch 390: 0.0212\n",
      "\n",
      "Start of epoch 391\n",
      "Training loss at epoch 391: 0.0211\n",
      "\n",
      "Start of epoch 392\n",
      "Training loss at epoch 392: 0.0211\n",
      "\n",
      "Start of epoch 393\n",
      "Training loss at epoch 393: 0.0210\n",
      "\n",
      "Start of epoch 394\n",
      "Training loss at epoch 394: 0.0209\n",
      "\n",
      "Start of epoch 395\n",
      "Training loss at epoch 395: 0.0209\n",
      "\n",
      "Start of epoch 396\n",
      "Training loss at epoch 396: 0.0208\n",
      "\n",
      "Start of epoch 397\n",
      "Training loss at epoch 397: 0.0207\n",
      "\n",
      "Start of epoch 398\n",
      "Training loss at epoch 398: 0.0207\n",
      "\n",
      "Start of epoch 399\n",
      "Training loss at epoch 399: 0.0206\n",
      "\n",
      "Start of epoch 400\n",
      "Training loss at epoch 400: 0.0206\n",
      "\n",
      "Start of epoch 401\n",
      "Training loss at epoch 401: 0.0205\n",
      "\n",
      "Start of epoch 402\n",
      "Training loss at epoch 402: 0.0205\n",
      "\n",
      "Start of epoch 403\n",
      "Training loss at epoch 403: 0.0204\n",
      "\n",
      "Start of epoch 404\n",
      "Training loss at epoch 404: 0.0203\n",
      "\n",
      "Start of epoch 405\n",
      "Training loss at epoch 405: 0.0203\n",
      "\n",
      "Start of epoch 406\n",
      "Training loss at epoch 406: 0.0202\n",
      "\n",
      "Start of epoch 407\n",
      "Training loss at epoch 407: 0.0202\n",
      "\n",
      "Start of epoch 408\n",
      "Training loss at epoch 408: 0.0201\n",
      "\n",
      "Start of epoch 409\n",
      "Training loss at epoch 409: 0.0201\n",
      "\n",
      "Start of epoch 410\n",
      "Training loss at epoch 410: 0.0200\n",
      "\n",
      "Start of epoch 411\n",
      "Training loss at epoch 411: 0.0200\n",
      "\n",
      "Start of epoch 412\n",
      "Training loss at epoch 412: 0.0199\n",
      "\n",
      "Start of epoch 413\n",
      "Training loss at epoch 413: 0.0199\n",
      "\n",
      "Start of epoch 414\n",
      "Training loss at epoch 414: 0.0198\n",
      "\n",
      "Start of epoch 415\n",
      "Training loss at epoch 415: 0.0197\n",
      "\n",
      "Start of epoch 416\n",
      "Training loss at epoch 416: 0.0197\n",
      "\n",
      "Start of epoch 417\n",
      "Training loss at epoch 417: 0.0196\n",
      "\n",
      "Start of epoch 418\n",
      "Training loss at epoch 418: 0.0196\n",
      "\n",
      "Start of epoch 419\n",
      "Training loss at epoch 419: 0.0195\n",
      "\n",
      "Start of epoch 420\n",
      "Training loss at epoch 420: 0.0195\n",
      "\n",
      "Start of epoch 421\n",
      "Training loss at epoch 421: 0.0194\n",
      "\n",
      "Start of epoch 422\n",
      "Training loss at epoch 422: 0.0194\n",
      "\n",
      "Start of epoch 423\n",
      "Training loss at epoch 423: 0.0193\n",
      "\n",
      "Start of epoch 424\n",
      "Training loss at epoch 424: 0.0192\n",
      "\n",
      "Start of epoch 425\n",
      "Training loss at epoch 425: 0.0192\n",
      "\n",
      "Start of epoch 426\n",
      "Training loss at epoch 426: 0.0191\n",
      "\n",
      "Start of epoch 427\n",
      "Training loss at epoch 427: 0.0191\n",
      "\n",
      "Start of epoch 428\n",
      "Training loss at epoch 428: 0.0190\n",
      "\n",
      "Start of epoch 429\n",
      "Training loss at epoch 429: 0.0190\n",
      "\n",
      "Start of epoch 430\n",
      "Training loss at epoch 430: 0.0189\n",
      "\n",
      "Start of epoch 431\n",
      "Training loss at epoch 431: 0.0188\n",
      "\n",
      "Start of epoch 432\n",
      "Training loss at epoch 432: 0.0188\n",
      "\n",
      "Start of epoch 433\n",
      "Training loss at epoch 433: 0.0187\n",
      "\n",
      "Start of epoch 434\n",
      "Training loss at epoch 434: 0.0187\n",
      "\n",
      "Start of epoch 435\n",
      "Training loss at epoch 435: 0.0186\n",
      "\n",
      "Start of epoch 436\n",
      "Training loss at epoch 436: 0.0185\n",
      "\n",
      "Start of epoch 437\n",
      "Training loss at epoch 437: 0.0185\n",
      "\n",
      "Start of epoch 438\n",
      "Training loss at epoch 438: 0.0184\n",
      "\n",
      "Start of epoch 439\n",
      "Training loss at epoch 439: 0.0184\n",
      "\n",
      "Start of epoch 440\n",
      "Training loss at epoch 440: 0.0183\n",
      "\n",
      "Start of epoch 441\n",
      "Training loss at epoch 441: 0.0183\n",
      "\n",
      "Start of epoch 442\n",
      "Training loss at epoch 442: 0.0182\n",
      "\n",
      "Start of epoch 443\n",
      "Training loss at epoch 443: 0.0182\n",
      "\n",
      "Start of epoch 444\n",
      "Training loss at epoch 444: 0.0181\n",
      "\n",
      "Start of epoch 445\n",
      "Training loss at epoch 445: 0.0181\n",
      "\n",
      "Start of epoch 446\n",
      "Training loss at epoch 446: 0.0180\n",
      "\n",
      "Start of epoch 447\n",
      "Training loss at epoch 447: 0.0180\n",
      "\n",
      "Start of epoch 448\n",
      "Training loss at epoch 448: 0.0179\n",
      "\n",
      "Start of epoch 449\n",
      "Training loss at epoch 449: 0.0179\n",
      "\n",
      "Start of epoch 450\n",
      "Training loss at epoch 450: 0.0179\n",
      "\n",
      "Start of epoch 451\n",
      "Training loss at epoch 451: 0.0178\n",
      "\n",
      "Start of epoch 452\n",
      "Training loss at epoch 452: 0.0178\n",
      "\n",
      "Start of epoch 453\n",
      "Training loss at epoch 453: 0.0178\n",
      "\n",
      "Start of epoch 454\n",
      "Training loss at epoch 454: 0.0177\n",
      "\n",
      "Start of epoch 455\n",
      "Training loss at epoch 455: 0.0177\n",
      "\n",
      "Start of epoch 456\n",
      "Training loss at epoch 456: 0.0177\n",
      "\n",
      "Start of epoch 457\n",
      "Training loss at epoch 457: 0.0176\n",
      "\n",
      "Start of epoch 458\n",
      "Training loss at epoch 458: 0.0176\n",
      "\n",
      "Start of epoch 459\n",
      "Training loss at epoch 459: 0.0176\n",
      "\n",
      "Start of epoch 460\n",
      "Training loss at epoch 460: 0.0176\n",
      "\n",
      "Start of epoch 461\n",
      "Training loss at epoch 461: 0.0175\n",
      "\n",
      "Start of epoch 462\n",
      "Training loss at epoch 462: 0.0175\n",
      "\n",
      "Start of epoch 463\n",
      "Training loss at epoch 463: 0.0175\n",
      "\n",
      "Start of epoch 464\n",
      "Training loss at epoch 464: 0.0174\n",
      "\n",
      "Start of epoch 465\n",
      "Training loss at epoch 465: 0.0174\n",
      "\n",
      "Start of epoch 466\n",
      "Training loss at epoch 466: 0.0174\n",
      "\n",
      "Start of epoch 467\n",
      "Training loss at epoch 467: 0.0174\n",
      "\n",
      "Start of epoch 468\n",
      "Training loss at epoch 468: 0.0174\n",
      "\n",
      "Start of epoch 469\n",
      "Training loss at epoch 469: 0.0173\n",
      "\n",
      "Start of epoch 470\n",
      "Training loss at epoch 470: 0.0173\n",
      "\n",
      "Start of epoch 471\n",
      "Training loss at epoch 471: 0.0173\n",
      "\n",
      "Start of epoch 472\n",
      "Training loss at epoch 472: 0.0173\n",
      "\n",
      "Start of epoch 473\n",
      "Training loss at epoch 473: 0.0172\n",
      "\n",
      "Start of epoch 474\n",
      "Training loss at epoch 474: 0.0172\n",
      "\n",
      "Start of epoch 475\n",
      "Training loss at epoch 475: 0.0172\n",
      "\n",
      "Start of epoch 476\n",
      "Training loss at epoch 476: 0.0172\n",
      "\n",
      "Start of epoch 477\n",
      "Training loss at epoch 477: 0.0172\n",
      "\n",
      "Start of epoch 478\n",
      "Training loss at epoch 478: 0.0172\n",
      "\n",
      "Start of epoch 479\n",
      "Training loss at epoch 479: 0.0171\n",
      "\n",
      "Start of epoch 480\n",
      "Training loss at epoch 480: 0.0171\n",
      "\n",
      "Start of epoch 481\n",
      "Training loss at epoch 481: 0.0171\n",
      "\n",
      "Start of epoch 482\n",
      "Training loss at epoch 482: 0.0171\n",
      "\n",
      "Start of epoch 483\n",
      "Training loss at epoch 483: 0.0171\n",
      "\n",
      "Start of epoch 484\n",
      "Training loss at epoch 484: 0.0171\n",
      "\n",
      "Start of epoch 485\n",
      "Training loss at epoch 485: 0.0170\n",
      "\n",
      "Start of epoch 486\n",
      "Training loss at epoch 486: 0.0170\n",
      "\n",
      "Start of epoch 487\n",
      "Training loss at epoch 487: 0.0170\n",
      "\n",
      "Start of epoch 488\n",
      "Training loss at epoch 488: 0.0170\n",
      "\n",
      "Start of epoch 489\n",
      "Training loss at epoch 489: 0.0170\n",
      "\n",
      "Start of epoch 490\n",
      "Training loss at epoch 490: 0.0170\n",
      "\n",
      "Start of epoch 491\n",
      "Training loss at epoch 491: 0.0169\n",
      "\n",
      "Start of epoch 492\n",
      "Training loss at epoch 492: 0.0169\n",
      "\n",
      "Start of epoch 493\n",
      "Training loss at epoch 493: 0.0169\n",
      "\n",
      "Start of epoch 494\n",
      "Training loss at epoch 494: 0.0169\n",
      "\n",
      "Start of epoch 495\n",
      "Training loss at epoch 495: 0.0169\n",
      "\n",
      "Start of epoch 496\n",
      "Training loss at epoch 496: 0.0169\n",
      "\n",
      "Start of epoch 497\n",
      "Training loss at epoch 497: 0.0169\n",
      "\n",
      "Start of epoch 498\n",
      "Training loss at epoch 498: 0.0168\n",
      "\n",
      "Start of epoch 499\n",
      "Training loss at epoch 499: 0.0168\n",
      "[<tf.Variable 'parameters:0' shape=(30,) dtype=float32, numpy=\n",
      "array([0.7116982 , 3.6063724 , 2.0397122 , 0.25121632, 3.0051591 ,\n",
      "       4.4465604 , 1.9852326 , 5.5937376 , 5.4621267 , 5.531683  ,\n",
      "       1.457281  , 5.6372185 , 4.11552   , 0.20659082, 4.09905   ,\n",
      "       0.42716348, 2.6014054 , 2.3565946 , 1.7959762 , 5.3429227 ,\n",
      "       4.3313823 , 5.5984497 , 4.3931074 , 4.908054  , 0.847102  ,\n",
      "       1.9622326 , 4.7280307 , 4.927669  , 2.524618  , 3.4956703 ],\n",
      "      dtype=float32)>]\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 0.7490\n",
      "\n",
      "Start of epoch 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 1: 0.7071\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.6820\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.6663\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.6534\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.6399\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.6247\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.6083\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.5921\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.5770\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.5636\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.5515\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.5401\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.5289\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.5181\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.5080\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.4987\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.4903\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.4828\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.4759\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.4695\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.4637\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.4584\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.4536\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.4496\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.4464\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.4441\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.4422\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.4407\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.4392\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.4376\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.4360\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.4343\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.4326\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.4310\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.4295\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.4282\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.4269\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.4255\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.4242\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.4229\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.4216\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.4205\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.4196\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.4187\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.4179\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.4172\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.4164\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.4155\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.4147\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.4138\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.4129\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.4119\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.4110\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.4101\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.4092\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.4085\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.4078\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.4072\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.4067\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.4063\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.4059\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.4056\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.4052\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.4049\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.4046\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.4043\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.4039\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.4036\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.4033\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.4030\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.4026\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.4023\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.4020\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.4017\n",
      "\n",
      "Start of epoch 75\n",
      "Training loss at epoch 75: 0.4014\n",
      "\n",
      "Start of epoch 76\n",
      "Training loss at epoch 76: 0.4011\n",
      "\n",
      "Start of epoch 77\n",
      "Training loss at epoch 77: 0.4008\n",
      "\n",
      "Start of epoch 78\n",
      "Training loss at epoch 78: 0.4005\n",
      "\n",
      "Start of epoch 79\n",
      "Training loss at epoch 79: 0.4003\n",
      "\n",
      "Start of epoch 80\n",
      "Training loss at epoch 80: 0.4000\n",
      "\n",
      "Start of epoch 81\n",
      "Training loss at epoch 81: 0.3998\n",
      "\n",
      "Start of epoch 82\n",
      "Training loss at epoch 82: 0.3995\n",
      "\n",
      "Start of epoch 83\n",
      "Training loss at epoch 83: 0.3993\n",
      "\n",
      "Start of epoch 84\n",
      "Training loss at epoch 84: 0.3991\n",
      "\n",
      "Start of epoch 85\n",
      "Training loss at epoch 85: 0.3990\n",
      "\n",
      "Start of epoch 86\n",
      "Training loss at epoch 86: 0.3988\n",
      "\n",
      "Start of epoch 87\n",
      "Training loss at epoch 87: 0.3986\n",
      "\n",
      "Start of epoch 88\n",
      "Training loss at epoch 88: 0.3985\n",
      "\n",
      "Start of epoch 89\n",
      "Training loss at epoch 89: 0.3983\n",
      "\n",
      "Start of epoch 90\n",
      "Training loss at epoch 90: 0.3982\n",
      "\n",
      "Start of epoch 91\n",
      "Training loss at epoch 91: 0.3980\n",
      "\n",
      "Start of epoch 92\n",
      "Training loss at epoch 92: 0.3979\n",
      "\n",
      "Start of epoch 93\n",
      "Training loss at epoch 93: 0.3977\n",
      "\n",
      "Start of epoch 94\n",
      "Training loss at epoch 94: 0.3976\n",
      "\n",
      "Start of epoch 95\n",
      "Training loss at epoch 95: 0.3974\n",
      "\n",
      "Start of epoch 96\n",
      "Training loss at epoch 96: 0.3972\n",
      "\n",
      "Start of epoch 97\n",
      "Training loss at epoch 97: 0.3971\n",
      "\n",
      "Start of epoch 98\n",
      "Training loss at epoch 98: 0.3969\n",
      "\n",
      "Start of epoch 99\n",
      "Training loss at epoch 99: 0.3967\n",
      "\n",
      "Start of epoch 100\n",
      "Training loss at epoch 100: 0.3966\n",
      "\n",
      "Start of epoch 101\n",
      "Training loss at epoch 101: 0.3964\n",
      "\n",
      "Start of epoch 102\n",
      "Training loss at epoch 102: 0.3962\n",
      "\n",
      "Start of epoch 103\n",
      "Training loss at epoch 103: 0.3960\n",
      "\n",
      "Start of epoch 104\n",
      "Training loss at epoch 104: 0.3958\n",
      "\n",
      "Start of epoch 105\n",
      "Training loss at epoch 105: 0.3957\n",
      "\n",
      "Start of epoch 106\n",
      "Training loss at epoch 106: 0.3955\n",
      "\n",
      "Start of epoch 107\n",
      "Training loss at epoch 107: 0.3953\n",
      "\n",
      "Start of epoch 108\n",
      "Training loss at epoch 108: 0.3951\n",
      "\n",
      "Start of epoch 109\n",
      "Training loss at epoch 109: 0.3949\n",
      "\n",
      "Start of epoch 110\n",
      "Training loss at epoch 110: 0.3947\n",
      "\n",
      "Start of epoch 111\n",
      "Training loss at epoch 111: 0.3945\n",
      "\n",
      "Start of epoch 112\n",
      "Training loss at epoch 112: 0.3943\n",
      "\n",
      "Start of epoch 113\n",
      "Training loss at epoch 113: 0.3941\n",
      "\n",
      "Start of epoch 114\n",
      "Training loss at epoch 114: 0.3938\n",
      "\n",
      "Start of epoch 115\n",
      "Training loss at epoch 115: 0.3936\n",
      "\n",
      "Start of epoch 116\n",
      "Training loss at epoch 116: 0.3934\n",
      "\n",
      "Start of epoch 117\n",
      "Training loss at epoch 117: 0.3931\n",
      "\n",
      "Start of epoch 118\n",
      "Training loss at epoch 118: 0.3929\n",
      "\n",
      "Start of epoch 119\n",
      "Training loss at epoch 119: 0.3926\n",
      "\n",
      "Start of epoch 120\n",
      "Training loss at epoch 120: 0.3923\n",
      "\n",
      "Start of epoch 121\n",
      "Training loss at epoch 121: 0.3920\n",
      "\n",
      "Start of epoch 122\n",
      "Training loss at epoch 122: 0.3917\n",
      "\n",
      "Start of epoch 123\n",
      "Training loss at epoch 123: 0.3913\n",
      "\n",
      "Start of epoch 124\n",
      "Training loss at epoch 124: 0.3910\n",
      "\n",
      "Start of epoch 125\n",
      "Training loss at epoch 125: 0.3906\n",
      "\n",
      "Start of epoch 126\n",
      "Training loss at epoch 126: 0.3902\n",
      "\n",
      "Start of epoch 127\n",
      "Training loss at epoch 127: 0.3898\n",
      "\n",
      "Start of epoch 128\n",
      "Training loss at epoch 128: 0.3893\n",
      "\n",
      "Start of epoch 129\n",
      "Training loss at epoch 129: 0.3888\n",
      "\n",
      "Start of epoch 130\n",
      "Training loss at epoch 130: 0.3883\n",
      "\n",
      "Start of epoch 131\n",
      "Training loss at epoch 131: 0.3877\n",
      "\n",
      "Start of epoch 132\n",
      "Training loss at epoch 132: 0.3871\n",
      "\n",
      "Start of epoch 133\n",
      "Training loss at epoch 133: 0.3864\n",
      "\n",
      "Start of epoch 134\n",
      "Training loss at epoch 134: 0.3856\n",
      "\n",
      "Start of epoch 135\n",
      "Training loss at epoch 135: 0.3848\n",
      "\n",
      "Start of epoch 136\n",
      "Training loss at epoch 136: 0.3838\n",
      "\n",
      "Start of epoch 137\n",
      "Training loss at epoch 137: 0.3827\n",
      "\n",
      "Start of epoch 138\n",
      "Training loss at epoch 138: 0.3814\n",
      "\n",
      "Start of epoch 139\n",
      "Training loss at epoch 139: 0.3800\n",
      "\n",
      "Start of epoch 140\n",
      "Training loss at epoch 140: 0.3784\n",
      "\n",
      "Start of epoch 141\n",
      "Training loss at epoch 141: 0.3765\n",
      "\n",
      "Start of epoch 142\n",
      "Training loss at epoch 142: 0.3743\n",
      "\n",
      "Start of epoch 143\n",
      "Training loss at epoch 143: 0.3718\n",
      "\n",
      "Start of epoch 144\n",
      "Training loss at epoch 144: 0.3690\n",
      "\n",
      "Start of epoch 145\n",
      "Training loss at epoch 145: 0.3659\n",
      "\n",
      "Start of epoch 146\n",
      "Training loss at epoch 146: 0.3625\n",
      "\n",
      "Start of epoch 147\n",
      "Training loss at epoch 147: 0.3589\n",
      "\n",
      "Start of epoch 148\n",
      "Training loss at epoch 148: 0.3553\n",
      "\n",
      "Start of epoch 149\n",
      "Training loss at epoch 149: 0.3517\n",
      "\n",
      "Start of epoch 150\n",
      "Training loss at epoch 150: 0.3482\n",
      "\n",
      "Start of epoch 151\n",
      "Training loss at epoch 151: 0.3449\n",
      "\n",
      "Start of epoch 152\n",
      "Training loss at epoch 152: 0.3418\n",
      "\n",
      "Start of epoch 153\n",
      "Training loss at epoch 153: 0.3387\n",
      "\n",
      "Start of epoch 154\n",
      "Training loss at epoch 154: 0.3357\n",
      "\n",
      "Start of epoch 155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 155: 0.3329\n",
      "\n",
      "Start of epoch 156\n",
      "Training loss at epoch 156: 0.3302\n",
      "\n",
      "Start of epoch 157\n",
      "Training loss at epoch 157: 0.3276\n",
      "\n",
      "Start of epoch 158\n",
      "Training loss at epoch 158: 0.3251\n",
      "\n",
      "Start of epoch 159\n",
      "Training loss at epoch 159: 0.3225\n",
      "\n",
      "Start of epoch 160\n",
      "Training loss at epoch 160: 0.3197\n",
      "\n",
      "Start of epoch 161\n",
      "Training loss at epoch 161: 0.3169\n",
      "\n",
      "Start of epoch 162\n",
      "Training loss at epoch 162: 0.3140\n",
      "\n",
      "Start of epoch 163\n",
      "Training loss at epoch 163: 0.3112\n",
      "\n",
      "Start of epoch 164\n",
      "Training loss at epoch 164: 0.3084\n",
      "\n",
      "Start of epoch 165\n",
      "Training loss at epoch 165: 0.3059\n",
      "\n",
      "Start of epoch 166\n",
      "Training loss at epoch 166: 0.3036\n",
      "\n",
      "Start of epoch 167\n",
      "Training loss at epoch 167: 0.3016\n",
      "\n",
      "Start of epoch 168\n",
      "Training loss at epoch 168: 0.2999\n",
      "\n",
      "Start of epoch 169\n",
      "Training loss at epoch 169: 0.2983\n",
      "\n",
      "Start of epoch 170\n",
      "Training loss at epoch 170: 0.2969\n",
      "\n",
      "Start of epoch 171\n",
      "Training loss at epoch 171: 0.2954\n",
      "\n",
      "Start of epoch 172\n",
      "Training loss at epoch 172: 0.2939\n",
      "\n",
      "Start of epoch 173\n",
      "Training loss at epoch 173: 0.2921\n",
      "\n",
      "Start of epoch 174\n",
      "Training loss at epoch 174: 0.2898\n",
      "\n",
      "Start of epoch 175\n",
      "Training loss at epoch 175: 0.2869\n",
      "\n",
      "Start of epoch 176\n",
      "Training loss at epoch 176: 0.2831\n",
      "\n",
      "Start of epoch 177\n",
      "Training loss at epoch 177: 0.2780\n",
      "\n",
      "Start of epoch 178\n",
      "Training loss at epoch 178: 0.2713\n",
      "\n",
      "Start of epoch 179\n",
      "Training loss at epoch 179: 0.2624\n",
      "\n",
      "Start of epoch 180\n",
      "Training loss at epoch 180: 0.2508\n",
      "\n",
      "Start of epoch 181\n",
      "Training loss at epoch 181: 0.2368\n",
      "\n",
      "Start of epoch 182\n",
      "Training loss at epoch 182: 0.2212\n",
      "\n",
      "Start of epoch 183\n",
      "Training loss at epoch 183: 0.2053\n",
      "\n",
      "Start of epoch 184\n",
      "Training loss at epoch 184: 0.1906\n",
      "\n",
      "Start of epoch 185\n",
      "Training loss at epoch 185: 0.1785\n",
      "\n",
      "Start of epoch 186\n",
      "Training loss at epoch 186: 0.1694\n",
      "\n",
      "Start of epoch 187\n",
      "Training loss at epoch 187: 0.1629\n",
      "\n",
      "Start of epoch 188\n",
      "Training loss at epoch 188: 0.1583\n",
      "\n",
      "Start of epoch 189\n",
      "Training loss at epoch 189: 0.1540\n",
      "\n",
      "Start of epoch 190\n",
      "Training loss at epoch 190: 0.1492\n",
      "\n",
      "Start of epoch 191\n",
      "Training loss at epoch 191: 0.1439\n",
      "\n",
      "Start of epoch 192\n",
      "Training loss at epoch 192: 0.1384\n",
      "\n",
      "Start of epoch 193\n",
      "Training loss at epoch 193: 0.1331\n",
      "\n",
      "Start of epoch 194\n",
      "Training loss at epoch 194: 0.1277\n",
      "\n",
      "Start of epoch 195\n",
      "Training loss at epoch 195: 0.1228\n",
      "\n",
      "Start of epoch 196\n",
      "Training loss at epoch 196: 0.1183\n",
      "\n",
      "Start of epoch 197\n",
      "Training loss at epoch 197: 0.1145\n",
      "\n",
      "Start of epoch 198\n",
      "Training loss at epoch 198: 0.1115\n",
      "\n",
      "Start of epoch 199\n",
      "Training loss at epoch 199: 0.1087\n",
      "\n",
      "Start of epoch 200\n",
      "Training loss at epoch 200: 0.1058\n",
      "\n",
      "Start of epoch 201\n",
      "Training loss at epoch 201: 0.1030\n",
      "\n",
      "Start of epoch 202\n",
      "Training loss at epoch 202: 0.1005\n",
      "\n",
      "Start of epoch 203\n",
      "Training loss at epoch 203: 0.0984\n",
      "\n",
      "Start of epoch 204\n",
      "Training loss at epoch 204: 0.0960\n",
      "\n",
      "Start of epoch 205\n",
      "Training loss at epoch 205: 0.0934\n",
      "\n",
      "Start of epoch 206\n",
      "Training loss at epoch 206: 0.0912\n",
      "\n",
      "Start of epoch 207\n",
      "Training loss at epoch 207: 0.0889\n",
      "\n",
      "Start of epoch 208\n",
      "Training loss at epoch 208: 0.0865\n",
      "\n",
      "Start of epoch 209\n",
      "Training loss at epoch 209: 0.0841\n",
      "\n",
      "Start of epoch 210\n",
      "Training loss at epoch 210: 0.0821\n",
      "\n",
      "Start of epoch 211\n",
      "Training loss at epoch 211: 0.0803\n",
      "\n",
      "Start of epoch 212\n",
      "Training loss at epoch 212: 0.0787\n",
      "\n",
      "Start of epoch 213\n",
      "Training loss at epoch 213: 0.0773\n",
      "\n",
      "Start of epoch 214\n",
      "Training loss at epoch 214: 0.0762\n",
      "\n",
      "Start of epoch 215\n",
      "Training loss at epoch 215: 0.0753\n",
      "\n",
      "Start of epoch 216\n",
      "Training loss at epoch 216: 0.0744\n",
      "\n",
      "Start of epoch 217\n",
      "Training loss at epoch 217: 0.0736\n",
      "\n",
      "Start of epoch 218\n",
      "Training loss at epoch 218: 0.0730\n",
      "\n",
      "Start of epoch 219\n",
      "Training loss at epoch 219: 0.0723\n",
      "\n",
      "Start of epoch 220\n",
      "Training loss at epoch 220: 0.0715\n",
      "\n",
      "Start of epoch 221\n",
      "Training loss at epoch 221: 0.0704\n",
      "\n",
      "Start of epoch 222\n",
      "Training loss at epoch 222: 0.0692\n",
      "\n",
      "Start of epoch 223\n",
      "Training loss at epoch 223: 0.0679\n",
      "\n",
      "Start of epoch 224\n",
      "Training loss at epoch 224: 0.0668\n",
      "\n",
      "Start of epoch 225\n",
      "Training loss at epoch 225: 0.0658\n",
      "\n",
      "Start of epoch 226\n",
      "Training loss at epoch 226: 0.0649\n",
      "\n",
      "Start of epoch 227\n",
      "Training loss at epoch 227: 0.0639\n",
      "\n",
      "Start of epoch 228\n",
      "Training loss at epoch 228: 0.0631\n",
      "\n",
      "Start of epoch 229\n",
      "Training loss at epoch 229: 0.0625\n",
      "\n",
      "Start of epoch 230\n",
      "Training loss at epoch 230: 0.0619\n",
      "\n",
      "Start of epoch 231\n",
      "Training loss at epoch 231: 0.0614\n",
      "\n",
      "Start of epoch 232\n",
      "Training loss at epoch 232: 0.0608\n",
      "\n",
      "Start of epoch 233\n",
      "Training loss at epoch 233: 0.0604\n",
      "\n",
      "Start of epoch 234\n",
      "Training loss at epoch 234: 0.0599\n",
      "\n",
      "Start of epoch 235\n",
      "Training loss at epoch 235: 0.0594\n",
      "\n",
      "Start of epoch 236\n",
      "Training loss at epoch 236: 0.0588\n",
      "\n",
      "Start of epoch 237\n",
      "Training loss at epoch 237: 0.0582\n",
      "\n",
      "Start of epoch 238\n",
      "Training loss at epoch 238: 0.0577\n",
      "\n",
      "Start of epoch 239\n",
      "Training loss at epoch 239: 0.0571\n",
      "\n",
      "Start of epoch 240\n",
      "Training loss at epoch 240: 0.0564\n",
      "\n",
      "Start of epoch 241\n",
      "Training loss at epoch 241: 0.0558\n",
      "\n",
      "Start of epoch 242\n",
      "Training loss at epoch 242: 0.0551\n",
      "\n",
      "Start of epoch 243\n",
      "Training loss at epoch 243: 0.0544\n",
      "\n",
      "Start of epoch 244\n",
      "Training loss at epoch 244: 0.0537\n",
      "\n",
      "Start of epoch 245\n",
      "Training loss at epoch 245: 0.0529\n",
      "\n",
      "Start of epoch 246\n",
      "Training loss at epoch 246: 0.0520\n",
      "\n",
      "Start of epoch 247\n",
      "Training loss at epoch 247: 0.0511\n",
      "\n",
      "Start of epoch 248\n",
      "Training loss at epoch 248: 0.0502\n",
      "\n",
      "Start of epoch 249\n",
      "Training loss at epoch 249: 0.0492\n",
      "\n",
      "Start of epoch 250\n",
      "Training loss at epoch 250: 0.0482\n",
      "\n",
      "Start of epoch 251\n",
      "Training loss at epoch 251: 0.0472\n",
      "\n",
      "Start of epoch 252\n",
      "Training loss at epoch 252: 0.0462\n",
      "\n",
      "Start of epoch 253\n",
      "Training loss at epoch 253: 0.0452\n",
      "\n",
      "Start of epoch 254\n",
      "Training loss at epoch 254: 0.0443\n",
      "\n",
      "Start of epoch 255\n",
      "Training loss at epoch 255: 0.0434\n",
      "\n",
      "Start of epoch 256\n",
      "Training loss at epoch 256: 0.0425\n",
      "\n",
      "Start of epoch 257\n",
      "Training loss at epoch 257: 0.0417\n",
      "\n",
      "Start of epoch 258\n",
      "Training loss at epoch 258: 0.0410\n",
      "\n",
      "Start of epoch 259\n",
      "Training loss at epoch 259: 0.0402\n",
      "\n",
      "Start of epoch 260\n",
      "Training loss at epoch 260: 0.0396\n",
      "\n",
      "Start of epoch 261\n",
      "Training loss at epoch 261: 0.0389\n",
      "\n",
      "Start of epoch 262\n",
      "Training loss at epoch 262: 0.0384\n",
      "\n",
      "Start of epoch 263\n",
      "Training loss at epoch 263: 0.0378\n",
      "\n",
      "Start of epoch 264\n",
      "Training loss at epoch 264: 0.0373\n",
      "\n",
      "Start of epoch 265\n",
      "Training loss at epoch 265: 0.0368\n",
      "\n",
      "Start of epoch 266\n",
      "Training loss at epoch 266: 0.0363\n",
      "\n",
      "Start of epoch 267\n",
      "Training loss at epoch 267: 0.0358\n",
      "\n",
      "Start of epoch 268\n",
      "Training loss at epoch 268: 0.0353\n",
      "\n",
      "Start of epoch 269\n",
      "Training loss at epoch 269: 0.0349\n",
      "\n",
      "Start of epoch 270\n",
      "Training loss at epoch 270: 0.0344\n",
      "\n",
      "Start of epoch 271\n",
      "Training loss at epoch 271: 0.0340\n",
      "\n",
      "Start of epoch 272\n",
      "Training loss at epoch 272: 0.0337\n",
      "\n",
      "Start of epoch 273\n",
      "Training loss at epoch 273: 0.0333\n",
      "\n",
      "Start of epoch 274\n",
      "Training loss at epoch 274: 0.0330\n",
      "\n",
      "Start of epoch 275\n",
      "Training loss at epoch 275: 0.0327\n",
      "\n",
      "Start of epoch 276\n",
      "Training loss at epoch 276: 0.0325\n",
      "\n",
      "Start of epoch 277\n",
      "Training loss at epoch 277: 0.0322\n",
      "\n",
      "Start of epoch 278\n",
      "Training loss at epoch 278: 0.0320\n",
      "\n",
      "Start of epoch 279\n",
      "Training loss at epoch 279: 0.0318\n",
      "\n",
      "Start of epoch 280\n",
      "Training loss at epoch 280: 0.0317\n",
      "\n",
      "Start of epoch 281\n",
      "Training loss at epoch 281: 0.0315\n",
      "\n",
      "Start of epoch 282\n",
      "Training loss at epoch 282: 0.0314\n",
      "\n",
      "Start of epoch 283\n",
      "Training loss at epoch 283: 0.0313\n",
      "\n",
      "Start of epoch 284\n",
      "Training loss at epoch 284: 0.0312\n",
      "\n",
      "Start of epoch 285\n",
      "Training loss at epoch 285: 0.0311\n",
      "\n",
      "Start of epoch 286\n",
      "Training loss at epoch 286: 0.0310\n",
      "\n",
      "Start of epoch 287\n",
      "Training loss at epoch 287: 0.0309\n",
      "\n",
      "Start of epoch 288\n",
      "Training loss at epoch 288: 0.0308\n",
      "\n",
      "Start of epoch 289\n",
      "Training loss at epoch 289: 0.0307\n",
      "\n",
      "Start of epoch 290\n",
      "Training loss at epoch 290: 0.0307\n",
      "\n",
      "Start of epoch 291\n",
      "Training loss at epoch 291: 0.0306\n",
      "\n",
      "Start of epoch 292\n",
      "Training loss at epoch 292: 0.0305\n",
      "\n",
      "Start of epoch 293\n",
      "Training loss at epoch 293: 0.0304\n",
      "\n",
      "Start of epoch 294\n",
      "Training loss at epoch 294: 0.0304\n",
      "\n",
      "Start of epoch 295\n",
      "Training loss at epoch 295: 0.0303\n",
      "\n",
      "Start of epoch 296\n",
      "Training loss at epoch 296: 0.0302\n",
      "\n",
      "Start of epoch 297\n",
      "Training loss at epoch 297: 0.0302\n",
      "\n",
      "Start of epoch 298\n",
      "Training loss at epoch 298: 0.0301\n",
      "\n",
      "Start of epoch 299\n",
      "Training loss at epoch 299: 0.0300\n",
      "\n",
      "Start of epoch 300\n",
      "Training loss at epoch 300: 0.0299\n",
      "\n",
      "Start of epoch 301\n",
      "Training loss at epoch 301: 0.0299\n",
      "\n",
      "Start of epoch 302\n",
      "Training loss at epoch 302: 0.0298\n",
      "\n",
      "Start of epoch 303\n",
      "Training loss at epoch 303: 0.0297\n",
      "\n",
      "Start of epoch 304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 304: 0.0297\n",
      "\n",
      "Start of epoch 305\n",
      "Training loss at epoch 305: 0.0296\n",
      "\n",
      "Start of epoch 306\n",
      "Training loss at epoch 306: 0.0295\n",
      "\n",
      "Start of epoch 307\n",
      "Training loss at epoch 307: 0.0294\n",
      "\n",
      "Start of epoch 308\n",
      "Training loss at epoch 308: 0.0294\n",
      "\n",
      "Start of epoch 309\n",
      "Training loss at epoch 309: 0.0293\n",
      "\n",
      "Start of epoch 310\n",
      "Training loss at epoch 310: 0.0292\n",
      "\n",
      "Start of epoch 311\n",
      "Training loss at epoch 311: 0.0291\n",
      "\n",
      "Start of epoch 312\n",
      "Training loss at epoch 312: 0.0291\n",
      "\n",
      "Start of epoch 313\n",
      "Training loss at epoch 313: 0.0290\n",
      "\n",
      "Start of epoch 314\n",
      "Training loss at epoch 314: 0.0289\n",
      "\n",
      "Start of epoch 315\n",
      "Training loss at epoch 315: 0.0288\n",
      "\n",
      "Start of epoch 316\n",
      "Training loss at epoch 316: 0.0288\n",
      "\n",
      "Start of epoch 317\n",
      "Training loss at epoch 317: 0.0287\n",
      "\n",
      "Start of epoch 318\n",
      "Training loss at epoch 318: 0.0286\n",
      "\n",
      "Start of epoch 319\n",
      "Training loss at epoch 319: 0.0286\n",
      "\n",
      "Start of epoch 320\n",
      "Training loss at epoch 320: 0.0285\n",
      "\n",
      "Start of epoch 321\n",
      "Training loss at epoch 321: 0.0284\n",
      "\n",
      "Start of epoch 322\n",
      "Training loss at epoch 322: 0.0283\n",
      "\n",
      "Start of epoch 323\n",
      "Training loss at epoch 323: 0.0283\n",
      "\n",
      "Start of epoch 324\n",
      "Training loss at epoch 324: 0.0282\n",
      "\n",
      "Start of epoch 325\n",
      "Training loss at epoch 325: 0.0281\n",
      "\n",
      "Start of epoch 326\n",
      "Training loss at epoch 326: 0.0281\n",
      "\n",
      "Start of epoch 327\n",
      "Training loss at epoch 327: 0.0280\n",
      "\n",
      "Start of epoch 328\n",
      "Training loss at epoch 328: 0.0279\n",
      "\n",
      "Start of epoch 329\n",
      "Training loss at epoch 329: 0.0278\n",
      "\n",
      "Start of epoch 330\n",
      "Training loss at epoch 330: 0.0278\n",
      "\n",
      "Start of epoch 331\n",
      "Training loss at epoch 331: 0.0277\n",
      "\n",
      "Start of epoch 332\n",
      "Training loss at epoch 332: 0.0276\n",
      "\n",
      "Start of epoch 333\n",
      "Training loss at epoch 333: 0.0275\n",
      "\n",
      "Start of epoch 334\n",
      "Training loss at epoch 334: 0.0275\n",
      "\n",
      "Start of epoch 335\n",
      "Training loss at epoch 335: 0.0274\n",
      "\n",
      "Start of epoch 336\n",
      "Training loss at epoch 336: 0.0273\n",
      "\n",
      "Start of epoch 337\n",
      "Training loss at epoch 337: 0.0273\n",
      "\n",
      "Start of epoch 338\n",
      "Training loss at epoch 338: 0.0272\n",
      "\n",
      "Start of epoch 339\n",
      "Training loss at epoch 339: 0.0271\n",
      "\n",
      "Start of epoch 340\n",
      "Training loss at epoch 340: 0.0271\n",
      "\n",
      "Start of epoch 341\n",
      "Training loss at epoch 341: 0.0270\n",
      "\n",
      "Start of epoch 342\n",
      "Training loss at epoch 342: 0.0269\n",
      "\n",
      "Start of epoch 343\n",
      "Training loss at epoch 343: 0.0269\n",
      "\n",
      "Start of epoch 344\n",
      "Training loss at epoch 344: 0.0268\n",
      "\n",
      "Start of epoch 345\n",
      "Training loss at epoch 345: 0.0267\n",
      "\n",
      "Start of epoch 346\n",
      "Training loss at epoch 346: 0.0267\n",
      "\n",
      "Start of epoch 347\n",
      "Training loss at epoch 347: 0.0266\n",
      "\n",
      "Start of epoch 348\n",
      "Training loss at epoch 348: 0.0265\n",
      "\n",
      "Start of epoch 349\n",
      "Training loss at epoch 349: 0.0265\n",
      "\n",
      "Start of epoch 350\n",
      "Training loss at epoch 350: 0.0264\n",
      "\n",
      "Start of epoch 351\n",
      "Training loss at epoch 351: 0.0263\n",
      "\n",
      "Start of epoch 352\n",
      "Training loss at epoch 352: 0.0263\n",
      "\n",
      "Start of epoch 353\n",
      "Training loss at epoch 353: 0.0262\n",
      "\n",
      "Start of epoch 354\n",
      "Training loss at epoch 354: 0.0261\n",
      "\n",
      "Start of epoch 355\n",
      "Training loss at epoch 355: 0.0261\n",
      "\n",
      "Start of epoch 356\n",
      "Training loss at epoch 356: 0.0260\n",
      "\n",
      "Start of epoch 357\n",
      "Training loss at epoch 357: 0.0260\n",
      "\n",
      "Start of epoch 358\n",
      "Training loss at epoch 358: 0.0259\n",
      "\n",
      "Start of epoch 359\n",
      "Training loss at epoch 359: 0.0259\n",
      "\n",
      "Start of epoch 360\n",
      "Training loss at epoch 360: 0.0258\n",
      "\n",
      "Start of epoch 361\n",
      "Training loss at epoch 361: 0.0257\n",
      "\n",
      "Start of epoch 362\n",
      "Training loss at epoch 362: 0.0257\n",
      "\n",
      "Start of epoch 363\n",
      "Training loss at epoch 363: 0.0256\n",
      "\n",
      "Start of epoch 364\n",
      "Training loss at epoch 364: 0.0256\n",
      "\n",
      "Start of epoch 365\n",
      "Training loss at epoch 365: 0.0255\n",
      "\n",
      "Start of epoch 366\n",
      "Training loss at epoch 366: 0.0255\n",
      "\n",
      "Start of epoch 367\n",
      "Training loss at epoch 367: 0.0254\n",
      "\n",
      "Start of epoch 368\n",
      "Training loss at epoch 368: 0.0254\n",
      "\n",
      "Start of epoch 369\n",
      "Training loss at epoch 369: 0.0253\n",
      "\n",
      "Start of epoch 370\n",
      "Training loss at epoch 370: 0.0253\n",
      "\n",
      "Start of epoch 371\n",
      "Training loss at epoch 371: 0.0252\n",
      "\n",
      "Start of epoch 372\n",
      "Training loss at epoch 372: 0.0252\n",
      "\n",
      "Start of epoch 373\n",
      "Training loss at epoch 373: 0.0252\n",
      "\n",
      "Start of epoch 374\n",
      "Training loss at epoch 374: 0.0251\n",
      "\n",
      "Start of epoch 375\n",
      "Training loss at epoch 375: 0.0251\n",
      "\n",
      "Start of epoch 376\n",
      "Training loss at epoch 376: 0.0250\n",
      "\n",
      "Start of epoch 377\n",
      "Training loss at epoch 377: 0.0250\n",
      "\n",
      "Start of epoch 378\n",
      "Training loss at epoch 378: 0.0250\n",
      "\n",
      "Start of epoch 379\n",
      "Training loss at epoch 379: 0.0249\n",
      "\n",
      "Start of epoch 380\n",
      "Training loss at epoch 380: 0.0249\n",
      "\n",
      "Start of epoch 381\n",
      "Training loss at epoch 381: 0.0249\n",
      "\n",
      "Start of epoch 382\n",
      "Training loss at epoch 382: 0.0248\n",
      "\n",
      "Start of epoch 383\n",
      "Training loss at epoch 383: 0.0248\n",
      "\n",
      "Start of epoch 384\n",
      "Training loss at epoch 384: 0.0248\n",
      "\n",
      "Start of epoch 385\n",
      "Training loss at epoch 385: 0.0247\n",
      "\n",
      "Start of epoch 386\n",
      "Training loss at epoch 386: 0.0247\n",
      "\n",
      "Start of epoch 387\n",
      "Training loss at epoch 387: 0.0247\n",
      "\n",
      "Start of epoch 388\n",
      "Training loss at epoch 388: 0.0246\n",
      "\n",
      "Start of epoch 389\n",
      "Training loss at epoch 389: 0.0246\n",
      "\n",
      "Start of epoch 390\n",
      "Training loss at epoch 390: 0.0246\n",
      "\n",
      "Start of epoch 391\n",
      "Training loss at epoch 391: 0.0246\n",
      "\n",
      "Start of epoch 392\n",
      "Training loss at epoch 392: 0.0245\n",
      "\n",
      "Start of epoch 393\n",
      "Training loss at epoch 393: 0.0245\n",
      "\n",
      "Start of epoch 394\n",
      "Training loss at epoch 394: 0.0245\n",
      "\n",
      "Start of epoch 395\n",
      "Training loss at epoch 395: 0.0245\n",
      "\n",
      "Start of epoch 396\n",
      "Training loss at epoch 396: 0.0245\n",
      "\n",
      "Start of epoch 397\n",
      "Training loss at epoch 397: 0.0244\n",
      "\n",
      "Start of epoch 398\n",
      "Training loss at epoch 398: 0.0244\n",
      "\n",
      "Start of epoch 399\n",
      "Training loss at epoch 399: 0.0244\n",
      "\n",
      "Start of epoch 400\n",
      "Training loss at epoch 400: 0.0244\n",
      "\n",
      "Start of epoch 401\n",
      "Training loss at epoch 401: 0.0244\n",
      "\n",
      "Start of epoch 402\n",
      "Training loss at epoch 402: 0.0244\n",
      "\n",
      "Start of epoch 403\n",
      "Training loss at epoch 403: 0.0243\n",
      "\n",
      "Start of epoch 404\n",
      "Training loss at epoch 404: 0.0243\n",
      "\n",
      "Start of epoch 405\n",
      "Training loss at epoch 405: 0.0243\n",
      "\n",
      "Start of epoch 406\n",
      "Training loss at epoch 406: 0.0243\n",
      "\n",
      "Start of epoch 407\n",
      "Training loss at epoch 407: 0.0243\n",
      "\n",
      "Start of epoch 408\n",
      "Training loss at epoch 408: 0.0243\n",
      "\n",
      "Start of epoch 409\n",
      "Training loss at epoch 409: 0.0243\n",
      "\n",
      "Start of epoch 410\n",
      "Training loss at epoch 410: 0.0243\n",
      "\n",
      "Start of epoch 411\n",
      "Training loss at epoch 411: 0.0242\n",
      "\n",
      "Start of epoch 412\n",
      "Training loss at epoch 412: 0.0242\n",
      "\n",
      "Start of epoch 413\n",
      "Training loss at epoch 413: 0.0242\n",
      "\n",
      "Start of epoch 414\n",
      "Training loss at epoch 414: 0.0242\n",
      "\n",
      "Start of epoch 415\n",
      "Training loss at epoch 415: 0.0242\n",
      "\n",
      "Start of epoch 416\n",
      "Training loss at epoch 416: 0.0242\n",
      "\n",
      "Start of epoch 417\n",
      "Training loss at epoch 417: 0.0242\n",
      "\n",
      "Start of epoch 418\n",
      "Training loss at epoch 418: 0.0242\n",
      "\n",
      "Start of epoch 419\n",
      "Training loss at epoch 419: 0.0242\n",
      "\n",
      "Start of epoch 420\n",
      "Training loss at epoch 420: 0.0242\n",
      "\n",
      "Start of epoch 421\n",
      "Training loss at epoch 421: 0.0242\n",
      "\n",
      "Start of epoch 422\n",
      "Training loss at epoch 422: 0.0242\n",
      "\n",
      "Start of epoch 423\n",
      "Training loss at epoch 423: 0.0242\n",
      "\n",
      "Start of epoch 424\n",
      "Training loss at epoch 424: 0.0242\n",
      "\n",
      "Start of epoch 425\n",
      "Training loss at epoch 425: 0.0241\n",
      "\n",
      "Start of epoch 426\n",
      "Training loss at epoch 426: 0.0241\n",
      "\n",
      "Start of epoch 427\n",
      "Training loss at epoch 427: 0.0241\n",
      "\n",
      "Start of epoch 428\n",
      "Training loss at epoch 428: 0.0241\n",
      "\n",
      "Start of epoch 429\n",
      "Training loss at epoch 429: 0.0241\n",
      "\n",
      "Start of epoch 430\n",
      "Training loss at epoch 430: 0.0241\n",
      "\n",
      "Start of epoch 431\n",
      "Training loss at epoch 431: 0.0241\n",
      "\n",
      "Start of epoch 432\n",
      "Training loss at epoch 432: 0.0241\n",
      "\n",
      "Start of epoch 433\n",
      "Training loss at epoch 433: 0.0241\n",
      "\n",
      "Start of epoch 434\n",
      "Training loss at epoch 434: 0.0241\n",
      "\n",
      "Start of epoch 435\n",
      "Training loss at epoch 435: 0.0241\n",
      "\n",
      "Start of epoch 436\n",
      "Training loss at epoch 436: 0.0241\n",
      "\n",
      "Start of epoch 437\n",
      "Training loss at epoch 437: 0.0241\n",
      "\n",
      "Start of epoch 438\n",
      "Training loss at epoch 438: 0.0241\n",
      "\n",
      "Start of epoch 439\n",
      "Training loss at epoch 439: 0.0241\n",
      "\n",
      "Start of epoch 440\n",
      "Training loss at epoch 440: 0.0241\n",
      "\n",
      "Start of epoch 441\n",
      "Training loss at epoch 441: 0.0241\n",
      "\n",
      "Start of epoch 442\n",
      "Training loss at epoch 442: 0.0241\n",
      "\n",
      "Start of epoch 443\n",
      "Training loss at epoch 443: 0.0241\n",
      "\n",
      "Start of epoch 444\n",
      "Training loss at epoch 444: 0.0241\n",
      "\n",
      "Start of epoch 445\n",
      "Training loss at epoch 445: 0.0241\n",
      "\n",
      "Start of epoch 446\n",
      "Training loss at epoch 446: 0.0241\n",
      "\n",
      "Start of epoch 447\n",
      "Training loss at epoch 447: 0.0241\n",
      "\n",
      "Start of epoch 448\n",
      "Training loss at epoch 448: 0.0241\n",
      "\n",
      "Start of epoch 449\n",
      "Training loss at epoch 449: 0.0241\n",
      "\n",
      "Start of epoch 450\n",
      "Training loss at epoch 450: 0.0241\n",
      "\n",
      "Start of epoch 451\n",
      "Training loss at epoch 451: 0.0241\n",
      "\n",
      "Start of epoch 452\n",
      "Training loss at epoch 452: 0.0241\n",
      "\n",
      "Start of epoch 453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 453: 0.0241\n",
      "\n",
      "Start of epoch 454\n",
      "Training loss at epoch 454: 0.0241\n",
      "\n",
      "Start of epoch 455\n",
      "Training loss at epoch 455: 0.0241\n",
      "\n",
      "Start of epoch 456\n",
      "Training loss at epoch 456: 0.0241\n",
      "\n",
      "Start of epoch 457\n",
      "Training loss at epoch 457: 0.0241\n",
      "\n",
      "Start of epoch 458\n",
      "Training loss at epoch 458: 0.0241\n",
      "\n",
      "Start of epoch 459\n",
      "Training loss at epoch 459: 0.0241\n",
      "\n",
      "Start of epoch 460\n",
      "Training loss at epoch 460: 0.0241\n",
      "\n",
      "Start of epoch 461\n",
      "Training loss at epoch 461: 0.0241\n",
      "\n",
      "Start of epoch 462\n",
      "Training loss at epoch 462: 0.0241\n",
      "\n",
      "Start of epoch 463\n",
      "Training loss at epoch 463: 0.0241\n",
      "\n",
      "Start of epoch 464\n",
      "Training loss at epoch 464: 0.0241\n",
      "\n",
      "Start of epoch 465\n",
      "Training loss at epoch 465: 0.0241\n",
      "\n",
      "Start of epoch 466\n",
      "Training loss at epoch 466: 0.0241\n",
      "\n",
      "Start of epoch 467\n",
      "Training loss at epoch 467: 0.0241\n",
      "\n",
      "Start of epoch 468\n",
      "Training loss at epoch 468: 0.0241\n",
      "\n",
      "Start of epoch 469\n",
      "Training loss at epoch 469: 0.0241\n",
      "\n",
      "Start of epoch 470\n",
      "Training loss at epoch 470: 0.0241\n",
      "\n",
      "Start of epoch 471\n",
      "Training loss at epoch 471: 0.0241\n",
      "\n",
      "Start of epoch 472\n",
      "Training loss at epoch 472: 0.0241\n",
      "\n",
      "Start of epoch 473\n",
      "Training loss at epoch 473: 0.0241\n",
      "\n",
      "Start of epoch 474\n",
      "Training loss at epoch 474: 0.0241\n",
      "\n",
      "Start of epoch 475\n",
      "Training loss at epoch 475: 0.0241\n",
      "\n",
      "Start of epoch 476\n",
      "Training loss at epoch 476: 0.0241\n",
      "\n",
      "Start of epoch 477\n",
      "Training loss at epoch 477: 0.0241\n",
      "\n",
      "Start of epoch 478\n",
      "Training loss at epoch 478: 0.0241\n",
      "\n",
      "Start of epoch 479\n",
      "Training loss at epoch 479: 0.0241\n",
      "\n",
      "Start of epoch 480\n",
      "Training loss at epoch 480: 0.0241\n",
      "\n",
      "Start of epoch 481\n",
      "Training loss at epoch 481: 0.0241\n",
      "\n",
      "Start of epoch 482\n",
      "Training loss at epoch 482: 0.0241\n",
      "\n",
      "Start of epoch 483\n",
      "Training loss at epoch 483: 0.0241\n",
      "\n",
      "Start of epoch 484\n",
      "Training loss at epoch 484: 0.0241\n",
      "\n",
      "Start of epoch 485\n",
      "Training loss at epoch 485: 0.0241\n",
      "\n",
      "Start of epoch 486\n",
      "Training loss at epoch 486: 0.0241\n",
      "\n",
      "Start of epoch 487\n",
      "Training loss at epoch 487: 0.0241\n",
      "\n",
      "Start of epoch 488\n",
      "Training loss at epoch 488: 0.0241\n",
      "\n",
      "Start of epoch 489\n",
      "Training loss at epoch 489: 0.0241\n",
      "\n",
      "Start of epoch 490\n",
      "Training loss at epoch 490: 0.0241\n",
      "\n",
      "Start of epoch 491\n",
      "Training loss at epoch 491: 0.0241\n",
      "\n",
      "Start of epoch 492\n",
      "Training loss at epoch 492: 0.0241\n",
      "\n",
      "Start of epoch 493\n",
      "Training loss at epoch 493: 0.0241\n",
      "\n",
      "Start of epoch 494\n",
      "Training loss at epoch 494: 0.0241\n",
      "\n",
      "Start of epoch 495\n",
      "Training loss at epoch 495: 0.0241\n",
      "\n",
      "Start of epoch 496\n",
      "Training loss at epoch 496: 0.0241\n",
      "\n",
      "Start of epoch 497\n",
      "Training loss at epoch 497: 0.0241\n",
      "\n",
      "Start of epoch 498\n",
      "Training loss at epoch 498: 0.0241\n",
      "\n",
      "Start of epoch 499\n",
      "Training loss at epoch 499: 0.0241\n",
      "[<tf.Variable 'parameters:0' shape=(30,) dtype=float32, numpy=\n",
      "array([3.3855855e+00, 4.7905540e+00, 1.9392993e+00, 3.4438357e+00,\n",
      "       3.1366687e+00, 3.6397088e+00, 1.9404154e+00, 3.1160812e+00,\n",
      "       5.6508260e+00, 1.0059252e+00, 9.7220457e-01, 2.5892653e+00,\n",
      "       1.8551446e+00, 8.1542766e-01, 4.1988187e+00, 1.3242329e+00,\n",
      "       3.8932867e+00, 3.2905687e-02, 2.4623110e+00, 2.2365560e-03,\n",
      "       1.3107289e+00, 2.8459928e+00, 6.1777468e+00, 4.7675695e+00,\n",
      "       5.0580478e+00, 4.2041283e+00, 9.4147247e-01, 5.5932469e+00,\n",
      "       2.7437165e+00, 8.9608598e-01], dtype=float32)>]\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.0081\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 0.9449\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.8807\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.8243\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.7823\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.7519\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.7254\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.6990\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.6724\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.6473\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.6263\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.6105\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.5995\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.5915\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.5845\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.5776\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.5704\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.5628\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.5548\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.5464\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.5375\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.5280\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.5183\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.5088\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.4999\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.4919\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.4852\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.4796\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.4748\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.4706\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.4668\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.4633\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.4600\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.4568\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.4538\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.4507\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.4476\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.4443\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.4412\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.4382\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.4356\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.4334\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.4315\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.4300\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.4287\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.4276\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.4267\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.4260\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.4253\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.4246\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.4239\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.4232\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.4226\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.4220\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.4214\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.4209\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.4204\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.4199\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.4195\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.4191\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.4187\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.4184\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.4181\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.4179\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.4177\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.4174\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.4173\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.4171\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.4169\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.4167\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.4165\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.4163\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.4161\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.4159\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.4157\n",
      "\n",
      "Start of epoch 75\n",
      "Training loss at epoch 75: 0.4155\n",
      "\n",
      "Start of epoch 76\n",
      "Training loss at epoch 76: 0.4153\n",
      "\n",
      "Start of epoch 77\n",
      "Training loss at epoch 77: 0.4151\n",
      "\n",
      "Start of epoch 78\n",
      "Training loss at epoch 78: 0.4149\n",
      "\n",
      "Start of epoch 79\n",
      "Training loss at epoch 79: 0.4147\n",
      "\n",
      "Start of epoch 80\n",
      "Training loss at epoch 80: 0.4146\n",
      "\n",
      "Start of epoch 81\n",
      "Training loss at epoch 81: 0.4144\n",
      "\n",
      "Start of epoch 82\n",
      "Training loss at epoch 82: 0.4143\n",
      "\n",
      "Start of epoch 83\n",
      "Training loss at epoch 83: 0.4141\n",
      "\n",
      "Start of epoch 84\n",
      "Training loss at epoch 84: 0.4139\n",
      "\n",
      "Start of epoch 85\n",
      "Training loss at epoch 85: 0.4138\n",
      "\n",
      "Start of epoch 86\n",
      "Training loss at epoch 86: 0.4136\n",
      "\n",
      "Start of epoch 87\n",
      "Training loss at epoch 87: 0.4134\n",
      "\n",
      "Start of epoch 88\n",
      "Training loss at epoch 88: 0.4133\n",
      "\n",
      "Start of epoch 89\n",
      "Training loss at epoch 89: 0.4131\n",
      "\n",
      "Start of epoch 90\n",
      "Training loss at epoch 90: 0.4129\n",
      "\n",
      "Start of epoch 91\n",
      "Training loss at epoch 91: 0.4127\n",
      "\n",
      "Start of epoch 92\n",
      "Training loss at epoch 92: 0.4126\n",
      "\n",
      "Start of epoch 93\n",
      "Training loss at epoch 93: 0.4124\n",
      "\n",
      "Start of epoch 94\n",
      "Training loss at epoch 94: 0.4122\n",
      "\n",
      "Start of epoch 95\n",
      "Training loss at epoch 95: 0.4120\n",
      "\n",
      "Start of epoch 96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 96: 0.4119\n",
      "\n",
      "Start of epoch 97\n",
      "Training loss at epoch 97: 0.4117\n",
      "\n",
      "Start of epoch 98\n",
      "Training loss at epoch 98: 0.4115\n",
      "\n",
      "Start of epoch 99\n",
      "Training loss at epoch 99: 0.4113\n",
      "\n",
      "Start of epoch 100\n",
      "Training loss at epoch 100: 0.4111\n",
      "\n",
      "Start of epoch 101\n",
      "Training loss at epoch 101: 0.4109\n",
      "\n",
      "Start of epoch 102\n",
      "Training loss at epoch 102: 0.4107\n",
      "\n",
      "Start of epoch 103\n",
      "Training loss at epoch 103: 0.4105\n",
      "\n",
      "Start of epoch 104\n",
      "Training loss at epoch 104: 0.4103\n",
      "\n",
      "Start of epoch 105\n",
      "Training loss at epoch 105: 0.4101\n",
      "\n",
      "Start of epoch 106\n",
      "Training loss at epoch 106: 0.4099\n",
      "\n",
      "Start of epoch 107\n",
      "Training loss at epoch 107: 0.4097\n",
      "\n",
      "Start of epoch 108\n",
      "Training loss at epoch 108: 0.4095\n",
      "\n",
      "Start of epoch 109\n",
      "Training loss at epoch 109: 0.4092\n",
      "\n",
      "Start of epoch 110\n",
      "Training loss at epoch 110: 0.4090\n",
      "\n",
      "Start of epoch 111\n",
      "Training loss at epoch 111: 0.4088\n",
      "\n",
      "Start of epoch 112\n",
      "Training loss at epoch 112: 0.4085\n",
      "\n",
      "Start of epoch 113\n",
      "Training loss at epoch 113: 0.4082\n",
      "\n",
      "Start of epoch 114\n",
      "Training loss at epoch 114: 0.4079\n",
      "\n",
      "Start of epoch 115\n",
      "Training loss at epoch 115: 0.4077\n",
      "\n",
      "Start of epoch 116\n",
      "Training loss at epoch 116: 0.4074\n",
      "\n",
      "Start of epoch 117\n",
      "Training loss at epoch 117: 0.4070\n",
      "\n",
      "Start of epoch 118\n",
      "Training loss at epoch 118: 0.4067\n",
      "\n",
      "Start of epoch 119\n",
      "Training loss at epoch 119: 0.4064\n",
      "\n",
      "Start of epoch 120\n",
      "Training loss at epoch 120: 0.4060\n",
      "\n",
      "Start of epoch 121\n",
      "Training loss at epoch 121: 0.4056\n",
      "\n",
      "Start of epoch 122\n",
      "Training loss at epoch 122: 0.4052\n",
      "\n",
      "Start of epoch 123\n",
      "Training loss at epoch 123: 0.4048\n",
      "\n",
      "Start of epoch 124\n",
      "Training loss at epoch 124: 0.4043\n",
      "\n",
      "Start of epoch 125\n",
      "Training loss at epoch 125: 0.4038\n",
      "\n",
      "Start of epoch 126\n",
      "Training loss at epoch 126: 0.4033\n",
      "\n",
      "Start of epoch 127\n",
      "Training loss at epoch 127: 0.4028\n",
      "\n",
      "Start of epoch 128\n",
      "Training loss at epoch 128: 0.4022\n",
      "\n",
      "Start of epoch 129\n",
      "Training loss at epoch 129: 0.4016\n",
      "\n",
      "Start of epoch 130\n",
      "Training loss at epoch 130: 0.4010\n",
      "\n",
      "Start of epoch 131\n",
      "Training loss at epoch 131: 0.4003\n",
      "\n",
      "Start of epoch 132\n",
      "Training loss at epoch 132: 0.3996\n",
      "\n",
      "Start of epoch 133\n",
      "Training loss at epoch 133: 0.3989\n",
      "\n",
      "Start of epoch 134\n",
      "Training loss at epoch 134: 0.3982\n",
      "\n",
      "Start of epoch 135\n",
      "Training loss at epoch 135: 0.3974\n",
      "\n",
      "Start of epoch 136\n",
      "Training loss at epoch 136: 0.3966\n",
      "\n",
      "Start of epoch 137\n",
      "Training loss at epoch 137: 0.3958\n",
      "\n",
      "Start of epoch 138\n",
      "Training loss at epoch 138: 0.3949\n",
      "\n",
      "Start of epoch 139\n",
      "Training loss at epoch 139: 0.3941\n",
      "\n",
      "Start of epoch 140\n",
      "Training loss at epoch 140: 0.3932\n",
      "\n",
      "Start of epoch 141\n",
      "Training loss at epoch 141: 0.3923\n",
      "\n",
      "Start of epoch 142\n",
      "Training loss at epoch 142: 0.3915\n",
      "\n",
      "Start of epoch 143\n",
      "Training loss at epoch 143: 0.3906\n",
      "\n",
      "Start of epoch 144\n",
      "Training loss at epoch 144: 0.3897\n",
      "\n",
      "Start of epoch 145\n",
      "Training loss at epoch 145: 0.3888\n",
      "\n",
      "Start of epoch 146\n",
      "Training loss at epoch 146: 0.3879\n",
      "\n",
      "Start of epoch 147\n",
      "Training loss at epoch 147: 0.3871\n",
      "\n",
      "Start of epoch 148\n",
      "Training loss at epoch 148: 0.3862\n",
      "\n",
      "Start of epoch 149\n",
      "Training loss at epoch 149: 0.3853\n",
      "\n",
      "Start of epoch 150\n",
      "Training loss at epoch 150: 0.3843\n",
      "\n",
      "Start of epoch 151\n",
      "Training loss at epoch 151: 0.3834\n",
      "\n",
      "Start of epoch 152\n",
      "Training loss at epoch 152: 0.3824\n",
      "\n",
      "Start of epoch 153\n",
      "Training loss at epoch 153: 0.3814\n",
      "\n",
      "Start of epoch 154\n",
      "Training loss at epoch 154: 0.3803\n",
      "\n",
      "Start of epoch 155\n",
      "Training loss at epoch 155: 0.3791\n",
      "\n",
      "Start of epoch 156\n",
      "Training loss at epoch 156: 0.3779\n",
      "\n",
      "Start of epoch 157\n",
      "Training loss at epoch 157: 0.3766\n",
      "\n",
      "Start of epoch 158\n",
      "Training loss at epoch 158: 0.3752\n",
      "\n",
      "Start of epoch 159\n",
      "Training loss at epoch 159: 0.3737\n",
      "\n",
      "Start of epoch 160\n",
      "Training loss at epoch 160: 0.3721\n",
      "\n",
      "Start of epoch 161\n",
      "Training loss at epoch 161: 0.3704\n",
      "\n",
      "Start of epoch 162\n",
      "Training loss at epoch 162: 0.3686\n",
      "\n",
      "Start of epoch 163\n",
      "Training loss at epoch 163: 0.3667\n",
      "\n",
      "Start of epoch 164\n",
      "Training loss at epoch 164: 0.3647\n",
      "\n",
      "Start of epoch 165\n",
      "Training loss at epoch 165: 0.3625\n",
      "\n",
      "Start of epoch 166\n",
      "Training loss at epoch 166: 0.3602\n",
      "\n",
      "Start of epoch 167\n",
      "Training loss at epoch 167: 0.3578\n",
      "\n",
      "Start of epoch 168\n",
      "Training loss at epoch 168: 0.3552\n",
      "\n",
      "Start of epoch 169\n",
      "Training loss at epoch 169: 0.3524\n",
      "\n",
      "Start of epoch 170\n",
      "Training loss at epoch 170: 0.3494\n",
      "\n",
      "Start of epoch 171\n",
      "Training loss at epoch 171: 0.3462\n",
      "\n",
      "Start of epoch 172\n",
      "Training loss at epoch 172: 0.3428\n",
      "\n",
      "Start of epoch 173\n",
      "Training loss at epoch 173: 0.3390\n",
      "\n",
      "Start of epoch 174\n",
      "Training loss at epoch 174: 0.3348\n",
      "\n",
      "Start of epoch 175\n",
      "Training loss at epoch 175: 0.3302\n",
      "\n",
      "Start of epoch 176\n",
      "Training loss at epoch 176: 0.3249\n",
      "\n",
      "Start of epoch 177\n",
      "Training loss at epoch 177: 0.3190\n",
      "\n",
      "Start of epoch 178\n",
      "Training loss at epoch 178: 0.3120\n",
      "\n",
      "Start of epoch 179\n",
      "Training loss at epoch 179: 0.3038\n",
      "\n",
      "Start of epoch 180\n",
      "Training loss at epoch 180: 0.2943\n",
      "\n",
      "Start of epoch 181\n",
      "Training loss at epoch 181: 0.2834\n",
      "\n",
      "Start of epoch 182\n",
      "Training loss at epoch 182: 0.2716\n",
      "\n",
      "Start of epoch 183\n",
      "Training loss at epoch 183: 0.2592\n",
      "\n",
      "Start of epoch 184\n",
      "Training loss at epoch 184: 0.2459\n",
      "\n",
      "Start of epoch 185\n",
      "Training loss at epoch 185: 0.2318\n",
      "\n",
      "Start of epoch 186\n",
      "Training loss at epoch 186: 0.2169\n",
      "\n",
      "Start of epoch 187\n",
      "Training loss at epoch 187: 0.2016\n",
      "\n",
      "Start of epoch 188\n",
      "Training loss at epoch 188: 0.1863\n",
      "\n",
      "Start of epoch 189\n",
      "Training loss at epoch 189: 0.1713\n",
      "\n",
      "Start of epoch 190\n",
      "Training loss at epoch 190: 0.1573\n",
      "\n",
      "Start of epoch 191\n",
      "Training loss at epoch 191: 0.1443\n",
      "\n",
      "Start of epoch 192\n",
      "Training loss at epoch 192: 0.1315\n",
      "\n",
      "Start of epoch 193\n",
      "Training loss at epoch 193: 0.1195\n",
      "\n",
      "Start of epoch 194\n",
      "Training loss at epoch 194: 0.1095\n",
      "\n",
      "Start of epoch 195\n",
      "Training loss at epoch 195: 0.1022\n",
      "\n",
      "Start of epoch 196\n",
      "Training loss at epoch 196: 0.0969\n",
      "\n",
      "Start of epoch 197\n",
      "Training loss at epoch 197: 0.0925\n",
      "\n",
      "Start of epoch 198\n",
      "Training loss at epoch 198: 0.0883\n",
      "\n",
      "Start of epoch 199\n",
      "Training loss at epoch 199: 0.0841\n",
      "\n",
      "Start of epoch 200\n",
      "Training loss at epoch 200: 0.0796\n",
      "\n",
      "Start of epoch 201\n",
      "Training loss at epoch 201: 0.0753\n",
      "\n",
      "Start of epoch 202\n",
      "Training loss at epoch 202: 0.0718\n",
      "\n",
      "Start of epoch 203\n",
      "Training loss at epoch 203: 0.0692\n",
      "\n",
      "Start of epoch 204\n",
      "Training loss at epoch 204: 0.0672\n",
      "\n",
      "Start of epoch 205\n",
      "Training loss at epoch 205: 0.0655\n",
      "\n",
      "Start of epoch 206\n",
      "Training loss at epoch 206: 0.0638\n",
      "\n",
      "Start of epoch 207\n",
      "Training loss at epoch 207: 0.0616\n",
      "\n",
      "Start of epoch 208\n",
      "Training loss at epoch 208: 0.0589\n",
      "\n",
      "Start of epoch 209\n",
      "Training loss at epoch 209: 0.0559\n",
      "\n",
      "Start of epoch 210\n",
      "Training loss at epoch 210: 0.0529\n",
      "\n",
      "Start of epoch 211\n",
      "Training loss at epoch 211: 0.0501\n",
      "\n",
      "Start of epoch 212\n",
      "Training loss at epoch 212: 0.0475\n",
      "\n",
      "Start of epoch 213\n",
      "Training loss at epoch 213: 0.0452\n",
      "\n",
      "Start of epoch 214\n",
      "Training loss at epoch 214: 0.0433\n",
      "\n",
      "Start of epoch 215\n",
      "Training loss at epoch 215: 0.0421\n",
      "\n",
      "Start of epoch 216\n",
      "Training loss at epoch 216: 0.0415\n",
      "\n",
      "Start of epoch 217\n",
      "Training loss at epoch 217: 0.0414\n",
      "\n",
      "Start of epoch 218\n",
      "Training loss at epoch 218: 0.0415\n",
      "\n",
      "Start of epoch 219\n",
      "Training loss at epoch 219: 0.0416\n",
      "\n",
      "Start of epoch 220\n",
      "Training loss at epoch 220: 0.0417\n",
      "\n",
      "Start of epoch 221\n",
      "Training loss at epoch 221: 0.0417\n",
      "\n",
      "Start of epoch 222\n",
      "Training loss at epoch 222: 0.0416\n",
      "\n",
      "Start of epoch 223\n",
      "Training loss at epoch 223: 0.0412\n",
      "\n",
      "Start of epoch 224\n",
      "Training loss at epoch 224: 0.0406\n",
      "\n",
      "Start of epoch 225\n",
      "Training loss at epoch 225: 0.0400\n",
      "\n",
      "Start of epoch 226\n",
      "Training loss at epoch 226: 0.0395\n",
      "\n",
      "Start of epoch 227\n",
      "Training loss at epoch 227: 0.0392\n",
      "\n",
      "Start of epoch 228\n",
      "Training loss at epoch 228: 0.0391\n",
      "\n",
      "Start of epoch 229\n",
      "Training loss at epoch 229: 0.0390\n",
      "\n",
      "Start of epoch 230\n",
      "Training loss at epoch 230: 0.0388\n",
      "\n",
      "Start of epoch 231\n",
      "Training loss at epoch 231: 0.0387\n",
      "\n",
      "Start of epoch 232\n",
      "Training loss at epoch 232: 0.0386\n",
      "\n",
      "Start of epoch 233\n",
      "Training loss at epoch 233: 0.0385\n",
      "\n",
      "Start of epoch 234\n",
      "Training loss at epoch 234: 0.0383\n",
      "\n",
      "Start of epoch 235\n",
      "Training loss at epoch 235: 0.0381\n",
      "\n",
      "Start of epoch 236\n",
      "Training loss at epoch 236: 0.0379\n",
      "\n",
      "Start of epoch 237\n",
      "Training loss at epoch 237: 0.0378\n",
      "\n",
      "Start of epoch 238\n",
      "Training loss at epoch 238: 0.0379\n",
      "\n",
      "Start of epoch 239\n",
      "Training loss at epoch 239: 0.0379\n",
      "\n",
      "Start of epoch 240\n",
      "Training loss at epoch 240: 0.0379\n",
      "\n",
      "Start of epoch 241\n",
      "Training loss at epoch 241: 0.0379\n",
      "\n",
      "Start of epoch 242\n",
      "Training loss at epoch 242: 0.0379\n",
      "\n",
      "Start of epoch 243\n",
      "Training loss at epoch 243: 0.0379\n",
      "\n",
      "Start of epoch 244\n",
      "Training loss at epoch 244: 0.0379\n",
      "\n",
      "Start of epoch 245\n",
      "Training loss at epoch 245: 0.0378\n",
      "\n",
      "Start of epoch 246\n",
      "Training loss at epoch 246: 0.0377\n",
      "\n",
      "Start of epoch 247\n",
      "Training loss at epoch 247: 0.0376\n",
      "\n",
      "Start of epoch 248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 248: 0.0376\n",
      "\n",
      "Start of epoch 249\n",
      "Training loss at epoch 249: 0.0376\n",
      "\n",
      "Start of epoch 250\n",
      "Training loss at epoch 250: 0.0376\n",
      "\n",
      "Start of epoch 251\n",
      "Training loss at epoch 251: 0.0375\n",
      "\n",
      "Start of epoch 252\n",
      "Training loss at epoch 252: 0.0375\n",
      "\n",
      "Start of epoch 253\n",
      "Training loss at epoch 253: 0.0375\n",
      "\n",
      "Start of epoch 254\n",
      "Training loss at epoch 254: 0.0375\n",
      "\n",
      "Start of epoch 255\n",
      "Training loss at epoch 255: 0.0375\n",
      "\n",
      "Start of epoch 256\n",
      "Training loss at epoch 256: 0.0375\n",
      "\n",
      "Start of epoch 257\n",
      "Training loss at epoch 257: 0.0374\n",
      "\n",
      "Start of epoch 258\n",
      "Training loss at epoch 258: 0.0374\n",
      "\n",
      "Start of epoch 259\n",
      "Training loss at epoch 259: 0.0374\n",
      "\n",
      "Start of epoch 260\n",
      "Training loss at epoch 260: 0.0374\n",
      "\n",
      "Start of epoch 261\n",
      "Training loss at epoch 261: 0.0374\n",
      "\n",
      "Start of epoch 262\n",
      "Training loss at epoch 262: 0.0374\n",
      "\n",
      "Start of epoch 263\n",
      "Training loss at epoch 263: 0.0374\n",
      "\n",
      "Start of epoch 264\n",
      "Training loss at epoch 264: 0.0374\n",
      "\n",
      "Start of epoch 265\n",
      "Training loss at epoch 265: 0.0374\n",
      "\n",
      "Start of epoch 266\n",
      "Training loss at epoch 266: 0.0374\n",
      "\n",
      "Start of epoch 267\n",
      "Training loss at epoch 267: 0.0374\n",
      "\n",
      "Start of epoch 268\n",
      "Training loss at epoch 268: 0.0374\n",
      "\n",
      "Start of epoch 269\n",
      "Training loss at epoch 269: 0.0374\n",
      "\n",
      "Start of epoch 270\n",
      "Training loss at epoch 270: 0.0374\n",
      "\n",
      "Start of epoch 271\n",
      "Training loss at epoch 271: 0.0374\n",
      "\n",
      "Start of epoch 272\n",
      "Training loss at epoch 272: 0.0374\n",
      "\n",
      "Start of epoch 273\n",
      "Training loss at epoch 273: 0.0374\n",
      "\n",
      "Start of epoch 274\n",
      "Training loss at epoch 274: 0.0374\n",
      "\n",
      "Start of epoch 275\n",
      "Training loss at epoch 275: 0.0374\n",
      "\n",
      "Start of epoch 276\n",
      "Training loss at epoch 276: 0.0374\n",
      "\n",
      "Start of epoch 277\n",
      "Training loss at epoch 277: 0.0374\n",
      "\n",
      "Start of epoch 278\n",
      "Training loss at epoch 278: 0.0374\n",
      "\n",
      "Start of epoch 279\n",
      "Training loss at epoch 279: 0.0374\n",
      "\n",
      "Start of epoch 280\n",
      "Training loss at epoch 280: 0.0374\n",
      "\n",
      "Start of epoch 281\n",
      "Training loss at epoch 281: 0.0374\n",
      "\n",
      "Start of epoch 282\n",
      "Training loss at epoch 282: 0.0374\n",
      "\n",
      "Start of epoch 283\n",
      "Training loss at epoch 283: 0.0374\n",
      "\n",
      "Start of epoch 284\n",
      "Training loss at epoch 284: 0.0374\n",
      "\n",
      "Start of epoch 285\n",
      "Training loss at epoch 285: 0.0374\n",
      "\n",
      "Start of epoch 286\n",
      "Training loss at epoch 286: 0.0374\n",
      "\n",
      "Start of epoch 287\n",
      "Training loss at epoch 287: 0.0374\n",
      "\n",
      "Start of epoch 288\n",
      "Training loss at epoch 288: 0.0374\n",
      "\n",
      "Start of epoch 289\n",
      "Training loss at epoch 289: 0.0374\n",
      "\n",
      "Start of epoch 290\n",
      "Training loss at epoch 290: 0.0374\n",
      "\n",
      "Start of epoch 291\n",
      "Training loss at epoch 291: 0.0374\n",
      "\n",
      "Start of epoch 292\n",
      "Training loss at epoch 292: 0.0374\n",
      "\n",
      "Start of epoch 293\n",
      "Training loss at epoch 293: 0.0374\n",
      "\n",
      "Start of epoch 294\n",
      "Training loss at epoch 294: 0.0374\n",
      "\n",
      "Start of epoch 295\n",
      "Training loss at epoch 295: 0.0374\n",
      "\n",
      "Start of epoch 296\n",
      "Training loss at epoch 296: 0.0374\n",
      "\n",
      "Start of epoch 297\n",
      "Training loss at epoch 297: 0.0374\n",
      "\n",
      "Start of epoch 298\n",
      "Training loss at epoch 298: 0.0374\n",
      "\n",
      "Start of epoch 299\n",
      "Training loss at epoch 299: 0.0374\n",
      "\n",
      "Start of epoch 300\n",
      "Training loss at epoch 300: 0.0374\n",
      "\n",
      "Start of epoch 301\n",
      "Training loss at epoch 301: 0.0374\n",
      "\n",
      "Start of epoch 302\n",
      "Training loss at epoch 302: 0.0374\n",
      "\n",
      "Start of epoch 303\n",
      "Training loss at epoch 303: 0.0374\n",
      "\n",
      "Start of epoch 304\n",
      "Training loss at epoch 304: 0.0374\n",
      "\n",
      "Start of epoch 305\n",
      "Training loss at epoch 305: 0.0374\n",
      "\n",
      "Start of epoch 306\n",
      "Training loss at epoch 306: 0.0374\n",
      "\n",
      "Start of epoch 307\n",
      "Training loss at epoch 307: 0.0374\n",
      "\n",
      "Start of epoch 308\n",
      "Training loss at epoch 308: 0.0374\n",
      "\n",
      "Start of epoch 309\n",
      "Training loss at epoch 309: 0.0374\n",
      "\n",
      "Start of epoch 310\n",
      "Training loss at epoch 310: 0.0374\n",
      "\n",
      "Start of epoch 311\n",
      "Training loss at epoch 311: 0.0374\n",
      "\n",
      "Start of epoch 312\n",
      "Training loss at epoch 312: 0.0374\n",
      "\n",
      "Start of epoch 313\n",
      "Training loss at epoch 313: 0.0374\n",
      "\n",
      "Start of epoch 314\n",
      "Training loss at epoch 314: 0.0374\n",
      "\n",
      "Start of epoch 315\n",
      "Training loss at epoch 315: 0.0374\n",
      "\n",
      "Start of epoch 316\n",
      "Training loss at epoch 316: 0.0374\n",
      "\n",
      "Start of epoch 317\n",
      "Training loss at epoch 317: 0.0374\n",
      "\n",
      "Start of epoch 318\n",
      "Training loss at epoch 318: 0.0374\n",
      "\n",
      "Start of epoch 319\n",
      "Training loss at epoch 319: 0.0374\n",
      "\n",
      "Start of epoch 320\n",
      "Training loss at epoch 320: 0.0374\n",
      "\n",
      "Start of epoch 321\n",
      "Training loss at epoch 321: 0.0374\n",
      "\n",
      "Start of epoch 322\n",
      "Training loss at epoch 322: 0.0374\n",
      "\n",
      "Start of epoch 323\n",
      "Training loss at epoch 323: 0.0374\n",
      "\n",
      "Start of epoch 324\n",
      "Training loss at epoch 324: 0.0374\n",
      "\n",
      "Start of epoch 325\n",
      "Training loss at epoch 325: 0.0374\n",
      "\n",
      "Start of epoch 326\n",
      "Training loss at epoch 326: 0.0374\n",
      "\n",
      "Start of epoch 327\n",
      "Training loss at epoch 327: 0.0374\n",
      "\n",
      "Start of epoch 328\n",
      "Training loss at epoch 328: 0.0374\n",
      "\n",
      "Start of epoch 329\n",
      "Training loss at epoch 329: 0.0374\n",
      "\n",
      "Start of epoch 330\n",
      "Training loss at epoch 330: 0.0374\n",
      "\n",
      "Start of epoch 331\n",
      "Training loss at epoch 331: 0.0374\n",
      "\n",
      "Start of epoch 332\n",
      "Training loss at epoch 332: 0.0374\n",
      "\n",
      "Start of epoch 333\n",
      "Training loss at epoch 333: 0.0374\n",
      "\n",
      "Start of epoch 334\n",
      "Training loss at epoch 334: 0.0374\n",
      "\n",
      "Start of epoch 335\n",
      "Training loss at epoch 335: 0.0374\n",
      "\n",
      "Start of epoch 336\n",
      "Training loss at epoch 336: 0.0374\n",
      "\n",
      "Start of epoch 337\n",
      "Training loss at epoch 337: 0.0374\n",
      "\n",
      "Start of epoch 338\n",
      "Training loss at epoch 338: 0.0374\n",
      "\n",
      "Start of epoch 339\n",
      "Training loss at epoch 339: 0.0374\n",
      "\n",
      "Start of epoch 340\n",
      "Training loss at epoch 340: 0.0374\n",
      "\n",
      "Start of epoch 341\n",
      "Training loss at epoch 341: 0.0374\n",
      "\n",
      "Start of epoch 342\n",
      "Training loss at epoch 342: 0.0374\n",
      "\n",
      "Start of epoch 343\n",
      "Training loss at epoch 343: 0.0374\n",
      "\n",
      "Start of epoch 344\n",
      "Training loss at epoch 344: 0.0374\n",
      "\n",
      "Start of epoch 345\n",
      "Training loss at epoch 345: 0.0374\n",
      "\n",
      "Start of epoch 346\n",
      "Training loss at epoch 346: 0.0374\n",
      "\n",
      "Start of epoch 347\n",
      "Training loss at epoch 347: 0.0374\n",
      "\n",
      "Start of epoch 348\n",
      "Training loss at epoch 348: 0.0374\n",
      "\n",
      "Start of epoch 349\n",
      "Training loss at epoch 349: 0.0374\n",
      "\n",
      "Start of epoch 350\n",
      "Training loss at epoch 350: 0.0374\n",
      "\n",
      "Start of epoch 351\n",
      "Training loss at epoch 351: 0.0374\n",
      "\n",
      "Start of epoch 352\n",
      "Training loss at epoch 352: 0.0374\n",
      "\n",
      "Start of epoch 353\n",
      "Training loss at epoch 353: 0.0374\n",
      "\n",
      "Start of epoch 354\n",
      "Training loss at epoch 354: 0.0374\n",
      "\n",
      "Start of epoch 355\n",
      "Training loss at epoch 355: 0.0374\n",
      "\n",
      "Start of epoch 356\n",
      "Training loss at epoch 356: 0.0374\n",
      "\n",
      "Start of epoch 357\n",
      "Training loss at epoch 357: 0.0374\n",
      "\n",
      "Start of epoch 358\n",
      "Training loss at epoch 358: 0.0374\n",
      "\n",
      "Start of epoch 359\n",
      "Training loss at epoch 359: 0.0374\n",
      "\n",
      "Start of epoch 360\n",
      "Training loss at epoch 360: 0.0374\n",
      "\n",
      "Start of epoch 361\n",
      "Training loss at epoch 361: 0.0374\n",
      "\n",
      "Start of epoch 362\n",
      "Training loss at epoch 362: 0.0374\n",
      "\n",
      "Start of epoch 363\n",
      "Training loss at epoch 363: 0.0374\n",
      "\n",
      "Start of epoch 364\n",
      "Training loss at epoch 364: 0.0374\n",
      "\n",
      "Start of epoch 365\n",
      "Training loss at epoch 365: 0.0374\n",
      "\n",
      "Start of epoch 366\n",
      "Training loss at epoch 366: 0.0374\n",
      "\n",
      "Start of epoch 367\n",
      "Training loss at epoch 367: 0.0374\n",
      "\n",
      "Start of epoch 368\n",
      "Training loss at epoch 368: 0.0374\n",
      "\n",
      "Start of epoch 369\n",
      "Training loss at epoch 369: 0.0374\n",
      "\n",
      "Start of epoch 370\n",
      "Training loss at epoch 370: 0.0374\n",
      "\n",
      "Start of epoch 371\n",
      "Training loss at epoch 371: 0.0374\n",
      "\n",
      "Start of epoch 372\n",
      "Training loss at epoch 372: 0.0374\n",
      "\n",
      "Start of epoch 373\n",
      "Training loss at epoch 373: 0.0374\n",
      "\n",
      "Start of epoch 374\n",
      "Training loss at epoch 374: 0.0374\n",
      "\n",
      "Start of epoch 375\n",
      "Training loss at epoch 375: 0.0374\n",
      "\n",
      "Start of epoch 376\n",
      "Training loss at epoch 376: 0.0374\n",
      "\n",
      "Start of epoch 377\n",
      "Training loss at epoch 377: 0.0374\n",
      "\n",
      "Start of epoch 378\n",
      "Training loss at epoch 378: 0.0374\n",
      "\n",
      "Start of epoch 379\n",
      "Training loss at epoch 379: 0.0374\n",
      "\n",
      "Start of epoch 380\n",
      "Training loss at epoch 380: 0.0374\n",
      "\n",
      "Start of epoch 381\n",
      "Training loss at epoch 381: 0.0374\n",
      "\n",
      "Start of epoch 382\n",
      "Training loss at epoch 382: 0.0374\n",
      "\n",
      "Start of epoch 383\n",
      "Training loss at epoch 383: 0.0374\n",
      "\n",
      "Start of epoch 384\n",
      "Training loss at epoch 384: 0.0374\n",
      "\n",
      "Start of epoch 385\n",
      "Training loss at epoch 385: 0.0374\n",
      "\n",
      "Start of epoch 386\n",
      "Training loss at epoch 386: 0.0374\n",
      "\n",
      "Start of epoch 387\n",
      "Training loss at epoch 387: 0.0374\n",
      "\n",
      "Start of epoch 388\n",
      "Training loss at epoch 388: 0.0374\n",
      "\n",
      "Start of epoch 389\n",
      "Training loss at epoch 389: 0.0374\n",
      "\n",
      "Start of epoch 390\n",
      "Training loss at epoch 390: 0.0374\n",
      "\n",
      "Start of epoch 391\n",
      "Training loss at epoch 391: 0.0374\n",
      "\n",
      "Start of epoch 392\n",
      "Training loss at epoch 392: 0.0374\n",
      "\n",
      "Start of epoch 393\n",
      "Training loss at epoch 393: 0.0374\n",
      "\n",
      "Start of epoch 394\n",
      "Training loss at epoch 394: 0.0374\n",
      "\n",
      "Start of epoch 395\n",
      "Training loss at epoch 395: 0.0374\n",
      "\n",
      "Start of epoch 396\n",
      "Training loss at epoch 396: 0.0374\n",
      "\n",
      "Start of epoch 397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 397: 0.0374\n",
      "\n",
      "Start of epoch 398\n",
      "Training loss at epoch 398: 0.0374\n",
      "\n",
      "Start of epoch 399\n",
      "Training loss at epoch 399: 0.0374\n",
      "\n",
      "Start of epoch 400\n",
      "Training loss at epoch 400: 0.0374\n",
      "\n",
      "Start of epoch 401\n",
      "Training loss at epoch 401: 0.0374\n",
      "\n",
      "Start of epoch 402\n",
      "Training loss at epoch 402: 0.0374\n",
      "\n",
      "Start of epoch 403\n",
      "Training loss at epoch 403: 0.0374\n",
      "\n",
      "Start of epoch 404\n",
      "Training loss at epoch 404: 0.0374\n",
      "\n",
      "Start of epoch 405\n",
      "Training loss at epoch 405: 0.0374\n",
      "\n",
      "Start of epoch 406\n",
      "Training loss at epoch 406: 0.0374\n",
      "\n",
      "Start of epoch 407\n",
      "Training loss at epoch 407: 0.0374\n",
      "\n",
      "Start of epoch 408\n",
      "Training loss at epoch 408: 0.0374\n",
      "\n",
      "Start of epoch 409\n",
      "Training loss at epoch 409: 0.0374\n",
      "\n",
      "Start of epoch 410\n",
      "Training loss at epoch 410: 0.0374\n",
      "\n",
      "Start of epoch 411\n",
      "Training loss at epoch 411: 0.0374\n",
      "\n",
      "Start of epoch 412\n",
      "Training loss at epoch 412: 0.0374\n",
      "\n",
      "Start of epoch 413\n",
      "Training loss at epoch 413: 0.0374\n",
      "\n",
      "Start of epoch 414\n",
      "Training loss at epoch 414: 0.0374\n",
      "\n",
      "Start of epoch 415\n",
      "Training loss at epoch 415: 0.0374\n",
      "\n",
      "Start of epoch 416\n",
      "Training loss at epoch 416: 0.0374\n",
      "\n",
      "Start of epoch 417\n",
      "Training loss at epoch 417: 0.0374\n",
      "\n",
      "Start of epoch 418\n",
      "Training loss at epoch 418: 0.0374\n",
      "\n",
      "Start of epoch 419\n",
      "Training loss at epoch 419: 0.0374\n",
      "\n",
      "Start of epoch 420\n",
      "Training loss at epoch 420: 0.0374\n",
      "\n",
      "Start of epoch 421\n",
      "Training loss at epoch 421: 0.0374\n",
      "\n",
      "Start of epoch 422\n",
      "Training loss at epoch 422: 0.0374\n",
      "\n",
      "Start of epoch 423\n",
      "Training loss at epoch 423: 0.0374\n",
      "\n",
      "Start of epoch 424\n",
      "Training loss at epoch 424: 0.0374\n",
      "\n",
      "Start of epoch 425\n",
      "Training loss at epoch 425: 0.0374\n",
      "\n",
      "Start of epoch 426\n",
      "Training loss at epoch 426: 0.0374\n",
      "\n",
      "Start of epoch 427\n",
      "Training loss at epoch 427: 0.0374\n",
      "\n",
      "Start of epoch 428\n",
      "Training loss at epoch 428: 0.0374\n",
      "\n",
      "Start of epoch 429\n",
      "Training loss at epoch 429: 0.0374\n",
      "\n",
      "Start of epoch 430\n",
      "Training loss at epoch 430: 0.0374\n",
      "\n",
      "Start of epoch 431\n",
      "Training loss at epoch 431: 0.0374\n",
      "\n",
      "Start of epoch 432\n",
      "Training loss at epoch 432: 0.0374\n",
      "\n",
      "Start of epoch 433\n",
      "Training loss at epoch 433: 0.0374\n",
      "\n",
      "Start of epoch 434\n",
      "Training loss at epoch 434: 0.0374\n",
      "\n",
      "Start of epoch 435\n",
      "Training loss at epoch 435: 0.0374\n",
      "\n",
      "Start of epoch 436\n",
      "Training loss at epoch 436: 0.0374\n",
      "\n",
      "Start of epoch 437\n",
      "Training loss at epoch 437: 0.0374\n",
      "\n",
      "Start of epoch 438\n",
      "Training loss at epoch 438: 0.0374\n",
      "\n",
      "Start of epoch 439\n",
      "Training loss at epoch 439: 0.0374\n",
      "\n",
      "Start of epoch 440\n",
      "Training loss at epoch 440: 0.0374\n",
      "\n",
      "Start of epoch 441\n",
      "Training loss at epoch 441: 0.0374\n",
      "\n",
      "Start of epoch 442\n",
      "Training loss at epoch 442: 0.0374\n",
      "\n",
      "Start of epoch 443\n",
      "Training loss at epoch 443: 0.0374\n",
      "\n",
      "Start of epoch 444\n",
      "Training loss at epoch 444: 0.0374\n",
      "\n",
      "Start of epoch 445\n",
      "Training loss at epoch 445: 0.0374\n",
      "\n",
      "Start of epoch 446\n",
      "Training loss at epoch 446: 0.0374\n",
      "\n",
      "Start of epoch 447\n",
      "Training loss at epoch 447: 0.0374\n",
      "\n",
      "Start of epoch 448\n",
      "Training loss at epoch 448: 0.0374\n",
      "\n",
      "Start of epoch 449\n",
      "Training loss at epoch 449: 0.0374\n",
      "\n",
      "Start of epoch 450\n",
      "Training loss at epoch 450: 0.0374\n",
      "\n",
      "Start of epoch 451\n",
      "Training loss at epoch 451: 0.0374\n",
      "\n",
      "Start of epoch 452\n",
      "Training loss at epoch 452: 0.0374\n",
      "\n",
      "Start of epoch 453\n",
      "Training loss at epoch 453: 0.0374\n",
      "\n",
      "Start of epoch 454\n",
      "Training loss at epoch 454: 0.0374\n",
      "\n",
      "Start of epoch 455\n",
      "Training loss at epoch 455: 0.0374\n",
      "\n",
      "Start of epoch 456\n",
      "Training loss at epoch 456: 0.0374\n",
      "\n",
      "Start of epoch 457\n",
      "Training loss at epoch 457: 0.0374\n",
      "\n",
      "Start of epoch 458\n",
      "Training loss at epoch 458: 0.0374\n",
      "\n",
      "Start of epoch 459\n",
      "Training loss at epoch 459: 0.0374\n",
      "\n",
      "Start of epoch 460\n",
      "Training loss at epoch 460: 0.0374\n",
      "\n",
      "Start of epoch 461\n",
      "Training loss at epoch 461: 0.0374\n",
      "\n",
      "Start of epoch 462\n",
      "Training loss at epoch 462: 0.0374\n",
      "\n",
      "Start of epoch 463\n",
      "Training loss at epoch 463: 0.0374\n",
      "\n",
      "Start of epoch 464\n",
      "Training loss at epoch 464: 0.0374\n",
      "\n",
      "Start of epoch 465\n",
      "Training loss at epoch 465: 0.0374\n",
      "\n",
      "Start of epoch 466\n",
      "Training loss at epoch 466: 0.0374\n",
      "\n",
      "Start of epoch 467\n",
      "Training loss at epoch 467: 0.0374\n",
      "\n",
      "Start of epoch 468\n",
      "Training loss at epoch 468: 0.0374\n",
      "\n",
      "Start of epoch 469\n",
      "Training loss at epoch 469: 0.0374\n",
      "\n",
      "Start of epoch 470\n",
      "Training loss at epoch 470: 0.0374\n",
      "\n",
      "Start of epoch 471\n",
      "Training loss at epoch 471: 0.0374\n",
      "\n",
      "Start of epoch 472\n",
      "Training loss at epoch 472: 0.0374\n",
      "\n",
      "Start of epoch 473\n",
      "Training loss at epoch 473: 0.0374\n",
      "\n",
      "Start of epoch 474\n",
      "Training loss at epoch 474: 0.0374\n",
      "\n",
      "Start of epoch 475\n",
      "Training loss at epoch 475: 0.0374\n",
      "\n",
      "Start of epoch 476\n",
      "Training loss at epoch 476: 0.0374\n",
      "\n",
      "Start of epoch 477\n",
      "Training loss at epoch 477: 0.0374\n",
      "\n",
      "Start of epoch 478\n",
      "Training loss at epoch 478: 0.0374\n",
      "\n",
      "Start of epoch 479\n",
      "Training loss at epoch 479: 0.0374\n",
      "\n",
      "Start of epoch 480\n",
      "Training loss at epoch 480: 0.0374\n",
      "\n",
      "Start of epoch 481\n",
      "Training loss at epoch 481: 0.0374\n",
      "\n",
      "Start of epoch 482\n",
      "Training loss at epoch 482: 0.0374\n",
      "\n",
      "Start of epoch 483\n",
      "Training loss at epoch 483: 0.0374\n",
      "\n",
      "Start of epoch 484\n",
      "Training loss at epoch 484: 0.0374\n",
      "\n",
      "Start of epoch 485\n",
      "Training loss at epoch 485: 0.0374\n",
      "\n",
      "Start of epoch 486\n",
      "Training loss at epoch 486: 0.0374\n",
      "\n",
      "Start of epoch 487\n",
      "Training loss at epoch 487: 0.0374\n",
      "\n",
      "Start of epoch 488\n",
      "Training loss at epoch 488: 0.0374\n",
      "\n",
      "Start of epoch 489\n",
      "Training loss at epoch 489: 0.0374\n",
      "\n",
      "Start of epoch 490\n",
      "Training loss at epoch 490: 0.0374\n",
      "\n",
      "Start of epoch 491\n",
      "Training loss at epoch 491: 0.0374\n",
      "\n",
      "Start of epoch 492\n",
      "Training loss at epoch 492: 0.0374\n",
      "\n",
      "Start of epoch 493\n",
      "Training loss at epoch 493: 0.0374\n",
      "\n",
      "Start of epoch 494\n",
      "Training loss at epoch 494: 0.0374\n",
      "\n",
      "Start of epoch 495\n",
      "Training loss at epoch 495: 0.0374\n",
      "\n",
      "Start of epoch 496\n",
      "Training loss at epoch 496: 0.0374\n",
      "\n",
      "Start of epoch 497\n",
      "Training loss at epoch 497: 0.0374\n",
      "\n",
      "Start of epoch 498\n",
      "Training loss at epoch 498: 0.0374\n",
      "\n",
      "Start of epoch 499\n",
      "Training loss at epoch 499: 0.0374\n",
      "[<tf.Variable 'parameters:0' shape=(30,) dtype=float32, numpy=\n",
      "array([1.5603094 , 0.4102275 , 3.5095916 , 3.8841796 , 2.908044  ,\n",
      "       2.2369988 , 5.1615233 , 0.70562667, 4.3535175 , 3.2686174 ,\n",
      "       3.7100937 , 0.6598769 , 5.6847224 , 4.4330025 , 2.4029944 ,\n",
      "       5.155067  , 2.2783277 , 1.8950692 , 3.5255733 , 3.6371129 ,\n",
      "       0.84379435, 1.5462242 , 0.6670285 , 4.773276  , 1.4150965 ,\n",
      "       3.5212193 , 0.72023845, 1.0364003 , 3.5747507 , 1.0950563 ],\n",
      "      dtype=float32)>]\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 0.8150\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 0.7573\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.7074\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.6679\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.6405\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.6247\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.6169\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.6129\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.6102\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.6075\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.6040\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.5994\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.5936\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.5872\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.5807\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.5746\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.5692\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.5646\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.5607\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.5575\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.5545\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.5517\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.5488\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.5455\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.5418\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.5375\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.5327\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.5276\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.5224\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.5174\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.5128\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.5086\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.5050\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.5018\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.4988\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.4961\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.4935\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.4911\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.4888\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.4866\n",
      "\n",
      "Start of epoch 40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 40: 0.4845\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.4824\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.4802\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.4780\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.4759\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.4737\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.4716\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.4695\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.4674\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.4651\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.4628\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.4604\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.4580\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.4554\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.4526\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.4497\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.4465\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.4433\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.4400\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.4365\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.4329\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.4293\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.4256\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.4219\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.4182\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.4145\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.4108\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.4071\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.4033\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.3995\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.3956\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.3918\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.3878\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.3838\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.3796\n",
      "\n",
      "Start of epoch 75\n",
      "Training loss at epoch 75: 0.3753\n",
      "\n",
      "Start of epoch 76\n",
      "Training loss at epoch 76: 0.3707\n",
      "\n",
      "Start of epoch 77\n",
      "Training loss at epoch 77: 0.3658\n",
      "\n",
      "Start of epoch 78\n",
      "Training loss at epoch 78: 0.3605\n",
      "\n",
      "Start of epoch 79\n",
      "Training loss at epoch 79: 0.3549\n",
      "\n",
      "Start of epoch 80\n",
      "Training loss at epoch 80: 0.3489\n",
      "\n",
      "Start of epoch 81\n",
      "Training loss at epoch 81: 0.3427\n",
      "\n",
      "Start of epoch 82\n",
      "Training loss at epoch 82: 0.3366\n",
      "\n",
      "Start of epoch 83\n",
      "Training loss at epoch 83: 0.3305\n",
      "\n",
      "Start of epoch 84\n",
      "Training loss at epoch 84: 0.3246\n",
      "\n",
      "Start of epoch 85\n",
      "Training loss at epoch 85: 0.3190\n",
      "\n",
      "Start of epoch 86\n",
      "Training loss at epoch 86: 0.3135\n",
      "\n",
      "Start of epoch 87\n",
      "Training loss at epoch 87: 0.3082\n",
      "\n",
      "Start of epoch 88\n",
      "Training loss at epoch 88: 0.3029\n",
      "\n",
      "Start of epoch 89\n",
      "Training loss at epoch 89: 0.2977\n",
      "\n",
      "Start of epoch 90\n",
      "Training loss at epoch 90: 0.2925\n",
      "\n",
      "Start of epoch 91\n",
      "Training loss at epoch 91: 0.2875\n",
      "\n",
      "Start of epoch 92\n",
      "Training loss at epoch 92: 0.2828\n",
      "\n",
      "Start of epoch 93\n",
      "Training loss at epoch 93: 0.2783\n",
      "\n",
      "Start of epoch 94\n",
      "Training loss at epoch 94: 0.2740\n",
      "\n",
      "Start of epoch 95\n",
      "Training loss at epoch 95: 0.2699\n",
      "\n",
      "Start of epoch 96\n",
      "Training loss at epoch 96: 0.2657\n",
      "\n",
      "Start of epoch 97\n",
      "Training loss at epoch 97: 0.2615\n",
      "\n",
      "Start of epoch 98\n",
      "Training loss at epoch 98: 0.2572\n",
      "\n",
      "Start of epoch 99\n",
      "Training loss at epoch 99: 0.2529\n",
      "\n",
      "Start of epoch 100\n",
      "Training loss at epoch 100: 0.2484\n",
      "\n",
      "Start of epoch 101\n",
      "Training loss at epoch 101: 0.2440\n",
      "\n",
      "Start of epoch 102\n",
      "Training loss at epoch 102: 0.2395\n",
      "\n",
      "Start of epoch 103\n",
      "Training loss at epoch 103: 0.2351\n",
      "\n",
      "Start of epoch 104\n",
      "Training loss at epoch 104: 0.2305\n",
      "\n",
      "Start of epoch 105\n",
      "Training loss at epoch 105: 0.2259\n",
      "\n",
      "Start of epoch 106\n",
      "Training loss at epoch 106: 0.2211\n",
      "\n",
      "Start of epoch 107\n",
      "Training loss at epoch 107: 0.2160\n",
      "\n",
      "Start of epoch 108\n",
      "Training loss at epoch 108: 0.2108\n",
      "\n",
      "Start of epoch 109\n",
      "Training loss at epoch 109: 0.2055\n",
      "\n",
      "Start of epoch 110\n",
      "Training loss at epoch 110: 0.2001\n",
      "\n",
      "Start of epoch 111\n",
      "Training loss at epoch 111: 0.1948\n",
      "\n",
      "Start of epoch 112\n",
      "Training loss at epoch 112: 0.1894\n",
      "\n",
      "Start of epoch 113\n",
      "Training loss at epoch 113: 0.1840\n",
      "\n",
      "Start of epoch 114\n",
      "Training loss at epoch 114: 0.1780\n",
      "\n",
      "Start of epoch 115\n",
      "Training loss at epoch 115: 0.1714\n",
      "\n",
      "Start of epoch 116\n",
      "Training loss at epoch 116: 0.1638\n",
      "\n",
      "Start of epoch 117\n",
      "Training loss at epoch 117: 0.1550\n",
      "\n",
      "Start of epoch 118\n",
      "Training loss at epoch 118: 0.1451\n",
      "\n",
      "Start of epoch 119\n",
      "Training loss at epoch 119: 0.1339\n",
      "\n",
      "Start of epoch 120\n",
      "Training loss at epoch 120: 0.1216\n",
      "\n",
      "Start of epoch 121\n",
      "Training loss at epoch 121: 0.1086\n",
      "\n",
      "Start of epoch 122\n",
      "Training loss at epoch 122: 0.0958\n",
      "\n",
      "Start of epoch 123\n",
      "Training loss at epoch 123: 0.0842\n",
      "\n",
      "Start of epoch 124\n",
      "Training loss at epoch 124: 0.0749\n",
      "\n",
      "Start of epoch 125\n",
      "Training loss at epoch 125: 0.0685\n",
      "\n",
      "Start of epoch 126\n",
      "Training loss at epoch 126: 0.0652\n",
      "\n",
      "Start of epoch 127\n",
      "Training loss at epoch 127: 0.0646\n",
      "\n",
      "Start of epoch 128\n",
      "Training loss at epoch 128: 0.0653\n",
      "\n",
      "Start of epoch 129\n",
      "Training loss at epoch 129: 0.0655\n",
      "\n",
      "Start of epoch 130\n",
      "Training loss at epoch 130: 0.0640\n",
      "\n",
      "Start of epoch 131\n",
      "Training loss at epoch 131: 0.0607\n",
      "\n",
      "Start of epoch 132\n",
      "Training loss at epoch 132: 0.0562\n",
      "\n",
      "Start of epoch 133\n",
      "Training loss at epoch 133: 0.0513\n",
      "\n",
      "Start of epoch 134\n",
      "Training loss at epoch 134: 0.0470\n",
      "\n",
      "Start of epoch 135\n",
      "Training loss at epoch 135: 0.0436\n",
      "\n",
      "Start of epoch 136\n",
      "Training loss at epoch 136: 0.0410\n",
      "\n",
      "Start of epoch 137\n",
      "Training loss at epoch 137: 0.0390\n",
      "\n",
      "Start of epoch 138\n",
      "Training loss at epoch 138: 0.0371\n",
      "\n",
      "Start of epoch 139\n",
      "Training loss at epoch 139: 0.0352\n",
      "\n",
      "Start of epoch 140\n",
      "Training loss at epoch 140: 0.0331\n",
      "\n",
      "Start of epoch 141\n",
      "Training loss at epoch 141: 0.0312\n",
      "\n",
      "Start of epoch 142\n",
      "Training loss at epoch 142: 0.0296\n",
      "\n",
      "Start of epoch 143\n",
      "Training loss at epoch 143: 0.0286\n",
      "\n",
      "Start of epoch 144\n",
      "Training loss at epoch 144: 0.0282\n",
      "\n",
      "Start of epoch 145\n",
      "Training loss at epoch 145: 0.0282\n",
      "\n",
      "Start of epoch 146\n",
      "Training loss at epoch 146: 0.0284\n",
      "\n",
      "Start of epoch 147\n",
      "Training loss at epoch 147: 0.0286\n",
      "\n",
      "Start of epoch 148\n",
      "Training loss at epoch 148: 0.0285\n",
      "\n",
      "Start of epoch 149\n",
      "Training loss at epoch 149: 0.0283\n",
      "\n",
      "Start of epoch 150\n",
      "Training loss at epoch 150: 0.0279\n",
      "\n",
      "Start of epoch 151\n",
      "Training loss at epoch 151: 0.0274\n",
      "\n",
      "Start of epoch 152\n",
      "Training loss at epoch 152: 0.0270\n",
      "\n",
      "Start of epoch 153\n",
      "Training loss at epoch 153: 0.0267\n",
      "\n",
      "Start of epoch 154\n",
      "Training loss at epoch 154: 0.0264\n",
      "\n",
      "Start of epoch 155\n",
      "Training loss at epoch 155: 0.0263\n",
      "\n",
      "Start of epoch 156\n",
      "Training loss at epoch 156: 0.0261\n",
      "\n",
      "Start of epoch 157\n",
      "Training loss at epoch 157: 0.0259\n",
      "\n",
      "Start of epoch 158\n",
      "Training loss at epoch 158: 0.0257\n",
      "\n",
      "Start of epoch 159\n",
      "Training loss at epoch 159: 0.0256\n",
      "\n",
      "Start of epoch 160\n",
      "Training loss at epoch 160: 0.0254\n",
      "\n",
      "Start of epoch 161\n",
      "Training loss at epoch 161: 0.0253\n",
      "\n",
      "Start of epoch 162\n",
      "Training loss at epoch 162: 0.0252\n",
      "\n",
      "Start of epoch 163\n",
      "Training loss at epoch 163: 0.0252\n",
      "\n",
      "Start of epoch 164\n",
      "Training loss at epoch 164: 0.0251\n",
      "\n",
      "Start of epoch 165\n",
      "Training loss at epoch 165: 0.0251\n",
      "\n",
      "Start of epoch 166\n",
      "Training loss at epoch 166: 0.0251\n",
      "\n",
      "Start of epoch 167\n",
      "Training loss at epoch 167: 0.0250\n",
      "\n",
      "Start of epoch 168\n",
      "Training loss at epoch 168: 0.0249\n",
      "\n",
      "Start of epoch 169\n",
      "Training loss at epoch 169: 0.0248\n",
      "\n",
      "Start of epoch 170\n",
      "Training loss at epoch 170: 0.0246\n",
      "\n",
      "Start of epoch 171\n",
      "Training loss at epoch 171: 0.0245\n",
      "\n",
      "Start of epoch 172\n",
      "Training loss at epoch 172: 0.0244\n",
      "\n",
      "Start of epoch 173\n",
      "Training loss at epoch 173: 0.0243\n",
      "\n",
      "Start of epoch 174\n",
      "Training loss at epoch 174: 0.0242\n",
      "\n",
      "Start of epoch 175\n",
      "Training loss at epoch 175: 0.0242\n",
      "\n",
      "Start of epoch 176\n",
      "Training loss at epoch 176: 0.0241\n",
      "\n",
      "Start of epoch 177\n",
      "Training loss at epoch 177: 0.0240\n",
      "\n",
      "Start of epoch 178\n",
      "Training loss at epoch 178: 0.0240\n",
      "\n",
      "Start of epoch 179\n",
      "Training loss at epoch 179: 0.0240\n",
      "\n",
      "Start of epoch 180\n",
      "Training loss at epoch 180: 0.0239\n",
      "\n",
      "Start of epoch 181\n",
      "Training loss at epoch 181: 0.0239\n",
      "\n",
      "Start of epoch 182\n",
      "Training loss at epoch 182: 0.0239\n",
      "\n",
      "Start of epoch 183\n",
      "Training loss at epoch 183: 0.0239\n",
      "\n",
      "Start of epoch 184\n",
      "Training loss at epoch 184: 0.0238\n",
      "\n",
      "Start of epoch 185\n",
      "Training loss at epoch 185: 0.0238\n",
      "\n",
      "Start of epoch 186\n",
      "Training loss at epoch 186: 0.0238\n",
      "\n",
      "Start of epoch 187\n",
      "Training loss at epoch 187: 0.0238\n",
      "\n",
      "Start of epoch 188\n",
      "Training loss at epoch 188: 0.0238\n",
      "\n",
      "Start of epoch 189\n",
      "Training loss at epoch 189: 0.0238\n",
      "\n",
      "Start of epoch 190\n",
      "Training loss at epoch 190: 0.0237\n",
      "\n",
      "Start of epoch 191\n",
      "Training loss at epoch 191: 0.0237\n",
      "\n",
      "Start of epoch 192\n",
      "Training loss at epoch 192: 0.0237\n",
      "\n",
      "Start of epoch 193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 193: 0.0237\n",
      "\n",
      "Start of epoch 194\n",
      "Training loss at epoch 194: 0.0237\n",
      "\n",
      "Start of epoch 195\n",
      "Training loss at epoch 195: 0.0237\n",
      "\n",
      "Start of epoch 196\n",
      "Training loss at epoch 196: 0.0236\n",
      "\n",
      "Start of epoch 197\n",
      "Training loss at epoch 197: 0.0236\n",
      "\n",
      "Start of epoch 198\n",
      "Training loss at epoch 198: 0.0236\n",
      "\n",
      "Start of epoch 199\n",
      "Training loss at epoch 199: 0.0236\n",
      "\n",
      "Start of epoch 200\n",
      "Training loss at epoch 200: 0.0236\n",
      "\n",
      "Start of epoch 201\n",
      "Training loss at epoch 201: 0.0236\n",
      "\n",
      "Start of epoch 202\n",
      "Training loss at epoch 202: 0.0236\n",
      "\n",
      "Start of epoch 203\n",
      "Training loss at epoch 203: 0.0236\n",
      "\n",
      "Start of epoch 204\n",
      "Training loss at epoch 204: 0.0236\n",
      "\n",
      "Start of epoch 205\n",
      "Training loss at epoch 205: 0.0236\n",
      "\n",
      "Start of epoch 206\n",
      "Training loss at epoch 206: 0.0235\n",
      "\n",
      "Start of epoch 207\n",
      "Training loss at epoch 207: 0.0235\n",
      "\n",
      "Start of epoch 208\n",
      "Training loss at epoch 208: 0.0235\n",
      "\n",
      "Start of epoch 209\n",
      "Training loss at epoch 209: 0.0235\n",
      "\n",
      "Start of epoch 210\n",
      "Training loss at epoch 210: 0.0235\n",
      "\n",
      "Start of epoch 211\n",
      "Training loss at epoch 211: 0.0235\n",
      "\n",
      "Start of epoch 212\n",
      "Training loss at epoch 212: 0.0235\n",
      "\n",
      "Start of epoch 213\n",
      "Training loss at epoch 213: 0.0235\n",
      "\n",
      "Start of epoch 214\n",
      "Training loss at epoch 214: 0.0235\n",
      "\n",
      "Start of epoch 215\n",
      "Training loss at epoch 215: 0.0235\n",
      "\n",
      "Start of epoch 216\n",
      "Training loss at epoch 216: 0.0235\n",
      "\n",
      "Start of epoch 217\n",
      "Training loss at epoch 217: 0.0235\n",
      "\n",
      "Start of epoch 218\n",
      "Training loss at epoch 218: 0.0235\n",
      "\n",
      "Start of epoch 219\n",
      "Training loss at epoch 219: 0.0235\n",
      "\n",
      "Start of epoch 220\n",
      "Training loss at epoch 220: 0.0235\n",
      "\n",
      "Start of epoch 221\n",
      "Training loss at epoch 221: 0.0235\n",
      "\n",
      "Start of epoch 222\n",
      "Training loss at epoch 222: 0.0235\n",
      "\n",
      "Start of epoch 223\n",
      "Training loss at epoch 223: 0.0235\n",
      "\n",
      "Start of epoch 224\n",
      "Training loss at epoch 224: 0.0235\n",
      "\n",
      "Start of epoch 225\n",
      "Training loss at epoch 225: 0.0235\n",
      "\n",
      "Start of epoch 226\n",
      "Training loss at epoch 226: 0.0234\n",
      "\n",
      "Start of epoch 227\n",
      "Training loss at epoch 227: 0.0234\n",
      "\n",
      "Start of epoch 228\n",
      "Training loss at epoch 228: 0.0234\n",
      "\n",
      "Start of epoch 229\n",
      "Training loss at epoch 229: 0.0234\n",
      "\n",
      "Start of epoch 230\n",
      "Training loss at epoch 230: 0.0234\n",
      "\n",
      "Start of epoch 231\n",
      "Training loss at epoch 231: 0.0234\n",
      "\n",
      "Start of epoch 232\n",
      "Training loss at epoch 232: 0.0234\n",
      "\n",
      "Start of epoch 233\n",
      "Training loss at epoch 233: 0.0234\n",
      "\n",
      "Start of epoch 234\n",
      "Training loss at epoch 234: 0.0234\n",
      "\n",
      "Start of epoch 235\n",
      "Training loss at epoch 235: 0.0234\n",
      "\n",
      "Start of epoch 236\n",
      "Training loss at epoch 236: 0.0234\n",
      "\n",
      "Start of epoch 237\n",
      "Training loss at epoch 237: 0.0234\n",
      "\n",
      "Start of epoch 238\n",
      "Training loss at epoch 238: 0.0234\n",
      "\n",
      "Start of epoch 239\n",
      "Training loss at epoch 239: 0.0234\n",
      "\n",
      "Start of epoch 240\n",
      "Training loss at epoch 240: 0.0234\n",
      "\n",
      "Start of epoch 241\n",
      "Training loss at epoch 241: 0.0234\n",
      "\n",
      "Start of epoch 242\n",
      "Training loss at epoch 242: 0.0234\n",
      "\n",
      "Start of epoch 243\n",
      "Training loss at epoch 243: 0.0234\n",
      "\n",
      "Start of epoch 244\n",
      "Training loss at epoch 244: 0.0234\n",
      "\n",
      "Start of epoch 245\n",
      "Training loss at epoch 245: 0.0234\n",
      "\n",
      "Start of epoch 246\n",
      "Training loss at epoch 246: 0.0234\n",
      "\n",
      "Start of epoch 247\n",
      "Training loss at epoch 247: 0.0234\n",
      "\n",
      "Start of epoch 248\n",
      "Training loss at epoch 248: 0.0234\n",
      "\n",
      "Start of epoch 249\n",
      "Training loss at epoch 249: 0.0234\n",
      "\n",
      "Start of epoch 250\n",
      "Training loss at epoch 250: 0.0234\n",
      "\n",
      "Start of epoch 251\n",
      "Training loss at epoch 251: 0.0234\n",
      "\n",
      "Start of epoch 252\n",
      "Training loss at epoch 252: 0.0234\n",
      "\n",
      "Start of epoch 253\n",
      "Training loss at epoch 253: 0.0234\n",
      "\n",
      "Start of epoch 254\n",
      "Training loss at epoch 254: 0.0234\n",
      "\n",
      "Start of epoch 255\n",
      "Training loss at epoch 255: 0.0234\n",
      "\n",
      "Start of epoch 256\n",
      "Training loss at epoch 256: 0.0234\n",
      "\n",
      "Start of epoch 257\n",
      "Training loss at epoch 257: 0.0234\n",
      "\n",
      "Start of epoch 258\n",
      "Training loss at epoch 258: 0.0234\n",
      "\n",
      "Start of epoch 259\n",
      "Training loss at epoch 259: 0.0234\n",
      "\n",
      "Start of epoch 260\n",
      "Training loss at epoch 260: 0.0234\n",
      "\n",
      "Start of epoch 261\n",
      "Training loss at epoch 261: 0.0234\n",
      "\n",
      "Start of epoch 262\n",
      "Training loss at epoch 262: 0.0234\n",
      "\n",
      "Start of epoch 263\n",
      "Training loss at epoch 263: 0.0234\n",
      "\n",
      "Start of epoch 264\n",
      "Training loss at epoch 264: 0.0234\n",
      "\n",
      "Start of epoch 265\n",
      "Training loss at epoch 265: 0.0234\n",
      "\n",
      "Start of epoch 266\n",
      "Training loss at epoch 266: 0.0234\n",
      "\n",
      "Start of epoch 267\n",
      "Training loss at epoch 267: 0.0234\n",
      "\n",
      "Start of epoch 268\n",
      "Training loss at epoch 268: 0.0234\n",
      "\n",
      "Start of epoch 269\n",
      "Training loss at epoch 269: 0.0234\n",
      "\n",
      "Start of epoch 270\n",
      "Training loss at epoch 270: 0.0234\n",
      "\n",
      "Start of epoch 271\n",
      "Training loss at epoch 271: 0.0234\n",
      "\n",
      "Start of epoch 272\n",
      "Training loss at epoch 272: 0.0234\n",
      "\n",
      "Start of epoch 273\n",
      "Training loss at epoch 273: 0.0234\n",
      "\n",
      "Start of epoch 274\n",
      "Training loss at epoch 274: 0.0234\n",
      "\n",
      "Start of epoch 275\n",
      "Training loss at epoch 275: 0.0234\n",
      "\n",
      "Start of epoch 276\n",
      "Training loss at epoch 276: 0.0234\n",
      "\n",
      "Start of epoch 277\n",
      "Training loss at epoch 277: 0.0234\n",
      "\n",
      "Start of epoch 278\n",
      "Training loss at epoch 278: 0.0234\n",
      "\n",
      "Start of epoch 279\n",
      "Training loss at epoch 279: 0.0234\n",
      "\n",
      "Start of epoch 280\n",
      "Training loss at epoch 280: 0.0234\n",
      "\n",
      "Start of epoch 281\n",
      "Training loss at epoch 281: 0.0234\n",
      "\n",
      "Start of epoch 282\n",
      "Training loss at epoch 282: 0.0234\n",
      "\n",
      "Start of epoch 283\n",
      "Training loss at epoch 283: 0.0234\n",
      "\n",
      "Start of epoch 284\n",
      "Training loss at epoch 284: 0.0234\n",
      "\n",
      "Start of epoch 285\n",
      "Training loss at epoch 285: 0.0234\n",
      "\n",
      "Start of epoch 286\n",
      "Training loss at epoch 286: 0.0234\n",
      "\n",
      "Start of epoch 287\n",
      "Training loss at epoch 287: 0.0234\n",
      "\n",
      "Start of epoch 288\n",
      "Training loss at epoch 288: 0.0234\n",
      "\n",
      "Start of epoch 289\n",
      "Training loss at epoch 289: 0.0234\n",
      "\n",
      "Start of epoch 290\n",
      "Training loss at epoch 290: 0.0234\n",
      "\n",
      "Start of epoch 291\n",
      "Training loss at epoch 291: 0.0234\n",
      "\n",
      "Start of epoch 292\n",
      "Training loss at epoch 292: 0.0234\n",
      "\n",
      "Start of epoch 293\n",
      "Training loss at epoch 293: 0.0234\n",
      "\n",
      "Start of epoch 294\n",
      "Training loss at epoch 294: 0.0234\n",
      "\n",
      "Start of epoch 295\n",
      "Training loss at epoch 295: 0.0234\n",
      "\n",
      "Start of epoch 296\n",
      "Training loss at epoch 296: 0.0234\n",
      "\n",
      "Start of epoch 297\n",
      "Training loss at epoch 297: 0.0234\n",
      "\n",
      "Start of epoch 298\n",
      "Training loss at epoch 298: 0.0234\n",
      "\n",
      "Start of epoch 299\n",
      "Training loss at epoch 299: 0.0234\n",
      "\n",
      "Start of epoch 300\n",
      "Training loss at epoch 300: 0.0234\n",
      "\n",
      "Start of epoch 301\n",
      "Training loss at epoch 301: 0.0234\n",
      "\n",
      "Start of epoch 302\n",
      "Training loss at epoch 302: 0.0234\n",
      "\n",
      "Start of epoch 303\n",
      "Training loss at epoch 303: 0.0234\n",
      "\n",
      "Start of epoch 304\n",
      "Training loss at epoch 304: 0.0234\n",
      "\n",
      "Start of epoch 305\n",
      "Training loss at epoch 305: 0.0234\n",
      "\n",
      "Start of epoch 306\n",
      "Training loss at epoch 306: 0.0234\n",
      "\n",
      "Start of epoch 307\n",
      "Training loss at epoch 307: 0.0234\n",
      "\n",
      "Start of epoch 308\n",
      "Training loss at epoch 308: 0.0234\n",
      "\n",
      "Start of epoch 309\n",
      "Training loss at epoch 309: 0.0234\n",
      "\n",
      "Start of epoch 310\n",
      "Training loss at epoch 310: 0.0234\n",
      "\n",
      "Start of epoch 311\n",
      "Training loss at epoch 311: 0.0234\n",
      "\n",
      "Start of epoch 312\n",
      "Training loss at epoch 312: 0.0234\n",
      "\n",
      "Start of epoch 313\n",
      "Training loss at epoch 313: 0.0234\n",
      "\n",
      "Start of epoch 314\n",
      "Training loss at epoch 314: 0.0234\n",
      "\n",
      "Start of epoch 315\n",
      "Training loss at epoch 315: 0.0234\n",
      "\n",
      "Start of epoch 316\n",
      "Training loss at epoch 316: 0.0234\n",
      "\n",
      "Start of epoch 317\n",
      "Training loss at epoch 317: 0.0234\n",
      "\n",
      "Start of epoch 318\n",
      "Training loss at epoch 318: 0.0234\n",
      "\n",
      "Start of epoch 319\n",
      "Training loss at epoch 319: 0.0234\n",
      "\n",
      "Start of epoch 320\n",
      "Training loss at epoch 320: 0.0234\n",
      "\n",
      "Start of epoch 321\n",
      "Training loss at epoch 321: 0.0234\n",
      "\n",
      "Start of epoch 322\n",
      "Training loss at epoch 322: 0.0234\n",
      "\n",
      "Start of epoch 323\n",
      "Training loss at epoch 323: 0.0234\n",
      "\n",
      "Start of epoch 324\n",
      "Training loss at epoch 324: 0.0234\n",
      "\n",
      "Start of epoch 325\n",
      "Training loss at epoch 325: 0.0234\n",
      "\n",
      "Start of epoch 326\n",
      "Training loss at epoch 326: 0.0234\n",
      "\n",
      "Start of epoch 327\n",
      "Training loss at epoch 327: 0.0234\n",
      "\n",
      "Start of epoch 328\n",
      "Training loss at epoch 328: 0.0234\n",
      "\n",
      "Start of epoch 329\n",
      "Training loss at epoch 329: 0.0234\n",
      "\n",
      "Start of epoch 330\n",
      "Training loss at epoch 330: 0.0234\n",
      "\n",
      "Start of epoch 331\n",
      "Training loss at epoch 331: 0.0234\n",
      "\n",
      "Start of epoch 332\n",
      "Training loss at epoch 332: 0.0234\n",
      "\n",
      "Start of epoch 333\n",
      "Training loss at epoch 333: 0.0234\n",
      "\n",
      "Start of epoch 334\n",
      "Training loss at epoch 334: 0.0234\n",
      "\n",
      "Start of epoch 335\n",
      "Training loss at epoch 335: 0.0234\n",
      "\n",
      "Start of epoch 336\n",
      "Training loss at epoch 336: 0.0234\n",
      "\n",
      "Start of epoch 337\n",
      "Training loss at epoch 337: 0.0234\n",
      "\n",
      "Start of epoch 338\n",
      "Training loss at epoch 338: 0.0234\n",
      "\n",
      "Start of epoch 339\n",
      "Training loss at epoch 339: 0.0234\n",
      "\n",
      "Start of epoch 340\n",
      "Training loss at epoch 340: 0.0234\n",
      "\n",
      "Start of epoch 341\n",
      "Training loss at epoch 341: 0.0234\n",
      "\n",
      "Start of epoch 342\n",
      "Training loss at epoch 342: 0.0234\n",
      "\n",
      "Start of epoch 343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 343: 0.0234\n",
      "\n",
      "Start of epoch 344\n",
      "Training loss at epoch 344: 0.0234\n",
      "\n",
      "Start of epoch 345\n",
      "Training loss at epoch 345: 0.0234\n",
      "\n",
      "Start of epoch 346\n",
      "Training loss at epoch 346: 0.0234\n",
      "\n",
      "Start of epoch 347\n",
      "Training loss at epoch 347: 0.0234\n",
      "\n",
      "Start of epoch 348\n",
      "Training loss at epoch 348: 0.0234\n",
      "\n",
      "Start of epoch 349\n",
      "Training loss at epoch 349: 0.0234\n",
      "\n",
      "Start of epoch 350\n",
      "Training loss at epoch 350: 0.0234\n",
      "\n",
      "Start of epoch 351\n",
      "Training loss at epoch 351: 0.0234\n",
      "\n",
      "Start of epoch 352\n",
      "Training loss at epoch 352: 0.0234\n",
      "\n",
      "Start of epoch 353\n",
      "Training loss at epoch 353: 0.0234\n",
      "\n",
      "Start of epoch 354\n",
      "Training loss at epoch 354: 0.0234\n",
      "\n",
      "Start of epoch 355\n",
      "Training loss at epoch 355: 0.0234\n",
      "\n",
      "Start of epoch 356\n",
      "Training loss at epoch 356: 0.0234\n",
      "\n",
      "Start of epoch 357\n",
      "Training loss at epoch 357: 0.0234\n",
      "\n",
      "Start of epoch 358\n",
      "Training loss at epoch 358: 0.0234\n",
      "\n",
      "Start of epoch 359\n",
      "Training loss at epoch 359: 0.0234\n",
      "\n",
      "Start of epoch 360\n",
      "Training loss at epoch 360: 0.0234\n",
      "\n",
      "Start of epoch 361\n",
      "Training loss at epoch 361: 0.0234\n",
      "\n",
      "Start of epoch 362\n",
      "Training loss at epoch 362: 0.0234\n",
      "\n",
      "Start of epoch 363\n",
      "Training loss at epoch 363: 0.0234\n",
      "\n",
      "Start of epoch 364\n",
      "Training loss at epoch 364: 0.0234\n",
      "\n",
      "Start of epoch 365\n",
      "Training loss at epoch 365: 0.0234\n",
      "\n",
      "Start of epoch 366\n",
      "Training loss at epoch 366: 0.0234\n",
      "\n",
      "Start of epoch 367\n",
      "Training loss at epoch 367: 0.0234\n",
      "\n",
      "Start of epoch 368\n",
      "Training loss at epoch 368: 0.0234\n",
      "\n",
      "Start of epoch 369\n",
      "Training loss at epoch 369: 0.0234\n",
      "\n",
      "Start of epoch 370\n",
      "Training loss at epoch 370: 0.0234\n",
      "\n",
      "Start of epoch 371\n",
      "Training loss at epoch 371: 0.0234\n",
      "\n",
      "Start of epoch 372\n",
      "Training loss at epoch 372: 0.0234\n",
      "\n",
      "Start of epoch 373\n",
      "Training loss at epoch 373: 0.0234\n",
      "\n",
      "Start of epoch 374\n",
      "Training loss at epoch 374: 0.0234\n",
      "\n",
      "Start of epoch 375\n",
      "Training loss at epoch 375: 0.0234\n",
      "\n",
      "Start of epoch 376\n",
      "Training loss at epoch 376: 0.0234\n",
      "\n",
      "Start of epoch 377\n",
      "Training loss at epoch 377: 0.0234\n",
      "\n",
      "Start of epoch 378\n",
      "Training loss at epoch 378: 0.0234\n",
      "\n",
      "Start of epoch 379\n",
      "Training loss at epoch 379: 0.0234\n",
      "\n",
      "Start of epoch 380\n",
      "Training loss at epoch 380: 0.0234\n",
      "\n",
      "Start of epoch 381\n",
      "Training loss at epoch 381: 0.0234\n",
      "\n",
      "Start of epoch 382\n",
      "Training loss at epoch 382: 0.0234\n",
      "\n",
      "Start of epoch 383\n",
      "Training loss at epoch 383: 0.0234\n",
      "\n",
      "Start of epoch 384\n",
      "Training loss at epoch 384: 0.0234\n",
      "\n",
      "Start of epoch 385\n",
      "Training loss at epoch 385: 0.0234\n",
      "\n",
      "Start of epoch 386\n",
      "Training loss at epoch 386: 0.0234\n",
      "\n",
      "Start of epoch 387\n",
      "Training loss at epoch 387: 0.0234\n",
      "\n",
      "Start of epoch 388\n",
      "Training loss at epoch 388: 0.0234\n",
      "\n",
      "Start of epoch 389\n",
      "Training loss at epoch 389: 0.0234\n",
      "\n",
      "Start of epoch 390\n",
      "Training loss at epoch 390: 0.0234\n",
      "\n",
      "Start of epoch 391\n",
      "Training loss at epoch 391: 0.0234\n",
      "\n",
      "Start of epoch 392\n",
      "Training loss at epoch 392: 0.0234\n",
      "\n",
      "Start of epoch 393\n",
      "Training loss at epoch 393: 0.0234\n",
      "\n",
      "Start of epoch 394\n",
      "Training loss at epoch 394: 0.0234\n",
      "\n",
      "Start of epoch 395\n",
      "Training loss at epoch 395: 0.0234\n",
      "\n",
      "Start of epoch 396\n",
      "Training loss at epoch 396: 0.0234\n",
      "\n",
      "Start of epoch 397\n",
      "Training loss at epoch 397: 0.0234\n",
      "\n",
      "Start of epoch 398\n",
      "Training loss at epoch 398: 0.0234\n",
      "\n",
      "Start of epoch 399\n",
      "Training loss at epoch 399: 0.0234\n",
      "\n",
      "Start of epoch 400\n",
      "Training loss at epoch 400: 0.0234\n",
      "\n",
      "Start of epoch 401\n",
      "Training loss at epoch 401: 0.0234\n",
      "\n",
      "Start of epoch 402\n",
      "Training loss at epoch 402: 0.0234\n",
      "\n",
      "Start of epoch 403\n",
      "Training loss at epoch 403: 0.0234\n",
      "\n",
      "Start of epoch 404\n",
      "Training loss at epoch 404: 0.0234\n",
      "\n",
      "Start of epoch 405\n",
      "Training loss at epoch 405: 0.0234\n",
      "\n",
      "Start of epoch 406\n",
      "Training loss at epoch 406: 0.0234\n",
      "\n",
      "Start of epoch 407\n",
      "Training loss at epoch 407: 0.0234\n",
      "\n",
      "Start of epoch 408\n",
      "Training loss at epoch 408: 0.0234\n",
      "\n",
      "Start of epoch 409\n",
      "Training loss at epoch 409: 0.0234\n",
      "\n",
      "Start of epoch 410\n",
      "Training loss at epoch 410: 0.0234\n",
      "\n",
      "Start of epoch 411\n",
      "Training loss at epoch 411: 0.0234\n",
      "\n",
      "Start of epoch 412\n",
      "Training loss at epoch 412: 0.0234\n",
      "\n",
      "Start of epoch 413\n",
      "Training loss at epoch 413: 0.0234\n",
      "\n",
      "Start of epoch 414\n",
      "Training loss at epoch 414: 0.0234\n",
      "\n",
      "Start of epoch 415\n",
      "Training loss at epoch 415: 0.0234\n",
      "\n",
      "Start of epoch 416\n",
      "Training loss at epoch 416: 0.0234\n",
      "\n",
      "Start of epoch 417\n",
      "Training loss at epoch 417: 0.0234\n",
      "\n",
      "Start of epoch 418\n",
      "Training loss at epoch 418: 0.0234\n",
      "\n",
      "Start of epoch 419\n",
      "Training loss at epoch 419: 0.0234\n",
      "\n",
      "Start of epoch 420\n",
      "Training loss at epoch 420: 0.0234\n",
      "\n",
      "Start of epoch 421\n",
      "Training loss at epoch 421: 0.0234\n",
      "\n",
      "Start of epoch 422\n",
      "Training loss at epoch 422: 0.0234\n",
      "\n",
      "Start of epoch 423\n",
      "Training loss at epoch 423: 0.0234\n",
      "\n",
      "Start of epoch 424\n",
      "Training loss at epoch 424: 0.0234\n",
      "\n",
      "Start of epoch 425\n",
      "Training loss at epoch 425: 0.0234\n",
      "\n",
      "Start of epoch 426\n",
      "Training loss at epoch 426: 0.0234\n",
      "\n",
      "Start of epoch 427\n",
      "Training loss at epoch 427: 0.0234\n",
      "\n",
      "Start of epoch 428\n",
      "Training loss at epoch 428: 0.0234\n",
      "\n",
      "Start of epoch 429\n",
      "Training loss at epoch 429: 0.0234\n",
      "\n",
      "Start of epoch 430\n",
      "Training loss at epoch 430: 0.0234\n",
      "\n",
      "Start of epoch 431\n",
      "Training loss at epoch 431: 0.0234\n",
      "\n",
      "Start of epoch 432\n",
      "Training loss at epoch 432: 0.0234\n",
      "\n",
      "Start of epoch 433\n",
      "Training loss at epoch 433: 0.0234\n",
      "\n",
      "Start of epoch 434\n",
      "Training loss at epoch 434: 0.0234\n",
      "\n",
      "Start of epoch 435\n",
      "Training loss at epoch 435: 0.0234\n",
      "\n",
      "Start of epoch 436\n",
      "Training loss at epoch 436: 0.0234\n",
      "\n",
      "Start of epoch 437\n",
      "Training loss at epoch 437: 0.0234\n",
      "\n",
      "Start of epoch 438\n",
      "Training loss at epoch 438: 0.0234\n",
      "\n",
      "Start of epoch 439\n",
      "Training loss at epoch 439: 0.0234\n",
      "\n",
      "Start of epoch 440\n",
      "Training loss at epoch 440: 0.0234\n",
      "\n",
      "Start of epoch 441\n",
      "Training loss at epoch 441: 0.0234\n",
      "\n",
      "Start of epoch 442\n",
      "Training loss at epoch 442: 0.0234\n",
      "\n",
      "Start of epoch 443\n",
      "Training loss at epoch 443: 0.0234\n",
      "\n",
      "Start of epoch 444\n",
      "Training loss at epoch 444: 0.0234\n",
      "\n",
      "Start of epoch 445\n",
      "Training loss at epoch 445: 0.0234\n",
      "\n",
      "Start of epoch 446\n",
      "Training loss at epoch 446: 0.0234\n",
      "\n",
      "Start of epoch 447\n",
      "Training loss at epoch 447: 0.0234\n",
      "\n",
      "Start of epoch 448\n",
      "Training loss at epoch 448: 0.0234\n",
      "\n",
      "Start of epoch 449\n",
      "Training loss at epoch 449: 0.0234\n",
      "\n",
      "Start of epoch 450\n",
      "Training loss at epoch 450: 0.0234\n",
      "\n",
      "Start of epoch 451\n",
      "Training loss at epoch 451: 0.0234\n",
      "\n",
      "Start of epoch 452\n",
      "Training loss at epoch 452: 0.0234\n",
      "\n",
      "Start of epoch 453\n",
      "Training loss at epoch 453: 0.0234\n",
      "\n",
      "Start of epoch 454\n",
      "Training loss at epoch 454: 0.0234\n",
      "\n",
      "Start of epoch 455\n",
      "Training loss at epoch 455: 0.0234\n",
      "\n",
      "Start of epoch 456\n",
      "Training loss at epoch 456: 0.0234\n",
      "\n",
      "Start of epoch 457\n",
      "Training loss at epoch 457: 0.0234\n",
      "\n",
      "Start of epoch 458\n",
      "Training loss at epoch 458: 0.0234\n",
      "\n",
      "Start of epoch 459\n",
      "Training loss at epoch 459: 0.0234\n",
      "\n",
      "Start of epoch 460\n",
      "Training loss at epoch 460: 0.0234\n",
      "\n",
      "Start of epoch 461\n",
      "Training loss at epoch 461: 0.0234\n",
      "\n",
      "Start of epoch 462\n",
      "Training loss at epoch 462: 0.0234\n",
      "\n",
      "Start of epoch 463\n",
      "Training loss at epoch 463: 0.0234\n",
      "\n",
      "Start of epoch 464\n",
      "Training loss at epoch 464: 0.0234\n",
      "\n",
      "Start of epoch 465\n",
      "Training loss at epoch 465: 0.0234\n",
      "\n",
      "Start of epoch 466\n",
      "Training loss at epoch 466: 0.0234\n",
      "\n",
      "Start of epoch 467\n",
      "Training loss at epoch 467: 0.0234\n",
      "\n",
      "Start of epoch 468\n",
      "Training loss at epoch 468: 0.0234\n",
      "\n",
      "Start of epoch 469\n",
      "Training loss at epoch 469: 0.0234\n",
      "\n",
      "Start of epoch 470\n",
      "Training loss at epoch 470: 0.0234\n",
      "\n",
      "Start of epoch 471\n",
      "Training loss at epoch 471: 0.0234\n",
      "\n",
      "Start of epoch 472\n",
      "Training loss at epoch 472: 0.0234\n",
      "\n",
      "Start of epoch 473\n",
      "Training loss at epoch 473: 0.0234\n",
      "\n",
      "Start of epoch 474\n",
      "Training loss at epoch 474: 0.0234\n",
      "\n",
      "Start of epoch 475\n",
      "Training loss at epoch 475: 0.0234\n",
      "\n",
      "Start of epoch 476\n",
      "Training loss at epoch 476: 0.0234\n",
      "\n",
      "Start of epoch 477\n",
      "Training loss at epoch 477: 0.0234\n",
      "\n",
      "Start of epoch 478\n",
      "Training loss at epoch 478: 0.0234\n",
      "\n",
      "Start of epoch 479\n",
      "Training loss at epoch 479: 0.0234\n",
      "\n",
      "Start of epoch 480\n",
      "Training loss at epoch 480: 0.0234\n",
      "\n",
      "Start of epoch 481\n",
      "Training loss at epoch 481: 0.0234\n",
      "\n",
      "Start of epoch 482\n",
      "Training loss at epoch 482: 0.0234\n",
      "\n",
      "Start of epoch 483\n",
      "Training loss at epoch 483: 0.0234\n",
      "\n",
      "Start of epoch 484\n",
      "Training loss at epoch 484: 0.0234\n",
      "\n",
      "Start of epoch 485\n",
      "Training loss at epoch 485: 0.0234\n",
      "\n",
      "Start of epoch 486\n",
      "Training loss at epoch 486: 0.0234\n",
      "\n",
      "Start of epoch 487\n",
      "Training loss at epoch 487: 0.0234\n",
      "\n",
      "Start of epoch 488\n",
      "Training loss at epoch 488: 0.0234\n",
      "\n",
      "Start of epoch 489\n",
      "Training loss at epoch 489: 0.0234\n",
      "\n",
      "Start of epoch 490\n",
      "Training loss at epoch 490: 0.0234\n",
      "\n",
      "Start of epoch 491\n",
      "Training loss at epoch 491: 0.0234\n",
      "\n",
      "Start of epoch 492\n",
      "Training loss at epoch 492: 0.0234\n",
      "\n",
      "Start of epoch 493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 493: 0.0234\n",
      "\n",
      "Start of epoch 494\n",
      "Training loss at epoch 494: 0.0234\n",
      "\n",
      "Start of epoch 495\n",
      "Training loss at epoch 495: 0.0234\n",
      "\n",
      "Start of epoch 496\n",
      "Training loss at epoch 496: 0.0234\n",
      "\n",
      "Start of epoch 497\n",
      "Training loss at epoch 497: 0.0234\n",
      "\n",
      "Start of epoch 498\n",
      "Training loss at epoch 498: 0.0234\n",
      "\n",
      "Start of epoch 499\n",
      "Training loss at epoch 499: 0.0234\n",
      "[<tf.Variable 'parameters:0' shape=(30,) dtype=float32, numpy=\n",
      "array([5.6575117 , 3.9597633 , 6.2687287 , 4.888274  , 3.1408737 ,\n",
      "       4.9928217 , 5.2683372 , 2.3658824 , 5.943661  , 4.2407327 ,\n",
      "       3.9086566 , 0.10747303, 0.09524313, 1.2860872 , 1.3299464 ,\n",
      "       2.2904327 , 4.700449  , 2.864579  , 2.921292  , 4.212913  ,\n",
      "       2.1378427 , 0.9577658 , 1.5126871 , 5.745279  , 3.145406  ,\n",
      "       0.8027274 , 0.8230953 , 0.3883024 , 4.393838  , 4.9080787 ],\n",
      "      dtype=float32)>]\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.2257\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 1.1295\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 1.0583\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 1.0134\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.9806\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.9483\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.9113\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.8690\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.8243\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.7814\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.7441\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.7142\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.6909\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.6708\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.6503\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.6279\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.6039\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.5803\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.5590\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.5412\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.5264\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.5136\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.5015\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.4898\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.4788\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.4691\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.4607\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.4531\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.4454\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.4370\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.4275\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.4170\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.4058\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.3943\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.3826\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.3704\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.3575\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.3440\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.3300\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.3159\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.3021\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.2889\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.2762\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.2641\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.2526\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.2420\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.2321\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.2229\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.2142\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.2058\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.1977\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.1898\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.1823\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.1751\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.1682\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.1616\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.1553\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.1493\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.1438\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.1386\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.1340\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.1300\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.1265\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.1234\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.1206\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.1180\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.1156\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.1133\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.1111\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.1089\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.1067\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.1046\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.1027\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.1009\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.0993\n",
      "\n",
      "Start of epoch 75\n",
      "Training loss at epoch 75: 0.0980\n",
      "\n",
      "Start of epoch 76\n",
      "Training loss at epoch 76: 0.0968\n",
      "\n",
      "Start of epoch 77\n",
      "Training loss at epoch 77: 0.0958\n",
      "\n",
      "Start of epoch 78\n",
      "Training loss at epoch 78: 0.0950\n",
      "\n",
      "Start of epoch 79\n",
      "Training loss at epoch 79: 0.0943\n",
      "\n",
      "Start of epoch 80\n",
      "Training loss at epoch 80: 0.0937\n",
      "\n",
      "Start of epoch 81\n",
      "Training loss at epoch 81: 0.0932\n",
      "\n",
      "Start of epoch 82\n",
      "Training loss at epoch 82: 0.0927\n",
      "\n",
      "Start of epoch 83\n",
      "Training loss at epoch 83: 0.0922\n",
      "\n",
      "Start of epoch 84\n",
      "Training loss at epoch 84: 0.0917\n",
      "\n",
      "Start of epoch 85\n",
      "Training loss at epoch 85: 0.0913\n",
      "\n",
      "Start of epoch 86\n",
      "Training loss at epoch 86: 0.0908\n",
      "\n",
      "Start of epoch 87\n",
      "Training loss at epoch 87: 0.0904\n",
      "\n",
      "Start of epoch 88\n",
      "Training loss at epoch 88: 0.0900\n",
      "\n",
      "Start of epoch 89\n",
      "Training loss at epoch 89: 0.0897\n",
      "\n",
      "Start of epoch 90\n",
      "Training loss at epoch 90: 0.0894\n",
      "\n",
      "Start of epoch 91\n",
      "Training loss at epoch 91: 0.0891\n",
      "\n",
      "Start of epoch 92\n",
      "Training loss at epoch 92: 0.0889\n",
      "\n",
      "Start of epoch 93\n",
      "Training loss at epoch 93: 0.0886\n",
      "\n",
      "Start of epoch 94\n",
      "Training loss at epoch 94: 0.0884\n",
      "\n",
      "Start of epoch 95\n",
      "Training loss at epoch 95: 0.0882\n",
      "\n",
      "Start of epoch 96\n",
      "Training loss at epoch 96: 0.0881\n",
      "\n",
      "Start of epoch 97\n",
      "Training loss at epoch 97: 0.0879\n",
      "\n",
      "Start of epoch 98\n",
      "Training loss at epoch 98: 0.0877\n",
      "\n",
      "Start of epoch 99\n",
      "Training loss at epoch 99: 0.0876\n",
      "\n",
      "Start of epoch 100\n",
      "Training loss at epoch 100: 0.0874\n",
      "\n",
      "Start of epoch 101\n",
      "Training loss at epoch 101: 0.0872\n",
      "\n",
      "Start of epoch 102\n",
      "Training loss at epoch 102: 0.0870\n",
      "\n",
      "Start of epoch 103\n",
      "Training loss at epoch 103: 0.0869\n",
      "\n",
      "Start of epoch 104\n",
      "Training loss at epoch 104: 0.0867\n",
      "\n",
      "Start of epoch 105\n",
      "Training loss at epoch 105: 0.0865\n",
      "\n",
      "Start of epoch 106\n",
      "Training loss at epoch 106: 0.0864\n",
      "\n",
      "Start of epoch 107\n",
      "Training loss at epoch 107: 0.0862\n",
      "\n",
      "Start of epoch 108\n",
      "Training loss at epoch 108: 0.0860\n",
      "\n",
      "Start of epoch 109\n",
      "Training loss at epoch 109: 0.0859\n",
      "\n",
      "Start of epoch 110\n",
      "Training loss at epoch 110: 0.0857\n",
      "\n",
      "Start of epoch 111\n",
      "Training loss at epoch 111: 0.0856\n",
      "\n",
      "Start of epoch 112\n",
      "Training loss at epoch 112: 0.0854\n",
      "\n",
      "Start of epoch 113\n",
      "Training loss at epoch 113: 0.0853\n",
      "\n",
      "Start of epoch 114\n",
      "Training loss at epoch 114: 0.0851\n",
      "\n",
      "Start of epoch 115\n",
      "Training loss at epoch 115: 0.0850\n",
      "\n",
      "Start of epoch 116\n",
      "Training loss at epoch 116: 0.0849\n",
      "\n",
      "Start of epoch 117\n",
      "Training loss at epoch 117: 0.0847\n",
      "\n",
      "Start of epoch 118\n",
      "Training loss at epoch 118: 0.0846\n",
      "\n",
      "Start of epoch 119\n",
      "Training loss at epoch 119: 0.0845\n",
      "\n",
      "Start of epoch 120\n",
      "Training loss at epoch 120: 0.0843\n",
      "\n",
      "Start of epoch 121\n",
      "Training loss at epoch 121: 0.0842\n",
      "\n",
      "Start of epoch 122\n",
      "Training loss at epoch 122: 0.0840\n",
      "\n",
      "Start of epoch 123\n",
      "Training loss at epoch 123: 0.0839\n",
      "\n",
      "Start of epoch 124\n",
      "Training loss at epoch 124: 0.0838\n",
      "\n",
      "Start of epoch 125\n",
      "Training loss at epoch 125: 0.0836\n",
      "\n",
      "Start of epoch 126\n",
      "Training loss at epoch 126: 0.0835\n",
      "\n",
      "Start of epoch 127\n",
      "Training loss at epoch 127: 0.0833\n",
      "\n",
      "Start of epoch 128\n",
      "Training loss at epoch 128: 0.0832\n",
      "\n",
      "Start of epoch 129\n",
      "Training loss at epoch 129: 0.0830\n",
      "\n",
      "Start of epoch 130\n",
      "Training loss at epoch 130: 0.0829\n",
      "\n",
      "Start of epoch 131\n",
      "Training loss at epoch 131: 0.0827\n",
      "\n",
      "Start of epoch 132\n",
      "Training loss at epoch 132: 0.0826\n",
      "\n",
      "Start of epoch 133\n",
      "Training loss at epoch 133: 0.0824\n",
      "\n",
      "Start of epoch 134\n",
      "Training loss at epoch 134: 0.0823\n",
      "\n",
      "Start of epoch 135\n",
      "Training loss at epoch 135: 0.0821\n",
      "\n",
      "Start of epoch 136\n",
      "Training loss at epoch 136: 0.0820\n",
      "\n",
      "Start of epoch 137\n",
      "Training loss at epoch 137: 0.0818\n",
      "\n",
      "Start of epoch 138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 138: 0.0816\n",
      "\n",
      "Start of epoch 139\n",
      "Training loss at epoch 139: 0.0815\n",
      "\n",
      "Start of epoch 140\n",
      "Training loss at epoch 140: 0.0813\n",
      "\n",
      "Start of epoch 141\n",
      "Training loss at epoch 141: 0.0811\n",
      "\n",
      "Start of epoch 142\n",
      "Training loss at epoch 142: 0.0810\n",
      "\n",
      "Start of epoch 143\n",
      "Training loss at epoch 143: 0.0808\n",
      "\n",
      "Start of epoch 144\n",
      "Training loss at epoch 144: 0.0806\n",
      "\n",
      "Start of epoch 145\n",
      "Training loss at epoch 145: 0.0805\n",
      "\n",
      "Start of epoch 146\n",
      "Training loss at epoch 146: 0.0803\n",
      "\n",
      "Start of epoch 147\n",
      "Training loss at epoch 147: 0.0801\n",
      "\n",
      "Start of epoch 148\n",
      "Training loss at epoch 148: 0.0799\n",
      "\n",
      "Start of epoch 149\n",
      "Training loss at epoch 149: 0.0797\n",
      "\n",
      "Start of epoch 150\n",
      "Training loss at epoch 150: 0.0796\n",
      "\n",
      "Start of epoch 151\n",
      "Training loss at epoch 151: 0.0794\n",
      "\n",
      "Start of epoch 152\n",
      "Training loss at epoch 152: 0.0792\n",
      "\n",
      "Start of epoch 153\n",
      "Training loss at epoch 153: 0.0790\n",
      "\n",
      "Start of epoch 154\n",
      "Training loss at epoch 154: 0.0788\n",
      "\n",
      "Start of epoch 155\n",
      "Training loss at epoch 155: 0.0786\n",
      "\n",
      "Start of epoch 156\n",
      "Training loss at epoch 156: 0.0785\n",
      "\n",
      "Start of epoch 157\n",
      "Training loss at epoch 157: 0.0783\n",
      "\n",
      "Start of epoch 158\n",
      "Training loss at epoch 158: 0.0781\n",
      "\n",
      "Start of epoch 159\n",
      "Training loss at epoch 159: 0.0779\n",
      "\n",
      "Start of epoch 160\n",
      "Training loss at epoch 160: 0.0777\n",
      "\n",
      "Start of epoch 161\n",
      "Training loss at epoch 161: 0.0775\n",
      "\n",
      "Start of epoch 162\n",
      "Training loss at epoch 162: 0.0773\n",
      "\n",
      "Start of epoch 163\n",
      "Training loss at epoch 163: 0.0771\n",
      "\n",
      "Start of epoch 164\n",
      "Training loss at epoch 164: 0.0769\n",
      "\n",
      "Start of epoch 165\n",
      "Training loss at epoch 165: 0.0767\n",
      "\n",
      "Start of epoch 166\n",
      "Training loss at epoch 166: 0.0765\n",
      "\n",
      "Start of epoch 167\n",
      "Training loss at epoch 167: 0.0763\n",
      "\n",
      "Start of epoch 168\n",
      "Training loss at epoch 168: 0.0761\n",
      "\n",
      "Start of epoch 169\n",
      "Training loss at epoch 169: 0.0758\n",
      "\n",
      "Start of epoch 170\n",
      "Training loss at epoch 170: 0.0756\n",
      "\n",
      "Start of epoch 171\n",
      "Training loss at epoch 171: 0.0754\n",
      "\n",
      "Start of epoch 172\n",
      "Training loss at epoch 172: 0.0752\n",
      "\n",
      "Start of epoch 173\n",
      "Training loss at epoch 173: 0.0750\n",
      "\n",
      "Start of epoch 174\n",
      "Training loss at epoch 174: 0.0748\n",
      "\n",
      "Start of epoch 175\n",
      "Training loss at epoch 175: 0.0746\n",
      "\n",
      "Start of epoch 176\n",
      "Training loss at epoch 176: 0.0743\n",
      "\n",
      "Start of epoch 177\n",
      "Training loss at epoch 177: 0.0741\n",
      "\n",
      "Start of epoch 178\n",
      "Training loss at epoch 178: 0.0739\n",
      "\n",
      "Start of epoch 179\n",
      "Training loss at epoch 179: 0.0737\n",
      "\n",
      "Start of epoch 180\n",
      "Training loss at epoch 180: 0.0735\n",
      "\n",
      "Start of epoch 181\n",
      "Training loss at epoch 181: 0.0732\n",
      "\n",
      "Start of epoch 182\n",
      "Training loss at epoch 182: 0.0730\n",
      "\n",
      "Start of epoch 183\n",
      "Training loss at epoch 183: 0.0728\n",
      "\n",
      "Start of epoch 184\n",
      "Training loss at epoch 184: 0.0726\n",
      "\n",
      "Start of epoch 185\n",
      "Training loss at epoch 185: 0.0723\n",
      "\n",
      "Start of epoch 186\n",
      "Training loss at epoch 186: 0.0721\n",
      "\n",
      "Start of epoch 187\n",
      "Training loss at epoch 187: 0.0719\n",
      "\n",
      "Start of epoch 188\n",
      "Training loss at epoch 188: 0.0717\n",
      "\n",
      "Start of epoch 189\n",
      "Training loss at epoch 189: 0.0714\n",
      "\n",
      "Start of epoch 190\n",
      "Training loss at epoch 190: 0.0712\n",
      "\n",
      "Start of epoch 191\n",
      "Training loss at epoch 191: 0.0710\n",
      "\n",
      "Start of epoch 192\n",
      "Training loss at epoch 192: 0.0708\n",
      "\n",
      "Start of epoch 193\n",
      "Training loss at epoch 193: 0.0705\n",
      "\n",
      "Start of epoch 194\n",
      "Training loss at epoch 194: 0.0703\n",
      "\n",
      "Start of epoch 195\n",
      "Training loss at epoch 195: 0.0701\n",
      "\n",
      "Start of epoch 196\n",
      "Training loss at epoch 196: 0.0699\n",
      "\n",
      "Start of epoch 197\n",
      "Training loss at epoch 197: 0.0696\n",
      "\n",
      "Start of epoch 198\n",
      "Training loss at epoch 198: 0.0694\n",
      "\n",
      "Start of epoch 199\n",
      "Training loss at epoch 199: 0.0692\n",
      "\n",
      "Start of epoch 200\n",
      "Training loss at epoch 200: 0.0690\n",
      "\n",
      "Start of epoch 201\n",
      "Training loss at epoch 201: 0.0688\n",
      "\n",
      "Start of epoch 202\n",
      "Training loss at epoch 202: 0.0685\n",
      "\n",
      "Start of epoch 203\n",
      "Training loss at epoch 203: 0.0683\n",
      "\n",
      "Start of epoch 204\n",
      "Training loss at epoch 204: 0.0681\n",
      "\n",
      "Start of epoch 205\n",
      "Training loss at epoch 205: 0.0679\n",
      "\n",
      "Start of epoch 206\n",
      "Training loss at epoch 206: 0.0677\n",
      "\n",
      "Start of epoch 207\n",
      "Training loss at epoch 207: 0.0675\n",
      "\n",
      "Start of epoch 208\n",
      "Training loss at epoch 208: 0.0673\n",
      "\n",
      "Start of epoch 209\n",
      "Training loss at epoch 209: 0.0670\n",
      "\n",
      "Start of epoch 210\n",
      "Training loss at epoch 210: 0.0668\n",
      "\n",
      "Start of epoch 211\n",
      "Training loss at epoch 211: 0.0666\n",
      "\n",
      "Start of epoch 212\n",
      "Training loss at epoch 212: 0.0664\n",
      "\n",
      "Start of epoch 213\n",
      "Training loss at epoch 213: 0.0662\n",
      "\n",
      "Start of epoch 214\n",
      "Training loss at epoch 214: 0.0660\n",
      "\n",
      "Start of epoch 215\n",
      "Training loss at epoch 215: 0.0658\n",
      "\n",
      "Start of epoch 216\n",
      "Training loss at epoch 216: 0.0656\n",
      "\n",
      "Start of epoch 217\n",
      "Training loss at epoch 217: 0.0655\n",
      "\n",
      "Start of epoch 218\n",
      "Training loss at epoch 218: 0.0653\n",
      "\n",
      "Start of epoch 219\n",
      "Training loss at epoch 219: 0.0651\n",
      "\n",
      "Start of epoch 220\n",
      "Training loss at epoch 220: 0.0649\n",
      "\n",
      "Start of epoch 221\n",
      "Training loss at epoch 221: 0.0647\n",
      "\n",
      "Start of epoch 222\n",
      "Training loss at epoch 222: 0.0645\n",
      "\n",
      "Start of epoch 223\n",
      "Training loss at epoch 223: 0.0644\n",
      "\n",
      "Start of epoch 224\n",
      "Training loss at epoch 224: 0.0642\n",
      "\n",
      "Start of epoch 225\n",
      "Training loss at epoch 225: 0.0640\n",
      "\n",
      "Start of epoch 226\n",
      "Training loss at epoch 226: 0.0639\n",
      "\n",
      "Start of epoch 227\n",
      "Training loss at epoch 227: 0.0637\n",
      "\n",
      "Start of epoch 228\n",
      "Training loss at epoch 228: 0.0636\n",
      "\n",
      "Start of epoch 229\n",
      "Training loss at epoch 229: 0.0634\n",
      "\n",
      "Start of epoch 230\n",
      "Training loss at epoch 230: 0.0632\n",
      "\n",
      "Start of epoch 231\n",
      "Training loss at epoch 231: 0.0631\n",
      "\n",
      "Start of epoch 232\n",
      "Training loss at epoch 232: 0.0629\n",
      "\n",
      "Start of epoch 233\n",
      "Training loss at epoch 233: 0.0628\n",
      "\n",
      "Start of epoch 234\n",
      "Training loss at epoch 234: 0.0627\n",
      "\n",
      "Start of epoch 235\n",
      "Training loss at epoch 235: 0.0625\n",
      "\n",
      "Start of epoch 236\n",
      "Training loss at epoch 236: 0.0624\n",
      "\n",
      "Start of epoch 237\n",
      "Training loss at epoch 237: 0.0623\n",
      "\n",
      "Start of epoch 238\n",
      "Training loss at epoch 238: 0.0621\n",
      "\n",
      "Start of epoch 239\n",
      "Training loss at epoch 239: 0.0620\n",
      "\n",
      "Start of epoch 240\n",
      "Training loss at epoch 240: 0.0619\n",
      "\n",
      "Start of epoch 241\n",
      "Training loss at epoch 241: 0.0618\n",
      "\n",
      "Start of epoch 242\n",
      "Training loss at epoch 242: 0.0617\n",
      "\n",
      "Start of epoch 243\n",
      "Training loss at epoch 243: 0.0616\n",
      "\n",
      "Start of epoch 244\n",
      "Training loss at epoch 244: 0.0614\n",
      "\n",
      "Start of epoch 245\n",
      "Training loss at epoch 245: 0.0613\n",
      "\n",
      "Start of epoch 246\n",
      "Training loss at epoch 246: 0.0612\n",
      "\n",
      "Start of epoch 247\n",
      "Training loss at epoch 247: 0.0611\n",
      "\n",
      "Start of epoch 248\n",
      "Training loss at epoch 248: 0.0610\n",
      "\n",
      "Start of epoch 249\n",
      "Training loss at epoch 249: 0.0610\n",
      "\n",
      "Start of epoch 250\n",
      "Training loss at epoch 250: 0.0609\n",
      "\n",
      "Start of epoch 251\n",
      "Training loss at epoch 251: 0.0608\n",
      "\n",
      "Start of epoch 252\n",
      "Training loss at epoch 252: 0.0607\n",
      "\n",
      "Start of epoch 253\n",
      "Training loss at epoch 253: 0.0606\n",
      "\n",
      "Start of epoch 254\n",
      "Training loss at epoch 254: 0.0605\n",
      "\n",
      "Start of epoch 255\n",
      "Training loss at epoch 255: 0.0605\n",
      "\n",
      "Start of epoch 256\n",
      "Training loss at epoch 256: 0.0604\n",
      "\n",
      "Start of epoch 257\n",
      "Training loss at epoch 257: 0.0603\n",
      "\n",
      "Start of epoch 258\n",
      "Training loss at epoch 258: 0.0603\n",
      "\n",
      "Start of epoch 259\n",
      "Training loss at epoch 259: 0.0602\n",
      "\n",
      "Start of epoch 260\n",
      "Training loss at epoch 260: 0.0601\n",
      "\n",
      "Start of epoch 261\n",
      "Training loss at epoch 261: 0.0601\n",
      "\n",
      "Start of epoch 262\n",
      "Training loss at epoch 262: 0.0600\n",
      "\n",
      "Start of epoch 263\n",
      "Training loss at epoch 263: 0.0600\n",
      "\n",
      "Start of epoch 264\n",
      "Training loss at epoch 264: 0.0599\n",
      "\n",
      "Start of epoch 265\n",
      "Training loss at epoch 265: 0.0598\n",
      "\n",
      "Start of epoch 266\n",
      "Training loss at epoch 266: 0.0598\n",
      "\n",
      "Start of epoch 267\n",
      "Training loss at epoch 267: 0.0597\n",
      "\n",
      "Start of epoch 268\n",
      "Training loss at epoch 268: 0.0597\n",
      "\n",
      "Start of epoch 269\n",
      "Training loss at epoch 269: 0.0597\n",
      "\n",
      "Start of epoch 270\n",
      "Training loss at epoch 270: 0.0596\n",
      "\n",
      "Start of epoch 271\n",
      "Training loss at epoch 271: 0.0596\n",
      "\n",
      "Start of epoch 272\n",
      "Training loss at epoch 272: 0.0595\n",
      "\n",
      "Start of epoch 273\n",
      "Training loss at epoch 273: 0.0595\n",
      "\n",
      "Start of epoch 274\n",
      "Training loss at epoch 274: 0.0595\n",
      "\n",
      "Start of epoch 275\n",
      "Training loss at epoch 275: 0.0594\n",
      "\n",
      "Start of epoch 276\n",
      "Training loss at epoch 276: 0.0594\n",
      "\n",
      "Start of epoch 277\n",
      "Training loss at epoch 277: 0.0594\n",
      "\n",
      "Start of epoch 278\n",
      "Training loss at epoch 278: 0.0593\n",
      "\n",
      "Start of epoch 279\n",
      "Training loss at epoch 279: 0.0593\n",
      "\n",
      "Start of epoch 280\n",
      "Training loss at epoch 280: 0.0593\n",
      "\n",
      "Start of epoch 281\n",
      "Training loss at epoch 281: 0.0593\n",
      "\n",
      "Start of epoch 282\n",
      "Training loss at epoch 282: 0.0592\n",
      "\n",
      "Start of epoch 283\n",
      "Training loss at epoch 283: 0.0592\n",
      "\n",
      "Start of epoch 284\n",
      "Training loss at epoch 284: 0.0592\n",
      "\n",
      "Start of epoch 285\n",
      "Training loss at epoch 285: 0.0592\n",
      "\n",
      "Start of epoch 286\n",
      "Training loss at epoch 286: 0.0591\n",
      "\n",
      "Start of epoch 287\n",
      "Training loss at epoch 287: 0.0591\n",
      "\n",
      "Start of epoch 288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 288: 0.0591\n",
      "\n",
      "Start of epoch 289\n",
      "Training loss at epoch 289: 0.0591\n",
      "\n",
      "Start of epoch 290\n",
      "Training loss at epoch 290: 0.0591\n",
      "\n",
      "Start of epoch 291\n",
      "Training loss at epoch 291: 0.0590\n",
      "\n",
      "Start of epoch 292\n",
      "Training loss at epoch 292: 0.0590\n",
      "\n",
      "Start of epoch 293\n",
      "Training loss at epoch 293: 0.0590\n",
      "\n",
      "Start of epoch 294\n",
      "Training loss at epoch 294: 0.0590\n",
      "\n",
      "Start of epoch 295\n",
      "Training loss at epoch 295: 0.0590\n",
      "\n",
      "Start of epoch 296\n",
      "Training loss at epoch 296: 0.0590\n",
      "\n",
      "Start of epoch 297\n",
      "Training loss at epoch 297: 0.0590\n",
      "\n",
      "Start of epoch 298\n",
      "Training loss at epoch 298: 0.0589\n",
      "\n",
      "Start of epoch 299\n",
      "Training loss at epoch 299: 0.0589\n",
      "\n",
      "Start of epoch 300\n",
      "Training loss at epoch 300: 0.0589\n",
      "\n",
      "Start of epoch 301\n",
      "Training loss at epoch 301: 0.0589\n",
      "\n",
      "Start of epoch 302\n",
      "Training loss at epoch 302: 0.0589\n",
      "\n",
      "Start of epoch 303\n",
      "Training loss at epoch 303: 0.0589\n",
      "\n",
      "Start of epoch 304\n",
      "Training loss at epoch 304: 0.0589\n",
      "\n",
      "Start of epoch 305\n",
      "Training loss at epoch 305: 0.0589\n",
      "\n",
      "Start of epoch 306\n",
      "Training loss at epoch 306: 0.0589\n",
      "\n",
      "Start of epoch 307\n",
      "Training loss at epoch 307: 0.0588\n",
      "\n",
      "Start of epoch 308\n",
      "Training loss at epoch 308: 0.0588\n",
      "\n",
      "Start of epoch 309\n",
      "Training loss at epoch 309: 0.0588\n",
      "\n",
      "Start of epoch 310\n",
      "Training loss at epoch 310: 0.0588\n",
      "\n",
      "Start of epoch 311\n",
      "Training loss at epoch 311: 0.0588\n",
      "\n",
      "Start of epoch 312\n",
      "Training loss at epoch 312: 0.0588\n",
      "\n",
      "Start of epoch 313\n",
      "Training loss at epoch 313: 0.0588\n",
      "\n",
      "Start of epoch 314\n",
      "Training loss at epoch 314: 0.0588\n",
      "\n",
      "Start of epoch 315\n",
      "Training loss at epoch 315: 0.0588\n",
      "\n",
      "Start of epoch 316\n",
      "Training loss at epoch 316: 0.0588\n",
      "\n",
      "Start of epoch 317\n",
      "Training loss at epoch 317: 0.0588\n",
      "\n",
      "Start of epoch 318\n",
      "Training loss at epoch 318: 0.0588\n",
      "\n",
      "Start of epoch 319\n",
      "Training loss at epoch 319: 0.0588\n",
      "\n",
      "Start of epoch 320\n",
      "Training loss at epoch 320: 0.0587\n",
      "\n",
      "Start of epoch 321\n",
      "Training loss at epoch 321: 0.0587\n",
      "\n",
      "Start of epoch 322\n",
      "Training loss at epoch 322: 0.0587\n",
      "\n",
      "Start of epoch 323\n",
      "Training loss at epoch 323: 0.0587\n",
      "\n",
      "Start of epoch 324\n",
      "Training loss at epoch 324: 0.0587\n",
      "\n",
      "Start of epoch 325\n",
      "Training loss at epoch 325: 0.0587\n",
      "\n",
      "Start of epoch 326\n",
      "Training loss at epoch 326: 0.0587\n",
      "\n",
      "Start of epoch 327\n",
      "Training loss at epoch 327: 0.0587\n",
      "\n",
      "Start of epoch 328\n",
      "Training loss at epoch 328: 0.0587\n",
      "\n",
      "Start of epoch 329\n",
      "Training loss at epoch 329: 0.0587\n",
      "\n",
      "Start of epoch 330\n",
      "Training loss at epoch 330: 0.0587\n",
      "\n",
      "Start of epoch 331\n",
      "Training loss at epoch 331: 0.0587\n",
      "\n",
      "Start of epoch 332\n",
      "Training loss at epoch 332: 0.0587\n",
      "\n",
      "Start of epoch 333\n",
      "Training loss at epoch 333: 0.0587\n",
      "\n",
      "Start of epoch 334\n",
      "Training loss at epoch 334: 0.0587\n",
      "\n",
      "Start of epoch 335\n",
      "Training loss at epoch 335: 0.0587\n",
      "\n",
      "Start of epoch 336\n",
      "Training loss at epoch 336: 0.0587\n",
      "\n",
      "Start of epoch 337\n",
      "Training loss at epoch 337: 0.0587\n",
      "\n",
      "Start of epoch 338\n",
      "Training loss at epoch 338: 0.0586\n",
      "\n",
      "Start of epoch 339\n",
      "Training loss at epoch 339: 0.0586\n",
      "\n",
      "Start of epoch 340\n",
      "Training loss at epoch 340: 0.0586\n",
      "\n",
      "Start of epoch 341\n",
      "Training loss at epoch 341: 0.0586\n",
      "\n",
      "Start of epoch 342\n",
      "Training loss at epoch 342: 0.0586\n",
      "\n",
      "Start of epoch 343\n",
      "Training loss at epoch 343: 0.0586\n",
      "\n",
      "Start of epoch 344\n",
      "Training loss at epoch 344: 0.0586\n",
      "\n",
      "Start of epoch 345\n",
      "Training loss at epoch 345: 0.0586\n",
      "\n",
      "Start of epoch 346\n",
      "Training loss at epoch 346: 0.0586\n",
      "\n",
      "Start of epoch 347\n",
      "Training loss at epoch 347: 0.0586\n",
      "\n",
      "Start of epoch 348\n",
      "Training loss at epoch 348: 0.0586\n",
      "\n",
      "Start of epoch 349\n",
      "Training loss at epoch 349: 0.0586\n",
      "\n",
      "Start of epoch 350\n",
      "Training loss at epoch 350: 0.0586\n",
      "\n",
      "Start of epoch 351\n",
      "Training loss at epoch 351: 0.0586\n",
      "\n",
      "Start of epoch 352\n",
      "Training loss at epoch 352: 0.0586\n",
      "\n",
      "Start of epoch 353\n",
      "Training loss at epoch 353: 0.0586\n",
      "\n",
      "Start of epoch 354\n",
      "Training loss at epoch 354: 0.0586\n",
      "\n",
      "Start of epoch 355\n",
      "Training loss at epoch 355: 0.0586\n",
      "\n",
      "Start of epoch 356\n",
      "Training loss at epoch 356: 0.0586\n",
      "\n",
      "Start of epoch 357\n",
      "Training loss at epoch 357: 0.0586\n",
      "\n",
      "Start of epoch 358\n",
      "Training loss at epoch 358: 0.0586\n",
      "\n",
      "Start of epoch 359\n",
      "Training loss at epoch 359: 0.0586\n",
      "\n",
      "Start of epoch 360\n",
      "Training loss at epoch 360: 0.0586\n",
      "\n",
      "Start of epoch 361\n",
      "Training loss at epoch 361: 0.0586\n",
      "\n",
      "Start of epoch 362\n",
      "Training loss at epoch 362: 0.0585\n",
      "\n",
      "Start of epoch 363\n",
      "Training loss at epoch 363: 0.0585\n",
      "\n",
      "Start of epoch 364\n",
      "Training loss at epoch 364: 0.0585\n",
      "\n",
      "Start of epoch 365\n",
      "Training loss at epoch 365: 0.0585\n",
      "\n",
      "Start of epoch 366\n",
      "Training loss at epoch 366: 0.0585\n",
      "\n",
      "Start of epoch 367\n",
      "Training loss at epoch 367: 0.0585\n",
      "\n",
      "Start of epoch 368\n",
      "Training loss at epoch 368: 0.0585\n",
      "\n",
      "Start of epoch 369\n",
      "Training loss at epoch 369: 0.0585\n",
      "\n",
      "Start of epoch 370\n",
      "Training loss at epoch 370: 0.0585\n",
      "\n",
      "Start of epoch 371\n",
      "Training loss at epoch 371: 0.0585\n",
      "\n",
      "Start of epoch 372\n",
      "Training loss at epoch 372: 0.0585\n",
      "\n",
      "Start of epoch 373\n",
      "Training loss at epoch 373: 0.0585\n",
      "\n",
      "Start of epoch 374\n",
      "Training loss at epoch 374: 0.0585\n",
      "\n",
      "Start of epoch 375\n",
      "Training loss at epoch 375: 0.0585\n",
      "\n",
      "Start of epoch 376\n",
      "Training loss at epoch 376: 0.0585\n",
      "\n",
      "Start of epoch 377\n",
      "Training loss at epoch 377: 0.0585\n",
      "\n",
      "Start of epoch 378\n",
      "Training loss at epoch 378: 0.0585\n",
      "\n",
      "Start of epoch 379\n",
      "Training loss at epoch 379: 0.0585\n",
      "\n",
      "Start of epoch 380\n",
      "Training loss at epoch 380: 0.0585\n",
      "\n",
      "Start of epoch 381\n",
      "Training loss at epoch 381: 0.0585\n",
      "\n",
      "Start of epoch 382\n",
      "Training loss at epoch 382: 0.0585\n",
      "\n",
      "Start of epoch 383\n",
      "Training loss at epoch 383: 0.0585\n",
      "\n",
      "Start of epoch 384\n",
      "Training loss at epoch 384: 0.0585\n",
      "\n",
      "Start of epoch 385\n",
      "Training loss at epoch 385: 0.0585\n",
      "\n",
      "Start of epoch 386\n",
      "Training loss at epoch 386: 0.0585\n",
      "\n",
      "Start of epoch 387\n",
      "Training loss at epoch 387: 0.0585\n",
      "\n",
      "Start of epoch 388\n",
      "Training loss at epoch 388: 0.0585\n",
      "\n",
      "Start of epoch 389\n",
      "Training loss at epoch 389: 0.0585\n",
      "\n",
      "Start of epoch 390\n",
      "Training loss at epoch 390: 0.0584\n",
      "\n",
      "Start of epoch 391\n",
      "Training loss at epoch 391: 0.0584\n",
      "\n",
      "Start of epoch 392\n",
      "Training loss at epoch 392: 0.0584\n",
      "\n",
      "Start of epoch 393\n",
      "Training loss at epoch 393: 0.0584\n",
      "\n",
      "Start of epoch 394\n",
      "Training loss at epoch 394: 0.0584\n",
      "\n",
      "Start of epoch 395\n",
      "Training loss at epoch 395: 0.0584\n",
      "\n",
      "Start of epoch 396\n",
      "Training loss at epoch 396: 0.0584\n",
      "\n",
      "Start of epoch 397\n",
      "Training loss at epoch 397: 0.0584\n",
      "\n",
      "Start of epoch 398\n",
      "Training loss at epoch 398: 0.0584\n",
      "\n",
      "Start of epoch 399\n",
      "Training loss at epoch 399: 0.0584\n",
      "\n",
      "Start of epoch 400\n",
      "Training loss at epoch 400: 0.0584\n",
      "\n",
      "Start of epoch 401\n",
      "Training loss at epoch 401: 0.0584\n",
      "\n",
      "Start of epoch 402\n",
      "Training loss at epoch 402: 0.0584\n",
      "\n",
      "Start of epoch 403\n",
      "Training loss at epoch 403: 0.0584\n",
      "\n",
      "Start of epoch 404\n",
      "Training loss at epoch 404: 0.0584\n",
      "\n",
      "Start of epoch 405\n",
      "Training loss at epoch 405: 0.0584\n",
      "\n",
      "Start of epoch 406\n",
      "Training loss at epoch 406: 0.0584\n",
      "\n",
      "Start of epoch 407\n",
      "Training loss at epoch 407: 0.0584\n",
      "\n",
      "Start of epoch 408\n",
      "Training loss at epoch 408: 0.0584\n",
      "\n",
      "Start of epoch 409\n",
      "Training loss at epoch 409: 0.0584\n",
      "\n",
      "Start of epoch 410\n",
      "Training loss at epoch 410: 0.0584\n",
      "\n",
      "Start of epoch 411\n",
      "Training loss at epoch 411: 0.0584\n",
      "\n",
      "Start of epoch 412\n",
      "Training loss at epoch 412: 0.0584\n",
      "\n",
      "Start of epoch 413\n",
      "Training loss at epoch 413: 0.0584\n",
      "\n",
      "Start of epoch 414\n",
      "Training loss at epoch 414: 0.0584\n",
      "\n",
      "Start of epoch 415\n",
      "Training loss at epoch 415: 0.0584\n",
      "\n",
      "Start of epoch 416\n",
      "Training loss at epoch 416: 0.0584\n",
      "\n",
      "Start of epoch 417\n",
      "Training loss at epoch 417: 0.0584\n",
      "\n",
      "Start of epoch 418\n",
      "Training loss at epoch 418: 0.0584\n",
      "\n",
      "Start of epoch 419\n",
      "Training loss at epoch 419: 0.0584\n",
      "\n",
      "Start of epoch 420\n",
      "Training loss at epoch 420: 0.0584\n",
      "\n",
      "Start of epoch 421\n",
      "Training loss at epoch 421: 0.0584\n",
      "\n",
      "Start of epoch 422\n",
      "Training loss at epoch 422: 0.0584\n",
      "\n",
      "Start of epoch 423\n",
      "Training loss at epoch 423: 0.0583\n",
      "\n",
      "Start of epoch 424\n",
      "Training loss at epoch 424: 0.0583\n",
      "\n",
      "Start of epoch 425\n",
      "Training loss at epoch 425: 0.0583\n",
      "\n",
      "Start of epoch 426\n",
      "Training loss at epoch 426: 0.0583\n",
      "\n",
      "Start of epoch 427\n",
      "Training loss at epoch 427: 0.0583\n",
      "\n",
      "Start of epoch 428\n",
      "Training loss at epoch 428: 0.0583\n",
      "\n",
      "Start of epoch 429\n",
      "Training loss at epoch 429: 0.0583\n",
      "\n",
      "Start of epoch 430\n",
      "Training loss at epoch 430: 0.0583\n",
      "\n",
      "Start of epoch 431\n",
      "Training loss at epoch 431: 0.0583\n",
      "\n",
      "Start of epoch 432\n",
      "Training loss at epoch 432: 0.0583\n",
      "\n",
      "Start of epoch 433\n",
      "Training loss at epoch 433: 0.0583\n",
      "\n",
      "Start of epoch 434\n",
      "Training loss at epoch 434: 0.0583\n",
      "\n",
      "Start of epoch 435\n",
      "Training loss at epoch 435: 0.0583\n",
      "\n",
      "Start of epoch 436\n",
      "Training loss at epoch 436: 0.0583\n",
      "\n",
      "Start of epoch 437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 437: 0.0583\n",
      "\n",
      "Start of epoch 438\n",
      "Training loss at epoch 438: 0.0583\n",
      "\n",
      "Start of epoch 439\n",
      "Training loss at epoch 439: 0.0583\n",
      "\n",
      "Start of epoch 440\n",
      "Training loss at epoch 440: 0.0583\n",
      "\n",
      "Start of epoch 441\n",
      "Training loss at epoch 441: 0.0583\n",
      "\n",
      "Start of epoch 442\n",
      "Training loss at epoch 442: 0.0583\n",
      "\n",
      "Start of epoch 443\n",
      "Training loss at epoch 443: 0.0583\n",
      "\n",
      "Start of epoch 444\n",
      "Training loss at epoch 444: 0.0583\n",
      "\n",
      "Start of epoch 445\n",
      "Training loss at epoch 445: 0.0583\n",
      "\n",
      "Start of epoch 446\n",
      "Training loss at epoch 446: 0.0583\n",
      "\n",
      "Start of epoch 447\n",
      "Training loss at epoch 447: 0.0583\n",
      "\n",
      "Start of epoch 448\n",
      "Training loss at epoch 448: 0.0583\n",
      "\n",
      "Start of epoch 449\n",
      "Training loss at epoch 449: 0.0583\n",
      "\n",
      "Start of epoch 450\n",
      "Training loss at epoch 450: 0.0583\n",
      "\n",
      "Start of epoch 451\n",
      "Training loss at epoch 451: 0.0583\n",
      "\n",
      "Start of epoch 452\n",
      "Training loss at epoch 452: 0.0583\n",
      "\n",
      "Start of epoch 453\n",
      "Training loss at epoch 453: 0.0583\n",
      "\n",
      "Start of epoch 454\n",
      "Training loss at epoch 454: 0.0583\n",
      "\n",
      "Start of epoch 455\n",
      "Training loss at epoch 455: 0.0583\n",
      "\n",
      "Start of epoch 456\n",
      "Training loss at epoch 456: 0.0583\n",
      "\n",
      "Start of epoch 457\n",
      "Training loss at epoch 457: 0.0583\n",
      "\n",
      "Start of epoch 458\n",
      "Training loss at epoch 458: 0.0583\n",
      "\n",
      "Start of epoch 459\n",
      "Training loss at epoch 459: 0.0583\n",
      "\n",
      "Start of epoch 460\n",
      "Training loss at epoch 460: 0.0583\n",
      "\n",
      "Start of epoch 461\n",
      "Training loss at epoch 461: 0.0583\n",
      "\n",
      "Start of epoch 462\n",
      "Training loss at epoch 462: 0.0583\n",
      "\n",
      "Start of epoch 463\n",
      "Training loss at epoch 463: 0.0583\n",
      "\n",
      "Start of epoch 464\n",
      "Training loss at epoch 464: 0.0583\n",
      "\n",
      "Start of epoch 465\n",
      "Training loss at epoch 465: 0.0582\n",
      "\n",
      "Start of epoch 466\n",
      "Training loss at epoch 466: 0.0582\n",
      "\n",
      "Start of epoch 467\n",
      "Training loss at epoch 467: 0.0582\n",
      "\n",
      "Start of epoch 468\n",
      "Training loss at epoch 468: 0.0582\n",
      "\n",
      "Start of epoch 469\n",
      "Training loss at epoch 469: 0.0582\n",
      "\n",
      "Start of epoch 470\n",
      "Training loss at epoch 470: 0.0582\n",
      "\n",
      "Start of epoch 471\n",
      "Training loss at epoch 471: 0.0582\n",
      "\n",
      "Start of epoch 472\n",
      "Training loss at epoch 472: 0.0582\n",
      "\n",
      "Start of epoch 473\n",
      "Training loss at epoch 473: 0.0582\n",
      "\n",
      "Start of epoch 474\n",
      "Training loss at epoch 474: 0.0582\n",
      "\n",
      "Start of epoch 475\n",
      "Training loss at epoch 475: 0.0582\n",
      "\n",
      "Start of epoch 476\n",
      "Training loss at epoch 476: 0.0582\n",
      "\n",
      "Start of epoch 477\n",
      "Training loss at epoch 477: 0.0582\n",
      "\n",
      "Start of epoch 478\n",
      "Training loss at epoch 478: 0.0582\n",
      "\n",
      "Start of epoch 479\n",
      "Training loss at epoch 479: 0.0582\n",
      "\n",
      "Start of epoch 480\n",
      "Training loss at epoch 480: 0.0582\n",
      "\n",
      "Start of epoch 481\n",
      "Training loss at epoch 481: 0.0582\n",
      "\n",
      "Start of epoch 482\n",
      "Training loss at epoch 482: 0.0582\n",
      "\n",
      "Start of epoch 483\n",
      "Training loss at epoch 483: 0.0582\n",
      "\n",
      "Start of epoch 484\n",
      "Training loss at epoch 484: 0.0582\n",
      "\n",
      "Start of epoch 485\n",
      "Training loss at epoch 485: 0.0582\n",
      "\n",
      "Start of epoch 486\n",
      "Training loss at epoch 486: 0.0582\n",
      "\n",
      "Start of epoch 487\n",
      "Training loss at epoch 487: 0.0582\n",
      "\n",
      "Start of epoch 488\n",
      "Training loss at epoch 488: 0.0582\n",
      "\n",
      "Start of epoch 489\n",
      "Training loss at epoch 489: 0.0582\n",
      "\n",
      "Start of epoch 490\n",
      "Training loss at epoch 490: 0.0582\n",
      "\n",
      "Start of epoch 491\n",
      "Training loss at epoch 491: 0.0582\n",
      "\n",
      "Start of epoch 492\n",
      "Training loss at epoch 492: 0.0582\n",
      "\n",
      "Start of epoch 493\n",
      "Training loss at epoch 493: 0.0582\n",
      "\n",
      "Start of epoch 494\n",
      "Training loss at epoch 494: 0.0582\n",
      "\n",
      "Start of epoch 495\n",
      "Training loss at epoch 495: 0.0582\n",
      "\n",
      "Start of epoch 496\n",
      "Training loss at epoch 496: 0.0582\n",
      "\n",
      "Start of epoch 497\n",
      "Training loss at epoch 497: 0.0582\n",
      "\n",
      "Start of epoch 498\n",
      "Training loss at epoch 498: 0.0582\n",
      "\n",
      "Start of epoch 499\n",
      "Training loss at epoch 499: 0.0582\n",
      "[<tf.Variable 'parameters:0' shape=(45,) dtype=float32, numpy=\n",
      "array([5.758013 , 4.0105486, 3.754209 , 4.0688653, 5.02849  , 2.576129 ,\n",
      "       2.9552164, 3.902577 , 0.3704189, 3.4743483, 4.354617 , 1.6082119,\n",
      "       2.105071 , 1.9847779, 2.747475 , 3.0552802, 4.1839643, 1.8599869,\n",
      "       4.4213295, 6.236183 , 5.877958 , 4.25203  , 3.8420122, 1.1890336,\n",
      "       5.592916 , 4.1885495, 5.3243613, 2.920841 , 3.118377 , 4.149151 ,\n",
      "       4.3215394, 6.123296 , 4.98194  , 3.3708563, 1.4636986, 2.7722576,\n",
      "       2.176237 , 4.3324246, 4.508661 , 4.9532037, 6.2548923, 4.710314 ,\n",
      "       3.1272805, 5.858983 , 0.9667997], dtype=float32)>]\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.0145\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 0.9611\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.9067\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.8540\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.8094\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.7799\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.7631\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.7503\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.7361\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.7201\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.7037\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.6886\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.6763\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.6665\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.6577\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.6486\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.6391\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.6297\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.6211\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.6135\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.6067\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.5997\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.5918\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.5826\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.5727\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.5631\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.5545\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.5473\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.5411\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.5352\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.5291\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.5225\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.5153\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.5076\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.4997\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.4916\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.4833\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.4748\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.4663\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.4578\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.4498\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.4428\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.4371\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.4327\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.4292\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.4262\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.4230\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.4194\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.4156\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.4117\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.4080\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.4047\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.4015\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.3984\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.3955\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.3927\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.3902\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.3879\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.3856\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.3834\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.3816\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.3800\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.3784\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.3768\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.3749\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.3731\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.3712\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.3694\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.3678\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.3661\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.3646\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.3632\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.3618\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.3605\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.3592\n",
      "\n",
      "Start of epoch 75\n",
      "Training loss at epoch 75: 0.3579\n",
      "\n",
      "Start of epoch 76\n",
      "Training loss at epoch 76: 0.3566\n",
      "\n",
      "Start of epoch 77\n",
      "Training loss at epoch 77: 0.3554\n",
      "\n",
      "Start of epoch 78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 78: 0.3541\n",
      "\n",
      "Start of epoch 79\n",
      "Training loss at epoch 79: 0.3529\n",
      "\n",
      "Start of epoch 80\n",
      "Training loss at epoch 80: 0.3517\n",
      "\n",
      "Start of epoch 81\n",
      "Training loss at epoch 81: 0.3506\n",
      "\n",
      "Start of epoch 82\n",
      "Training loss at epoch 82: 0.3496\n",
      "\n",
      "Start of epoch 83\n",
      "Training loss at epoch 83: 0.3485\n",
      "\n",
      "Start of epoch 84\n",
      "Training loss at epoch 84: 0.3475\n",
      "\n",
      "Start of epoch 85\n",
      "Training loss at epoch 85: 0.3464\n",
      "\n",
      "Start of epoch 86\n",
      "Training loss at epoch 86: 0.3454\n",
      "\n",
      "Start of epoch 87\n",
      "Training loss at epoch 87: 0.3444\n",
      "\n",
      "Start of epoch 88\n",
      "Training loss at epoch 88: 0.3435\n",
      "\n",
      "Start of epoch 89\n",
      "Training loss at epoch 89: 0.3425\n",
      "\n",
      "Start of epoch 90\n",
      "Training loss at epoch 90: 0.3416\n",
      "\n",
      "Start of epoch 91\n",
      "Training loss at epoch 91: 0.3407\n",
      "\n",
      "Start of epoch 92\n",
      "Training loss at epoch 92: 0.3398\n",
      "\n",
      "Start of epoch 93\n",
      "Training loss at epoch 93: 0.3389\n",
      "\n",
      "Start of epoch 94\n",
      "Training loss at epoch 94: 0.3380\n",
      "\n",
      "Start of epoch 95\n",
      "Training loss at epoch 95: 0.3371\n",
      "\n",
      "Start of epoch 96\n",
      "Training loss at epoch 96: 0.3362\n",
      "\n",
      "Start of epoch 97\n",
      "Training loss at epoch 97: 0.3354\n",
      "\n",
      "Start of epoch 98\n",
      "Training loss at epoch 98: 0.3345\n",
      "\n",
      "Start of epoch 99\n",
      "Training loss at epoch 99: 0.3337\n",
      "\n",
      "Start of epoch 100\n",
      "Training loss at epoch 100: 0.3328\n",
      "\n",
      "Start of epoch 101\n",
      "Training loss at epoch 101: 0.3320\n",
      "\n",
      "Start of epoch 102\n",
      "Training loss at epoch 102: 0.3311\n",
      "\n",
      "Start of epoch 103\n",
      "Training loss at epoch 103: 0.3303\n",
      "\n",
      "Start of epoch 104\n",
      "Training loss at epoch 104: 0.3295\n",
      "\n",
      "Start of epoch 105\n",
      "Training loss at epoch 105: 0.3287\n",
      "\n",
      "Start of epoch 106\n",
      "Training loss at epoch 106: 0.3279\n",
      "\n",
      "Start of epoch 107\n",
      "Training loss at epoch 107: 0.3271\n",
      "\n",
      "Start of epoch 108\n",
      "Training loss at epoch 108: 0.3263\n",
      "\n",
      "Start of epoch 109\n",
      "Training loss at epoch 109: 0.3255\n",
      "\n",
      "Start of epoch 110\n",
      "Training loss at epoch 110: 0.3248\n",
      "\n",
      "Start of epoch 111\n",
      "Training loss at epoch 111: 0.3240\n",
      "\n",
      "Start of epoch 112\n",
      "Training loss at epoch 112: 0.3233\n",
      "\n",
      "Start of epoch 113\n",
      "Training loss at epoch 113: 0.3225\n",
      "\n",
      "Start of epoch 114\n",
      "Training loss at epoch 114: 0.3218\n",
      "\n",
      "Start of epoch 115\n",
      "Training loss at epoch 115: 0.3211\n",
      "\n",
      "Start of epoch 116\n",
      "Training loss at epoch 116: 0.3204\n",
      "\n",
      "Start of epoch 117\n",
      "Training loss at epoch 117: 0.3197\n",
      "\n",
      "Start of epoch 118\n",
      "Training loss at epoch 118: 0.3190\n",
      "\n",
      "Start of epoch 119\n",
      "Training loss at epoch 119: 0.3184\n",
      "\n",
      "Start of epoch 120\n",
      "Training loss at epoch 120: 0.3177\n",
      "\n",
      "Start of epoch 121\n",
      "Training loss at epoch 121: 0.3171\n",
      "\n",
      "Start of epoch 122\n",
      "Training loss at epoch 122: 0.3165\n",
      "\n",
      "Start of epoch 123\n",
      "Training loss at epoch 123: 0.3159\n",
      "\n",
      "Start of epoch 124\n",
      "Training loss at epoch 124: 0.3154\n",
      "\n",
      "Start of epoch 125\n",
      "Training loss at epoch 125: 0.3148\n",
      "\n",
      "Start of epoch 126\n",
      "Training loss at epoch 126: 0.3143\n",
      "\n",
      "Start of epoch 127\n",
      "Training loss at epoch 127: 0.3139\n",
      "\n",
      "Start of epoch 128\n",
      "Training loss at epoch 128: 0.3134\n",
      "\n",
      "Start of epoch 129\n",
      "Training loss at epoch 129: 0.3130\n",
      "\n",
      "Start of epoch 130\n",
      "Training loss at epoch 130: 0.3126\n",
      "\n",
      "Start of epoch 131\n",
      "Training loss at epoch 131: 0.3122\n",
      "\n",
      "Start of epoch 132\n",
      "Training loss at epoch 132: 0.3119\n",
      "\n",
      "Start of epoch 133\n",
      "Training loss at epoch 133: 0.3116\n",
      "\n",
      "Start of epoch 134\n",
      "Training loss at epoch 134: 0.3113\n",
      "\n",
      "Start of epoch 135\n",
      "Training loss at epoch 135: 0.3111\n",
      "\n",
      "Start of epoch 136\n",
      "Training loss at epoch 136: 0.3108\n",
      "\n",
      "Start of epoch 137\n",
      "Training loss at epoch 137: 0.3106\n",
      "\n",
      "Start of epoch 138\n",
      "Training loss at epoch 138: 0.3104\n",
      "\n",
      "Start of epoch 139\n",
      "Training loss at epoch 139: 0.3103\n",
      "\n",
      "Start of epoch 140\n",
      "Training loss at epoch 140: 0.3101\n",
      "\n",
      "Start of epoch 141\n",
      "Training loss at epoch 141: 0.3100\n",
      "\n",
      "Start of epoch 142\n",
      "Training loss at epoch 142: 0.3099\n",
      "\n",
      "Start of epoch 143\n",
      "Training loss at epoch 143: 0.3098\n",
      "\n",
      "Start of epoch 144\n",
      "Training loss at epoch 144: 0.3097\n",
      "\n",
      "Start of epoch 145\n",
      "Training loss at epoch 145: 0.3096\n",
      "\n",
      "Start of epoch 146\n",
      "Training loss at epoch 146: 0.3096\n",
      "\n",
      "Start of epoch 147\n",
      "Training loss at epoch 147: 0.3095\n",
      "\n",
      "Start of epoch 148\n",
      "Training loss at epoch 148: 0.3095\n",
      "\n",
      "Start of epoch 149\n",
      "Training loss at epoch 149: 0.3094\n",
      "\n",
      "Start of epoch 150\n",
      "Training loss at epoch 150: 0.3094\n",
      "\n",
      "Start of epoch 151\n",
      "Training loss at epoch 151: 0.3093\n",
      "\n",
      "Start of epoch 152\n",
      "Training loss at epoch 152: 0.3093\n",
      "\n",
      "Start of epoch 153\n",
      "Training loss at epoch 153: 0.3093\n",
      "\n",
      "Start of epoch 154\n",
      "Training loss at epoch 154: 0.3092\n",
      "\n",
      "Start of epoch 155\n",
      "Training loss at epoch 155: 0.3092\n",
      "\n",
      "Start of epoch 156\n",
      "Training loss at epoch 156: 0.3092\n",
      "\n",
      "Start of epoch 157\n",
      "Training loss at epoch 157: 0.3092\n",
      "\n",
      "Start of epoch 158\n",
      "Training loss at epoch 158: 0.3091\n",
      "\n",
      "Start of epoch 159\n",
      "Training loss at epoch 159: 0.3091\n",
      "\n",
      "Start of epoch 160\n",
      "Training loss at epoch 160: 0.3091\n",
      "\n",
      "Start of epoch 161\n",
      "Training loss at epoch 161: 0.3091\n",
      "\n",
      "Start of epoch 162\n",
      "Training loss at epoch 162: 0.3091\n",
      "\n",
      "Start of epoch 163\n",
      "Training loss at epoch 163: 0.3090\n",
      "\n",
      "Start of epoch 164\n",
      "Training loss at epoch 164: 0.3090\n",
      "\n",
      "Start of epoch 165\n",
      "Training loss at epoch 165: 0.3090\n",
      "\n",
      "Start of epoch 166\n",
      "Training loss at epoch 166: 0.3090\n",
      "\n",
      "Start of epoch 167\n",
      "Training loss at epoch 167: 0.3090\n",
      "\n",
      "Start of epoch 168\n",
      "Training loss at epoch 168: 0.3089\n",
      "\n",
      "Start of epoch 169\n",
      "Training loss at epoch 169: 0.3089\n",
      "\n",
      "Start of epoch 170\n",
      "Training loss at epoch 170: 0.3089\n",
      "\n",
      "Start of epoch 171\n",
      "Training loss at epoch 171: 0.3089\n",
      "\n",
      "Start of epoch 172\n",
      "Training loss at epoch 172: 0.3089\n",
      "\n",
      "Start of epoch 173\n",
      "Training loss at epoch 173: 0.3088\n",
      "\n",
      "Start of epoch 174\n",
      "Training loss at epoch 174: 0.3088\n",
      "\n",
      "Start of epoch 175\n",
      "Training loss at epoch 175: 0.3088\n",
      "\n",
      "Start of epoch 176\n",
      "Training loss at epoch 176: 0.3088\n",
      "\n",
      "Start of epoch 177\n",
      "Training loss at epoch 177: 0.3087\n",
      "\n",
      "Start of epoch 178\n",
      "Training loss at epoch 178: 0.3087\n",
      "\n",
      "Start of epoch 179\n",
      "Training loss at epoch 179: 0.3087\n",
      "\n",
      "Start of epoch 180\n",
      "Training loss at epoch 180: 0.3087\n",
      "\n",
      "Start of epoch 181\n",
      "Training loss at epoch 181: 0.3087\n",
      "\n",
      "Start of epoch 182\n",
      "Training loss at epoch 182: 0.3086\n",
      "\n",
      "Start of epoch 183\n",
      "Training loss at epoch 183: 0.3086\n",
      "\n",
      "Start of epoch 184\n",
      "Training loss at epoch 184: 0.3086\n",
      "\n",
      "Start of epoch 185\n",
      "Training loss at epoch 185: 0.3086\n",
      "\n",
      "Start of epoch 186\n",
      "Training loss at epoch 186: 0.3086\n",
      "\n",
      "Start of epoch 187\n",
      "Training loss at epoch 187: 0.3085\n",
      "\n",
      "Start of epoch 188\n",
      "Training loss at epoch 188: 0.3085\n",
      "\n",
      "Start of epoch 189\n",
      "Training loss at epoch 189: 0.3085\n",
      "\n",
      "Start of epoch 190\n",
      "Training loss at epoch 190: 0.3085\n",
      "\n",
      "Start of epoch 191\n",
      "Training loss at epoch 191: 0.3084\n",
      "\n",
      "Start of epoch 192\n",
      "Training loss at epoch 192: 0.3084\n",
      "\n",
      "Start of epoch 193\n",
      "Training loss at epoch 193: 0.3084\n",
      "\n",
      "Start of epoch 194\n",
      "Training loss at epoch 194: 0.3084\n",
      "\n",
      "Start of epoch 195\n",
      "Training loss at epoch 195: 0.3084\n",
      "\n",
      "Start of epoch 196\n",
      "Training loss at epoch 196: 0.3083\n",
      "\n",
      "Start of epoch 197\n",
      "Training loss at epoch 197: 0.3083\n",
      "\n",
      "Start of epoch 198\n",
      "Training loss at epoch 198: 0.3083\n",
      "\n",
      "Start of epoch 199\n",
      "Training loss at epoch 199: 0.3083\n",
      "\n",
      "Start of epoch 200\n",
      "Training loss at epoch 200: 0.3082\n",
      "\n",
      "Start of epoch 201\n",
      "Training loss at epoch 201: 0.3082\n",
      "\n",
      "Start of epoch 202\n",
      "Training loss at epoch 202: 0.3082\n",
      "\n",
      "Start of epoch 203\n",
      "Training loss at epoch 203: 0.3081\n",
      "\n",
      "Start of epoch 204\n",
      "Training loss at epoch 204: 0.3081\n",
      "\n",
      "Start of epoch 205\n",
      "Training loss at epoch 205: 0.3081\n",
      "\n",
      "Start of epoch 206\n",
      "Training loss at epoch 206: 0.3081\n",
      "\n",
      "Start of epoch 207\n",
      "Training loss at epoch 207: 0.3080\n",
      "\n",
      "Start of epoch 208\n",
      "Training loss at epoch 208: 0.3080\n",
      "\n",
      "Start of epoch 209\n",
      "Training loss at epoch 209: 0.3080\n",
      "\n",
      "Start of epoch 210\n",
      "Training loss at epoch 210: 0.3079\n",
      "\n",
      "Start of epoch 211\n",
      "Training loss at epoch 211: 0.3079\n",
      "\n",
      "Start of epoch 212\n",
      "Training loss at epoch 212: 0.3079\n",
      "\n",
      "Start of epoch 213\n",
      "Training loss at epoch 213: 0.3078\n",
      "\n",
      "Start of epoch 214\n",
      "Training loss at epoch 214: 0.3078\n",
      "\n",
      "Start of epoch 215\n",
      "Training loss at epoch 215: 0.3078\n",
      "\n",
      "Start of epoch 216\n",
      "Training loss at epoch 216: 0.3077\n",
      "\n",
      "Start of epoch 217\n",
      "Training loss at epoch 217: 0.3077\n",
      "\n",
      "Start of epoch 218\n",
      "Training loss at epoch 218: 0.3077\n",
      "\n",
      "Start of epoch 219\n",
      "Training loss at epoch 219: 0.3076\n",
      "\n",
      "Start of epoch 220\n",
      "Training loss at epoch 220: 0.3076\n",
      "\n",
      "Start of epoch 221\n",
      "Training loss at epoch 221: 0.3075\n",
      "\n",
      "Start of epoch 222\n",
      "Training loss at epoch 222: 0.3075\n",
      "\n",
      "Start of epoch 223\n",
      "Training loss at epoch 223: 0.3075\n",
      "\n",
      "Start of epoch 224\n",
      "Training loss at epoch 224: 0.3074\n",
      "\n",
      "Start of epoch 225\n",
      "Training loss at epoch 225: 0.3074\n",
      "\n",
      "Start of epoch 226\n",
      "Training loss at epoch 226: 0.3073\n",
      "\n",
      "Start of epoch 227\n",
      "Training loss at epoch 227: 0.3073\n",
      "\n",
      "Start of epoch 228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 228: 0.3073\n",
      "\n",
      "Start of epoch 229\n",
      "Training loss at epoch 229: 0.3072\n",
      "\n",
      "Start of epoch 230\n",
      "Training loss at epoch 230: 0.3072\n",
      "\n",
      "Start of epoch 231\n",
      "Training loss at epoch 231: 0.3071\n",
      "\n",
      "Start of epoch 232\n",
      "Training loss at epoch 232: 0.3071\n",
      "\n",
      "Start of epoch 233\n",
      "Training loss at epoch 233: 0.3070\n",
      "\n",
      "Start of epoch 234\n",
      "Training loss at epoch 234: 0.3070\n",
      "\n",
      "Start of epoch 235\n",
      "Training loss at epoch 235: 0.3069\n",
      "\n",
      "Start of epoch 236\n",
      "Training loss at epoch 236: 0.3069\n",
      "\n",
      "Start of epoch 237\n",
      "Training loss at epoch 237: 0.3068\n",
      "\n",
      "Start of epoch 238\n",
      "Training loss at epoch 238: 0.3068\n",
      "\n",
      "Start of epoch 239\n",
      "Training loss at epoch 239: 0.3067\n",
      "\n",
      "Start of epoch 240\n",
      "Training loss at epoch 240: 0.3067\n",
      "\n",
      "Start of epoch 241\n",
      "Training loss at epoch 241: 0.3066\n",
      "\n",
      "Start of epoch 242\n",
      "Training loss at epoch 242: 0.3066\n",
      "\n",
      "Start of epoch 243\n",
      "Training loss at epoch 243: 0.3065\n",
      "\n",
      "Start of epoch 244\n",
      "Training loss at epoch 244: 0.3065\n",
      "\n",
      "Start of epoch 245\n",
      "Training loss at epoch 245: 0.3064\n",
      "\n",
      "Start of epoch 246\n",
      "Training loss at epoch 246: 0.3064\n",
      "\n",
      "Start of epoch 247\n",
      "Training loss at epoch 247: 0.3063\n",
      "\n",
      "Start of epoch 248\n",
      "Training loss at epoch 248: 0.3062\n",
      "\n",
      "Start of epoch 249\n",
      "Training loss at epoch 249: 0.3062\n",
      "\n",
      "Start of epoch 250\n",
      "Training loss at epoch 250: 0.3061\n",
      "\n",
      "Start of epoch 251\n",
      "Training loss at epoch 251: 0.3061\n",
      "\n",
      "Start of epoch 252\n",
      "Training loss at epoch 252: 0.3060\n",
      "\n",
      "Start of epoch 253\n",
      "Training loss at epoch 253: 0.3060\n",
      "\n",
      "Start of epoch 254\n",
      "Training loss at epoch 254: 0.3059\n",
      "\n",
      "Start of epoch 255\n",
      "Training loss at epoch 255: 0.3058\n",
      "\n",
      "Start of epoch 256\n",
      "Training loss at epoch 256: 0.3058\n",
      "\n",
      "Start of epoch 257\n",
      "Training loss at epoch 257: 0.3057\n",
      "\n",
      "Start of epoch 258\n",
      "Training loss at epoch 258: 0.3056\n",
      "\n",
      "Start of epoch 259\n",
      "Training loss at epoch 259: 0.3056\n",
      "\n",
      "Start of epoch 260\n",
      "Training loss at epoch 260: 0.3055\n",
      "\n",
      "Start of epoch 261\n",
      "Training loss at epoch 261: 0.3055\n",
      "\n",
      "Start of epoch 262\n",
      "Training loss at epoch 262: 0.3054\n",
      "\n",
      "Start of epoch 263\n",
      "Training loss at epoch 263: 0.3053\n",
      "\n",
      "Start of epoch 264\n",
      "Training loss at epoch 264: 0.3053\n",
      "\n",
      "Start of epoch 265\n",
      "Training loss at epoch 265: 0.3052\n",
      "\n",
      "Start of epoch 266\n",
      "Training loss at epoch 266: 0.3051\n",
      "\n",
      "Start of epoch 267\n",
      "Training loss at epoch 267: 0.3051\n",
      "\n",
      "Start of epoch 268\n",
      "Training loss at epoch 268: 0.3050\n",
      "\n",
      "Start of epoch 269\n",
      "Training loss at epoch 269: 0.3049\n",
      "\n",
      "Start of epoch 270\n",
      "Training loss at epoch 270: 0.3049\n",
      "\n",
      "Start of epoch 271\n",
      "Training loss at epoch 271: 0.3048\n",
      "\n",
      "Start of epoch 272\n",
      "Training loss at epoch 272: 0.3047\n",
      "\n",
      "Start of epoch 273\n",
      "Training loss at epoch 273: 0.3046\n",
      "\n",
      "Start of epoch 274\n",
      "Training loss at epoch 274: 0.3046\n",
      "\n",
      "Start of epoch 275\n",
      "Training loss at epoch 275: 0.3045\n",
      "\n",
      "Start of epoch 276\n",
      "Training loss at epoch 276: 0.3044\n",
      "\n",
      "Start of epoch 277\n",
      "Training loss at epoch 277: 0.3044\n",
      "\n",
      "Start of epoch 278\n",
      "Training loss at epoch 278: 0.3043\n",
      "\n",
      "Start of epoch 279\n",
      "Training loss at epoch 279: 0.3042\n",
      "\n",
      "Start of epoch 280\n",
      "Training loss at epoch 280: 0.3041\n",
      "\n",
      "Start of epoch 281\n",
      "Training loss at epoch 281: 0.3041\n",
      "\n",
      "Start of epoch 282\n",
      "Training loss at epoch 282: 0.3040\n",
      "\n",
      "Start of epoch 283\n",
      "Training loss at epoch 283: 0.3039\n",
      "\n",
      "Start of epoch 284\n",
      "Training loss at epoch 284: 0.3038\n",
      "\n",
      "Start of epoch 285\n",
      "Training loss at epoch 285: 0.3038\n",
      "\n",
      "Start of epoch 286\n",
      "Training loss at epoch 286: 0.3037\n",
      "\n",
      "Start of epoch 287\n",
      "Training loss at epoch 287: 0.3036\n",
      "\n",
      "Start of epoch 288\n",
      "Training loss at epoch 288: 0.3035\n",
      "\n",
      "Start of epoch 289\n",
      "Training loss at epoch 289: 0.3034\n",
      "\n",
      "Start of epoch 290\n",
      "Training loss at epoch 290: 0.3034\n",
      "\n",
      "Start of epoch 291\n",
      "Training loss at epoch 291: 0.3033\n",
      "\n",
      "Start of epoch 292\n",
      "Training loss at epoch 292: 0.3032\n",
      "\n",
      "Start of epoch 293\n",
      "Training loss at epoch 293: 0.3031\n",
      "\n",
      "Start of epoch 294\n",
      "Training loss at epoch 294: 0.3030\n",
      "\n",
      "Start of epoch 295\n",
      "Training loss at epoch 295: 0.3030\n",
      "\n",
      "Start of epoch 296\n",
      "Training loss at epoch 296: 0.3029\n",
      "\n",
      "Start of epoch 297\n",
      "Training loss at epoch 297: 0.3028\n",
      "\n",
      "Start of epoch 298\n",
      "Training loss at epoch 298: 0.3027\n",
      "\n",
      "Start of epoch 299\n",
      "Training loss at epoch 299: 0.3026\n",
      "\n",
      "Start of epoch 300\n",
      "Training loss at epoch 300: 0.3025\n",
      "\n",
      "Start of epoch 301\n",
      "Training loss at epoch 301: 0.3025\n",
      "\n",
      "Start of epoch 302\n",
      "Training loss at epoch 302: 0.3024\n",
      "\n",
      "Start of epoch 303\n",
      "Training loss at epoch 303: 0.3023\n",
      "\n",
      "Start of epoch 304\n",
      "Training loss at epoch 304: 0.3022\n",
      "\n",
      "Start of epoch 305\n",
      "Training loss at epoch 305: 0.3021\n",
      "\n",
      "Start of epoch 306\n",
      "Training loss at epoch 306: 0.3020\n",
      "\n",
      "Start of epoch 307\n",
      "Training loss at epoch 307: 0.3019\n",
      "\n",
      "Start of epoch 308\n",
      "Training loss at epoch 308: 0.3018\n",
      "\n",
      "Start of epoch 309\n",
      "Training loss at epoch 309: 0.3018\n",
      "\n",
      "Start of epoch 310\n",
      "Training loss at epoch 310: 0.3017\n",
      "\n",
      "Start of epoch 311\n",
      "Training loss at epoch 311: 0.3016\n",
      "\n",
      "Start of epoch 312\n",
      "Training loss at epoch 312: 0.3015\n",
      "\n",
      "Start of epoch 313\n",
      "Training loss at epoch 313: 0.3014\n",
      "\n",
      "Start of epoch 314\n",
      "Training loss at epoch 314: 0.3013\n",
      "\n",
      "Start of epoch 315\n",
      "Training loss at epoch 315: 0.3012\n",
      "\n",
      "Start of epoch 316\n",
      "Training loss at epoch 316: 0.3011\n",
      "\n",
      "Start of epoch 317\n",
      "Training loss at epoch 317: 0.3010\n",
      "\n",
      "Start of epoch 318\n",
      "Training loss at epoch 318: 0.3009\n",
      "\n",
      "Start of epoch 319\n",
      "Training loss at epoch 319: 0.3009\n",
      "\n",
      "Start of epoch 320\n",
      "Training loss at epoch 320: 0.3008\n",
      "\n",
      "Start of epoch 321\n",
      "Training loss at epoch 321: 0.3007\n",
      "\n",
      "Start of epoch 322\n",
      "Training loss at epoch 322: 0.3006\n",
      "\n",
      "Start of epoch 323\n",
      "Training loss at epoch 323: 0.3005\n",
      "\n",
      "Start of epoch 324\n",
      "Training loss at epoch 324: 0.3004\n",
      "\n",
      "Start of epoch 325\n",
      "Training loss at epoch 325: 0.3003\n",
      "\n",
      "Start of epoch 326\n",
      "Training loss at epoch 326: 0.3002\n",
      "\n",
      "Start of epoch 327\n",
      "Training loss at epoch 327: 0.3001\n",
      "\n",
      "Start of epoch 328\n",
      "Training loss at epoch 328: 0.3000\n",
      "\n",
      "Start of epoch 329\n",
      "Training loss at epoch 329: 0.2999\n",
      "\n",
      "Start of epoch 330\n",
      "Training loss at epoch 330: 0.2998\n",
      "\n",
      "Start of epoch 331\n",
      "Training loss at epoch 331: 0.2997\n",
      "\n",
      "Start of epoch 332\n",
      "Training loss at epoch 332: 0.2996\n",
      "\n",
      "Start of epoch 333\n",
      "Training loss at epoch 333: 0.2995\n",
      "\n",
      "Start of epoch 334\n",
      "Training loss at epoch 334: 0.2994\n",
      "\n",
      "Start of epoch 335\n",
      "Training loss at epoch 335: 0.2993\n",
      "\n",
      "Start of epoch 336\n",
      "Training loss at epoch 336: 0.2992\n",
      "\n",
      "Start of epoch 337\n",
      "Training loss at epoch 337: 0.2991\n",
      "\n",
      "Start of epoch 338\n",
      "Training loss at epoch 338: 0.2990\n",
      "\n",
      "Start of epoch 339\n",
      "Training loss at epoch 339: 0.2988\n",
      "\n",
      "Start of epoch 340\n",
      "Training loss at epoch 340: 0.2987\n",
      "\n",
      "Start of epoch 341\n",
      "Training loss at epoch 341: 0.2986\n",
      "\n",
      "Start of epoch 342\n",
      "Training loss at epoch 342: 0.2985\n",
      "\n",
      "Start of epoch 343\n",
      "Training loss at epoch 343: 0.2984\n",
      "\n",
      "Start of epoch 344\n",
      "Training loss at epoch 344: 0.2983\n",
      "\n",
      "Start of epoch 345\n",
      "Training loss at epoch 345: 0.2982\n",
      "\n",
      "Start of epoch 346\n",
      "Training loss at epoch 346: 0.2980\n",
      "\n",
      "Start of epoch 347\n",
      "Training loss at epoch 347: 0.2979\n",
      "\n",
      "Start of epoch 348\n",
      "Training loss at epoch 348: 0.2978\n",
      "\n",
      "Start of epoch 349\n",
      "Training loss at epoch 349: 0.2977\n",
      "\n",
      "Start of epoch 350\n",
      "Training loss at epoch 350: 0.2976\n",
      "\n",
      "Start of epoch 351\n",
      "Training loss at epoch 351: 0.2974\n",
      "\n",
      "Start of epoch 352\n",
      "Training loss at epoch 352: 0.2973\n",
      "\n",
      "Start of epoch 353\n",
      "Training loss at epoch 353: 0.2972\n",
      "\n",
      "Start of epoch 354\n",
      "Training loss at epoch 354: 0.2970\n",
      "\n",
      "Start of epoch 355\n",
      "Training loss at epoch 355: 0.2969\n",
      "\n",
      "Start of epoch 356\n",
      "Training loss at epoch 356: 0.2968\n",
      "\n",
      "Start of epoch 357\n",
      "Training loss at epoch 357: 0.2966\n",
      "\n",
      "Start of epoch 358\n",
      "Training loss at epoch 358: 0.2965\n",
      "\n",
      "Start of epoch 359\n",
      "Training loss at epoch 359: 0.2964\n",
      "\n",
      "Start of epoch 360\n",
      "Training loss at epoch 360: 0.2962\n",
      "\n",
      "Start of epoch 361\n",
      "Training loss at epoch 361: 0.2961\n",
      "\n",
      "Start of epoch 362\n",
      "Training loss at epoch 362: 0.2959\n",
      "\n",
      "Start of epoch 363\n",
      "Training loss at epoch 363: 0.2958\n",
      "\n",
      "Start of epoch 364\n",
      "Training loss at epoch 364: 0.2956\n",
      "\n",
      "Start of epoch 365\n",
      "Training loss at epoch 365: 0.2955\n",
      "\n",
      "Start of epoch 366\n",
      "Training loss at epoch 366: 0.2953\n",
      "\n",
      "Start of epoch 367\n",
      "Training loss at epoch 367: 0.2951\n",
      "\n",
      "Start of epoch 368\n",
      "Training loss at epoch 368: 0.2950\n",
      "\n",
      "Start of epoch 369\n",
      "Training loss at epoch 369: 0.2948\n",
      "\n",
      "Start of epoch 370\n",
      "Training loss at epoch 370: 0.2947\n",
      "\n",
      "Start of epoch 371\n",
      "Training loss at epoch 371: 0.2945\n",
      "\n",
      "Start of epoch 372\n",
      "Training loss at epoch 372: 0.2943\n",
      "\n",
      "Start of epoch 373\n",
      "Training loss at epoch 373: 0.2941\n",
      "\n",
      "Start of epoch 374\n",
      "Training loss at epoch 374: 0.2940\n",
      "\n",
      "Start of epoch 375\n",
      "Training loss at epoch 375: 0.2938\n",
      "\n",
      "Start of epoch 376\n",
      "Training loss at epoch 376: 0.2936\n",
      "\n",
      "Start of epoch 377\n",
      "Training loss at epoch 377: 0.2934\n",
      "\n",
      "Start of epoch 378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 378: 0.2933\n",
      "\n",
      "Start of epoch 379\n",
      "Training loss at epoch 379: 0.2931\n",
      "\n",
      "Start of epoch 380\n",
      "Training loss at epoch 380: 0.2929\n",
      "\n",
      "Start of epoch 381\n",
      "Training loss at epoch 381: 0.2927\n",
      "\n",
      "Start of epoch 382\n",
      "Training loss at epoch 382: 0.2925\n",
      "\n",
      "Start of epoch 383\n",
      "Training loss at epoch 383: 0.2923\n",
      "\n",
      "Start of epoch 384\n",
      "Training loss at epoch 384: 0.2921\n",
      "\n",
      "Start of epoch 385\n",
      "Training loss at epoch 385: 0.2919\n",
      "\n",
      "Start of epoch 386\n",
      "Training loss at epoch 386: 0.2917\n",
      "\n",
      "Start of epoch 387\n",
      "Training loss at epoch 387: 0.2915\n",
      "\n",
      "Start of epoch 388\n",
      "Training loss at epoch 388: 0.2913\n",
      "\n",
      "Start of epoch 389\n",
      "Training loss at epoch 389: 0.2912\n",
      "\n",
      "Start of epoch 390\n",
      "Training loss at epoch 390: 0.2910\n",
      "\n",
      "Start of epoch 391\n",
      "Training loss at epoch 391: 0.2908\n",
      "\n",
      "Start of epoch 392\n",
      "Training loss at epoch 392: 0.2906\n",
      "\n",
      "Start of epoch 393\n",
      "Training loss at epoch 393: 0.2904\n",
      "\n",
      "Start of epoch 394\n",
      "Training loss at epoch 394: 0.2902\n",
      "\n",
      "Start of epoch 395\n",
      "Training loss at epoch 395: 0.2900\n",
      "\n",
      "Start of epoch 396\n",
      "Training loss at epoch 396: 0.2898\n",
      "\n",
      "Start of epoch 397\n",
      "Training loss at epoch 397: 0.2896\n",
      "\n",
      "Start of epoch 398\n",
      "Training loss at epoch 398: 0.2894\n",
      "\n",
      "Start of epoch 399\n",
      "Training loss at epoch 399: 0.2892\n",
      "\n",
      "Start of epoch 400\n",
      "Training loss at epoch 400: 0.2890\n",
      "\n",
      "Start of epoch 401\n",
      "Training loss at epoch 401: 0.2888\n",
      "\n",
      "Start of epoch 402\n",
      "Training loss at epoch 402: 0.2886\n",
      "\n",
      "Start of epoch 403\n",
      "Training loss at epoch 403: 0.2884\n",
      "\n",
      "Start of epoch 404\n",
      "Training loss at epoch 404: 0.2883\n",
      "\n",
      "Start of epoch 405\n",
      "Training loss at epoch 405: 0.2881\n",
      "\n",
      "Start of epoch 406\n",
      "Training loss at epoch 406: 0.2879\n",
      "\n",
      "Start of epoch 407\n",
      "Training loss at epoch 407: 0.2877\n",
      "\n",
      "Start of epoch 408\n",
      "Training loss at epoch 408: 0.2875\n",
      "\n",
      "Start of epoch 409\n",
      "Training loss at epoch 409: 0.2874\n",
      "\n",
      "Start of epoch 410\n",
      "Training loss at epoch 410: 0.2872\n",
      "\n",
      "Start of epoch 411\n",
      "Training loss at epoch 411: 0.2870\n",
      "\n",
      "Start of epoch 412\n",
      "Training loss at epoch 412: 0.2869\n",
      "\n",
      "Start of epoch 413\n",
      "Training loss at epoch 413: 0.2867\n",
      "\n",
      "Start of epoch 414\n",
      "Training loss at epoch 414: 0.2866\n",
      "\n",
      "Start of epoch 415\n",
      "Training loss at epoch 415: 0.2864\n",
      "\n",
      "Start of epoch 416\n",
      "Training loss at epoch 416: 0.2863\n",
      "\n",
      "Start of epoch 417\n",
      "Training loss at epoch 417: 0.2861\n",
      "\n",
      "Start of epoch 418\n",
      "Training loss at epoch 418: 0.2860\n",
      "\n",
      "Start of epoch 419\n",
      "Training loss at epoch 419: 0.2859\n",
      "\n",
      "Start of epoch 420\n",
      "Training loss at epoch 420: 0.2857\n",
      "\n",
      "Start of epoch 421\n",
      "Training loss at epoch 421: 0.2856\n",
      "\n",
      "Start of epoch 422\n",
      "Training loss at epoch 422: 0.2855\n",
      "\n",
      "Start of epoch 423\n",
      "Training loss at epoch 423: 0.2854\n",
      "\n",
      "Start of epoch 424\n",
      "Training loss at epoch 424: 0.2852\n",
      "\n",
      "Start of epoch 425\n",
      "Training loss at epoch 425: 0.2851\n",
      "\n",
      "Start of epoch 426\n",
      "Training loss at epoch 426: 0.2850\n",
      "\n",
      "Start of epoch 427\n",
      "Training loss at epoch 427: 0.2849\n",
      "\n",
      "Start of epoch 428\n",
      "Training loss at epoch 428: 0.2848\n",
      "\n",
      "Start of epoch 429\n",
      "Training loss at epoch 429: 0.2847\n",
      "\n",
      "Start of epoch 430\n",
      "Training loss at epoch 430: 0.2846\n",
      "\n",
      "Start of epoch 431\n",
      "Training loss at epoch 431: 0.2845\n",
      "\n",
      "Start of epoch 432\n",
      "Training loss at epoch 432: 0.2844\n",
      "\n",
      "Start of epoch 433\n",
      "Training loss at epoch 433: 0.2843\n",
      "\n",
      "Start of epoch 434\n",
      "Training loss at epoch 434: 0.2842\n",
      "\n",
      "Start of epoch 435\n",
      "Training loss at epoch 435: 0.2841\n",
      "\n",
      "Start of epoch 436\n",
      "Training loss at epoch 436: 0.2840\n",
      "\n",
      "Start of epoch 437\n",
      "Training loss at epoch 437: 0.2840\n",
      "\n",
      "Start of epoch 438\n",
      "Training loss at epoch 438: 0.2839\n",
      "\n",
      "Start of epoch 439\n",
      "Training loss at epoch 439: 0.2838\n",
      "\n",
      "Start of epoch 440\n",
      "Training loss at epoch 440: 0.2837\n",
      "\n",
      "Start of epoch 441\n",
      "Training loss at epoch 441: 0.2836\n",
      "\n",
      "Start of epoch 442\n",
      "Training loss at epoch 442: 0.2836\n",
      "\n",
      "Start of epoch 443\n",
      "Training loss at epoch 443: 0.2835\n",
      "\n",
      "Start of epoch 444\n",
      "Training loss at epoch 444: 0.2834\n",
      "\n",
      "Start of epoch 445\n",
      "Training loss at epoch 445: 0.2834\n",
      "\n",
      "Start of epoch 446\n",
      "Training loss at epoch 446: 0.2833\n",
      "\n",
      "Start of epoch 447\n",
      "Training loss at epoch 447: 0.2832\n",
      "\n",
      "Start of epoch 448\n",
      "Training loss at epoch 448: 0.2832\n",
      "\n",
      "Start of epoch 449\n",
      "Training loss at epoch 449: 0.2831\n",
      "\n",
      "Start of epoch 450\n",
      "Training loss at epoch 450: 0.2830\n",
      "\n",
      "Start of epoch 451\n",
      "Training loss at epoch 451: 0.2830\n",
      "\n",
      "Start of epoch 452\n",
      "Training loss at epoch 452: 0.2829\n",
      "\n",
      "Start of epoch 453\n",
      "Training loss at epoch 453: 0.2828\n",
      "\n",
      "Start of epoch 454\n",
      "Training loss at epoch 454: 0.2828\n",
      "\n",
      "Start of epoch 455\n",
      "Training loss at epoch 455: 0.2827\n",
      "\n",
      "Start of epoch 456\n",
      "Training loss at epoch 456: 0.2827\n",
      "\n",
      "Start of epoch 457\n",
      "Training loss at epoch 457: 0.2826\n",
      "\n",
      "Start of epoch 458\n",
      "Training loss at epoch 458: 0.2826\n",
      "\n",
      "Start of epoch 459\n",
      "Training loss at epoch 459: 0.2825\n",
      "\n",
      "Start of epoch 460\n",
      "Training loss at epoch 460: 0.2825\n",
      "\n",
      "Start of epoch 461\n",
      "Training loss at epoch 461: 0.2824\n",
      "\n",
      "Start of epoch 462\n",
      "Training loss at epoch 462: 0.2823\n",
      "\n",
      "Start of epoch 463\n",
      "Training loss at epoch 463: 0.2823\n",
      "\n",
      "Start of epoch 464\n",
      "Training loss at epoch 464: 0.2822\n",
      "\n",
      "Start of epoch 465\n",
      "Training loss at epoch 465: 0.2822\n",
      "\n",
      "Start of epoch 466\n",
      "Training loss at epoch 466: 0.2821\n",
      "\n",
      "Start of epoch 467\n",
      "Training loss at epoch 467: 0.2821\n",
      "\n",
      "Start of epoch 468\n",
      "Training loss at epoch 468: 0.2821\n",
      "\n",
      "Start of epoch 469\n",
      "Training loss at epoch 469: 0.2820\n",
      "\n",
      "Start of epoch 470\n",
      "Training loss at epoch 470: 0.2820\n",
      "\n",
      "Start of epoch 471\n",
      "Training loss at epoch 471: 0.2819\n",
      "\n",
      "Start of epoch 472\n",
      "Training loss at epoch 472: 0.2819\n",
      "\n",
      "Start of epoch 473\n",
      "Training loss at epoch 473: 0.2818\n",
      "\n",
      "Start of epoch 474\n",
      "Training loss at epoch 474: 0.2818\n",
      "\n",
      "Start of epoch 475\n",
      "Training loss at epoch 475: 0.2817\n",
      "\n",
      "Start of epoch 476\n",
      "Training loss at epoch 476: 0.2817\n",
      "\n",
      "Start of epoch 477\n",
      "Training loss at epoch 477: 0.2816\n",
      "\n",
      "Start of epoch 478\n",
      "Training loss at epoch 478: 0.2816\n",
      "\n",
      "Start of epoch 479\n",
      "Training loss at epoch 479: 0.2816\n",
      "\n",
      "Start of epoch 480\n",
      "Training loss at epoch 480: 0.2815\n",
      "\n",
      "Start of epoch 481\n",
      "Training loss at epoch 481: 0.2815\n",
      "\n",
      "Start of epoch 482\n",
      "Training loss at epoch 482: 0.2814\n",
      "\n",
      "Start of epoch 483\n",
      "Training loss at epoch 483: 0.2814\n",
      "\n",
      "Start of epoch 484\n",
      "Training loss at epoch 484: 0.2814\n",
      "\n",
      "Start of epoch 485\n",
      "Training loss at epoch 485: 0.2813\n",
      "\n",
      "Start of epoch 486\n",
      "Training loss at epoch 486: 0.2813\n",
      "\n",
      "Start of epoch 487\n",
      "Training loss at epoch 487: 0.2813\n",
      "\n",
      "Start of epoch 488\n",
      "Training loss at epoch 488: 0.2812\n",
      "\n",
      "Start of epoch 489\n",
      "Training loss at epoch 489: 0.2812\n",
      "\n",
      "Start of epoch 490\n",
      "Training loss at epoch 490: 0.2811\n",
      "\n",
      "Start of epoch 491\n",
      "Training loss at epoch 491: 0.2811\n",
      "\n",
      "Start of epoch 492\n",
      "Training loss at epoch 492: 0.2811\n",
      "\n",
      "Start of epoch 493\n",
      "Training loss at epoch 493: 0.2810\n",
      "\n",
      "Start of epoch 494\n",
      "Training loss at epoch 494: 0.2810\n",
      "\n",
      "Start of epoch 495\n",
      "Training loss at epoch 495: 0.2810\n",
      "\n",
      "Start of epoch 496\n",
      "Training loss at epoch 496: 0.2809\n",
      "\n",
      "Start of epoch 497\n",
      "Training loss at epoch 497: 0.2809\n",
      "\n",
      "Start of epoch 498\n",
      "Training loss at epoch 498: 0.2809\n",
      "\n",
      "Start of epoch 499\n",
      "Training loss at epoch 499: 0.2809\n",
      "[<tf.Variable 'parameters:0' shape=(45,) dtype=float32, numpy=\n",
      "array([5.259152  , 1.8068317 , 0.18237968, 0.29394907, 0.48729882,\n",
      "       3.9754064 , 1.5660162 , 3.411324  , 3.8152373 , 4.2556477 ,\n",
      "       4.0095644 , 5.3331227 , 2.2482924 , 0.5448366 , 4.7614546 ,\n",
      "       5.3472795 , 5.5533304 , 0.23896246, 5.521182  , 3.5588393 ,\n",
      "       0.26116997, 0.05924402, 3.721513  , 0.13345858, 0.287739  ,\n",
      "       0.3231142 , 1.8334299 , 5.728346  , 2.0072498 , 0.18331671,\n",
      "       3.759972  , 4.9608064 , 2.168786  , 1.5376143 , 5.748602  ,\n",
      "       3.8799348 , 3.6644914 , 0.9297856 , 1.086388  , 4.4578996 ,\n",
      "       3.152267  , 1.511926  , 1.3594493 , 2.4155643 , 0.38979515],\n",
      "      dtype=float32)>]\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.1303\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 1.0445\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.9667\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.9028\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.8516\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.8123\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.7833\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.7601\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.7384\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.7177\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.6997\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.6862\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.6767\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.6685\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.6584\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.6448\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.6278\n",
      "\n",
      "Start of epoch 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 17: 0.6088\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.5890\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.5698\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.5522\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.5367\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.5232\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.5112\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.5006\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.4913\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.4835\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.4772\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.4719\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.4671\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.4625\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.4579\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.4536\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.4499\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.4469\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.4445\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.4426\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.4407\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.4386\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.4362\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.4335\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.4305\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.4273\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.4240\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.4208\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.4178\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.4149\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.4124\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.4101\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.4081\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.4062\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.4044\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.4028\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.4012\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.3996\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.3981\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.3965\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.3949\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.3932\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.3915\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.3896\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.3876\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.3855\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.3833\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.3811\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.3789\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.3767\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.3744\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.3722\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.3700\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.3677\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.3655\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.3633\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.3612\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.3591\n",
      "\n",
      "Start of epoch 75\n",
      "Training loss at epoch 75: 0.3571\n",
      "\n",
      "Start of epoch 76\n",
      "Training loss at epoch 76: 0.3551\n",
      "\n",
      "Start of epoch 77\n",
      "Training loss at epoch 77: 0.3533\n",
      "\n",
      "Start of epoch 78\n",
      "Training loss at epoch 78: 0.3516\n",
      "\n",
      "Start of epoch 79\n",
      "Training loss at epoch 79: 0.3500\n",
      "\n",
      "Start of epoch 80\n",
      "Training loss at epoch 80: 0.3485\n",
      "\n",
      "Start of epoch 81\n",
      "Training loss at epoch 81: 0.3471\n",
      "\n",
      "Start of epoch 82\n",
      "Training loss at epoch 82: 0.3458\n",
      "\n",
      "Start of epoch 83\n",
      "Training loss at epoch 83: 0.3447\n",
      "\n",
      "Start of epoch 84\n",
      "Training loss at epoch 84: 0.3436\n",
      "\n",
      "Start of epoch 85\n",
      "Training loss at epoch 85: 0.3426\n",
      "\n",
      "Start of epoch 86\n",
      "Training loss at epoch 86: 0.3417\n",
      "\n",
      "Start of epoch 87\n",
      "Training loss at epoch 87: 0.3409\n",
      "\n",
      "Start of epoch 88\n",
      "Training loss at epoch 88: 0.3402\n",
      "\n",
      "Start of epoch 89\n",
      "Training loss at epoch 89: 0.3395\n",
      "\n",
      "Start of epoch 90\n",
      "Training loss at epoch 90: 0.3389\n",
      "\n",
      "Start of epoch 91\n",
      "Training loss at epoch 91: 0.3383\n",
      "\n",
      "Start of epoch 92\n",
      "Training loss at epoch 92: 0.3378\n",
      "\n",
      "Start of epoch 93\n",
      "Training loss at epoch 93: 0.3373\n",
      "\n",
      "Start of epoch 94\n",
      "Training loss at epoch 94: 0.3369\n",
      "\n",
      "Start of epoch 95\n",
      "Training loss at epoch 95: 0.3364\n",
      "\n",
      "Start of epoch 96\n",
      "Training loss at epoch 96: 0.3361\n",
      "\n",
      "Start of epoch 97\n",
      "Training loss at epoch 97: 0.3357\n",
      "\n",
      "Start of epoch 98\n",
      "Training loss at epoch 98: 0.3353\n",
      "\n",
      "Start of epoch 99\n",
      "Training loss at epoch 99: 0.3350\n",
      "\n",
      "Start of epoch 100\n",
      "Training loss at epoch 100: 0.3346\n",
      "\n",
      "Start of epoch 101\n",
      "Training loss at epoch 101: 0.3343\n",
      "\n",
      "Start of epoch 102\n",
      "Training loss at epoch 102: 0.3340\n",
      "\n",
      "Start of epoch 103\n",
      "Training loss at epoch 103: 0.3336\n",
      "\n",
      "Start of epoch 104\n",
      "Training loss at epoch 104: 0.3333\n",
      "\n",
      "Start of epoch 105\n",
      "Training loss at epoch 105: 0.3329\n",
      "\n",
      "Start of epoch 106\n",
      "Training loss at epoch 106: 0.3326\n",
      "\n",
      "Start of epoch 107\n",
      "Training loss at epoch 107: 0.3322\n",
      "\n",
      "Start of epoch 108\n",
      "Training loss at epoch 108: 0.3319\n",
      "\n",
      "Start of epoch 109\n",
      "Training loss at epoch 109: 0.3315\n",
      "\n",
      "Start of epoch 110\n",
      "Training loss at epoch 110: 0.3312\n",
      "\n",
      "Start of epoch 111\n",
      "Training loss at epoch 111: 0.3308\n",
      "\n",
      "Start of epoch 112\n",
      "Training loss at epoch 112: 0.3305\n",
      "\n",
      "Start of epoch 113\n",
      "Training loss at epoch 113: 0.3301\n",
      "\n",
      "Start of epoch 114\n",
      "Training loss at epoch 114: 0.3298\n",
      "\n",
      "Start of epoch 115\n",
      "Training loss at epoch 115: 0.3295\n",
      "\n",
      "Start of epoch 116\n",
      "Training loss at epoch 116: 0.3292\n",
      "\n",
      "Start of epoch 117\n",
      "Training loss at epoch 117: 0.3288\n",
      "\n",
      "Start of epoch 118\n",
      "Training loss at epoch 118: 0.3285\n",
      "\n",
      "Start of epoch 119\n",
      "Training loss at epoch 119: 0.3282\n",
      "\n",
      "Start of epoch 120\n",
      "Training loss at epoch 120: 0.3279\n",
      "\n",
      "Start of epoch 121\n",
      "Training loss at epoch 121: 0.3276\n",
      "\n",
      "Start of epoch 122\n",
      "Training loss at epoch 122: 0.3273\n",
      "\n",
      "Start of epoch 123\n",
      "Training loss at epoch 123: 0.3270\n",
      "\n",
      "Start of epoch 124\n",
      "Training loss at epoch 124: 0.3267\n",
      "\n",
      "Start of epoch 125\n",
      "Training loss at epoch 125: 0.3264\n",
      "\n",
      "Start of epoch 126\n",
      "Training loss at epoch 126: 0.3262\n",
      "\n",
      "Start of epoch 127\n",
      "Training loss at epoch 127: 0.3259\n",
      "\n",
      "Start of epoch 128\n",
      "Training loss at epoch 128: 0.3256\n",
      "\n",
      "Start of epoch 129\n",
      "Training loss at epoch 129: 0.3253\n",
      "\n",
      "Start of epoch 130\n",
      "Training loss at epoch 130: 0.3250\n",
      "\n",
      "Start of epoch 131\n",
      "Training loss at epoch 131: 0.3247\n",
      "\n",
      "Start of epoch 132\n",
      "Training loss at epoch 132: 0.3244\n",
      "\n",
      "Start of epoch 133\n",
      "Training loss at epoch 133: 0.3241\n",
      "\n",
      "Start of epoch 134\n",
      "Training loss at epoch 134: 0.3239\n",
      "\n",
      "Start of epoch 135\n",
      "Training loss at epoch 135: 0.3236\n",
      "\n",
      "Start of epoch 136\n",
      "Training loss at epoch 136: 0.3233\n",
      "\n",
      "Start of epoch 137\n",
      "Training loss at epoch 137: 0.3231\n",
      "\n",
      "Start of epoch 138\n",
      "Training loss at epoch 138: 0.3228\n",
      "\n",
      "Start of epoch 139\n",
      "Training loss at epoch 139: 0.3226\n",
      "\n",
      "Start of epoch 140\n",
      "Training loss at epoch 140: 0.3223\n",
      "\n",
      "Start of epoch 141\n",
      "Training loss at epoch 141: 0.3221\n",
      "\n",
      "Start of epoch 142\n",
      "Training loss at epoch 142: 0.3218\n",
      "\n",
      "Start of epoch 143\n",
      "Training loss at epoch 143: 0.3216\n",
      "\n",
      "Start of epoch 144\n",
      "Training loss at epoch 144: 0.3213\n",
      "\n",
      "Start of epoch 145\n",
      "Training loss at epoch 145: 0.3211\n",
      "\n",
      "Start of epoch 146\n",
      "Training loss at epoch 146: 0.3208\n",
      "\n",
      "Start of epoch 147\n",
      "Training loss at epoch 147: 0.3205\n",
      "\n",
      "Start of epoch 148\n",
      "Training loss at epoch 148: 0.3203\n",
      "\n",
      "Start of epoch 149\n",
      "Training loss at epoch 149: 0.3200\n",
      "\n",
      "Start of epoch 150\n",
      "Training loss at epoch 150: 0.3197\n",
      "\n",
      "Start of epoch 151\n",
      "Training loss at epoch 151: 0.3194\n",
      "\n",
      "Start of epoch 152\n",
      "Training loss at epoch 152: 0.3190\n",
      "\n",
      "Start of epoch 153\n",
      "Training loss at epoch 153: 0.3187\n",
      "\n",
      "Start of epoch 154\n",
      "Training loss at epoch 154: 0.3184\n",
      "\n",
      "Start of epoch 155\n",
      "Training loss at epoch 155: 0.3180\n",
      "\n",
      "Start of epoch 156\n",
      "Training loss at epoch 156: 0.3176\n",
      "\n",
      "Start of epoch 157\n",
      "Training loss at epoch 157: 0.3172\n",
      "\n",
      "Start of epoch 158\n",
      "Training loss at epoch 158: 0.3168\n",
      "\n",
      "Start of epoch 159\n",
      "Training loss at epoch 159: 0.3164\n",
      "\n",
      "Start of epoch 160\n",
      "Training loss at epoch 160: 0.3160\n",
      "\n",
      "Start of epoch 161\n",
      "Training loss at epoch 161: 0.3156\n",
      "\n",
      "Start of epoch 162\n",
      "Training loss at epoch 162: 0.3152\n",
      "\n",
      "Start of epoch 163\n",
      "Training loss at epoch 163: 0.3147\n",
      "\n",
      "Start of epoch 164\n",
      "Training loss at epoch 164: 0.3143\n",
      "\n",
      "Start of epoch 165\n",
      "Training loss at epoch 165: 0.3138\n",
      "\n",
      "Start of epoch 166\n",
      "Training loss at epoch 166: 0.3134\n",
      "\n",
      "Start of epoch 167\n",
      "Training loss at epoch 167: 0.3129\n",
      "\n",
      "Start of epoch 168\n",
      "Training loss at epoch 168: 0.3125\n",
      "\n",
      "Start of epoch 169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 169: 0.3120\n",
      "\n",
      "Start of epoch 170\n",
      "Training loss at epoch 170: 0.3116\n",
      "\n",
      "Start of epoch 171\n",
      "Training loss at epoch 171: 0.3111\n",
      "\n",
      "Start of epoch 172\n",
      "Training loss at epoch 172: 0.3107\n",
      "\n",
      "Start of epoch 173\n",
      "Training loss at epoch 173: 0.3103\n",
      "\n",
      "Start of epoch 174\n",
      "Training loss at epoch 174: 0.3099\n",
      "\n",
      "Start of epoch 175\n",
      "Training loss at epoch 175: 0.3095\n",
      "\n",
      "Start of epoch 176\n",
      "Training loss at epoch 176: 0.3091\n",
      "\n",
      "Start of epoch 177\n",
      "Training loss at epoch 177: 0.3087\n",
      "\n",
      "Start of epoch 178\n",
      "Training loss at epoch 178: 0.3083\n",
      "\n",
      "Start of epoch 179\n",
      "Training loss at epoch 179: 0.3080\n",
      "\n",
      "Start of epoch 180\n",
      "Training loss at epoch 180: 0.3076\n",
      "\n",
      "Start of epoch 181\n",
      "Training loss at epoch 181: 0.3073\n",
      "\n",
      "Start of epoch 182\n",
      "Training loss at epoch 182: 0.3069\n",
      "\n",
      "Start of epoch 183\n",
      "Training loss at epoch 183: 0.3066\n",
      "\n",
      "Start of epoch 184\n",
      "Training loss at epoch 184: 0.3062\n",
      "\n",
      "Start of epoch 185\n",
      "Training loss at epoch 185: 0.3059\n",
      "\n",
      "Start of epoch 186\n",
      "Training loss at epoch 186: 0.3056\n",
      "\n",
      "Start of epoch 187\n",
      "Training loss at epoch 187: 0.3053\n",
      "\n",
      "Start of epoch 188\n",
      "Training loss at epoch 188: 0.3049\n",
      "\n",
      "Start of epoch 189\n",
      "Training loss at epoch 189: 0.3046\n",
      "\n",
      "Start of epoch 190\n",
      "Training loss at epoch 190: 0.3043\n",
      "\n",
      "Start of epoch 191\n",
      "Training loss at epoch 191: 0.3040\n",
      "\n",
      "Start of epoch 192\n",
      "Training loss at epoch 192: 0.3036\n",
      "\n",
      "Start of epoch 193\n",
      "Training loss at epoch 193: 0.3033\n",
      "\n",
      "Start of epoch 194\n",
      "Training loss at epoch 194: 0.3030\n",
      "\n",
      "Start of epoch 195\n",
      "Training loss at epoch 195: 0.3026\n",
      "\n",
      "Start of epoch 196\n",
      "Training loss at epoch 196: 0.3023\n",
      "\n",
      "Start of epoch 197\n",
      "Training loss at epoch 197: 0.3019\n",
      "\n",
      "Start of epoch 198\n",
      "Training loss at epoch 198: 0.3015\n",
      "\n",
      "Start of epoch 199\n",
      "Training loss at epoch 199: 0.3012\n",
      "\n",
      "Start of epoch 200\n",
      "Training loss at epoch 200: 0.3008\n",
      "\n",
      "Start of epoch 201\n",
      "Training loss at epoch 201: 0.3004\n",
      "\n",
      "Start of epoch 202\n",
      "Training loss at epoch 202: 0.3000\n",
      "\n",
      "Start of epoch 203\n",
      "Training loss at epoch 203: 0.2996\n",
      "\n",
      "Start of epoch 204\n",
      "Training loss at epoch 204: 0.2992\n",
      "\n",
      "Start of epoch 205\n",
      "Training loss at epoch 205: 0.2988\n",
      "\n",
      "Start of epoch 206\n",
      "Training loss at epoch 206: 0.2983\n",
      "\n",
      "Start of epoch 207\n",
      "Training loss at epoch 207: 0.2979\n",
      "\n",
      "Start of epoch 208\n",
      "Training loss at epoch 208: 0.2974\n",
      "\n",
      "Start of epoch 209\n",
      "Training loss at epoch 209: 0.2969\n",
      "\n",
      "Start of epoch 210\n",
      "Training loss at epoch 210: 0.2964\n",
      "\n",
      "Start of epoch 211\n",
      "Training loss at epoch 211: 0.2959\n",
      "\n",
      "Start of epoch 212\n",
      "Training loss at epoch 212: 0.2953\n",
      "\n",
      "Start of epoch 213\n",
      "Training loss at epoch 213: 0.2948\n",
      "\n",
      "Start of epoch 214\n",
      "Training loss at epoch 214: 0.2941\n",
      "\n",
      "Start of epoch 215\n",
      "Training loss at epoch 215: 0.2934\n",
      "\n",
      "Start of epoch 216\n",
      "Training loss at epoch 216: 0.2927\n",
      "\n",
      "Start of epoch 217\n",
      "Training loss at epoch 217: 0.2919\n",
      "\n",
      "Start of epoch 218\n",
      "Training loss at epoch 218: 0.2910\n",
      "\n",
      "Start of epoch 219\n",
      "Training loss at epoch 219: 0.2899\n",
      "\n",
      "Start of epoch 220\n",
      "Training loss at epoch 220: 0.2888\n",
      "\n",
      "Start of epoch 221\n",
      "Training loss at epoch 221: 0.2874\n",
      "\n",
      "Start of epoch 222\n",
      "Training loss at epoch 222: 0.2859\n",
      "\n",
      "Start of epoch 223\n",
      "Training loss at epoch 223: 0.2840\n",
      "\n",
      "Start of epoch 224\n",
      "Training loss at epoch 224: 0.2819\n",
      "\n",
      "Start of epoch 225\n",
      "Training loss at epoch 225: 0.2792\n",
      "\n",
      "Start of epoch 226\n",
      "Training loss at epoch 226: 0.2760\n",
      "\n",
      "Start of epoch 227\n",
      "Training loss at epoch 227: 0.2720\n",
      "\n",
      "Start of epoch 228\n",
      "Training loss at epoch 228: 0.2670\n",
      "\n",
      "Start of epoch 229\n",
      "Training loss at epoch 229: 0.2609\n",
      "\n",
      "Start of epoch 230\n",
      "Training loss at epoch 230: 0.2534\n",
      "\n",
      "Start of epoch 231\n",
      "Training loss at epoch 231: 0.2443\n",
      "\n",
      "Start of epoch 232\n",
      "Training loss at epoch 232: 0.2336\n",
      "\n",
      "Start of epoch 233\n",
      "Training loss at epoch 233: 0.2219\n",
      "\n",
      "Start of epoch 234\n",
      "Training loss at epoch 234: 0.2102\n",
      "\n",
      "Start of epoch 235\n",
      "Training loss at epoch 235: 0.1999\n",
      "\n",
      "Start of epoch 236\n",
      "Training loss at epoch 236: 0.1924\n",
      "\n",
      "Start of epoch 237\n",
      "Training loss at epoch 237: 0.1878\n",
      "\n",
      "Start of epoch 238\n",
      "Training loss at epoch 238: 0.1848\n",
      "\n",
      "Start of epoch 239\n",
      "Training loss at epoch 239: 0.1817\n",
      "\n",
      "Start of epoch 240\n",
      "Training loss at epoch 240: 0.1776\n",
      "\n",
      "Start of epoch 241\n",
      "Training loss at epoch 241: 0.1734\n",
      "\n",
      "Start of epoch 242\n",
      "Training loss at epoch 242: 0.1698\n",
      "\n",
      "Start of epoch 243\n",
      "Training loss at epoch 243: 0.1670\n",
      "\n",
      "Start of epoch 244\n",
      "Training loss at epoch 244: 0.1646\n",
      "\n",
      "Start of epoch 245\n",
      "Training loss at epoch 245: 0.1626\n",
      "\n",
      "Start of epoch 246\n",
      "Training loss at epoch 246: 0.1612\n",
      "\n",
      "Start of epoch 247\n",
      "Training loss at epoch 247: 0.1605\n",
      "\n",
      "Start of epoch 248\n",
      "Training loss at epoch 248: 0.1603\n",
      "\n",
      "Start of epoch 249\n",
      "Training loss at epoch 249: 0.1599\n",
      "\n",
      "Start of epoch 250\n",
      "Training loss at epoch 250: 0.1592\n",
      "\n",
      "Start of epoch 251\n",
      "Training loss at epoch 251: 0.1583\n",
      "\n",
      "Start of epoch 252\n",
      "Training loss at epoch 252: 0.1575\n",
      "\n",
      "Start of epoch 253\n",
      "Training loss at epoch 253: 0.1567\n",
      "\n",
      "Start of epoch 254\n",
      "Training loss at epoch 254: 0.1560\n",
      "\n",
      "Start of epoch 255\n",
      "Training loss at epoch 255: 0.1553\n",
      "\n",
      "Start of epoch 256\n",
      "Training loss at epoch 256: 0.1548\n",
      "\n",
      "Start of epoch 257\n",
      "Training loss at epoch 257: 0.1544\n",
      "\n",
      "Start of epoch 258\n",
      "Training loss at epoch 258: 0.1541\n",
      "\n",
      "Start of epoch 259\n",
      "Training loss at epoch 259: 0.1538\n",
      "\n",
      "Start of epoch 260\n",
      "Training loss at epoch 260: 0.1535\n",
      "\n",
      "Start of epoch 261\n",
      "Training loss at epoch 261: 0.1532\n",
      "\n",
      "Start of epoch 262\n",
      "Training loss at epoch 262: 0.1528\n",
      "\n",
      "Start of epoch 263\n",
      "Training loss at epoch 263: 0.1523\n",
      "\n",
      "Start of epoch 264\n",
      "Training loss at epoch 264: 0.1519\n",
      "\n",
      "Start of epoch 265\n",
      "Training loss at epoch 265: 0.1515\n",
      "\n",
      "Start of epoch 266\n",
      "Training loss at epoch 266: 0.1511\n",
      "\n",
      "Start of epoch 267\n",
      "Training loss at epoch 267: 0.1506\n",
      "\n",
      "Start of epoch 268\n",
      "Training loss at epoch 268: 0.1501\n",
      "\n",
      "Start of epoch 269\n",
      "Training loss at epoch 269: 0.1498\n",
      "\n",
      "Start of epoch 270\n",
      "Training loss at epoch 270: 0.1494\n",
      "\n",
      "Start of epoch 271\n",
      "Training loss at epoch 271: 0.1491\n",
      "\n",
      "Start of epoch 272\n",
      "Training loss at epoch 272: 0.1488\n",
      "\n",
      "Start of epoch 273\n",
      "Training loss at epoch 273: 0.1484\n",
      "\n",
      "Start of epoch 274\n",
      "Training loss at epoch 274: 0.1480\n",
      "\n",
      "Start of epoch 275\n",
      "Training loss at epoch 275: 0.1476\n",
      "\n",
      "Start of epoch 276\n",
      "Training loss at epoch 276: 0.1472\n",
      "\n",
      "Start of epoch 277\n",
      "Training loss at epoch 277: 0.1468\n",
      "\n",
      "Start of epoch 278\n",
      "Training loss at epoch 278: 0.1464\n",
      "\n",
      "Start of epoch 279\n",
      "Training loss at epoch 279: 0.1460\n",
      "\n",
      "Start of epoch 280\n",
      "Training loss at epoch 280: 0.1455\n",
      "\n",
      "Start of epoch 281\n",
      "Training loss at epoch 281: 0.1450\n",
      "\n",
      "Start of epoch 282\n",
      "Training loss at epoch 282: 0.1446\n",
      "\n",
      "Start of epoch 283\n",
      "Training loss at epoch 283: 0.1441\n",
      "\n",
      "Start of epoch 284\n",
      "Training loss at epoch 284: 0.1437\n",
      "\n",
      "Start of epoch 285\n",
      "Training loss at epoch 285: 0.1431\n",
      "\n",
      "Start of epoch 286\n",
      "Training loss at epoch 286: 0.1426\n",
      "\n",
      "Start of epoch 287\n",
      "Training loss at epoch 287: 0.1420\n",
      "\n",
      "Start of epoch 288\n",
      "Training loss at epoch 288: 0.1413\n",
      "\n",
      "Start of epoch 289\n",
      "Training loss at epoch 289: 0.1406\n",
      "\n",
      "Start of epoch 290\n",
      "Training loss at epoch 290: 0.1399\n",
      "\n",
      "Start of epoch 291\n",
      "Training loss at epoch 291: 0.1391\n",
      "\n",
      "Start of epoch 292\n",
      "Training loss at epoch 292: 0.1382\n",
      "\n",
      "Start of epoch 293\n",
      "Training loss at epoch 293: 0.1372\n",
      "\n",
      "Start of epoch 294\n",
      "Training loss at epoch 294: 0.1362\n",
      "\n",
      "Start of epoch 295\n",
      "Training loss at epoch 295: 0.1351\n",
      "\n",
      "Start of epoch 296\n",
      "Training loss at epoch 296: 0.1338\n",
      "\n",
      "Start of epoch 297\n",
      "Training loss at epoch 297: 0.1325\n",
      "\n",
      "Start of epoch 298\n",
      "Training loss at epoch 298: 0.1310\n",
      "\n",
      "Start of epoch 299\n",
      "Training loss at epoch 299: 0.1294\n",
      "\n",
      "Start of epoch 300\n",
      "Training loss at epoch 300: 0.1277\n",
      "\n",
      "Start of epoch 301\n",
      "Training loss at epoch 301: 0.1259\n",
      "\n",
      "Start of epoch 302\n",
      "Training loss at epoch 302: 0.1239\n",
      "\n",
      "Start of epoch 303\n",
      "Training loss at epoch 303: 0.1218\n",
      "\n",
      "Start of epoch 304\n",
      "Training loss at epoch 304: 0.1197\n",
      "\n",
      "Start of epoch 305\n",
      "Training loss at epoch 305: 0.1174\n",
      "\n",
      "Start of epoch 306\n",
      "Training loss at epoch 306: 0.1151\n",
      "\n",
      "Start of epoch 307\n",
      "Training loss at epoch 307: 0.1129\n",
      "\n",
      "Start of epoch 308\n",
      "Training loss at epoch 308: 0.1106\n",
      "\n",
      "Start of epoch 309\n",
      "Training loss at epoch 309: 0.1085\n",
      "\n",
      "Start of epoch 310\n",
      "Training loss at epoch 310: 0.1065\n",
      "\n",
      "Start of epoch 311\n",
      "Training loss at epoch 311: 0.1046\n",
      "\n",
      "Start of epoch 312\n",
      "Training loss at epoch 312: 0.1028\n",
      "\n",
      "Start of epoch 313\n",
      "Training loss at epoch 313: 0.1012\n",
      "\n",
      "Start of epoch 314\n",
      "Training loss at epoch 314: 0.0998\n",
      "\n",
      "Start of epoch 315\n",
      "Training loss at epoch 315: 0.0986\n",
      "\n",
      "Start of epoch 316\n",
      "Training loss at epoch 316: 0.0975\n",
      "\n",
      "Start of epoch 317\n",
      "Training loss at epoch 317: 0.0967\n",
      "\n",
      "Start of epoch 318\n",
      "Training loss at epoch 318: 0.0961\n",
      "\n",
      "Start of epoch 319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 319: 0.0957\n",
      "\n",
      "Start of epoch 320\n",
      "Training loss at epoch 320: 0.0954\n",
      "\n",
      "Start of epoch 321\n",
      "Training loss at epoch 321: 0.0953\n",
      "\n",
      "Start of epoch 322\n",
      "Training loss at epoch 322: 0.0953\n",
      "\n",
      "Start of epoch 323\n",
      "Training loss at epoch 323: 0.0953\n",
      "\n",
      "Start of epoch 324\n",
      "Training loss at epoch 324: 0.0953\n",
      "\n",
      "Start of epoch 325\n",
      "Training loss at epoch 325: 0.0953\n",
      "\n",
      "Start of epoch 326\n",
      "Training loss at epoch 326: 0.0953\n",
      "\n",
      "Start of epoch 327\n",
      "Training loss at epoch 327: 0.0952\n",
      "\n",
      "Start of epoch 328\n",
      "Training loss at epoch 328: 0.0951\n",
      "\n",
      "Start of epoch 329\n",
      "Training loss at epoch 329: 0.0950\n",
      "\n",
      "Start of epoch 330\n",
      "Training loss at epoch 330: 0.0949\n",
      "\n",
      "Start of epoch 331\n",
      "Training loss at epoch 331: 0.0947\n",
      "\n",
      "Start of epoch 332\n",
      "Training loss at epoch 332: 0.0945\n",
      "\n",
      "Start of epoch 333\n",
      "Training loss at epoch 333: 0.0943\n",
      "\n",
      "Start of epoch 334\n",
      "Training loss at epoch 334: 0.0941\n",
      "\n",
      "Start of epoch 335\n",
      "Training loss at epoch 335: 0.0940\n",
      "\n",
      "Start of epoch 336\n",
      "Training loss at epoch 336: 0.0938\n",
      "\n",
      "Start of epoch 337\n",
      "Training loss at epoch 337: 0.0936\n",
      "\n",
      "Start of epoch 338\n",
      "Training loss at epoch 338: 0.0935\n",
      "\n",
      "Start of epoch 339\n",
      "Training loss at epoch 339: 0.0934\n",
      "\n",
      "Start of epoch 340\n",
      "Training loss at epoch 340: 0.0933\n",
      "\n",
      "Start of epoch 341\n",
      "Training loss at epoch 341: 0.0932\n",
      "\n",
      "Start of epoch 342\n",
      "Training loss at epoch 342: 0.0930\n",
      "\n",
      "Start of epoch 343\n",
      "Training loss at epoch 343: 0.0929\n",
      "\n",
      "Start of epoch 344\n",
      "Training loss at epoch 344: 0.0928\n",
      "\n",
      "Start of epoch 345\n",
      "Training loss at epoch 345: 0.0927\n",
      "\n",
      "Start of epoch 346\n",
      "Training loss at epoch 346: 0.0926\n",
      "\n",
      "Start of epoch 347\n",
      "Training loss at epoch 347: 0.0925\n",
      "\n",
      "Start of epoch 348\n",
      "Training loss at epoch 348: 0.0924\n",
      "\n",
      "Start of epoch 349\n",
      "Training loss at epoch 349: 0.0923\n",
      "\n",
      "Start of epoch 350\n",
      "Training loss at epoch 350: 0.0922\n",
      "\n",
      "Start of epoch 351\n",
      "Training loss at epoch 351: 0.0921\n",
      "\n",
      "Start of epoch 352\n",
      "Training loss at epoch 352: 0.0920\n",
      "\n",
      "Start of epoch 353\n",
      "Training loss at epoch 353: 0.0919\n",
      "\n",
      "Start of epoch 354\n",
      "Training loss at epoch 354: 0.0919\n",
      "\n",
      "Start of epoch 355\n",
      "Training loss at epoch 355: 0.0918\n",
      "\n",
      "Start of epoch 356\n",
      "Training loss at epoch 356: 0.0917\n",
      "\n",
      "Start of epoch 357\n",
      "Training loss at epoch 357: 0.0916\n",
      "\n",
      "Start of epoch 358\n",
      "Training loss at epoch 358: 0.0915\n",
      "\n",
      "Start of epoch 359\n",
      "Training loss at epoch 359: 0.0915\n",
      "\n",
      "Start of epoch 360\n",
      "Training loss at epoch 360: 0.0914\n",
      "\n",
      "Start of epoch 361\n",
      "Training loss at epoch 361: 0.0913\n",
      "\n",
      "Start of epoch 362\n",
      "Training loss at epoch 362: 0.0912\n",
      "\n",
      "Start of epoch 363\n",
      "Training loss at epoch 363: 0.0912\n",
      "\n",
      "Start of epoch 364\n",
      "Training loss at epoch 364: 0.0911\n",
      "\n",
      "Start of epoch 365\n",
      "Training loss at epoch 365: 0.0910\n",
      "\n",
      "Start of epoch 366\n",
      "Training loss at epoch 366: 0.0909\n",
      "\n",
      "Start of epoch 367\n",
      "Training loss at epoch 367: 0.0909\n",
      "\n",
      "Start of epoch 368\n",
      "Training loss at epoch 368: 0.0908\n",
      "\n",
      "Start of epoch 369\n",
      "Training loss at epoch 369: 0.0907\n",
      "\n",
      "Start of epoch 370\n",
      "Training loss at epoch 370: 0.0907\n",
      "\n",
      "Start of epoch 371\n",
      "Training loss at epoch 371: 0.0906\n",
      "\n",
      "Start of epoch 372\n",
      "Training loss at epoch 372: 0.0905\n",
      "\n",
      "Start of epoch 373\n",
      "Training loss at epoch 373: 0.0904\n",
      "\n",
      "Start of epoch 374\n",
      "Training loss at epoch 374: 0.0904\n",
      "\n",
      "Start of epoch 375\n",
      "Training loss at epoch 375: 0.0903\n",
      "\n",
      "Start of epoch 376\n",
      "Training loss at epoch 376: 0.0902\n",
      "\n",
      "Start of epoch 377\n",
      "Training loss at epoch 377: 0.0902\n",
      "\n",
      "Start of epoch 378\n",
      "Training loss at epoch 378: 0.0901\n",
      "\n",
      "Start of epoch 379\n",
      "Training loss at epoch 379: 0.0900\n",
      "\n",
      "Start of epoch 380\n",
      "Training loss at epoch 380: 0.0900\n",
      "\n",
      "Start of epoch 381\n",
      "Training loss at epoch 381: 0.0899\n",
      "\n",
      "Start of epoch 382\n",
      "Training loss at epoch 382: 0.0899\n",
      "\n",
      "Start of epoch 383\n",
      "Training loss at epoch 383: 0.0898\n",
      "\n",
      "Start of epoch 384\n",
      "Training loss at epoch 384: 0.0897\n",
      "\n",
      "Start of epoch 385\n",
      "Training loss at epoch 385: 0.0897\n",
      "\n",
      "Start of epoch 386\n",
      "Training loss at epoch 386: 0.0896\n",
      "\n",
      "Start of epoch 387\n",
      "Training loss at epoch 387: 0.0895\n",
      "\n",
      "Start of epoch 388\n",
      "Training loss at epoch 388: 0.0895\n",
      "\n",
      "Start of epoch 389\n",
      "Training loss at epoch 389: 0.0894\n",
      "\n",
      "Start of epoch 390\n",
      "Training loss at epoch 390: 0.0893\n",
      "\n",
      "Start of epoch 391\n",
      "Training loss at epoch 391: 0.0893\n",
      "\n",
      "Start of epoch 392\n",
      "Training loss at epoch 392: 0.0892\n",
      "\n",
      "Start of epoch 393\n",
      "Training loss at epoch 393: 0.0892\n",
      "\n",
      "Start of epoch 394\n",
      "Training loss at epoch 394: 0.0891\n",
      "\n",
      "Start of epoch 395\n",
      "Training loss at epoch 395: 0.0890\n",
      "\n",
      "Start of epoch 396\n",
      "Training loss at epoch 396: 0.0890\n",
      "\n",
      "Start of epoch 397\n",
      "Training loss at epoch 397: 0.0889\n",
      "\n",
      "Start of epoch 398\n",
      "Training loss at epoch 398: 0.0888\n",
      "\n",
      "Start of epoch 399\n",
      "Training loss at epoch 399: 0.0888\n",
      "\n",
      "Start of epoch 400\n",
      "Training loss at epoch 400: 0.0887\n",
      "\n",
      "Start of epoch 401\n",
      "Training loss at epoch 401: 0.0887\n",
      "\n",
      "Start of epoch 402\n",
      "Training loss at epoch 402: 0.0886\n",
      "\n",
      "Start of epoch 403\n",
      "Training loss at epoch 403: 0.0885\n",
      "\n",
      "Start of epoch 404\n",
      "Training loss at epoch 404: 0.0885\n",
      "\n",
      "Start of epoch 405\n",
      "Training loss at epoch 405: 0.0884\n",
      "\n",
      "Start of epoch 406\n",
      "Training loss at epoch 406: 0.0883\n",
      "\n",
      "Start of epoch 407\n",
      "Training loss at epoch 407: 0.0883\n",
      "\n",
      "Start of epoch 408\n",
      "Training loss at epoch 408: 0.0882\n",
      "\n",
      "Start of epoch 409\n",
      "Training loss at epoch 409: 0.0881\n",
      "\n",
      "Start of epoch 410\n",
      "Training loss at epoch 410: 0.0881\n",
      "\n",
      "Start of epoch 411\n",
      "Training loss at epoch 411: 0.0880\n",
      "\n",
      "Start of epoch 412\n",
      "Training loss at epoch 412: 0.0879\n",
      "\n",
      "Start of epoch 413\n",
      "Training loss at epoch 413: 0.0879\n",
      "\n",
      "Start of epoch 414\n",
      "Training loss at epoch 414: 0.0878\n",
      "\n",
      "Start of epoch 415\n",
      "Training loss at epoch 415: 0.0877\n",
      "\n",
      "Start of epoch 416\n",
      "Training loss at epoch 416: 0.0877\n",
      "\n",
      "Start of epoch 417\n",
      "Training loss at epoch 417: 0.0876\n",
      "\n",
      "Start of epoch 418\n",
      "Training loss at epoch 418: 0.0875\n",
      "\n",
      "Start of epoch 419\n",
      "Training loss at epoch 419: 0.0875\n",
      "\n",
      "Start of epoch 420\n",
      "Training loss at epoch 420: 0.0874\n",
      "\n",
      "Start of epoch 421\n",
      "Training loss at epoch 421: 0.0873\n",
      "\n",
      "Start of epoch 422\n",
      "Training loss at epoch 422: 0.0873\n",
      "\n",
      "Start of epoch 423\n",
      "Training loss at epoch 423: 0.0872\n",
      "\n",
      "Start of epoch 424\n",
      "Training loss at epoch 424: 0.0871\n",
      "\n",
      "Start of epoch 425\n",
      "Training loss at epoch 425: 0.0870\n",
      "\n",
      "Start of epoch 426\n",
      "Training loss at epoch 426: 0.0870\n",
      "\n",
      "Start of epoch 427\n",
      "Training loss at epoch 427: 0.0869\n",
      "\n",
      "Start of epoch 428\n",
      "Training loss at epoch 428: 0.0868\n",
      "\n",
      "Start of epoch 429\n",
      "Training loss at epoch 429: 0.0867\n",
      "\n",
      "Start of epoch 430\n",
      "Training loss at epoch 430: 0.0867\n",
      "\n",
      "Start of epoch 431\n",
      "Training loss at epoch 431: 0.0866\n",
      "\n",
      "Start of epoch 432\n",
      "Training loss at epoch 432: 0.0865\n",
      "\n",
      "Start of epoch 433\n",
      "Training loss at epoch 433: 0.0864\n",
      "\n",
      "Start of epoch 434\n",
      "Training loss at epoch 434: 0.0863\n",
      "\n",
      "Start of epoch 435\n",
      "Training loss at epoch 435: 0.0862\n",
      "\n",
      "Start of epoch 436\n",
      "Training loss at epoch 436: 0.0862\n",
      "\n",
      "Start of epoch 437\n",
      "Training loss at epoch 437: 0.0861\n",
      "\n",
      "Start of epoch 438\n",
      "Training loss at epoch 438: 0.0860\n",
      "\n",
      "Start of epoch 439\n",
      "Training loss at epoch 439: 0.0859\n",
      "\n",
      "Start of epoch 440\n",
      "Training loss at epoch 440: 0.0858\n",
      "\n",
      "Start of epoch 441\n",
      "Training loss at epoch 441: 0.0857\n",
      "\n",
      "Start of epoch 442\n",
      "Training loss at epoch 442: 0.0856\n",
      "\n",
      "Start of epoch 443\n",
      "Training loss at epoch 443: 0.0855\n",
      "\n",
      "Start of epoch 444\n",
      "Training loss at epoch 444: 0.0855\n",
      "\n",
      "Start of epoch 445\n",
      "Training loss at epoch 445: 0.0854\n",
      "\n",
      "Start of epoch 446\n",
      "Training loss at epoch 446: 0.0853\n",
      "\n",
      "Start of epoch 447\n",
      "Training loss at epoch 447: 0.0852\n",
      "\n",
      "Start of epoch 448\n",
      "Training loss at epoch 448: 0.0851\n",
      "\n",
      "Start of epoch 449\n",
      "Training loss at epoch 449: 0.0850\n",
      "\n",
      "Start of epoch 450\n",
      "Training loss at epoch 450: 0.0849\n",
      "\n",
      "Start of epoch 451\n",
      "Training loss at epoch 451: 0.0848\n",
      "\n",
      "Start of epoch 452\n",
      "Training loss at epoch 452: 0.0847\n",
      "\n",
      "Start of epoch 453\n",
      "Training loss at epoch 453: 0.0846\n",
      "\n",
      "Start of epoch 454\n",
      "Training loss at epoch 454: 0.0844\n",
      "\n",
      "Start of epoch 455\n",
      "Training loss at epoch 455: 0.0843\n",
      "\n",
      "Start of epoch 456\n",
      "Training loss at epoch 456: 0.0842\n",
      "\n",
      "Start of epoch 457\n",
      "Training loss at epoch 457: 0.0841\n",
      "\n",
      "Start of epoch 458\n",
      "Training loss at epoch 458: 0.0840\n",
      "\n",
      "Start of epoch 459\n",
      "Training loss at epoch 459: 0.0839\n",
      "\n",
      "Start of epoch 460\n",
      "Training loss at epoch 460: 0.0838\n",
      "\n",
      "Start of epoch 461\n",
      "Training loss at epoch 461: 0.0836\n",
      "\n",
      "Start of epoch 462\n",
      "Training loss at epoch 462: 0.0835\n",
      "\n",
      "Start of epoch 463\n",
      "Training loss at epoch 463: 0.0834\n",
      "\n",
      "Start of epoch 464\n",
      "Training loss at epoch 464: 0.0833\n",
      "\n",
      "Start of epoch 465\n",
      "Training loss at epoch 465: 0.0831\n",
      "\n",
      "Start of epoch 466\n",
      "Training loss at epoch 466: 0.0830\n",
      "\n",
      "Start of epoch 467\n",
      "Training loss at epoch 467: 0.0829\n",
      "\n",
      "Start of epoch 468\n",
      "Training loss at epoch 468: 0.0827\n",
      "\n",
      "Start of epoch 469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 469: 0.0826\n",
      "\n",
      "Start of epoch 470\n",
      "Training loss at epoch 470: 0.0824\n",
      "\n",
      "Start of epoch 471\n",
      "Training loss at epoch 471: 0.0823\n",
      "\n",
      "Start of epoch 472\n",
      "Training loss at epoch 472: 0.0821\n",
      "\n",
      "Start of epoch 473\n",
      "Training loss at epoch 473: 0.0820\n",
      "\n",
      "Start of epoch 474\n",
      "Training loss at epoch 474: 0.0818\n",
      "\n",
      "Start of epoch 475\n",
      "Training loss at epoch 475: 0.0816\n",
      "\n",
      "Start of epoch 476\n",
      "Training loss at epoch 476: 0.0815\n",
      "\n",
      "Start of epoch 477\n",
      "Training loss at epoch 477: 0.0813\n",
      "\n",
      "Start of epoch 478\n",
      "Training loss at epoch 478: 0.0811\n",
      "\n",
      "Start of epoch 479\n",
      "Training loss at epoch 479: 0.0809\n",
      "\n",
      "Start of epoch 480\n",
      "Training loss at epoch 480: 0.0807\n",
      "\n",
      "Start of epoch 481\n",
      "Training loss at epoch 481: 0.0805\n",
      "\n",
      "Start of epoch 482\n",
      "Training loss at epoch 482: 0.0803\n",
      "\n",
      "Start of epoch 483\n",
      "Training loss at epoch 483: 0.0801\n",
      "\n",
      "Start of epoch 484\n",
      "Training loss at epoch 484: 0.0799\n",
      "\n",
      "Start of epoch 485\n",
      "Training loss at epoch 485: 0.0797\n",
      "\n",
      "Start of epoch 486\n",
      "Training loss at epoch 486: 0.0794\n",
      "\n",
      "Start of epoch 487\n",
      "Training loss at epoch 487: 0.0792\n",
      "\n",
      "Start of epoch 488\n",
      "Training loss at epoch 488: 0.0789\n",
      "\n",
      "Start of epoch 489\n",
      "Training loss at epoch 489: 0.0787\n",
      "\n",
      "Start of epoch 490\n",
      "Training loss at epoch 490: 0.0784\n",
      "\n",
      "Start of epoch 491\n",
      "Training loss at epoch 491: 0.0781\n",
      "\n",
      "Start of epoch 492\n",
      "Training loss at epoch 492: 0.0778\n",
      "\n",
      "Start of epoch 493\n",
      "Training loss at epoch 493: 0.0774\n",
      "\n",
      "Start of epoch 494\n",
      "Training loss at epoch 494: 0.0771\n",
      "\n",
      "Start of epoch 495\n",
      "Training loss at epoch 495: 0.0767\n",
      "\n",
      "Start of epoch 496\n",
      "Training loss at epoch 496: 0.0763\n",
      "\n",
      "Start of epoch 497\n",
      "Training loss at epoch 497: 0.0759\n",
      "\n",
      "Start of epoch 498\n",
      "Training loss at epoch 498: 0.0755\n",
      "\n",
      "Start of epoch 499\n",
      "Training loss at epoch 499: 0.0750\n",
      "[<tf.Variable 'parameters:0' shape=(45,) dtype=float32, numpy=\n",
      "array([3.142743  , 1.6211308 , 6.2127533 , 1.403728  , 0.5748421 ,\n",
      "       5.8714156 , 5.158472  , 5.786588  , 1.6906012 , 3.3182492 ,\n",
      "       4.858122  , 0.38375887, 0.3583126 , 5.866459  , 5.0671377 ,\n",
      "       5.828251  , 0.97697425, 0.2249117 , 0.5937352 , 5.895576  ,\n",
      "       5.1195526 , 4.471942  , 1.0231847 , 2.0065742 , 2.158195  ,\n",
      "       1.0113435 , 0.55272895, 0.31191644, 5.727847  , 5.3882537 ,\n",
      "       0.3614315 , 5.183798  , 0.8544393 , 1.5969969 , 3.1413836 ,\n",
      "       5.9380727 , 0.51083434, 1.2580216 , 4.3443036 , 2.3086405 ,\n",
      "       1.8087461 , 3.083661  , 0.77426183, 1.2260948 , 5.415547  ],\n",
      "      dtype=float32)>]\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.0369\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 0.9525\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.8810\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.8278\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.7884\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.7558\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.7268\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.7017\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.6816\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.6669\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.6559\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.6460\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.6352\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.6232\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.6105\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.5976\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.5848\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.5722\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.5600\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.5488\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.5386\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.5297\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.5218\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.5147\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.5082\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.5025\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.4975\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.4933\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.4898\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.4867\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.4839\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.4809\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.4777\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.4741\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.4705\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.4670\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.4640\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.4614\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.4592\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.4573\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.4558\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.4544\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.4531\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.4519\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.4507\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.4495\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.4483\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.4473\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.4465\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.4458\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.4453\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.4449\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.4444\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.4438\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.4430\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.4420\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.4410\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.4401\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.4393\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.4386\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.4381\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.4377\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.4374\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.4371\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.4368\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.4365\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.4362\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.4358\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.4354\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.4351\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.4348\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.4345\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.4343\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.4340\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.4338\n",
      "\n",
      "Start of epoch 75\n",
      "Training loss at epoch 75: 0.4335\n",
      "\n",
      "Start of epoch 76\n",
      "Training loss at epoch 76: 0.4333\n",
      "\n",
      "Start of epoch 77\n",
      "Training loss at epoch 77: 0.4330\n",
      "\n",
      "Start of epoch 78\n",
      "Training loss at epoch 78: 0.4327\n",
      "\n",
      "Start of epoch 79\n",
      "Training loss at epoch 79: 0.4324\n",
      "\n",
      "Start of epoch 80\n",
      "Training loss at epoch 80: 0.4320\n",
      "\n",
      "Start of epoch 81\n",
      "Training loss at epoch 81: 0.4317\n",
      "\n",
      "Start of epoch 82\n",
      "Training loss at epoch 82: 0.4313\n",
      "\n",
      "Start of epoch 83\n",
      "Training loss at epoch 83: 0.4310\n",
      "\n",
      "Start of epoch 84\n",
      "Training loss at epoch 84: 0.4306\n",
      "\n",
      "Start of epoch 85\n",
      "Training loss at epoch 85: 0.4301\n",
      "\n",
      "Start of epoch 86\n",
      "Training loss at epoch 86: 0.4297\n",
      "\n",
      "Start of epoch 87\n",
      "Training loss at epoch 87: 0.4292\n",
      "\n",
      "Start of epoch 88\n",
      "Training loss at epoch 88: 0.4287\n",
      "\n",
      "Start of epoch 89\n",
      "Training loss at epoch 89: 0.4282\n",
      "\n",
      "Start of epoch 90\n",
      "Training loss at epoch 90: 0.4277\n",
      "\n",
      "Start of epoch 91\n",
      "Training loss at epoch 91: 0.4271\n",
      "\n",
      "Start of epoch 92\n",
      "Training loss at epoch 92: 0.4265\n",
      "\n",
      "Start of epoch 93\n",
      "Training loss at epoch 93: 0.4259\n",
      "\n",
      "Start of epoch 94\n",
      "Training loss at epoch 94: 0.4252\n",
      "\n",
      "Start of epoch 95\n",
      "Training loss at epoch 95: 0.4245\n",
      "\n",
      "Start of epoch 96\n",
      "Training loss at epoch 96: 0.4237\n",
      "\n",
      "Start of epoch 97\n",
      "Training loss at epoch 97: 0.4229\n",
      "\n",
      "Start of epoch 98\n",
      "Training loss at epoch 98: 0.4221\n",
      "\n",
      "Start of epoch 99\n",
      "Training loss at epoch 99: 0.4212\n",
      "\n",
      "Start of epoch 100\n",
      "Training loss at epoch 100: 0.4202\n",
      "\n",
      "Start of epoch 101\n",
      "Training loss at epoch 101: 0.4192\n",
      "\n",
      "Start of epoch 102\n",
      "Training loss at epoch 102: 0.4181\n",
      "\n",
      "Start of epoch 103\n",
      "Training loss at epoch 103: 0.4170\n",
      "\n",
      "Start of epoch 104\n",
      "Training loss at epoch 104: 0.4158\n",
      "\n",
      "Start of epoch 105\n",
      "Training loss at epoch 105: 0.4145\n",
      "\n",
      "Start of epoch 106\n",
      "Training loss at epoch 106: 0.4131\n",
      "\n",
      "Start of epoch 107\n",
      "Training loss at epoch 107: 0.4116\n",
      "\n",
      "Start of epoch 108\n",
      "Training loss at epoch 108: 0.4100\n",
      "\n",
      "Start of epoch 109\n",
      "Training loss at epoch 109: 0.4083\n",
      "\n",
      "Start of epoch 110\n",
      "Training loss at epoch 110: 0.4064\n",
      "\n",
      "Start of epoch 111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 111: 0.4044\n",
      "\n",
      "Start of epoch 112\n",
      "Training loss at epoch 112: 0.4022\n",
      "\n",
      "Start of epoch 113\n",
      "Training loss at epoch 113: 0.3998\n",
      "\n",
      "Start of epoch 114\n",
      "Training loss at epoch 114: 0.3972\n",
      "\n",
      "Start of epoch 115\n",
      "Training loss at epoch 115: 0.3944\n",
      "\n",
      "Start of epoch 116\n",
      "Training loss at epoch 116: 0.3914\n",
      "\n",
      "Start of epoch 117\n",
      "Training loss at epoch 117: 0.3882\n",
      "\n",
      "Start of epoch 118\n",
      "Training loss at epoch 118: 0.3848\n",
      "\n",
      "Start of epoch 119\n",
      "Training loss at epoch 119: 0.3813\n",
      "\n",
      "Start of epoch 120\n",
      "Training loss at epoch 120: 0.3776\n",
      "\n",
      "Start of epoch 121\n",
      "Training loss at epoch 121: 0.3738\n",
      "\n",
      "Start of epoch 122\n",
      "Training loss at epoch 122: 0.3699\n",
      "\n",
      "Start of epoch 123\n",
      "Training loss at epoch 123: 0.3659\n",
      "\n",
      "Start of epoch 124\n",
      "Training loss at epoch 124: 0.3619\n",
      "\n",
      "Start of epoch 125\n",
      "Training loss at epoch 125: 0.3580\n",
      "\n",
      "Start of epoch 126\n",
      "Training loss at epoch 126: 0.3540\n",
      "\n",
      "Start of epoch 127\n",
      "Training loss at epoch 127: 0.3502\n",
      "\n",
      "Start of epoch 128\n",
      "Training loss at epoch 128: 0.3464\n",
      "\n",
      "Start of epoch 129\n",
      "Training loss at epoch 129: 0.3429\n",
      "\n",
      "Start of epoch 130\n",
      "Training loss at epoch 130: 0.3396\n",
      "\n",
      "Start of epoch 131\n",
      "Training loss at epoch 131: 0.3366\n",
      "\n",
      "Start of epoch 132\n",
      "Training loss at epoch 132: 0.3339\n",
      "\n",
      "Start of epoch 133\n",
      "Training loss at epoch 133: 0.3314\n",
      "\n",
      "Start of epoch 134\n",
      "Training loss at epoch 134: 0.3291\n",
      "\n",
      "Start of epoch 135\n",
      "Training loss at epoch 135: 0.3269\n",
      "\n",
      "Start of epoch 136\n",
      "Training loss at epoch 136: 0.3245\n",
      "\n",
      "Start of epoch 137\n",
      "Training loss at epoch 137: 0.3218\n",
      "\n",
      "Start of epoch 138\n",
      "Training loss at epoch 138: 0.3189\n",
      "\n",
      "Start of epoch 139\n",
      "Training loss at epoch 139: 0.3156\n",
      "\n",
      "Start of epoch 140\n",
      "Training loss at epoch 140: 0.3120\n",
      "\n",
      "Start of epoch 141\n",
      "Training loss at epoch 141: 0.3083\n",
      "\n",
      "Start of epoch 142\n",
      "Training loss at epoch 142: 0.3047\n",
      "\n",
      "Start of epoch 143\n",
      "Training loss at epoch 143: 0.3010\n",
      "\n",
      "Start of epoch 144\n",
      "Training loss at epoch 144: 0.2976\n",
      "\n",
      "Start of epoch 145\n",
      "Training loss at epoch 145: 0.2944\n",
      "\n",
      "Start of epoch 146\n",
      "Training loss at epoch 146: 0.2914\n",
      "\n",
      "Start of epoch 147\n",
      "Training loss at epoch 147: 0.2888\n",
      "\n",
      "Start of epoch 148\n",
      "Training loss at epoch 148: 0.2866\n",
      "\n",
      "Start of epoch 149\n",
      "Training loss at epoch 149: 0.2848\n",
      "\n",
      "Start of epoch 150\n",
      "Training loss at epoch 150: 0.2833\n",
      "\n",
      "Start of epoch 151\n",
      "Training loss at epoch 151: 0.2821\n",
      "\n",
      "Start of epoch 152\n",
      "Training loss at epoch 152: 0.2812\n",
      "\n",
      "Start of epoch 153\n",
      "Training loss at epoch 153: 0.2805\n",
      "\n",
      "Start of epoch 154\n",
      "Training loss at epoch 154: 0.2799\n",
      "\n",
      "Start of epoch 155\n",
      "Training loss at epoch 155: 0.2794\n",
      "\n",
      "Start of epoch 156\n",
      "Training loss at epoch 156: 0.2789\n",
      "\n",
      "Start of epoch 157\n",
      "Training loss at epoch 157: 0.2784\n",
      "\n",
      "Start of epoch 158\n",
      "Training loss at epoch 158: 0.2778\n",
      "\n",
      "Start of epoch 159\n",
      "Training loss at epoch 159: 0.2771\n",
      "\n",
      "Start of epoch 160\n",
      "Training loss at epoch 160: 0.2763\n",
      "\n",
      "Start of epoch 161\n",
      "Training loss at epoch 161: 0.2754\n",
      "\n",
      "Start of epoch 162\n",
      "Training loss at epoch 162: 0.2744\n",
      "\n",
      "Start of epoch 163\n",
      "Training loss at epoch 163: 0.2734\n",
      "\n",
      "Start of epoch 164\n",
      "Training loss at epoch 164: 0.2723\n",
      "\n",
      "Start of epoch 165\n",
      "Training loss at epoch 165: 0.2712\n",
      "\n",
      "Start of epoch 166\n",
      "Training loss at epoch 166: 0.2701\n",
      "\n",
      "Start of epoch 167\n",
      "Training loss at epoch 167: 0.2690\n",
      "\n",
      "Start of epoch 168\n",
      "Training loss at epoch 168: 0.2679\n",
      "\n",
      "Start of epoch 169\n",
      "Training loss at epoch 169: 0.2668\n",
      "\n",
      "Start of epoch 170\n",
      "Training loss at epoch 170: 0.2657\n",
      "\n",
      "Start of epoch 171\n",
      "Training loss at epoch 171: 0.2646\n",
      "\n",
      "Start of epoch 172\n",
      "Training loss at epoch 172: 0.2635\n",
      "\n",
      "Start of epoch 173\n",
      "Training loss at epoch 173: 0.2623\n",
      "\n",
      "Start of epoch 174\n",
      "Training loss at epoch 174: 0.2611\n",
      "\n",
      "Start of epoch 175\n",
      "Training loss at epoch 175: 0.2599\n",
      "\n",
      "Start of epoch 176\n",
      "Training loss at epoch 176: 0.2587\n",
      "\n",
      "Start of epoch 177\n",
      "Training loss at epoch 177: 0.2575\n",
      "\n",
      "Start of epoch 178\n",
      "Training loss at epoch 178: 0.2562\n",
      "\n",
      "Start of epoch 179\n",
      "Training loss at epoch 179: 0.2548\n",
      "\n",
      "Start of epoch 180\n",
      "Training loss at epoch 180: 0.2534\n",
      "\n",
      "Start of epoch 181\n",
      "Training loss at epoch 181: 0.2520\n",
      "\n",
      "Start of epoch 182\n",
      "Training loss at epoch 182: 0.2506\n",
      "\n",
      "Start of epoch 183\n",
      "Training loss at epoch 183: 0.2491\n",
      "\n",
      "Start of epoch 184\n",
      "Training loss at epoch 184: 0.2476\n",
      "\n",
      "Start of epoch 185\n",
      "Training loss at epoch 185: 0.2461\n",
      "\n",
      "Start of epoch 186\n",
      "Training loss at epoch 186: 0.2446\n",
      "\n",
      "Start of epoch 187\n",
      "Training loss at epoch 187: 0.2431\n",
      "\n",
      "Start of epoch 188\n",
      "Training loss at epoch 188: 0.2415\n",
      "\n",
      "Start of epoch 189\n",
      "Training loss at epoch 189: 0.2400\n",
      "\n",
      "Start of epoch 190\n",
      "Training loss at epoch 190: 0.2385\n",
      "\n",
      "Start of epoch 191\n",
      "Training loss at epoch 191: 0.2371\n",
      "\n",
      "Start of epoch 192\n",
      "Training loss at epoch 192: 0.2356\n",
      "\n",
      "Start of epoch 193\n",
      "Training loss at epoch 193: 0.2342\n",
      "\n",
      "Start of epoch 194\n",
      "Training loss at epoch 194: 0.2328\n",
      "\n",
      "Start of epoch 195\n",
      "Training loss at epoch 195: 0.2314\n",
      "\n",
      "Start of epoch 196\n",
      "Training loss at epoch 196: 0.2301\n",
      "\n",
      "Start of epoch 197\n",
      "Training loss at epoch 197: 0.2287\n",
      "\n",
      "Start of epoch 198\n",
      "Training loss at epoch 198: 0.2274\n",
      "\n",
      "Start of epoch 199\n",
      "Training loss at epoch 199: 0.2260\n",
      "\n",
      "Start of epoch 200\n",
      "Training loss at epoch 200: 0.2247\n",
      "\n",
      "Start of epoch 201\n",
      "Training loss at epoch 201: 0.2233\n",
      "\n",
      "Start of epoch 202\n",
      "Training loss at epoch 202: 0.2218\n",
      "\n",
      "Start of epoch 203\n",
      "Training loss at epoch 203: 0.2203\n",
      "\n",
      "Start of epoch 204\n",
      "Training loss at epoch 204: 0.2188\n",
      "\n",
      "Start of epoch 205\n",
      "Training loss at epoch 205: 0.2172\n",
      "\n",
      "Start of epoch 206\n",
      "Training loss at epoch 206: 0.2156\n",
      "\n",
      "Start of epoch 207\n",
      "Training loss at epoch 207: 0.2140\n",
      "\n",
      "Start of epoch 208\n",
      "Training loss at epoch 208: 0.2124\n",
      "\n",
      "Start of epoch 209\n",
      "Training loss at epoch 209: 0.2108\n",
      "\n",
      "Start of epoch 210\n",
      "Training loss at epoch 210: 0.2093\n",
      "\n",
      "Start of epoch 211\n",
      "Training loss at epoch 211: 0.2077\n",
      "\n",
      "Start of epoch 212\n",
      "Training loss at epoch 212: 0.2061\n",
      "\n",
      "Start of epoch 213\n",
      "Training loss at epoch 213: 0.2044\n",
      "\n",
      "Start of epoch 214\n",
      "Training loss at epoch 214: 0.2026\n",
      "\n",
      "Start of epoch 215\n",
      "Training loss at epoch 215: 0.2007\n",
      "\n",
      "Start of epoch 216\n",
      "Training loss at epoch 216: 0.1987\n",
      "\n",
      "Start of epoch 217\n",
      "Training loss at epoch 217: 0.1966\n",
      "\n",
      "Start of epoch 218\n",
      "Training loss at epoch 218: 0.1944\n",
      "\n",
      "Start of epoch 219\n",
      "Training loss at epoch 219: 0.1922\n",
      "\n",
      "Start of epoch 220\n",
      "Training loss at epoch 220: 0.1899\n",
      "\n",
      "Start of epoch 221\n",
      "Training loss at epoch 221: 0.1877\n",
      "\n",
      "Start of epoch 222\n",
      "Training loss at epoch 222: 0.1854\n",
      "\n",
      "Start of epoch 223\n",
      "Training loss at epoch 223: 0.1833\n",
      "\n",
      "Start of epoch 224\n",
      "Training loss at epoch 224: 0.1812\n",
      "\n",
      "Start of epoch 225\n",
      "Training loss at epoch 225: 0.1791\n",
      "\n",
      "Start of epoch 226\n",
      "Training loss at epoch 226: 0.1770\n",
      "\n",
      "Start of epoch 227\n",
      "Training loss at epoch 227: 0.1749\n",
      "\n",
      "Start of epoch 228\n",
      "Training loss at epoch 228: 0.1728\n",
      "\n",
      "Start of epoch 229\n",
      "Training loss at epoch 229: 0.1706\n",
      "\n",
      "Start of epoch 230\n",
      "Training loss at epoch 230: 0.1683\n",
      "\n",
      "Start of epoch 231\n",
      "Training loss at epoch 231: 0.1658\n",
      "\n",
      "Start of epoch 232\n",
      "Training loss at epoch 232: 0.1632\n",
      "\n",
      "Start of epoch 233\n",
      "Training loss at epoch 233: 0.1603\n",
      "\n",
      "Start of epoch 234\n",
      "Training loss at epoch 234: 0.1572\n",
      "\n",
      "Start of epoch 235\n",
      "Training loss at epoch 235: 0.1538\n",
      "\n",
      "Start of epoch 236\n",
      "Training loss at epoch 236: 0.1500\n",
      "\n",
      "Start of epoch 237\n",
      "Training loss at epoch 237: 0.1459\n",
      "\n",
      "Start of epoch 238\n",
      "Training loss at epoch 238: 0.1415\n",
      "\n",
      "Start of epoch 239\n",
      "Training loss at epoch 239: 0.1369\n",
      "\n",
      "Start of epoch 240\n",
      "Training loss at epoch 240: 0.1321\n",
      "\n",
      "Start of epoch 241\n",
      "Training loss at epoch 241: 0.1272\n",
      "\n",
      "Start of epoch 242\n",
      "Training loss at epoch 242: 0.1224\n",
      "\n",
      "Start of epoch 243\n",
      "Training loss at epoch 243: 0.1178\n",
      "\n",
      "Start of epoch 244\n",
      "Training loss at epoch 244: 0.1138\n",
      "\n",
      "Start of epoch 245\n",
      "Training loss at epoch 245: 0.1104\n",
      "\n",
      "Start of epoch 246\n",
      "Training loss at epoch 246: 0.1078\n",
      "\n",
      "Start of epoch 247\n",
      "Training loss at epoch 247: 0.1058\n",
      "\n",
      "Start of epoch 248\n",
      "Training loss at epoch 248: 0.1044\n",
      "\n",
      "Start of epoch 249\n",
      "Training loss at epoch 249: 0.1034\n",
      "\n",
      "Start of epoch 250\n",
      "Training loss at epoch 250: 0.1024\n",
      "\n",
      "Start of epoch 251\n",
      "Training loss at epoch 251: 0.1012\n",
      "\n",
      "Start of epoch 252\n",
      "Training loss at epoch 252: 0.0998\n",
      "\n",
      "Start of epoch 253\n",
      "Training loss at epoch 253: 0.0980\n",
      "\n",
      "Start of epoch 254\n",
      "Training loss at epoch 254: 0.0959\n",
      "\n",
      "Start of epoch 255\n",
      "Training loss at epoch 255: 0.0939\n",
      "\n",
      "Start of epoch 256\n",
      "Training loss at epoch 256: 0.0919\n",
      "\n",
      "Start of epoch 257\n",
      "Training loss at epoch 257: 0.0902\n",
      "\n",
      "Start of epoch 258\n",
      "Training loss at epoch 258: 0.0888\n",
      "\n",
      "Start of epoch 259\n",
      "Training loss at epoch 259: 0.0878\n",
      "\n",
      "Start of epoch 260\n",
      "Training loss at epoch 260: 0.0870\n",
      "\n",
      "Start of epoch 261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 261: 0.0864\n",
      "\n",
      "Start of epoch 262\n",
      "Training loss at epoch 262: 0.0857\n",
      "\n",
      "Start of epoch 263\n",
      "Training loss at epoch 263: 0.0850\n",
      "\n",
      "Start of epoch 264\n",
      "Training loss at epoch 264: 0.0842\n",
      "\n",
      "Start of epoch 265\n",
      "Training loss at epoch 265: 0.0834\n",
      "\n",
      "Start of epoch 266\n",
      "Training loss at epoch 266: 0.0825\n",
      "\n",
      "Start of epoch 267\n",
      "Training loss at epoch 267: 0.0818\n",
      "\n",
      "Start of epoch 268\n",
      "Training loss at epoch 268: 0.0812\n",
      "\n",
      "Start of epoch 269\n",
      "Training loss at epoch 269: 0.0808\n",
      "\n",
      "Start of epoch 270\n",
      "Training loss at epoch 270: 0.0805\n",
      "\n",
      "Start of epoch 271\n",
      "Training loss at epoch 271: 0.0802\n",
      "\n",
      "Start of epoch 272\n",
      "Training loss at epoch 272: 0.0800\n",
      "\n",
      "Start of epoch 273\n",
      "Training loss at epoch 273: 0.0796\n",
      "\n",
      "Start of epoch 274\n",
      "Training loss at epoch 274: 0.0791\n",
      "\n",
      "Start of epoch 275\n",
      "Training loss at epoch 275: 0.0786\n",
      "\n",
      "Start of epoch 276\n",
      "Training loss at epoch 276: 0.0781\n",
      "\n",
      "Start of epoch 277\n",
      "Training loss at epoch 277: 0.0775\n",
      "\n",
      "Start of epoch 278\n",
      "Training loss at epoch 278: 0.0770\n",
      "\n",
      "Start of epoch 279\n",
      "Training loss at epoch 279: 0.0765\n",
      "\n",
      "Start of epoch 280\n",
      "Training loss at epoch 280: 0.0761\n",
      "\n",
      "Start of epoch 281\n",
      "Training loss at epoch 281: 0.0756\n",
      "\n",
      "Start of epoch 282\n",
      "Training loss at epoch 282: 0.0752\n",
      "\n",
      "Start of epoch 283\n",
      "Training loss at epoch 283: 0.0747\n",
      "\n",
      "Start of epoch 284\n",
      "Training loss at epoch 284: 0.0742\n",
      "\n",
      "Start of epoch 285\n",
      "Training loss at epoch 285: 0.0737\n",
      "\n",
      "Start of epoch 286\n",
      "Training loss at epoch 286: 0.0732\n",
      "\n",
      "Start of epoch 287\n",
      "Training loss at epoch 287: 0.0727\n",
      "\n",
      "Start of epoch 288\n",
      "Training loss at epoch 288: 0.0722\n",
      "\n",
      "Start of epoch 289\n",
      "Training loss at epoch 289: 0.0717\n",
      "\n",
      "Start of epoch 290\n",
      "Training loss at epoch 290: 0.0712\n",
      "\n",
      "Start of epoch 291\n",
      "Training loss at epoch 291: 0.0707\n",
      "\n",
      "Start of epoch 292\n",
      "Training loss at epoch 292: 0.0702\n",
      "\n",
      "Start of epoch 293\n",
      "Training loss at epoch 293: 0.0696\n",
      "\n",
      "Start of epoch 294\n",
      "Training loss at epoch 294: 0.0690\n",
      "\n",
      "Start of epoch 295\n",
      "Training loss at epoch 295: 0.0684\n",
      "\n",
      "Start of epoch 296\n",
      "Training loss at epoch 296: 0.0678\n",
      "\n",
      "Start of epoch 297\n",
      "Training loss at epoch 297: 0.0672\n",
      "\n",
      "Start of epoch 298\n",
      "Training loss at epoch 298: 0.0666\n",
      "\n",
      "Start of epoch 299\n",
      "Training loss at epoch 299: 0.0659\n",
      "\n",
      "Start of epoch 300\n",
      "Training loss at epoch 300: 0.0653\n",
      "\n",
      "Start of epoch 301\n",
      "Training loss at epoch 301: 0.0646\n",
      "\n",
      "Start of epoch 302\n",
      "Training loss at epoch 302: 0.0639\n",
      "\n",
      "Start of epoch 303\n",
      "Training loss at epoch 303: 0.0632\n",
      "\n",
      "Start of epoch 304\n",
      "Training loss at epoch 304: 0.0625\n",
      "\n",
      "Start of epoch 305\n",
      "Training loss at epoch 305: 0.0618\n",
      "\n",
      "Start of epoch 306\n",
      "Training loss at epoch 306: 0.0610\n",
      "\n",
      "Start of epoch 307\n",
      "Training loss at epoch 307: 0.0602\n",
      "\n",
      "Start of epoch 308\n",
      "Training loss at epoch 308: 0.0595\n",
      "\n",
      "Start of epoch 309\n",
      "Training loss at epoch 309: 0.0587\n",
      "\n",
      "Start of epoch 310\n",
      "Training loss at epoch 310: 0.0579\n",
      "\n",
      "Start of epoch 311\n",
      "Training loss at epoch 311: 0.0571\n",
      "\n",
      "Start of epoch 312\n",
      "Training loss at epoch 312: 0.0562\n",
      "\n",
      "Start of epoch 313\n",
      "Training loss at epoch 313: 0.0554\n",
      "\n",
      "Start of epoch 314\n",
      "Training loss at epoch 314: 0.0546\n",
      "\n",
      "Start of epoch 315\n",
      "Training loss at epoch 315: 0.0537\n",
      "\n",
      "Start of epoch 316\n",
      "Training loss at epoch 316: 0.0528\n",
      "\n",
      "Start of epoch 317\n",
      "Training loss at epoch 317: 0.0520\n",
      "\n",
      "Start of epoch 318\n",
      "Training loss at epoch 318: 0.0511\n",
      "\n",
      "Start of epoch 319\n",
      "Training loss at epoch 319: 0.0502\n",
      "\n",
      "Start of epoch 320\n",
      "Training loss at epoch 320: 0.0493\n",
      "\n",
      "Start of epoch 321\n",
      "Training loss at epoch 321: 0.0484\n",
      "\n",
      "Start of epoch 322\n",
      "Training loss at epoch 322: 0.0474\n",
      "\n",
      "Start of epoch 323\n",
      "Training loss at epoch 323: 0.0465\n",
      "\n",
      "Start of epoch 324\n",
      "Training loss at epoch 324: 0.0456\n",
      "\n",
      "Start of epoch 325\n",
      "Training loss at epoch 325: 0.0447\n",
      "\n",
      "Start of epoch 326\n",
      "Training loss at epoch 326: 0.0438\n",
      "\n",
      "Start of epoch 327\n",
      "Training loss at epoch 327: 0.0429\n",
      "\n",
      "Start of epoch 328\n",
      "Training loss at epoch 328: 0.0420\n",
      "\n",
      "Start of epoch 329\n",
      "Training loss at epoch 329: 0.0411\n",
      "\n",
      "Start of epoch 330\n",
      "Training loss at epoch 330: 0.0402\n",
      "\n",
      "Start of epoch 331\n",
      "Training loss at epoch 331: 0.0394\n",
      "\n",
      "Start of epoch 332\n",
      "Training loss at epoch 332: 0.0385\n",
      "\n",
      "Start of epoch 333\n",
      "Training loss at epoch 333: 0.0377\n",
      "\n",
      "Start of epoch 334\n",
      "Training loss at epoch 334: 0.0370\n",
      "\n",
      "Start of epoch 335\n",
      "Training loss at epoch 335: 0.0362\n",
      "\n",
      "Start of epoch 336\n",
      "Training loss at epoch 336: 0.0355\n",
      "\n",
      "Start of epoch 337\n",
      "Training loss at epoch 337: 0.0348\n",
      "\n",
      "Start of epoch 338\n",
      "Training loss at epoch 338: 0.0342\n",
      "\n",
      "Start of epoch 339\n",
      "Training loss at epoch 339: 0.0336\n",
      "\n",
      "Start of epoch 340\n",
      "Training loss at epoch 340: 0.0330\n",
      "\n",
      "Start of epoch 341\n",
      "Training loss at epoch 341: 0.0325\n",
      "\n",
      "Start of epoch 342\n",
      "Training loss at epoch 342: 0.0319\n",
      "\n",
      "Start of epoch 343\n",
      "Training loss at epoch 343: 0.0315\n",
      "\n",
      "Start of epoch 344\n",
      "Training loss at epoch 344: 0.0310\n",
      "\n",
      "Start of epoch 345\n",
      "Training loss at epoch 345: 0.0305\n",
      "\n",
      "Start of epoch 346\n",
      "Training loss at epoch 346: 0.0301\n",
      "\n",
      "Start of epoch 347\n",
      "Training loss at epoch 347: 0.0297\n",
      "\n",
      "Start of epoch 348\n",
      "Training loss at epoch 348: 0.0293\n",
      "\n",
      "Start of epoch 349\n",
      "Training loss at epoch 349: 0.0290\n",
      "\n",
      "Start of epoch 350\n",
      "Training loss at epoch 350: 0.0286\n",
      "\n",
      "Start of epoch 351\n",
      "Training loss at epoch 351: 0.0282\n",
      "\n",
      "Start of epoch 352\n",
      "Training loss at epoch 352: 0.0279\n",
      "\n",
      "Start of epoch 353\n",
      "Training loss at epoch 353: 0.0275\n",
      "\n",
      "Start of epoch 354\n",
      "Training loss at epoch 354: 0.0272\n",
      "\n",
      "Start of epoch 355\n",
      "Training loss at epoch 355: 0.0269\n",
      "\n",
      "Start of epoch 356\n",
      "Training loss at epoch 356: 0.0265\n",
      "\n",
      "Start of epoch 357\n",
      "Training loss at epoch 357: 0.0262\n",
      "\n",
      "Start of epoch 358\n",
      "Training loss at epoch 358: 0.0258\n",
      "\n",
      "Start of epoch 359\n",
      "Training loss at epoch 359: 0.0255\n",
      "\n",
      "Start of epoch 360\n",
      "Training loss at epoch 360: 0.0251\n",
      "\n",
      "Start of epoch 361\n",
      "Training loss at epoch 361: 0.0247\n",
      "\n",
      "Start of epoch 362\n",
      "Training loss at epoch 362: 0.0243\n",
      "\n",
      "Start of epoch 363\n",
      "Training loss at epoch 363: 0.0239\n",
      "\n",
      "Start of epoch 364\n",
      "Training loss at epoch 364: 0.0235\n",
      "\n",
      "Start of epoch 365\n",
      "Training loss at epoch 365: 0.0230\n",
      "\n",
      "Start of epoch 366\n",
      "Training loss at epoch 366: 0.0225\n",
      "\n",
      "Start of epoch 367\n",
      "Training loss at epoch 367: 0.0220\n",
      "\n",
      "Start of epoch 368\n",
      "Training loss at epoch 368: 0.0215\n",
      "\n",
      "Start of epoch 369\n",
      "Training loss at epoch 369: 0.0209\n",
      "\n",
      "Start of epoch 370\n",
      "Training loss at epoch 370: 0.0202\n",
      "\n",
      "Start of epoch 371\n",
      "Training loss at epoch 371: 0.0196\n",
      "\n",
      "Start of epoch 372\n",
      "Training loss at epoch 372: 0.0188\n",
      "\n",
      "Start of epoch 373\n",
      "Training loss at epoch 373: 0.0181\n",
      "\n",
      "Start of epoch 374\n",
      "Training loss at epoch 374: 0.0173\n",
      "\n",
      "Start of epoch 375\n",
      "Training loss at epoch 375: 0.0164\n",
      "\n",
      "Start of epoch 376\n",
      "Training loss at epoch 376: 0.0155\n",
      "\n",
      "Start of epoch 377\n",
      "Training loss at epoch 377: 0.0146\n",
      "\n",
      "Start of epoch 378\n",
      "Training loss at epoch 378: 0.0136\n",
      "\n",
      "Start of epoch 379\n",
      "Training loss at epoch 379: 0.0126\n",
      "\n",
      "Start of epoch 380\n",
      "Training loss at epoch 380: 0.0115\n",
      "\n",
      "Start of epoch 381\n",
      "Training loss at epoch 381: 0.0104\n",
      "\n",
      "Start of epoch 382\n",
      "Training loss at epoch 382: 0.0093\n",
      "\n",
      "Start of epoch 383\n",
      "Training loss at epoch 383: 0.0082\n",
      "\n",
      "Start of epoch 384\n",
      "Training loss at epoch 384: 0.0072\n",
      "\n",
      "Start of epoch 385\n",
      "Training loss at epoch 385: 0.0061\n",
      "\n",
      "Start of epoch 386\n",
      "Training loss at epoch 386: 0.0052\n",
      "\n",
      "Start of epoch 387\n",
      "Training loss at epoch 387: 0.0043\n",
      "\n",
      "Start of epoch 388\n",
      "Training loss at epoch 388: 0.0035\n",
      "\n",
      "Start of epoch 389\n",
      "Training loss at epoch 389: 0.0028\n",
      "\n",
      "Start of epoch 390\n",
      "Training loss at epoch 390: 0.0023\n",
      "\n",
      "Start of epoch 391\n",
      "Training loss at epoch 391: 0.0018\n",
      "\n",
      "Start of epoch 392\n",
      "Training loss at epoch 392: 0.0015\n",
      "\n",
      "Start of epoch 393\n",
      "Training loss at epoch 393: 0.0012\n",
      "\n",
      "Start of epoch 394\n",
      "Training loss at epoch 394: 0.0010\n",
      "\n",
      "Start of epoch 395\n",
      "Training loss at epoch 395: 0.0009\n",
      "\n",
      "Start of epoch 396\n",
      "Training loss at epoch 396: 0.0008\n",
      "\n",
      "Start of epoch 397\n",
      "Training loss at epoch 397: 0.0007\n",
      "\n",
      "Start of epoch 398\n",
      "Training loss at epoch 398: 0.0007\n",
      "\n",
      "Start of epoch 399\n",
      "Training loss at epoch 399: 0.0006\n",
      "\n",
      "Start of epoch 400\n",
      "Training loss at epoch 400: 0.0006\n",
      "\n",
      "Start of epoch 401\n",
      "Training loss at epoch 401: 0.0006\n",
      "\n",
      "Start of epoch 402\n",
      "Training loss at epoch 402: 0.0005\n",
      "\n",
      "Start of epoch 403\n",
      "Training loss at epoch 403: 0.0005\n",
      "\n",
      "Start of epoch 404\n",
      "Training loss at epoch 404: 0.0005\n",
      "\n",
      "Start of epoch 405\n",
      "Training loss at epoch 405: 0.0005\n",
      "\n",
      "Start of epoch 406\n",
      "Training loss at epoch 406: 0.0004\n",
      "\n",
      "Start of epoch 407\n",
      "Training loss at epoch 407: 0.0004\n",
      "\n",
      "Start of epoch 408\n",
      "Training loss at epoch 408: 0.0004\n",
      "\n",
      "Start of epoch 409\n",
      "Training loss at epoch 409: 0.0004\n",
      "\n",
      "Start of epoch 410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 410: 0.0004\n",
      "\n",
      "Start of epoch 411\n",
      "Training loss at epoch 411: 0.0004\n",
      "\n",
      "Start of epoch 412\n",
      "Training loss at epoch 412: 0.0003\n",
      "\n",
      "Start of epoch 413\n",
      "Training loss at epoch 413: 0.0003\n",
      "\n",
      "Start of epoch 414\n",
      "Training loss at epoch 414: 0.0003\n",
      "\n",
      "Start of epoch 415\n",
      "Training loss at epoch 415: 0.0003\n",
      "\n",
      "Start of epoch 416\n",
      "Training loss at epoch 416: 0.0003\n",
      "\n",
      "Start of epoch 417\n",
      "Training loss at epoch 417: 0.0003\n",
      "\n",
      "Start of epoch 418\n",
      "Training loss at epoch 418: 0.0002\n",
      "\n",
      "Start of epoch 419\n",
      "Training loss at epoch 419: 0.0002\n",
      "\n",
      "Start of epoch 420\n",
      "Training loss at epoch 420: 0.0002\n",
      "\n",
      "Start of epoch 421\n",
      "Training loss at epoch 421: 0.0002\n",
      "\n",
      "Start of epoch 422\n",
      "Training loss at epoch 422: 0.0002\n",
      "\n",
      "Start of epoch 423\n",
      "Training loss at epoch 423: 0.0002\n",
      "\n",
      "Start of epoch 424\n",
      "Training loss at epoch 424: 0.0002\n",
      "\n",
      "Start of epoch 425\n",
      "Training loss at epoch 425: 0.0002\n",
      "\n",
      "Start of epoch 426\n",
      "Training loss at epoch 426: 0.0002\n",
      "\n",
      "Start of epoch 427\n",
      "Training loss at epoch 427: 0.0002\n",
      "\n",
      "Start of epoch 428\n",
      "Training loss at epoch 428: 0.0002\n",
      "\n",
      "Start of epoch 429\n",
      "Training loss at epoch 429: 0.0002\n",
      "\n",
      "Start of epoch 430\n",
      "Training loss at epoch 430: 0.0002\n",
      "\n",
      "Start of epoch 431\n",
      "Training loss at epoch 431: 0.0002\n",
      "\n",
      "Start of epoch 432\n",
      "Training loss at epoch 432: 0.0002\n",
      "\n",
      "Start of epoch 433\n",
      "Training loss at epoch 433: 0.0002\n",
      "\n",
      "Start of epoch 434\n",
      "Training loss at epoch 434: 0.0002\n",
      "\n",
      "Start of epoch 435\n",
      "Training loss at epoch 435: 0.0002\n",
      "\n",
      "Start of epoch 436\n",
      "Training loss at epoch 436: 0.0002\n",
      "\n",
      "Start of epoch 437\n",
      "Training loss at epoch 437: 0.0001\n",
      "\n",
      "Start of epoch 438\n",
      "Training loss at epoch 438: 0.0001\n",
      "\n",
      "Start of epoch 439\n",
      "Training loss at epoch 439: 0.0001\n",
      "\n",
      "Start of epoch 440\n",
      "Training loss at epoch 440: 0.0001\n",
      "\n",
      "Start of epoch 441\n",
      "Training loss at epoch 441: 0.0001\n",
      "\n",
      "Start of epoch 442\n",
      "Training loss at epoch 442: 0.0001\n",
      "\n",
      "Start of epoch 443\n",
      "Training loss at epoch 443: 0.0001\n",
      "\n",
      "Start of epoch 444\n",
      "Training loss at epoch 444: 0.0001\n",
      "\n",
      "Start of epoch 445\n",
      "Training loss at epoch 445: 0.0001\n",
      "\n",
      "Start of epoch 446\n",
      "Training loss at epoch 446: 0.0001\n",
      "\n",
      "Start of epoch 447\n",
      "Training loss at epoch 447: 0.0001\n",
      "\n",
      "Start of epoch 448\n",
      "Training loss at epoch 448: 0.0001\n",
      "\n",
      "Start of epoch 449\n",
      "Training loss at epoch 449: 0.0001\n",
      "\n",
      "Start of epoch 450\n",
      "Training loss at epoch 450: 0.0001\n",
      "\n",
      "Start of epoch 451\n",
      "Training loss at epoch 451: 0.0001\n",
      "\n",
      "Start of epoch 452\n",
      "Training loss at epoch 452: 0.0001\n",
      "\n",
      "Start of epoch 453\n",
      "Training loss at epoch 453: 0.0001\n",
      "\n",
      "Start of epoch 454\n",
      "Training loss at epoch 454: 0.0001\n",
      "\n",
      "Start of epoch 455\n",
      "Training loss at epoch 455: 0.0001\n",
      "\n",
      "Start of epoch 456\n",
      "Training loss at epoch 456: 0.0001\n",
      "\n",
      "Start of epoch 457\n",
      "Training loss at epoch 457: 0.0001\n",
      "\n",
      "Start of epoch 458\n",
      "Training loss at epoch 458: 0.0001\n",
      "\n",
      "Start of epoch 459\n",
      "Training loss at epoch 459: 0.0001\n",
      "\n",
      "Start of epoch 460\n",
      "Training loss at epoch 460: 0.0001\n",
      "\n",
      "Start of epoch 461\n",
      "Training loss at epoch 461: 0.0001\n",
      "\n",
      "Start of epoch 462\n",
      "Training loss at epoch 462: 0.0001\n",
      "\n",
      "Start of epoch 463\n",
      "Training loss at epoch 463: 0.0001\n",
      "\n",
      "Start of epoch 464\n",
      "Training loss at epoch 464: 0.0001\n",
      "\n",
      "Start of epoch 465\n",
      "Training loss at epoch 465: 0.0001\n",
      "\n",
      "Start of epoch 466\n",
      "Training loss at epoch 466: 0.0001\n",
      "\n",
      "Start of epoch 467\n",
      "Training loss at epoch 467: 0.0001\n",
      "\n",
      "Start of epoch 468\n",
      "Training loss at epoch 468: 0.0001\n",
      "\n",
      "Start of epoch 469\n",
      "Training loss at epoch 469: 0.0001\n",
      "\n",
      "Start of epoch 470\n",
      "Training loss at epoch 470: 0.0001\n",
      "\n",
      "Start of epoch 471\n",
      "Training loss at epoch 471: 0.0001\n",
      "\n",
      "Start of epoch 472\n",
      "Training loss at epoch 472: 0.0001\n",
      "\n",
      "Start of epoch 473\n",
      "Training loss at epoch 473: 0.0001\n",
      "\n",
      "Start of epoch 474\n",
      "Training loss at epoch 474: 0.0001\n",
      "\n",
      "Start of epoch 475\n",
      "Training loss at epoch 475: 0.0001\n",
      "\n",
      "Start of epoch 476\n",
      "Training loss at epoch 476: 0.0001\n",
      "\n",
      "Start of epoch 477\n",
      "Training loss at epoch 477: 0.0001\n",
      "\n",
      "Start of epoch 478\n",
      "Training loss at epoch 478: 0.0001\n",
      "\n",
      "Start of epoch 479\n",
      "Training loss at epoch 479: 0.0001\n",
      "\n",
      "Start of epoch 480\n",
      "Training loss at epoch 480: 0.0001\n",
      "\n",
      "Start of epoch 481\n",
      "Training loss at epoch 481: 0.0001\n",
      "\n",
      "Start of epoch 482\n",
      "Training loss at epoch 482: 0.0001\n",
      "\n",
      "Start of epoch 483\n",
      "Training loss at epoch 483: 0.0001\n",
      "\n",
      "Start of epoch 484\n",
      "Training loss at epoch 484: 0.0001\n",
      "\n",
      "Start of epoch 485\n",
      "Training loss at epoch 485: 0.0001\n",
      "\n",
      "Start of epoch 486\n",
      "Training loss at epoch 486: 0.0001\n",
      "\n",
      "Start of epoch 487\n",
      "Training loss at epoch 487: 0.0001\n",
      "\n",
      "Start of epoch 488\n",
      "Training loss at epoch 488: 0.0001\n",
      "\n",
      "Start of epoch 489\n",
      "Training loss at epoch 489: 0.0001\n",
      "\n",
      "Start of epoch 490\n",
      "Training loss at epoch 490: 0.0001\n",
      "\n",
      "Start of epoch 491\n",
      "Training loss at epoch 491: 0.0001\n",
      "\n",
      "Start of epoch 492\n",
      "Training loss at epoch 492: 0.0001\n",
      "\n",
      "Start of epoch 493\n",
      "Training loss at epoch 493: 0.0001\n",
      "\n",
      "Start of epoch 494\n",
      "Training loss at epoch 494: 0.0001\n",
      "\n",
      "Start of epoch 495\n",
      "Training loss at epoch 495: 0.0001\n",
      "\n",
      "Start of epoch 496\n",
      "Training loss at epoch 496: 0.0001\n",
      "\n",
      "Start of epoch 497\n",
      "Training loss at epoch 497: 0.0001\n",
      "\n",
      "Start of epoch 498\n",
      "Training loss at epoch 498: 0.0001\n",
      "\n",
      "Start of epoch 499\n",
      "Training loss at epoch 499: 0.0001\n",
      "[<tf.Variable 'parameters:0' shape=(45,) dtype=float32, numpy=\n",
      "array([1.7145134e+00, 5.9796715e+00, 6.0598421e+00, 3.9173434e-03,\n",
      "       1.8855658e+00, 3.3372688e+00, 4.6624665e+00, 2.9917188e+00,\n",
      "       5.0112014e+00, 7.6449996e-01, 3.2076077e+00, 3.5482998e+00,\n",
      "       3.0541162e+00, 4.1879730e+00, 5.7795191e+00, 3.6363502e+00,\n",
      "       3.3650813e+00, 9.4858587e-01, 1.3803746e+00, 5.8221645e+00,\n",
      "       2.6904676e+00, 5.8452392e+00, 3.0186540e-01, 2.1795719e+00,\n",
      "       9.2221236e-01, 1.9146949e+00, 2.8089218e+00, 3.7726790e-01,\n",
      "       5.0254636e+00, 2.9712265e+00, 2.2782850e+00, 3.0468678e+00,\n",
      "       1.6227674e+00, 2.7292111e+00, 1.2668802e+00, 5.5135751e-01,\n",
      "       4.3642797e+00, 4.7255749e-01, 5.1886654e+00, 1.6831754e+00,\n",
      "       4.7544246e+00, 3.2773576e+00, 5.7904339e+00, 5.9638734e+00,\n",
      "       2.1569681e+00], dtype=float32)>]\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.1690\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 1.0928\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 1.0236\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.9605\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.9036\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.8548\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.8144\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.7828\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.7624\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.7536\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.7511\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.7478\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.7396\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.7262\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.7096\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.6926\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.6785\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.6691\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.6644\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.6621\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.6592\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.6535\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.6440\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.6316\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.6177\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.6043\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.5925\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.5823\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.5727\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.5624\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.5509\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.5386\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.5265\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.5157\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.5067\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.4992\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.4922\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.4846\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.4757\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.4658\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.4554\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.4458\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.4375\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.4306\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.4247\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.4193\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.4139\n",
      "\n",
      "Start of epoch 47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 47: 0.4084\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.4029\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.3974\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.3922\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.3873\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.3827\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.3781\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.3735\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.3687\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.3638\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.3589\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.3541\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.3495\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.3450\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.3407\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.3363\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.3319\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.3274\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.3229\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.3183\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.3138\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.3093\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.3048\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.3004\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.2962\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.2922\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.2883\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.2846\n",
      "\n",
      "Start of epoch 75\n",
      "Training loss at epoch 75: 0.2809\n",
      "\n",
      "Start of epoch 76\n",
      "Training loss at epoch 76: 0.2774\n",
      "\n",
      "Start of epoch 77\n",
      "Training loss at epoch 77: 0.2739\n",
      "\n",
      "Start of epoch 78\n",
      "Training loss at epoch 78: 0.2708\n",
      "\n",
      "Start of epoch 79\n",
      "Training loss at epoch 79: 0.2680\n",
      "\n",
      "Start of epoch 80\n",
      "Training loss at epoch 80: 0.2655\n",
      "\n",
      "Start of epoch 81\n",
      "Training loss at epoch 81: 0.2634\n",
      "\n",
      "Start of epoch 82\n",
      "Training loss at epoch 82: 0.2616\n",
      "\n",
      "Start of epoch 83\n",
      "Training loss at epoch 83: 0.2598\n",
      "\n",
      "Start of epoch 84\n",
      "Training loss at epoch 84: 0.2581\n",
      "\n",
      "Start of epoch 85\n",
      "Training loss at epoch 85: 0.2562\n",
      "\n",
      "Start of epoch 86\n",
      "Training loss at epoch 86: 0.2543\n",
      "\n",
      "Start of epoch 87\n",
      "Training loss at epoch 87: 0.2523\n",
      "\n",
      "Start of epoch 88\n",
      "Training loss at epoch 88: 0.2503\n",
      "\n",
      "Start of epoch 89\n",
      "Training loss at epoch 89: 0.2482\n",
      "\n",
      "Start of epoch 90\n",
      "Training loss at epoch 90: 0.2462\n",
      "\n",
      "Start of epoch 91\n",
      "Training loss at epoch 91: 0.2441\n",
      "\n",
      "Start of epoch 92\n",
      "Training loss at epoch 92: 0.2420\n",
      "\n",
      "Start of epoch 93\n",
      "Training loss at epoch 93: 0.2400\n",
      "\n",
      "Start of epoch 94\n",
      "Training loss at epoch 94: 0.2379\n",
      "\n",
      "Start of epoch 95\n",
      "Training loss at epoch 95: 0.2360\n",
      "\n",
      "Start of epoch 96\n",
      "Training loss at epoch 96: 0.2340\n",
      "\n",
      "Start of epoch 97\n",
      "Training loss at epoch 97: 0.2322\n",
      "\n",
      "Start of epoch 98\n",
      "Training loss at epoch 98: 0.2304\n",
      "\n",
      "Start of epoch 99\n",
      "Training loss at epoch 99: 0.2287\n",
      "\n",
      "Start of epoch 100\n",
      "Training loss at epoch 100: 0.2270\n",
      "\n",
      "Start of epoch 101\n",
      "Training loss at epoch 101: 0.2254\n",
      "\n",
      "Start of epoch 102\n",
      "Training loss at epoch 102: 0.2239\n",
      "\n",
      "Start of epoch 103\n",
      "Training loss at epoch 103: 0.2224\n",
      "\n",
      "Start of epoch 104\n",
      "Training loss at epoch 104: 0.2210\n",
      "\n",
      "Start of epoch 105\n",
      "Training loss at epoch 105: 0.2197\n",
      "\n",
      "Start of epoch 106\n",
      "Training loss at epoch 106: 0.2184\n",
      "\n",
      "Start of epoch 107\n",
      "Training loss at epoch 107: 0.2171\n",
      "\n",
      "Start of epoch 108\n",
      "Training loss at epoch 108: 0.2159\n",
      "\n",
      "Start of epoch 109\n",
      "Training loss at epoch 109: 0.2145\n",
      "\n",
      "Start of epoch 110\n",
      "Training loss at epoch 110: 0.2132\n",
      "\n",
      "Start of epoch 111\n",
      "Training loss at epoch 111: 0.2117\n",
      "\n",
      "Start of epoch 112\n",
      "Training loss at epoch 112: 0.2102\n",
      "\n",
      "Start of epoch 113\n",
      "Training loss at epoch 113: 0.2086\n",
      "\n",
      "Start of epoch 114\n",
      "Training loss at epoch 114: 0.2068\n",
      "\n",
      "Start of epoch 115\n",
      "Training loss at epoch 115: 0.2050\n",
      "\n",
      "Start of epoch 116\n",
      "Training loss at epoch 116: 0.2030\n",
      "\n",
      "Start of epoch 117\n",
      "Training loss at epoch 117: 0.2009\n",
      "\n",
      "Start of epoch 118\n",
      "Training loss at epoch 118: 0.1987\n",
      "\n",
      "Start of epoch 119\n",
      "Training loss at epoch 119: 0.1964\n",
      "\n",
      "Start of epoch 120\n",
      "Training loss at epoch 120: 0.1939\n",
      "\n",
      "Start of epoch 121\n",
      "Training loss at epoch 121: 0.1912\n",
      "\n",
      "Start of epoch 122\n",
      "Training loss at epoch 122: 0.1884\n",
      "\n",
      "Start of epoch 123\n",
      "Training loss at epoch 123: 0.1854\n",
      "\n",
      "Start of epoch 124\n",
      "Training loss at epoch 124: 0.1823\n",
      "\n",
      "Start of epoch 125\n",
      "Training loss at epoch 125: 0.1790\n",
      "\n",
      "Start of epoch 126\n",
      "Training loss at epoch 126: 0.1757\n",
      "\n",
      "Start of epoch 127\n",
      "Training loss at epoch 127: 0.1723\n",
      "\n",
      "Start of epoch 128\n",
      "Training loss at epoch 128: 0.1689\n",
      "\n",
      "Start of epoch 129\n",
      "Training loss at epoch 129: 0.1655\n",
      "\n",
      "Start of epoch 130\n",
      "Training loss at epoch 130: 0.1621\n",
      "\n",
      "Start of epoch 131\n",
      "Training loss at epoch 131: 0.1588\n",
      "\n",
      "Start of epoch 132\n",
      "Training loss at epoch 132: 0.1555\n",
      "\n",
      "Start of epoch 133\n",
      "Training loss at epoch 133: 0.1522\n",
      "\n",
      "Start of epoch 134\n",
      "Training loss at epoch 134: 0.1490\n",
      "\n",
      "Start of epoch 135\n",
      "Training loss at epoch 135: 0.1459\n",
      "\n",
      "Start of epoch 136\n",
      "Training loss at epoch 136: 0.1428\n",
      "\n",
      "Start of epoch 137\n",
      "Training loss at epoch 137: 0.1398\n",
      "\n",
      "Start of epoch 138\n",
      "Training loss at epoch 138: 0.1370\n",
      "\n",
      "Start of epoch 139\n",
      "Training loss at epoch 139: 0.1343\n",
      "\n",
      "Start of epoch 140\n",
      "Training loss at epoch 140: 0.1319\n",
      "\n",
      "Start of epoch 141\n",
      "Training loss at epoch 141: 0.1297\n",
      "\n",
      "Start of epoch 142\n",
      "Training loss at epoch 142: 0.1277\n",
      "\n",
      "Start of epoch 143\n",
      "Training loss at epoch 143: 0.1259\n",
      "\n",
      "Start of epoch 144\n",
      "Training loss at epoch 144: 0.1242\n",
      "\n",
      "Start of epoch 145\n",
      "Training loss at epoch 145: 0.1227\n",
      "\n",
      "Start of epoch 146\n",
      "Training loss at epoch 146: 0.1212\n",
      "\n",
      "Start of epoch 147\n",
      "Training loss at epoch 147: 0.1197\n",
      "\n",
      "Start of epoch 148\n",
      "Training loss at epoch 148: 0.1182\n",
      "\n",
      "Start of epoch 149\n",
      "Training loss at epoch 149: 0.1166\n",
      "\n",
      "Start of epoch 150\n",
      "Training loss at epoch 150: 0.1151\n",
      "\n",
      "Start of epoch 151\n",
      "Training loss at epoch 151: 0.1135\n",
      "\n",
      "Start of epoch 152\n",
      "Training loss at epoch 152: 0.1119\n",
      "\n",
      "Start of epoch 153\n",
      "Training loss at epoch 153: 0.1103\n",
      "\n",
      "Start of epoch 154\n",
      "Training loss at epoch 154: 0.1088\n",
      "\n",
      "Start of epoch 155\n",
      "Training loss at epoch 155: 0.1072\n",
      "\n",
      "Start of epoch 156\n",
      "Training loss at epoch 156: 0.1057\n",
      "\n",
      "Start of epoch 157\n",
      "Training loss at epoch 157: 0.1043\n",
      "\n",
      "Start of epoch 158\n",
      "Training loss at epoch 158: 0.1028\n",
      "\n",
      "Start of epoch 159\n",
      "Training loss at epoch 159: 0.1013\n",
      "\n",
      "Start of epoch 160\n",
      "Training loss at epoch 160: 0.0997\n",
      "\n",
      "Start of epoch 161\n",
      "Training loss at epoch 161: 0.0982\n",
      "\n",
      "Start of epoch 162\n",
      "Training loss at epoch 162: 0.0965\n",
      "\n",
      "Start of epoch 163\n",
      "Training loss at epoch 163: 0.0947\n",
      "\n",
      "Start of epoch 164\n",
      "Training loss at epoch 164: 0.0928\n",
      "\n",
      "Start of epoch 165\n",
      "Training loss at epoch 165: 0.0907\n",
      "\n",
      "Start of epoch 166\n",
      "Training loss at epoch 166: 0.0885\n",
      "\n",
      "Start of epoch 167\n",
      "Training loss at epoch 167: 0.0860\n",
      "\n",
      "Start of epoch 168\n",
      "Training loss at epoch 168: 0.0833\n",
      "\n",
      "Start of epoch 169\n",
      "Training loss at epoch 169: 0.0804\n",
      "\n",
      "Start of epoch 170\n",
      "Training loss at epoch 170: 0.0773\n",
      "\n",
      "Start of epoch 171\n",
      "Training loss at epoch 171: 0.0740\n",
      "\n",
      "Start of epoch 172\n",
      "Training loss at epoch 172: 0.0707\n",
      "\n",
      "Start of epoch 173\n",
      "Training loss at epoch 173: 0.0673\n",
      "\n",
      "Start of epoch 174\n",
      "Training loss at epoch 174: 0.0640\n",
      "\n",
      "Start of epoch 175\n",
      "Training loss at epoch 175: 0.0609\n",
      "\n",
      "Start of epoch 176\n",
      "Training loss at epoch 176: 0.0581\n",
      "\n",
      "Start of epoch 177\n",
      "Training loss at epoch 177: 0.0556\n",
      "\n",
      "Start of epoch 178\n",
      "Training loss at epoch 178: 0.0534\n",
      "\n",
      "Start of epoch 179\n",
      "Training loss at epoch 179: 0.0515\n",
      "\n",
      "Start of epoch 180\n",
      "Training loss at epoch 180: 0.0499\n",
      "\n",
      "Start of epoch 181\n",
      "Training loss at epoch 181: 0.0483\n",
      "\n",
      "Start of epoch 182\n",
      "Training loss at epoch 182: 0.0468\n",
      "\n",
      "Start of epoch 183\n",
      "Training loss at epoch 183: 0.0454\n",
      "\n",
      "Start of epoch 184\n",
      "Training loss at epoch 184: 0.0440\n",
      "\n",
      "Start of epoch 185\n",
      "Training loss at epoch 185: 0.0427\n",
      "\n",
      "Start of epoch 186\n",
      "Training loss at epoch 186: 0.0416\n",
      "\n",
      "Start of epoch 187\n",
      "Training loss at epoch 187: 0.0407\n",
      "\n",
      "Start of epoch 188\n",
      "Training loss at epoch 188: 0.0397\n",
      "\n",
      "Start of epoch 189\n",
      "Training loss at epoch 189: 0.0386\n",
      "\n",
      "Start of epoch 190\n",
      "Training loss at epoch 190: 0.0375\n",
      "\n",
      "Start of epoch 191\n",
      "Training loss at epoch 191: 0.0363\n",
      "\n",
      "Start of epoch 192\n",
      "Training loss at epoch 192: 0.0351\n",
      "\n",
      "Start of epoch 193\n",
      "Training loss at epoch 193: 0.0340\n",
      "\n",
      "Start of epoch 194\n",
      "Training loss at epoch 194: 0.0328\n",
      "\n",
      "Start of epoch 195\n",
      "Training loss at epoch 195: 0.0317\n",
      "\n",
      "Start of epoch 196\n",
      "Training loss at epoch 196: 0.0306\n",
      "\n",
      "Start of epoch 197\n",
      "Training loss at epoch 197: 0.0294\n",
      "\n",
      "Start of epoch 198\n",
      "Training loss at epoch 198: 0.0283\n",
      "\n",
      "Start of epoch 199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 199: 0.0273\n",
      "\n",
      "Start of epoch 200\n",
      "Training loss at epoch 200: 0.0262\n",
      "\n",
      "Start of epoch 201\n",
      "Training loss at epoch 201: 0.0253\n",
      "\n",
      "Start of epoch 202\n",
      "Training loss at epoch 202: 0.0244\n",
      "\n",
      "Start of epoch 203\n",
      "Training loss at epoch 203: 0.0236\n",
      "\n",
      "Start of epoch 204\n",
      "Training loss at epoch 204: 0.0228\n",
      "\n",
      "Start of epoch 205\n",
      "Training loss at epoch 205: 0.0220\n",
      "\n",
      "Start of epoch 206\n",
      "Training loss at epoch 206: 0.0213\n",
      "\n",
      "Start of epoch 207\n",
      "Training loss at epoch 207: 0.0206\n",
      "\n",
      "Start of epoch 208\n",
      "Training loss at epoch 208: 0.0200\n",
      "\n",
      "Start of epoch 209\n",
      "Training loss at epoch 209: 0.0194\n",
      "\n",
      "Start of epoch 210\n",
      "Training loss at epoch 210: 0.0189\n",
      "\n",
      "Start of epoch 211\n",
      "Training loss at epoch 211: 0.0184\n",
      "\n",
      "Start of epoch 212\n",
      "Training loss at epoch 212: 0.0179\n",
      "\n",
      "Start of epoch 213\n",
      "Training loss at epoch 213: 0.0175\n",
      "\n",
      "Start of epoch 214\n",
      "Training loss at epoch 214: 0.0171\n",
      "\n",
      "Start of epoch 215\n",
      "Training loss at epoch 215: 0.0168\n",
      "\n",
      "Start of epoch 216\n",
      "Training loss at epoch 216: 0.0164\n",
      "\n",
      "Start of epoch 217\n",
      "Training loss at epoch 217: 0.0161\n",
      "\n",
      "Start of epoch 218\n",
      "Training loss at epoch 218: 0.0158\n",
      "\n",
      "Start of epoch 219\n",
      "Training loss at epoch 219: 0.0156\n",
      "\n",
      "Start of epoch 220\n",
      "Training loss at epoch 220: 0.0153\n",
      "\n",
      "Start of epoch 221\n",
      "Training loss at epoch 221: 0.0151\n",
      "\n",
      "Start of epoch 222\n",
      "Training loss at epoch 222: 0.0149\n",
      "\n",
      "Start of epoch 223\n",
      "Training loss at epoch 223: 0.0148\n",
      "\n",
      "Start of epoch 224\n",
      "Training loss at epoch 224: 0.0146\n",
      "\n",
      "Start of epoch 225\n",
      "Training loss at epoch 225: 0.0144\n",
      "\n",
      "Start of epoch 226\n",
      "Training loss at epoch 226: 0.0143\n",
      "\n",
      "Start of epoch 227\n",
      "Training loss at epoch 227: 0.0141\n",
      "\n",
      "Start of epoch 228\n",
      "Training loss at epoch 228: 0.0140\n",
      "\n",
      "Start of epoch 229\n",
      "Training loss at epoch 229: 0.0139\n",
      "\n",
      "Start of epoch 230\n",
      "Training loss at epoch 230: 0.0138\n",
      "\n",
      "Start of epoch 231\n",
      "Training loss at epoch 231: 0.0137\n",
      "\n",
      "Start of epoch 232\n",
      "Training loss at epoch 232: 0.0136\n",
      "\n",
      "Start of epoch 233\n",
      "Training loss at epoch 233: 0.0135\n",
      "\n",
      "Start of epoch 234\n",
      "Training loss at epoch 234: 0.0134\n",
      "\n",
      "Start of epoch 235\n",
      "Training loss at epoch 235: 0.0133\n",
      "\n",
      "Start of epoch 236\n",
      "Training loss at epoch 236: 0.0132\n",
      "\n",
      "Start of epoch 237\n",
      "Training loss at epoch 237: 0.0131\n",
      "\n",
      "Start of epoch 238\n",
      "Training loss at epoch 238: 0.0130\n",
      "\n",
      "Start of epoch 239\n",
      "Training loss at epoch 239: 0.0130\n",
      "\n",
      "Start of epoch 240\n",
      "Training loss at epoch 240: 0.0129\n",
      "\n",
      "Start of epoch 241\n",
      "Training loss at epoch 241: 0.0129\n",
      "\n",
      "Start of epoch 242\n",
      "Training loss at epoch 242: 0.0128\n",
      "\n",
      "Start of epoch 243\n",
      "Training loss at epoch 243: 0.0127\n",
      "\n",
      "Start of epoch 244\n",
      "Training loss at epoch 244: 0.0127\n",
      "\n",
      "Start of epoch 245\n",
      "Training loss at epoch 245: 0.0126\n",
      "\n",
      "Start of epoch 246\n",
      "Training loss at epoch 246: 0.0126\n",
      "\n",
      "Start of epoch 247\n",
      "Training loss at epoch 247: 0.0125\n",
      "\n",
      "Start of epoch 248\n",
      "Training loss at epoch 248: 0.0125\n",
      "\n",
      "Start of epoch 249\n",
      "Training loss at epoch 249: 0.0125\n",
      "\n",
      "Start of epoch 250\n",
      "Training loss at epoch 250: 0.0124\n",
      "\n",
      "Start of epoch 251\n",
      "Training loss at epoch 251: 0.0124\n",
      "\n",
      "Start of epoch 252\n",
      "Training loss at epoch 252: 0.0123\n",
      "\n",
      "Start of epoch 253\n",
      "Training loss at epoch 253: 0.0123\n",
      "\n",
      "Start of epoch 254\n",
      "Training loss at epoch 254: 0.0123\n",
      "\n",
      "Start of epoch 255\n",
      "Training loss at epoch 255: 0.0122\n",
      "\n",
      "Start of epoch 256\n",
      "Training loss at epoch 256: 0.0122\n",
      "\n",
      "Start of epoch 257\n",
      "Training loss at epoch 257: 0.0122\n",
      "\n",
      "Start of epoch 258\n",
      "Training loss at epoch 258: 0.0122\n",
      "\n",
      "Start of epoch 259\n",
      "Training loss at epoch 259: 0.0121\n",
      "\n",
      "Start of epoch 260\n",
      "Training loss at epoch 260: 0.0121\n",
      "\n",
      "Start of epoch 261\n",
      "Training loss at epoch 261: 0.0121\n",
      "\n",
      "Start of epoch 262\n",
      "Training loss at epoch 262: 0.0121\n",
      "\n",
      "Start of epoch 263\n",
      "Training loss at epoch 263: 0.0120\n",
      "\n",
      "Start of epoch 264\n",
      "Training loss at epoch 264: 0.0120\n",
      "\n",
      "Start of epoch 265\n",
      "Training loss at epoch 265: 0.0120\n",
      "\n",
      "Start of epoch 266\n",
      "Training loss at epoch 266: 0.0120\n",
      "\n",
      "Start of epoch 267\n",
      "Training loss at epoch 267: 0.0120\n",
      "\n",
      "Start of epoch 268\n",
      "Training loss at epoch 268: 0.0119\n",
      "\n",
      "Start of epoch 269\n",
      "Training loss at epoch 269: 0.0119\n",
      "\n",
      "Start of epoch 270\n",
      "Training loss at epoch 270: 0.0119\n",
      "\n",
      "Start of epoch 271\n",
      "Training loss at epoch 271: 0.0119\n",
      "\n",
      "Start of epoch 272\n",
      "Training loss at epoch 272: 0.0119\n",
      "\n",
      "Start of epoch 273\n",
      "Training loss at epoch 273: 0.0118\n",
      "\n",
      "Start of epoch 274\n",
      "Training loss at epoch 274: 0.0118\n",
      "\n",
      "Start of epoch 275\n",
      "Training loss at epoch 275: 0.0118\n",
      "\n",
      "Start of epoch 276\n",
      "Training loss at epoch 276: 0.0118\n",
      "\n",
      "Start of epoch 277\n",
      "Training loss at epoch 277: 0.0118\n",
      "\n",
      "Start of epoch 278\n",
      "Training loss at epoch 278: 0.0118\n",
      "\n",
      "Start of epoch 279\n",
      "Training loss at epoch 279: 0.0118\n",
      "\n",
      "Start of epoch 280\n",
      "Training loss at epoch 280: 0.0117\n",
      "\n",
      "Start of epoch 281\n",
      "Training loss at epoch 281: 0.0117\n",
      "\n",
      "Start of epoch 282\n",
      "Training loss at epoch 282: 0.0117\n",
      "\n",
      "Start of epoch 283\n",
      "Training loss at epoch 283: 0.0117\n",
      "\n",
      "Start of epoch 284\n",
      "Training loss at epoch 284: 0.0117\n",
      "\n",
      "Start of epoch 285\n",
      "Training loss at epoch 285: 0.0117\n",
      "\n",
      "Start of epoch 286\n",
      "Training loss at epoch 286: 0.0117\n",
      "\n",
      "Start of epoch 287\n",
      "Training loss at epoch 287: 0.0117\n",
      "\n",
      "Start of epoch 288\n",
      "Training loss at epoch 288: 0.0117\n",
      "\n",
      "Start of epoch 289\n",
      "Training loss at epoch 289: 0.0116\n",
      "\n",
      "Start of epoch 290\n",
      "Training loss at epoch 290: 0.0116\n",
      "\n",
      "Start of epoch 291\n",
      "Training loss at epoch 291: 0.0116\n",
      "\n",
      "Start of epoch 292\n",
      "Training loss at epoch 292: 0.0116\n",
      "\n",
      "Start of epoch 293\n",
      "Training loss at epoch 293: 0.0116\n",
      "\n",
      "Start of epoch 294\n",
      "Training loss at epoch 294: 0.0116\n",
      "\n",
      "Start of epoch 295\n",
      "Training loss at epoch 295: 0.0116\n",
      "\n",
      "Start of epoch 296\n",
      "Training loss at epoch 296: 0.0116\n",
      "\n",
      "Start of epoch 297\n",
      "Training loss at epoch 297: 0.0116\n",
      "\n",
      "Start of epoch 298\n",
      "Training loss at epoch 298: 0.0116\n",
      "\n",
      "Start of epoch 299\n",
      "Training loss at epoch 299: 0.0116\n",
      "\n",
      "Start of epoch 300\n",
      "Training loss at epoch 300: 0.0115\n",
      "\n",
      "Start of epoch 301\n",
      "Training loss at epoch 301: 0.0115\n",
      "\n",
      "Start of epoch 302\n",
      "Training loss at epoch 302: 0.0115\n",
      "\n",
      "Start of epoch 303\n",
      "Training loss at epoch 303: 0.0115\n",
      "\n",
      "Start of epoch 304\n",
      "Training loss at epoch 304: 0.0115\n",
      "\n",
      "Start of epoch 305\n",
      "Training loss at epoch 305: 0.0115\n",
      "\n",
      "Start of epoch 306\n",
      "Training loss at epoch 306: 0.0115\n",
      "\n",
      "Start of epoch 307\n",
      "Training loss at epoch 307: 0.0115\n",
      "\n",
      "Start of epoch 308\n",
      "Training loss at epoch 308: 0.0115\n",
      "\n",
      "Start of epoch 309\n",
      "Training loss at epoch 309: 0.0115\n",
      "\n",
      "Start of epoch 310\n",
      "Training loss at epoch 310: 0.0115\n",
      "\n",
      "Start of epoch 311\n",
      "Training loss at epoch 311: 0.0115\n",
      "\n",
      "Start of epoch 312\n",
      "Training loss at epoch 312: 0.0115\n",
      "\n",
      "Start of epoch 313\n",
      "Training loss at epoch 313: 0.0115\n",
      "\n",
      "Start of epoch 314\n",
      "Training loss at epoch 314: 0.0115\n",
      "\n",
      "Start of epoch 315\n",
      "Training loss at epoch 315: 0.0115\n",
      "\n",
      "Start of epoch 316\n",
      "Training loss at epoch 316: 0.0115\n",
      "\n",
      "Start of epoch 317\n",
      "Training loss at epoch 317: 0.0114\n",
      "\n",
      "Start of epoch 318\n",
      "Training loss at epoch 318: 0.0114\n",
      "\n",
      "Start of epoch 319\n",
      "Training loss at epoch 319: 0.0114\n",
      "\n",
      "Start of epoch 320\n",
      "Training loss at epoch 320: 0.0114\n",
      "\n",
      "Start of epoch 321\n",
      "Training loss at epoch 321: 0.0114\n",
      "\n",
      "Start of epoch 322\n",
      "Training loss at epoch 322: 0.0114\n",
      "\n",
      "Start of epoch 323\n",
      "Training loss at epoch 323: 0.0114\n",
      "\n",
      "Start of epoch 324\n",
      "Training loss at epoch 324: 0.0114\n",
      "\n",
      "Start of epoch 325\n",
      "Training loss at epoch 325: 0.0114\n",
      "\n",
      "Start of epoch 326\n",
      "Training loss at epoch 326: 0.0114\n",
      "\n",
      "Start of epoch 327\n",
      "Training loss at epoch 327: 0.0114\n",
      "\n",
      "Start of epoch 328\n",
      "Training loss at epoch 328: 0.0114\n",
      "\n",
      "Start of epoch 329\n",
      "Training loss at epoch 329: 0.0114\n",
      "\n",
      "Start of epoch 330\n",
      "Training loss at epoch 330: 0.0114\n",
      "\n",
      "Start of epoch 331\n",
      "Training loss at epoch 331: 0.0114\n",
      "\n",
      "Start of epoch 332\n",
      "Training loss at epoch 332: 0.0114\n",
      "\n",
      "Start of epoch 333\n",
      "Training loss at epoch 333: 0.0114\n",
      "\n",
      "Start of epoch 334\n",
      "Training loss at epoch 334: 0.0114\n",
      "\n",
      "Start of epoch 335\n",
      "Training loss at epoch 335: 0.0114\n",
      "\n",
      "Start of epoch 336\n",
      "Training loss at epoch 336: 0.0114\n",
      "\n",
      "Start of epoch 337\n",
      "Training loss at epoch 337: 0.0114\n",
      "\n",
      "Start of epoch 338\n",
      "Training loss at epoch 338: 0.0114\n",
      "\n",
      "Start of epoch 339\n",
      "Training loss at epoch 339: 0.0114\n",
      "\n",
      "Start of epoch 340\n",
      "Training loss at epoch 340: 0.0113\n",
      "\n",
      "Start of epoch 341\n",
      "Training loss at epoch 341: 0.0113\n",
      "\n",
      "Start of epoch 342\n",
      "Training loss at epoch 342: 0.0113\n",
      "\n",
      "Start of epoch 343\n",
      "Training loss at epoch 343: 0.0113\n",
      "\n",
      "Start of epoch 344\n",
      "Training loss at epoch 344: 0.0113\n",
      "\n",
      "Start of epoch 345\n",
      "Training loss at epoch 345: 0.0113\n",
      "\n",
      "Start of epoch 346\n",
      "Training loss at epoch 346: 0.0113\n",
      "\n",
      "Start of epoch 347\n",
      "Training loss at epoch 347: 0.0113\n",
      "\n",
      "Start of epoch 348\n",
      "Training loss at epoch 348: 0.0113\n",
      "\n",
      "Start of epoch 349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 349: 0.0113\n",
      "\n",
      "Start of epoch 350\n",
      "Training loss at epoch 350: 0.0113\n",
      "\n",
      "Start of epoch 351\n",
      "Training loss at epoch 351: 0.0113\n",
      "\n",
      "Start of epoch 352\n",
      "Training loss at epoch 352: 0.0113\n",
      "\n",
      "Start of epoch 353\n",
      "Training loss at epoch 353: 0.0113\n",
      "\n",
      "Start of epoch 354\n",
      "Training loss at epoch 354: 0.0113\n",
      "\n",
      "Start of epoch 355\n",
      "Training loss at epoch 355: 0.0113\n",
      "\n",
      "Start of epoch 356\n",
      "Training loss at epoch 356: 0.0113\n",
      "\n",
      "Start of epoch 357\n",
      "Training loss at epoch 357: 0.0113\n",
      "\n",
      "Start of epoch 358\n",
      "Training loss at epoch 358: 0.0113\n",
      "\n",
      "Start of epoch 359\n",
      "Training loss at epoch 359: 0.0113\n",
      "\n",
      "Start of epoch 360\n",
      "Training loss at epoch 360: 0.0113\n",
      "\n",
      "Start of epoch 361\n",
      "Training loss at epoch 361: 0.0113\n",
      "\n",
      "Start of epoch 362\n",
      "Training loss at epoch 362: 0.0113\n",
      "\n",
      "Start of epoch 363\n",
      "Training loss at epoch 363: 0.0113\n",
      "\n",
      "Start of epoch 364\n",
      "Training loss at epoch 364: 0.0113\n",
      "\n",
      "Start of epoch 365\n",
      "Training loss at epoch 365: 0.0113\n",
      "\n",
      "Start of epoch 366\n",
      "Training loss at epoch 366: 0.0113\n",
      "\n",
      "Start of epoch 367\n",
      "Training loss at epoch 367: 0.0113\n",
      "\n",
      "Start of epoch 368\n",
      "Training loss at epoch 368: 0.0112\n",
      "\n",
      "Start of epoch 369\n",
      "Training loss at epoch 369: 0.0112\n",
      "\n",
      "Start of epoch 370\n",
      "Training loss at epoch 370: 0.0112\n",
      "\n",
      "Start of epoch 371\n",
      "Training loss at epoch 371: 0.0112\n",
      "\n",
      "Start of epoch 372\n",
      "Training loss at epoch 372: 0.0112\n",
      "\n",
      "Start of epoch 373\n",
      "Training loss at epoch 373: 0.0112\n",
      "\n",
      "Start of epoch 374\n",
      "Training loss at epoch 374: 0.0112\n",
      "\n",
      "Start of epoch 375\n",
      "Training loss at epoch 375: 0.0112\n",
      "\n",
      "Start of epoch 376\n",
      "Training loss at epoch 376: 0.0112\n",
      "\n",
      "Start of epoch 377\n",
      "Training loss at epoch 377: 0.0112\n",
      "\n",
      "Start of epoch 378\n",
      "Training loss at epoch 378: 0.0112\n",
      "\n",
      "Start of epoch 379\n",
      "Training loss at epoch 379: 0.0112\n",
      "\n",
      "Start of epoch 380\n",
      "Training loss at epoch 380: 0.0112\n",
      "\n",
      "Start of epoch 381\n",
      "Training loss at epoch 381: 0.0112\n",
      "\n",
      "Start of epoch 382\n",
      "Training loss at epoch 382: 0.0112\n",
      "\n",
      "Start of epoch 383\n",
      "Training loss at epoch 383: 0.0112\n",
      "\n",
      "Start of epoch 384\n",
      "Training loss at epoch 384: 0.0112\n",
      "\n",
      "Start of epoch 385\n",
      "Training loss at epoch 385: 0.0112\n",
      "\n",
      "Start of epoch 386\n",
      "Training loss at epoch 386: 0.0112\n",
      "\n",
      "Start of epoch 387\n",
      "Training loss at epoch 387: 0.0112\n",
      "\n",
      "Start of epoch 388\n",
      "Training loss at epoch 388: 0.0112\n",
      "\n",
      "Start of epoch 389\n",
      "Training loss at epoch 389: 0.0112\n",
      "\n",
      "Start of epoch 390\n",
      "Training loss at epoch 390: 0.0112\n",
      "\n",
      "Start of epoch 391\n",
      "Training loss at epoch 391: 0.0112\n",
      "\n",
      "Start of epoch 392\n",
      "Training loss at epoch 392: 0.0112\n",
      "\n",
      "Start of epoch 393\n",
      "Training loss at epoch 393: 0.0112\n",
      "\n",
      "Start of epoch 394\n",
      "Training loss at epoch 394: 0.0112\n",
      "\n",
      "Start of epoch 395\n",
      "Training loss at epoch 395: 0.0112\n",
      "\n",
      "Start of epoch 396\n",
      "Training loss at epoch 396: 0.0112\n",
      "\n",
      "Start of epoch 397\n",
      "Training loss at epoch 397: 0.0112\n",
      "\n",
      "Start of epoch 398\n",
      "Training loss at epoch 398: 0.0112\n",
      "\n",
      "Start of epoch 399\n",
      "Training loss at epoch 399: 0.0112\n",
      "\n",
      "Start of epoch 400\n",
      "Training loss at epoch 400: 0.0111\n",
      "\n",
      "Start of epoch 401\n",
      "Training loss at epoch 401: 0.0111\n",
      "\n",
      "Start of epoch 402\n",
      "Training loss at epoch 402: 0.0111\n",
      "\n",
      "Start of epoch 403\n",
      "Training loss at epoch 403: 0.0111\n",
      "\n",
      "Start of epoch 404\n",
      "Training loss at epoch 404: 0.0111\n",
      "\n",
      "Start of epoch 405\n",
      "Training loss at epoch 405: 0.0111\n",
      "\n",
      "Start of epoch 406\n",
      "Training loss at epoch 406: 0.0111\n",
      "\n",
      "Start of epoch 407\n",
      "Training loss at epoch 407: 0.0111\n",
      "\n",
      "Start of epoch 408\n",
      "Training loss at epoch 408: 0.0111\n",
      "\n",
      "Start of epoch 409\n",
      "Training loss at epoch 409: 0.0111\n",
      "\n",
      "Start of epoch 410\n",
      "Training loss at epoch 410: 0.0111\n",
      "\n",
      "Start of epoch 411\n",
      "Training loss at epoch 411: 0.0111\n",
      "\n",
      "Start of epoch 412\n",
      "Training loss at epoch 412: 0.0111\n",
      "\n",
      "Start of epoch 413\n",
      "Training loss at epoch 413: 0.0111\n",
      "\n",
      "Start of epoch 414\n",
      "Training loss at epoch 414: 0.0111\n",
      "\n",
      "Start of epoch 415\n",
      "Training loss at epoch 415: 0.0111\n",
      "\n",
      "Start of epoch 416\n",
      "Training loss at epoch 416: 0.0111\n",
      "\n",
      "Start of epoch 417\n",
      "Training loss at epoch 417: 0.0111\n",
      "\n",
      "Start of epoch 418\n",
      "Training loss at epoch 418: 0.0111\n",
      "\n",
      "Start of epoch 419\n",
      "Training loss at epoch 419: 0.0111\n",
      "\n",
      "Start of epoch 420\n",
      "Training loss at epoch 420: 0.0111\n",
      "\n",
      "Start of epoch 421\n",
      "Training loss at epoch 421: 0.0111\n",
      "\n",
      "Start of epoch 422\n",
      "Training loss at epoch 422: 0.0111\n",
      "\n",
      "Start of epoch 423\n",
      "Training loss at epoch 423: 0.0111\n",
      "\n",
      "Start of epoch 424\n",
      "Training loss at epoch 424: 0.0111\n",
      "\n",
      "Start of epoch 425\n",
      "Training loss at epoch 425: 0.0111\n",
      "\n",
      "Start of epoch 426\n",
      "Training loss at epoch 426: 0.0111\n",
      "\n",
      "Start of epoch 427\n",
      "Training loss at epoch 427: 0.0111\n",
      "\n",
      "Start of epoch 428\n",
      "Training loss at epoch 428: 0.0111\n",
      "\n",
      "Start of epoch 429\n",
      "Training loss at epoch 429: 0.0111\n",
      "\n",
      "Start of epoch 430\n",
      "Training loss at epoch 430: 0.0111\n",
      "\n",
      "Start of epoch 431\n",
      "Training loss at epoch 431: 0.0111\n",
      "\n",
      "Start of epoch 432\n",
      "Training loss at epoch 432: 0.0111\n",
      "\n",
      "Start of epoch 433\n",
      "Training loss at epoch 433: 0.0111\n",
      "\n",
      "Start of epoch 434\n",
      "Training loss at epoch 434: 0.0111\n",
      "\n",
      "Start of epoch 435\n",
      "Training loss at epoch 435: 0.0111\n",
      "\n",
      "Start of epoch 436\n",
      "Training loss at epoch 436: 0.0110\n",
      "\n",
      "Start of epoch 437\n",
      "Training loss at epoch 437: 0.0110\n",
      "\n",
      "Start of epoch 438\n",
      "Training loss at epoch 438: 0.0110\n",
      "\n",
      "Start of epoch 439\n",
      "Training loss at epoch 439: 0.0110\n",
      "\n",
      "Start of epoch 440\n",
      "Training loss at epoch 440: 0.0110\n",
      "\n",
      "Start of epoch 441\n",
      "Training loss at epoch 441: 0.0110\n",
      "\n",
      "Start of epoch 442\n",
      "Training loss at epoch 442: 0.0110\n",
      "\n",
      "Start of epoch 443\n",
      "Training loss at epoch 443: 0.0110\n",
      "\n",
      "Start of epoch 444\n",
      "Training loss at epoch 444: 0.0110\n",
      "\n",
      "Start of epoch 445\n",
      "Training loss at epoch 445: 0.0110\n",
      "\n",
      "Start of epoch 446\n",
      "Training loss at epoch 446: 0.0110\n",
      "\n",
      "Start of epoch 447\n",
      "Training loss at epoch 447: 0.0110\n",
      "\n",
      "Start of epoch 448\n",
      "Training loss at epoch 448: 0.0110\n",
      "\n",
      "Start of epoch 449\n",
      "Training loss at epoch 449: 0.0110\n",
      "\n",
      "Start of epoch 450\n",
      "Training loss at epoch 450: 0.0110\n",
      "\n",
      "Start of epoch 451\n",
      "Training loss at epoch 451: 0.0110\n",
      "\n",
      "Start of epoch 452\n",
      "Training loss at epoch 452: 0.0110\n",
      "\n",
      "Start of epoch 453\n",
      "Training loss at epoch 453: 0.0110\n",
      "\n",
      "Start of epoch 454\n",
      "Training loss at epoch 454: 0.0110\n",
      "\n",
      "Start of epoch 455\n",
      "Training loss at epoch 455: 0.0110\n",
      "\n",
      "Start of epoch 456\n",
      "Training loss at epoch 456: 0.0110\n",
      "\n",
      "Start of epoch 457\n",
      "Training loss at epoch 457: 0.0110\n",
      "\n",
      "Start of epoch 458\n",
      "Training loss at epoch 458: 0.0110\n",
      "\n",
      "Start of epoch 459\n",
      "Training loss at epoch 459: 0.0110\n",
      "\n",
      "Start of epoch 460\n",
      "Training loss at epoch 460: 0.0110\n",
      "\n",
      "Start of epoch 461\n",
      "Training loss at epoch 461: 0.0110\n",
      "\n",
      "Start of epoch 462\n",
      "Training loss at epoch 462: 0.0110\n",
      "\n",
      "Start of epoch 463\n",
      "Training loss at epoch 463: 0.0110\n",
      "\n",
      "Start of epoch 464\n",
      "Training loss at epoch 464: 0.0110\n",
      "\n",
      "Start of epoch 465\n",
      "Training loss at epoch 465: 0.0110\n",
      "\n",
      "Start of epoch 466\n",
      "Training loss at epoch 466: 0.0110\n",
      "\n",
      "Start of epoch 467\n",
      "Training loss at epoch 467: 0.0110\n",
      "\n",
      "Start of epoch 468\n",
      "Training loss at epoch 468: 0.0110\n",
      "\n",
      "Start of epoch 469\n",
      "Training loss at epoch 469: 0.0110\n",
      "\n",
      "Start of epoch 470\n",
      "Training loss at epoch 470: 0.0110\n",
      "\n",
      "Start of epoch 471\n",
      "Training loss at epoch 471: 0.0110\n",
      "\n",
      "Start of epoch 472\n",
      "Training loss at epoch 472: 0.0110\n",
      "\n",
      "Start of epoch 473\n",
      "Training loss at epoch 473: 0.0109\n",
      "\n",
      "Start of epoch 474\n",
      "Training loss at epoch 474: 0.0109\n",
      "\n",
      "Start of epoch 475\n",
      "Training loss at epoch 475: 0.0109\n",
      "\n",
      "Start of epoch 476\n",
      "Training loss at epoch 476: 0.0109\n",
      "\n",
      "Start of epoch 477\n",
      "Training loss at epoch 477: 0.0109\n",
      "\n",
      "Start of epoch 478\n",
      "Training loss at epoch 478: 0.0109\n",
      "\n",
      "Start of epoch 479\n",
      "Training loss at epoch 479: 0.0109\n",
      "\n",
      "Start of epoch 480\n",
      "Training loss at epoch 480: 0.0109\n",
      "\n",
      "Start of epoch 481\n",
      "Training loss at epoch 481: 0.0109\n",
      "\n",
      "Start of epoch 482\n",
      "Training loss at epoch 482: 0.0109\n",
      "\n",
      "Start of epoch 483\n",
      "Training loss at epoch 483: 0.0109\n",
      "\n",
      "Start of epoch 484\n",
      "Training loss at epoch 484: 0.0109\n",
      "\n",
      "Start of epoch 485\n",
      "Training loss at epoch 485: 0.0109\n",
      "\n",
      "Start of epoch 486\n",
      "Training loss at epoch 486: 0.0109\n",
      "\n",
      "Start of epoch 487\n",
      "Training loss at epoch 487: 0.0109\n",
      "\n",
      "Start of epoch 488\n",
      "Training loss at epoch 488: 0.0109\n",
      "\n",
      "Start of epoch 489\n",
      "Training loss at epoch 489: 0.0109\n",
      "\n",
      "Start of epoch 490\n",
      "Training loss at epoch 490: 0.0109\n",
      "\n",
      "Start of epoch 491\n",
      "Training loss at epoch 491: 0.0109\n",
      "\n",
      "Start of epoch 492\n",
      "Training loss at epoch 492: 0.0109\n",
      "\n",
      "Start of epoch 493\n",
      "Training loss at epoch 493: 0.0109\n",
      "\n",
      "Start of epoch 494\n",
      "Training loss at epoch 494: 0.0109\n",
      "\n",
      "Start of epoch 495\n",
      "Training loss at epoch 495: 0.0109\n",
      "\n",
      "Start of epoch 496\n",
      "Training loss at epoch 496: 0.0109\n",
      "\n",
      "Start of epoch 497\n",
      "Training loss at epoch 497: 0.0109\n",
      "\n",
      "Start of epoch 498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 498: 0.0109\n",
      "\n",
      "Start of epoch 499\n",
      "Training loss at epoch 499: 0.0109\n",
      "[<tf.Variable 'parameters:0' shape=(45,) dtype=float32, numpy=\n",
      "array([4.413902  , 3.2594337 , 1.6420096 , 6.0265784 , 4.204766  ,\n",
      "       3.3882782 , 4.154652  , 4.364699  , 4.6481214 , 2.2949185 ,\n",
      "       0.5467091 , 1.3336256 , 0.23033606, 4.367606  , 2.0513084 ,\n",
      "       6.039899  , 0.25356522, 0.783047  , 5.763462  , 2.4026597 ,\n",
      "       5.688776  , 4.673912  , 3.136343  , 1.8514235 , 3.7299125 ,\n",
      "       2.9297123 , 2.2152152 , 5.5722003 , 0.5953119 , 2.1137087 ,\n",
      "       0.7793866 , 1.4733894 , 0.11701622, 1.1896957 , 0.4166226 ,\n",
      "       2.4342277 , 4.965727  , 4.6106253 , 5.8579283 , 3.454339  ,\n",
      "       2.3726144 , 2.8436844 , 4.0736914 , 4.228277  , 4.437603  ],\n",
      "      dtype=float32)>]\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.0633\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 0.9622\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.8777\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.8195\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.7771\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.7386\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.7015\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.6693\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.6450\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.6292\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.6195\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.6132\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.6078\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.6019\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.5951\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.5867\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.5763\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.5639\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.5503\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.5367\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.5243\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.5134\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.5038\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.4946\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.4849\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.4745\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.4635\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.4523\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.4414\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.4310\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.4210\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.4114\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.4023\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.3940\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.3865\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.3799\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.3742\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.3693\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.3652\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.3620\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.3596\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.3579\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.3564\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.3549\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.3531\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.3509\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.3486\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.3461\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.3435\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.3410\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.3385\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.3362\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.3341\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.3322\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.3305\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.3290\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.3276\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.3263\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.3251\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.3240\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.3229\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.3218\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.3207\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.3197\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.3186\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.3176\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.3165\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.3155\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.3144\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.3134\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.3124\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.3114\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.3105\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.3096\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.3087\n",
      "\n",
      "Start of epoch 75\n",
      "Training loss at epoch 75: 0.3078\n",
      "\n",
      "Start of epoch 76\n",
      "Training loss at epoch 76: 0.3070\n",
      "\n",
      "Start of epoch 77\n",
      "Training loss at epoch 77: 0.3063\n",
      "\n",
      "Start of epoch 78\n",
      "Training loss at epoch 78: 0.3056\n",
      "\n",
      "Start of epoch 79\n",
      "Training loss at epoch 79: 0.3049\n",
      "\n",
      "Start of epoch 80\n",
      "Training loss at epoch 80: 0.3042\n",
      "\n",
      "Start of epoch 81\n",
      "Training loss at epoch 81: 0.3035\n",
      "\n",
      "Start of epoch 82\n",
      "Training loss at epoch 82: 0.3029\n",
      "\n",
      "Start of epoch 83\n",
      "Training loss at epoch 83: 0.3022\n",
      "\n",
      "Start of epoch 84\n",
      "Training loss at epoch 84: 0.3016\n",
      "\n",
      "Start of epoch 85\n",
      "Training loss at epoch 85: 0.3010\n",
      "\n",
      "Start of epoch 86\n",
      "Training loss at epoch 86: 0.3003\n",
      "\n",
      "Start of epoch 87\n",
      "Training loss at epoch 87: 0.2997\n",
      "\n",
      "Start of epoch 88\n",
      "Training loss at epoch 88: 0.2991\n",
      "\n",
      "Start of epoch 89\n",
      "Training loss at epoch 89: 0.2985\n",
      "\n",
      "Start of epoch 90\n",
      "Training loss at epoch 90: 0.2980\n",
      "\n",
      "Start of epoch 91\n",
      "Training loss at epoch 91: 0.2974\n",
      "\n",
      "Start of epoch 92\n",
      "Training loss at epoch 92: 0.2968\n",
      "\n",
      "Start of epoch 93\n",
      "Training loss at epoch 93: 0.2963\n",
      "\n",
      "Start of epoch 94\n",
      "Training loss at epoch 94: 0.2957\n",
      "\n",
      "Start of epoch 95\n",
      "Training loss at epoch 95: 0.2951\n",
      "\n",
      "Start of epoch 96\n",
      "Training loss at epoch 96: 0.2946\n",
      "\n",
      "Start of epoch 97\n",
      "Training loss at epoch 97: 0.2940\n",
      "\n",
      "Start of epoch 98\n",
      "Training loss at epoch 98: 0.2934\n",
      "\n",
      "Start of epoch 99\n",
      "Training loss at epoch 99: 0.2927\n",
      "\n",
      "Start of epoch 100\n",
      "Training loss at epoch 100: 0.2921\n",
      "\n",
      "Start of epoch 101\n",
      "Training loss at epoch 101: 0.2915\n",
      "\n",
      "Start of epoch 102\n",
      "Training loss at epoch 102: 0.2908\n",
      "\n",
      "Start of epoch 103\n",
      "Training loss at epoch 103: 0.2901\n",
      "\n",
      "Start of epoch 104\n",
      "Training loss at epoch 104: 0.2893\n",
      "\n",
      "Start of epoch 105\n",
      "Training loss at epoch 105: 0.2886\n",
      "\n",
      "Start of epoch 106\n",
      "Training loss at epoch 106: 0.2877\n",
      "\n",
      "Start of epoch 107\n",
      "Training loss at epoch 107: 0.2869\n",
      "\n",
      "Start of epoch 108\n",
      "Training loss at epoch 108: 0.2859\n",
      "\n",
      "Start of epoch 109\n",
      "Training loss at epoch 109: 0.2850\n",
      "\n",
      "Start of epoch 110\n",
      "Training loss at epoch 110: 0.2839\n",
      "\n",
      "Start of epoch 111\n",
      "Training loss at epoch 111: 0.2828\n",
      "\n",
      "Start of epoch 112\n",
      "Training loss at epoch 112: 0.2816\n",
      "\n",
      "Start of epoch 113\n",
      "Training loss at epoch 113: 0.2804\n",
      "\n",
      "Start of epoch 114\n",
      "Training loss at epoch 114: 0.2791\n",
      "\n",
      "Start of epoch 115\n",
      "Training loss at epoch 115: 0.2778\n",
      "\n",
      "Start of epoch 116\n",
      "Training loss at epoch 116: 0.2764\n",
      "\n",
      "Start of epoch 117\n",
      "Training loss at epoch 117: 0.2750\n",
      "\n",
      "Start of epoch 118\n",
      "Training loss at epoch 118: 0.2737\n",
      "\n",
      "Start of epoch 119\n",
      "Training loss at epoch 119: 0.2723\n",
      "\n",
      "Start of epoch 120\n",
      "Training loss at epoch 120: 0.2710\n",
      "\n",
      "Start of epoch 121\n",
      "Training loss at epoch 121: 0.2698\n",
      "\n",
      "Start of epoch 122\n",
      "Training loss at epoch 122: 0.2687\n",
      "\n",
      "Start of epoch 123\n",
      "Training loss at epoch 123: 0.2677\n",
      "\n",
      "Start of epoch 124\n",
      "Training loss at epoch 124: 0.2667\n",
      "\n",
      "Start of epoch 125\n",
      "Training loss at epoch 125: 0.2659\n",
      "\n",
      "Start of epoch 126\n",
      "Training loss at epoch 126: 0.2651\n",
      "\n",
      "Start of epoch 127\n",
      "Training loss at epoch 127: 0.2644\n",
      "\n",
      "Start of epoch 128\n",
      "Training loss at epoch 128: 0.2636\n",
      "\n",
      "Start of epoch 129\n",
      "Training loss at epoch 129: 0.2629\n",
      "\n",
      "Start of epoch 130\n",
      "Training loss at epoch 130: 0.2621\n",
      "\n",
      "Start of epoch 131\n",
      "Training loss at epoch 131: 0.2614\n",
      "\n",
      "Start of epoch 132\n",
      "Training loss at epoch 132: 0.2606\n",
      "\n",
      "Start of epoch 133\n",
      "Training loss at epoch 133: 0.2598\n",
      "\n",
      "Start of epoch 134\n",
      "Training loss at epoch 134: 0.2591\n",
      "\n",
      "Start of epoch 135\n",
      "Training loss at epoch 135: 0.2584\n",
      "\n",
      "Start of epoch 136\n",
      "Training loss at epoch 136: 0.2577\n",
      "\n",
      "Start of epoch 137\n",
      "Training loss at epoch 137: 0.2571\n",
      "\n",
      "Start of epoch 138\n",
      "Training loss at epoch 138: 0.2565\n",
      "\n",
      "Start of epoch 139\n",
      "Training loss at epoch 139: 0.2559\n",
      "\n",
      "Start of epoch 140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 140: 0.2554\n",
      "\n",
      "Start of epoch 141\n",
      "Training loss at epoch 141: 0.2549\n",
      "\n",
      "Start of epoch 142\n",
      "Training loss at epoch 142: 0.2545\n",
      "\n",
      "Start of epoch 143\n",
      "Training loss at epoch 143: 0.2541\n",
      "\n",
      "Start of epoch 144\n",
      "Training loss at epoch 144: 0.2537\n",
      "\n",
      "Start of epoch 145\n",
      "Training loss at epoch 145: 0.2533\n",
      "\n",
      "Start of epoch 146\n",
      "Training loss at epoch 146: 0.2529\n",
      "\n",
      "Start of epoch 147\n",
      "Training loss at epoch 147: 0.2525\n",
      "\n",
      "Start of epoch 148\n",
      "Training loss at epoch 148: 0.2522\n",
      "\n",
      "Start of epoch 149\n",
      "Training loss at epoch 149: 0.2518\n",
      "\n",
      "Start of epoch 150\n",
      "Training loss at epoch 150: 0.2515\n",
      "\n",
      "Start of epoch 151\n",
      "Training loss at epoch 151: 0.2512\n",
      "\n",
      "Start of epoch 152\n",
      "Training loss at epoch 152: 0.2509\n",
      "\n",
      "Start of epoch 153\n",
      "Training loss at epoch 153: 0.2506\n",
      "\n",
      "Start of epoch 154\n",
      "Training loss at epoch 154: 0.2503\n",
      "\n",
      "Start of epoch 155\n",
      "Training loss at epoch 155: 0.2501\n",
      "\n",
      "Start of epoch 156\n",
      "Training loss at epoch 156: 0.2498\n",
      "\n",
      "Start of epoch 157\n",
      "Training loss at epoch 157: 0.2496\n",
      "\n",
      "Start of epoch 158\n",
      "Training loss at epoch 158: 0.2493\n",
      "\n",
      "Start of epoch 159\n",
      "Training loss at epoch 159: 0.2491\n",
      "\n",
      "Start of epoch 160\n",
      "Training loss at epoch 160: 0.2489\n",
      "\n",
      "Start of epoch 161\n",
      "Training loss at epoch 161: 0.2487\n",
      "\n",
      "Start of epoch 162\n",
      "Training loss at epoch 162: 0.2485\n",
      "\n",
      "Start of epoch 163\n",
      "Training loss at epoch 163: 0.2483\n",
      "\n",
      "Start of epoch 164\n",
      "Training loss at epoch 164: 0.2481\n",
      "\n",
      "Start of epoch 165\n",
      "Training loss at epoch 165: 0.2479\n",
      "\n",
      "Start of epoch 166\n",
      "Training loss at epoch 166: 0.2477\n",
      "\n",
      "Start of epoch 167\n",
      "Training loss at epoch 167: 0.2476\n",
      "\n",
      "Start of epoch 168\n",
      "Training loss at epoch 168: 0.2474\n",
      "\n",
      "Start of epoch 169\n",
      "Training loss at epoch 169: 0.2472\n",
      "\n",
      "Start of epoch 170\n",
      "Training loss at epoch 170: 0.2471\n",
      "\n",
      "Start of epoch 171\n",
      "Training loss at epoch 171: 0.2469\n",
      "\n",
      "Start of epoch 172\n",
      "Training loss at epoch 172: 0.2468\n",
      "\n",
      "Start of epoch 173\n",
      "Training loss at epoch 173: 0.2466\n",
      "\n",
      "Start of epoch 174\n",
      "Training loss at epoch 174: 0.2464\n",
      "\n",
      "Start of epoch 175\n",
      "Training loss at epoch 175: 0.2463\n",
      "\n",
      "Start of epoch 176\n",
      "Training loss at epoch 176: 0.2461\n",
      "\n",
      "Start of epoch 177\n",
      "Training loss at epoch 177: 0.2460\n",
      "\n",
      "Start of epoch 178\n",
      "Training loss at epoch 178: 0.2458\n",
      "\n",
      "Start of epoch 179\n",
      "Training loss at epoch 179: 0.2457\n",
      "\n",
      "Start of epoch 180\n",
      "Training loss at epoch 180: 0.2455\n",
      "\n",
      "Start of epoch 181\n",
      "Training loss at epoch 181: 0.2454\n",
      "\n",
      "Start of epoch 182\n",
      "Training loss at epoch 182: 0.2452\n",
      "\n",
      "Start of epoch 183\n",
      "Training loss at epoch 183: 0.2451\n",
      "\n",
      "Start of epoch 184\n",
      "Training loss at epoch 184: 0.2450\n",
      "\n",
      "Start of epoch 185\n",
      "Training loss at epoch 185: 0.2448\n",
      "\n",
      "Start of epoch 186\n",
      "Training loss at epoch 186: 0.2447\n",
      "\n",
      "Start of epoch 187\n",
      "Training loss at epoch 187: 0.2445\n",
      "\n",
      "Start of epoch 188\n",
      "Training loss at epoch 188: 0.2444\n",
      "\n",
      "Start of epoch 189\n",
      "Training loss at epoch 189: 0.2442\n",
      "\n",
      "Start of epoch 190\n",
      "Training loss at epoch 190: 0.2441\n",
      "\n",
      "Start of epoch 191\n",
      "Training loss at epoch 191: 0.2439\n",
      "\n",
      "Start of epoch 192\n",
      "Training loss at epoch 192: 0.2438\n",
      "\n",
      "Start of epoch 193\n",
      "Training loss at epoch 193: 0.2437\n",
      "\n",
      "Start of epoch 194\n",
      "Training loss at epoch 194: 0.2435\n",
      "\n",
      "Start of epoch 195\n",
      "Training loss at epoch 195: 0.2434\n",
      "\n",
      "Start of epoch 196\n",
      "Training loss at epoch 196: 0.2432\n",
      "\n",
      "Start of epoch 197\n",
      "Training loss at epoch 197: 0.2431\n",
      "\n",
      "Start of epoch 198\n",
      "Training loss at epoch 198: 0.2430\n",
      "\n",
      "Start of epoch 199\n",
      "Training loss at epoch 199: 0.2428\n",
      "\n",
      "Start of epoch 200\n",
      "Training loss at epoch 200: 0.2427\n",
      "\n",
      "Start of epoch 201\n",
      "Training loss at epoch 201: 0.2426\n",
      "\n",
      "Start of epoch 202\n",
      "Training loss at epoch 202: 0.2424\n",
      "\n",
      "Start of epoch 203\n",
      "Training loss at epoch 203: 0.2423\n",
      "\n",
      "Start of epoch 204\n",
      "Training loss at epoch 204: 0.2422\n",
      "\n",
      "Start of epoch 205\n",
      "Training loss at epoch 205: 0.2420\n",
      "\n",
      "Start of epoch 206\n",
      "Training loss at epoch 206: 0.2419\n",
      "\n",
      "Start of epoch 207\n",
      "Training loss at epoch 207: 0.2418\n",
      "\n",
      "Start of epoch 208\n",
      "Training loss at epoch 208: 0.2417\n",
      "\n",
      "Start of epoch 209\n",
      "Training loss at epoch 209: 0.2416\n",
      "\n",
      "Start of epoch 210\n",
      "Training loss at epoch 210: 0.2414\n",
      "\n",
      "Start of epoch 211\n",
      "Training loss at epoch 211: 0.2413\n",
      "\n",
      "Start of epoch 212\n",
      "Training loss at epoch 212: 0.2412\n",
      "\n",
      "Start of epoch 213\n",
      "Training loss at epoch 213: 0.2411\n",
      "\n",
      "Start of epoch 214\n",
      "Training loss at epoch 214: 0.2410\n",
      "\n",
      "Start of epoch 215\n",
      "Training loss at epoch 215: 0.2409\n",
      "\n",
      "Start of epoch 216\n",
      "Training loss at epoch 216: 0.2408\n",
      "\n",
      "Start of epoch 217\n",
      "Training loss at epoch 217: 0.2407\n",
      "\n",
      "Start of epoch 218\n",
      "Training loss at epoch 218: 0.2406\n",
      "\n",
      "Start of epoch 219\n",
      "Training loss at epoch 219: 0.2405\n",
      "\n",
      "Start of epoch 220\n",
      "Training loss at epoch 220: 0.2404\n",
      "\n",
      "Start of epoch 221\n",
      "Training loss at epoch 221: 0.2403\n",
      "\n",
      "Start of epoch 222\n",
      "Training loss at epoch 222: 0.2402\n",
      "\n",
      "Start of epoch 223\n",
      "Training loss at epoch 223: 0.2401\n",
      "\n",
      "Start of epoch 224\n",
      "Training loss at epoch 224: 0.2401\n",
      "\n",
      "Start of epoch 225\n",
      "Training loss at epoch 225: 0.2400\n",
      "\n",
      "Start of epoch 226\n",
      "Training loss at epoch 226: 0.2399\n",
      "\n",
      "Start of epoch 227\n",
      "Training loss at epoch 227: 0.2398\n",
      "\n",
      "Start of epoch 228\n",
      "Training loss at epoch 228: 0.2397\n",
      "\n",
      "Start of epoch 229\n",
      "Training loss at epoch 229: 0.2396\n",
      "\n",
      "Start of epoch 230\n",
      "Training loss at epoch 230: 0.2396\n",
      "\n",
      "Start of epoch 231\n",
      "Training loss at epoch 231: 0.2395\n",
      "\n",
      "Start of epoch 232\n",
      "Training loss at epoch 232: 0.2394\n",
      "\n",
      "Start of epoch 233\n",
      "Training loss at epoch 233: 0.2394\n",
      "\n",
      "Start of epoch 234\n",
      "Training loss at epoch 234: 0.2393\n",
      "\n",
      "Start of epoch 235\n",
      "Training loss at epoch 235: 0.2392\n",
      "\n",
      "Start of epoch 236\n",
      "Training loss at epoch 236: 0.2392\n",
      "\n",
      "Start of epoch 237\n",
      "Training loss at epoch 237: 0.2391\n",
      "\n",
      "Start of epoch 238\n",
      "Training loss at epoch 238: 0.2390\n",
      "\n",
      "Start of epoch 239\n",
      "Training loss at epoch 239: 0.2390\n",
      "\n",
      "Start of epoch 240\n",
      "Training loss at epoch 240: 0.2389\n",
      "\n",
      "Start of epoch 241\n",
      "Training loss at epoch 241: 0.2388\n",
      "\n",
      "Start of epoch 242\n",
      "Training loss at epoch 242: 0.2388\n",
      "\n",
      "Start of epoch 243\n",
      "Training loss at epoch 243: 0.2387\n",
      "\n",
      "Start of epoch 244\n",
      "Training loss at epoch 244: 0.2387\n",
      "\n",
      "Start of epoch 245\n",
      "Training loss at epoch 245: 0.2386\n",
      "\n",
      "Start of epoch 246\n",
      "Training loss at epoch 246: 0.2385\n",
      "\n",
      "Start of epoch 247\n",
      "Training loss at epoch 247: 0.2385\n",
      "\n",
      "Start of epoch 248\n",
      "Training loss at epoch 248: 0.2384\n",
      "\n",
      "Start of epoch 249\n",
      "Training loss at epoch 249: 0.2384\n",
      "\n",
      "Start of epoch 250\n",
      "Training loss at epoch 250: 0.2383\n",
      "\n",
      "Start of epoch 251\n",
      "Training loss at epoch 251: 0.2383\n",
      "\n",
      "Start of epoch 252\n",
      "Training loss at epoch 252: 0.2382\n",
      "\n",
      "Start of epoch 253\n",
      "Training loss at epoch 253: 0.2382\n",
      "\n",
      "Start of epoch 254\n",
      "Training loss at epoch 254: 0.2381\n",
      "\n",
      "Start of epoch 255\n",
      "Training loss at epoch 255: 0.2381\n",
      "\n",
      "Start of epoch 256\n",
      "Training loss at epoch 256: 0.2380\n",
      "\n",
      "Start of epoch 257\n",
      "Training loss at epoch 257: 0.2380\n",
      "\n",
      "Start of epoch 258\n",
      "Training loss at epoch 258: 0.2379\n",
      "\n",
      "Start of epoch 259\n",
      "Training loss at epoch 259: 0.2379\n",
      "\n",
      "Start of epoch 260\n",
      "Training loss at epoch 260: 0.2378\n",
      "\n",
      "Start of epoch 261\n",
      "Training loss at epoch 261: 0.2378\n",
      "\n",
      "Start of epoch 262\n",
      "Training loss at epoch 262: 0.2377\n",
      "\n",
      "Start of epoch 263\n",
      "Training loss at epoch 263: 0.2377\n",
      "\n",
      "Start of epoch 264\n",
      "Training loss at epoch 264: 0.2376\n",
      "\n",
      "Start of epoch 265\n",
      "Training loss at epoch 265: 0.2376\n",
      "\n",
      "Start of epoch 266\n",
      "Training loss at epoch 266: 0.2375\n",
      "\n",
      "Start of epoch 267\n",
      "Training loss at epoch 267: 0.2375\n",
      "\n",
      "Start of epoch 268\n",
      "Training loss at epoch 268: 0.2374\n",
      "\n",
      "Start of epoch 269\n",
      "Training loss at epoch 269: 0.2374\n",
      "\n",
      "Start of epoch 270\n",
      "Training loss at epoch 270: 0.2373\n",
      "\n",
      "Start of epoch 271\n",
      "Training loss at epoch 271: 0.2373\n",
      "\n",
      "Start of epoch 272\n",
      "Training loss at epoch 272: 0.2372\n",
      "\n",
      "Start of epoch 273\n",
      "Training loss at epoch 273: 0.2372\n",
      "\n",
      "Start of epoch 274\n",
      "Training loss at epoch 274: 0.2371\n",
      "\n",
      "Start of epoch 275\n",
      "Training loss at epoch 275: 0.2371\n",
      "\n",
      "Start of epoch 276\n",
      "Training loss at epoch 276: 0.2370\n",
      "\n",
      "Start of epoch 277\n",
      "Training loss at epoch 277: 0.2370\n",
      "\n",
      "Start of epoch 278\n",
      "Training loss at epoch 278: 0.2369\n",
      "\n",
      "Start of epoch 279\n",
      "Training loss at epoch 279: 0.2369\n",
      "\n",
      "Start of epoch 280\n",
      "Training loss at epoch 280: 0.2368\n",
      "\n",
      "Start of epoch 281\n",
      "Training loss at epoch 281: 0.2368\n",
      "\n",
      "Start of epoch 282\n",
      "Training loss at epoch 282: 0.2367\n",
      "\n",
      "Start of epoch 283\n",
      "Training loss at epoch 283: 0.2366\n",
      "\n",
      "Start of epoch 284\n",
      "Training loss at epoch 284: 0.2366\n",
      "\n",
      "Start of epoch 285\n",
      "Training loss at epoch 285: 0.2365\n",
      "\n",
      "Start of epoch 286\n",
      "Training loss at epoch 286: 0.2365\n",
      "\n",
      "Start of epoch 287\n",
      "Training loss at epoch 287: 0.2364\n",
      "\n",
      "Start of epoch 288\n",
      "Training loss at epoch 288: 0.2363\n",
      "\n",
      "Start of epoch 289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 289: 0.2363\n",
      "\n",
      "Start of epoch 290\n",
      "Training loss at epoch 290: 0.2362\n",
      "\n",
      "Start of epoch 291\n",
      "Training loss at epoch 291: 0.2361\n",
      "\n",
      "Start of epoch 292\n",
      "Training loss at epoch 292: 0.2361\n",
      "\n",
      "Start of epoch 293\n",
      "Training loss at epoch 293: 0.2360\n",
      "\n",
      "Start of epoch 294\n",
      "Training loss at epoch 294: 0.2359\n",
      "\n",
      "Start of epoch 295\n",
      "Training loss at epoch 295: 0.2358\n",
      "\n",
      "Start of epoch 296\n",
      "Training loss at epoch 296: 0.2357\n",
      "\n",
      "Start of epoch 297\n",
      "Training loss at epoch 297: 0.2357\n",
      "\n",
      "Start of epoch 298\n",
      "Training loss at epoch 298: 0.2356\n",
      "\n",
      "Start of epoch 299\n",
      "Training loss at epoch 299: 0.2355\n",
      "\n",
      "Start of epoch 300\n",
      "Training loss at epoch 300: 0.2354\n",
      "\n",
      "Start of epoch 301\n",
      "Training loss at epoch 301: 0.2353\n",
      "\n",
      "Start of epoch 302\n",
      "Training loss at epoch 302: 0.2352\n",
      "\n",
      "Start of epoch 303\n",
      "Training loss at epoch 303: 0.2350\n",
      "\n",
      "Start of epoch 304\n",
      "Training loss at epoch 304: 0.2349\n",
      "\n",
      "Start of epoch 305\n",
      "Training loss at epoch 305: 0.2348\n",
      "\n",
      "Start of epoch 306\n",
      "Training loss at epoch 306: 0.2347\n",
      "\n",
      "Start of epoch 307\n",
      "Training loss at epoch 307: 0.2345\n",
      "\n",
      "Start of epoch 308\n",
      "Training loss at epoch 308: 0.2344\n",
      "\n",
      "Start of epoch 309\n",
      "Training loss at epoch 309: 0.2342\n",
      "\n",
      "Start of epoch 310\n",
      "Training loss at epoch 310: 0.2341\n",
      "\n",
      "Start of epoch 311\n",
      "Training loss at epoch 311: 0.2339\n",
      "\n",
      "Start of epoch 312\n",
      "Training loss at epoch 312: 0.2337\n",
      "\n",
      "Start of epoch 313\n",
      "Training loss at epoch 313: 0.2335\n",
      "\n",
      "Start of epoch 314\n",
      "Training loss at epoch 314: 0.2333\n",
      "\n",
      "Start of epoch 315\n",
      "Training loss at epoch 315: 0.2330\n",
      "\n",
      "Start of epoch 316\n",
      "Training loss at epoch 316: 0.2328\n",
      "\n",
      "Start of epoch 317\n",
      "Training loss at epoch 317: 0.2325\n",
      "\n",
      "Start of epoch 318\n",
      "Training loss at epoch 318: 0.2322\n",
      "\n",
      "Start of epoch 319\n",
      "Training loss at epoch 319: 0.2318\n",
      "\n",
      "Start of epoch 320\n",
      "Training loss at epoch 320: 0.2315\n",
      "\n",
      "Start of epoch 321\n",
      "Training loss at epoch 321: 0.2311\n",
      "\n",
      "Start of epoch 322\n",
      "Training loss at epoch 322: 0.2307\n",
      "\n",
      "Start of epoch 323\n",
      "Training loss at epoch 323: 0.2302\n",
      "\n",
      "Start of epoch 324\n",
      "Training loss at epoch 324: 0.2297\n",
      "\n",
      "Start of epoch 325\n",
      "Training loss at epoch 325: 0.2291\n",
      "\n",
      "Start of epoch 326\n",
      "Training loss at epoch 326: 0.2284\n",
      "\n",
      "Start of epoch 327\n",
      "Training loss at epoch 327: 0.2277\n",
      "\n",
      "Start of epoch 328\n",
      "Training loss at epoch 328: 0.2269\n",
      "\n",
      "Start of epoch 329\n",
      "Training loss at epoch 329: 0.2259\n",
      "\n",
      "Start of epoch 330\n",
      "Training loss at epoch 330: 0.2249\n",
      "\n",
      "Start of epoch 331\n",
      "Training loss at epoch 331: 0.2237\n",
      "\n",
      "Start of epoch 332\n",
      "Training loss at epoch 332: 0.2224\n",
      "\n",
      "Start of epoch 333\n",
      "Training loss at epoch 333: 0.2209\n",
      "\n",
      "Start of epoch 334\n",
      "Training loss at epoch 334: 0.2191\n",
      "\n",
      "Start of epoch 335\n",
      "Training loss at epoch 335: 0.2171\n",
      "\n",
      "Start of epoch 336\n",
      "Training loss at epoch 336: 0.2148\n",
      "\n",
      "Start of epoch 337\n",
      "Training loss at epoch 337: 0.2121\n",
      "\n",
      "Start of epoch 338\n",
      "Training loss at epoch 338: 0.2090\n",
      "\n",
      "Start of epoch 339\n",
      "Training loss at epoch 339: 0.2054\n",
      "\n",
      "Start of epoch 340\n",
      "Training loss at epoch 340: 0.2012\n",
      "\n",
      "Start of epoch 341\n",
      "Training loss at epoch 341: 0.1964\n",
      "\n",
      "Start of epoch 342\n",
      "Training loss at epoch 342: 0.1908\n",
      "\n",
      "Start of epoch 343\n",
      "Training loss at epoch 343: 0.1845\n",
      "\n",
      "Start of epoch 344\n",
      "Training loss at epoch 344: 0.1775\n",
      "\n",
      "Start of epoch 345\n",
      "Training loss at epoch 345: 0.1698\n",
      "\n",
      "Start of epoch 346\n",
      "Training loss at epoch 346: 0.1615\n",
      "\n",
      "Start of epoch 347\n",
      "Training loss at epoch 347: 0.1530\n",
      "\n",
      "Start of epoch 348\n",
      "Training loss at epoch 348: 0.1444\n",
      "\n",
      "Start of epoch 349\n",
      "Training loss at epoch 349: 0.1363\n",
      "\n",
      "Start of epoch 350\n",
      "Training loss at epoch 350: 0.1288\n",
      "\n",
      "Start of epoch 351\n",
      "Training loss at epoch 351: 0.1222\n",
      "\n",
      "Start of epoch 352\n",
      "Training loss at epoch 352: 0.1166\n",
      "\n",
      "Start of epoch 353\n",
      "Training loss at epoch 353: 0.1120\n",
      "\n",
      "Start of epoch 354\n",
      "Training loss at epoch 354: 0.1082\n",
      "\n",
      "Start of epoch 355\n",
      "Training loss at epoch 355: 0.1050\n",
      "\n",
      "Start of epoch 356\n",
      "Training loss at epoch 356: 0.1023\n",
      "\n",
      "Start of epoch 357\n",
      "Training loss at epoch 357: 0.0999\n",
      "\n",
      "Start of epoch 358\n",
      "Training loss at epoch 358: 0.0975\n",
      "\n",
      "Start of epoch 359\n",
      "Training loss at epoch 359: 0.0950\n",
      "\n",
      "Start of epoch 360\n",
      "Training loss at epoch 360: 0.0925\n",
      "\n",
      "Start of epoch 361\n",
      "Training loss at epoch 361: 0.0900\n",
      "\n",
      "Start of epoch 362\n",
      "Training loss at epoch 362: 0.0874\n",
      "\n",
      "Start of epoch 363\n",
      "Training loss at epoch 363: 0.0846\n",
      "\n",
      "Start of epoch 364\n",
      "Training loss at epoch 364: 0.0817\n",
      "\n",
      "Start of epoch 365\n",
      "Training loss at epoch 365: 0.0786\n",
      "\n",
      "Start of epoch 366\n",
      "Training loss at epoch 366: 0.0756\n",
      "\n",
      "Start of epoch 367\n",
      "Training loss at epoch 367: 0.0728\n",
      "\n",
      "Start of epoch 368\n",
      "Training loss at epoch 368: 0.0703\n",
      "\n",
      "Start of epoch 369\n",
      "Training loss at epoch 369: 0.0681\n",
      "\n",
      "Start of epoch 370\n",
      "Training loss at epoch 370: 0.0664\n",
      "\n",
      "Start of epoch 371\n",
      "Training loss at epoch 371: 0.0652\n",
      "\n",
      "Start of epoch 372\n",
      "Training loss at epoch 372: 0.0642\n",
      "\n",
      "Start of epoch 373\n",
      "Training loss at epoch 373: 0.0634\n",
      "\n",
      "Start of epoch 374\n",
      "Training loss at epoch 374: 0.0627\n",
      "\n",
      "Start of epoch 375\n",
      "Training loss at epoch 375: 0.0621\n",
      "\n",
      "Start of epoch 376\n",
      "Training loss at epoch 376: 0.0614\n",
      "\n",
      "Start of epoch 377\n",
      "Training loss at epoch 377: 0.0608\n",
      "\n",
      "Start of epoch 378\n",
      "Training loss at epoch 378: 0.0602\n",
      "\n",
      "Start of epoch 379\n",
      "Training loss at epoch 379: 0.0596\n",
      "\n",
      "Start of epoch 380\n",
      "Training loss at epoch 380: 0.0590\n",
      "\n",
      "Start of epoch 381\n",
      "Training loss at epoch 381: 0.0585\n",
      "\n",
      "Start of epoch 382\n",
      "Training loss at epoch 382: 0.0580\n",
      "\n",
      "Start of epoch 383\n",
      "Training loss at epoch 383: 0.0576\n",
      "\n",
      "Start of epoch 384\n",
      "Training loss at epoch 384: 0.0573\n",
      "\n",
      "Start of epoch 385\n",
      "Training loss at epoch 385: 0.0570\n",
      "\n",
      "Start of epoch 386\n",
      "Training loss at epoch 386: 0.0568\n",
      "\n",
      "Start of epoch 387\n",
      "Training loss at epoch 387: 0.0567\n",
      "\n",
      "Start of epoch 388\n",
      "Training loss at epoch 388: 0.0566\n",
      "\n",
      "Start of epoch 389\n",
      "Training loss at epoch 389: 0.0564\n",
      "\n",
      "Start of epoch 390\n",
      "Training loss at epoch 390: 0.0563\n",
      "\n",
      "Start of epoch 391\n",
      "Training loss at epoch 391: 0.0563\n",
      "\n",
      "Start of epoch 392\n",
      "Training loss at epoch 392: 0.0562\n",
      "\n",
      "Start of epoch 393\n",
      "Training loss at epoch 393: 0.0561\n",
      "\n",
      "Start of epoch 394\n",
      "Training loss at epoch 394: 0.0559\n",
      "\n",
      "Start of epoch 395\n",
      "Training loss at epoch 395: 0.0558\n",
      "\n",
      "Start of epoch 396\n",
      "Training loss at epoch 396: 0.0557\n",
      "\n",
      "Start of epoch 397\n",
      "Training loss at epoch 397: 0.0556\n",
      "\n",
      "Start of epoch 398\n",
      "Training loss at epoch 398: 0.0555\n",
      "\n",
      "Start of epoch 399\n",
      "Training loss at epoch 399: 0.0554\n",
      "\n",
      "Start of epoch 400\n",
      "Training loss at epoch 400: 0.0554\n",
      "\n",
      "Start of epoch 401\n",
      "Training loss at epoch 401: 0.0553\n",
      "\n",
      "Start of epoch 402\n",
      "Training loss at epoch 402: 0.0553\n",
      "\n",
      "Start of epoch 403\n",
      "Training loss at epoch 403: 0.0553\n",
      "\n",
      "Start of epoch 404\n",
      "Training loss at epoch 404: 0.0552\n",
      "\n",
      "Start of epoch 405\n",
      "Training loss at epoch 405: 0.0552\n",
      "\n",
      "Start of epoch 406\n",
      "Training loss at epoch 406: 0.0552\n",
      "\n",
      "Start of epoch 407\n",
      "Training loss at epoch 407: 0.0552\n",
      "\n",
      "Start of epoch 408\n",
      "Training loss at epoch 408: 0.0552\n",
      "\n",
      "Start of epoch 409\n",
      "Training loss at epoch 409: 0.0552\n",
      "\n",
      "Start of epoch 410\n",
      "Training loss at epoch 410: 0.0551\n",
      "\n",
      "Start of epoch 411\n",
      "Training loss at epoch 411: 0.0551\n",
      "\n",
      "Start of epoch 412\n",
      "Training loss at epoch 412: 0.0551\n",
      "\n",
      "Start of epoch 413\n",
      "Training loss at epoch 413: 0.0551\n",
      "\n",
      "Start of epoch 414\n",
      "Training loss at epoch 414: 0.0551\n",
      "\n",
      "Start of epoch 415\n",
      "Training loss at epoch 415: 0.0551\n",
      "\n",
      "Start of epoch 416\n",
      "Training loss at epoch 416: 0.0551\n",
      "\n",
      "Start of epoch 417\n",
      "Training loss at epoch 417: 0.0550\n",
      "\n",
      "Start of epoch 418\n",
      "Training loss at epoch 418: 0.0550\n",
      "\n",
      "Start of epoch 419\n",
      "Training loss at epoch 419: 0.0550\n",
      "\n",
      "Start of epoch 420\n",
      "Training loss at epoch 420: 0.0550\n",
      "\n",
      "Start of epoch 421\n",
      "Training loss at epoch 421: 0.0550\n",
      "\n",
      "Start of epoch 422\n",
      "Training loss at epoch 422: 0.0550\n",
      "\n",
      "Start of epoch 423\n",
      "Training loss at epoch 423: 0.0550\n",
      "\n",
      "Start of epoch 424\n",
      "Training loss at epoch 424: 0.0550\n",
      "\n",
      "Start of epoch 425\n",
      "Training loss at epoch 425: 0.0550\n",
      "\n",
      "Start of epoch 426\n",
      "Training loss at epoch 426: 0.0549\n",
      "\n",
      "Start of epoch 427\n",
      "Training loss at epoch 427: 0.0549\n",
      "\n",
      "Start of epoch 428\n",
      "Training loss at epoch 428: 0.0549\n",
      "\n",
      "Start of epoch 429\n",
      "Training loss at epoch 429: 0.0549\n",
      "\n",
      "Start of epoch 430\n",
      "Training loss at epoch 430: 0.0549\n",
      "\n",
      "Start of epoch 431\n",
      "Training loss at epoch 431: 0.0549\n",
      "\n",
      "Start of epoch 432\n",
      "Training loss at epoch 432: 0.0549\n",
      "\n",
      "Start of epoch 433\n",
      "Training loss at epoch 433: 0.0549\n",
      "\n",
      "Start of epoch 434\n",
      "Training loss at epoch 434: 0.0549\n",
      "\n",
      "Start of epoch 435\n",
      "Training loss at epoch 435: 0.0548\n",
      "\n",
      "Start of epoch 436\n",
      "Training loss at epoch 436: 0.0548\n",
      "\n",
      "Start of epoch 437\n",
      "Training loss at epoch 437: 0.0548\n",
      "\n",
      "Start of epoch 438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 438: 0.0548\n",
      "\n",
      "Start of epoch 439\n",
      "Training loss at epoch 439: 0.0548\n",
      "\n",
      "Start of epoch 440\n",
      "Training loss at epoch 440: 0.0548\n",
      "\n",
      "Start of epoch 441\n",
      "Training loss at epoch 441: 0.0548\n",
      "\n",
      "Start of epoch 442\n",
      "Training loss at epoch 442: 0.0548\n",
      "\n",
      "Start of epoch 443\n",
      "Training loss at epoch 443: 0.0548\n",
      "\n",
      "Start of epoch 444\n",
      "Training loss at epoch 444: 0.0548\n",
      "\n",
      "Start of epoch 445\n",
      "Training loss at epoch 445: 0.0547\n",
      "\n",
      "Start of epoch 446\n",
      "Training loss at epoch 446: 0.0547\n",
      "\n",
      "Start of epoch 447\n",
      "Training loss at epoch 447: 0.0547\n",
      "\n",
      "Start of epoch 448\n",
      "Training loss at epoch 448: 0.0547\n",
      "\n",
      "Start of epoch 449\n",
      "Training loss at epoch 449: 0.0547\n",
      "\n",
      "Start of epoch 450\n",
      "Training loss at epoch 450: 0.0547\n",
      "\n",
      "Start of epoch 451\n",
      "Training loss at epoch 451: 0.0547\n",
      "\n",
      "Start of epoch 452\n",
      "Training loss at epoch 452: 0.0547\n",
      "\n",
      "Start of epoch 453\n",
      "Training loss at epoch 453: 0.0547\n",
      "\n",
      "Start of epoch 454\n",
      "Training loss at epoch 454: 0.0547\n",
      "\n",
      "Start of epoch 455\n",
      "Training loss at epoch 455: 0.0546\n",
      "\n",
      "Start of epoch 456\n",
      "Training loss at epoch 456: 0.0546\n",
      "\n",
      "Start of epoch 457\n",
      "Training loss at epoch 457: 0.0546\n",
      "\n",
      "Start of epoch 458\n",
      "Training loss at epoch 458: 0.0546\n",
      "\n",
      "Start of epoch 459\n",
      "Training loss at epoch 459: 0.0546\n",
      "\n",
      "Start of epoch 460\n",
      "Training loss at epoch 460: 0.0546\n",
      "\n",
      "Start of epoch 461\n",
      "Training loss at epoch 461: 0.0546\n",
      "\n",
      "Start of epoch 462\n",
      "Training loss at epoch 462: 0.0546\n",
      "\n",
      "Start of epoch 463\n",
      "Training loss at epoch 463: 0.0546\n",
      "\n",
      "Start of epoch 464\n",
      "Training loss at epoch 464: 0.0546\n",
      "\n",
      "Start of epoch 465\n",
      "Training loss at epoch 465: 0.0545\n",
      "\n",
      "Start of epoch 466\n",
      "Training loss at epoch 466: 0.0545\n",
      "\n",
      "Start of epoch 467\n",
      "Training loss at epoch 467: 0.0545\n",
      "\n",
      "Start of epoch 468\n",
      "Training loss at epoch 468: 0.0545\n",
      "\n",
      "Start of epoch 469\n",
      "Training loss at epoch 469: 0.0545\n",
      "\n",
      "Start of epoch 470\n",
      "Training loss at epoch 470: 0.0545\n",
      "\n",
      "Start of epoch 471\n",
      "Training loss at epoch 471: 0.0545\n",
      "\n",
      "Start of epoch 472\n",
      "Training loss at epoch 472: 0.0545\n",
      "\n",
      "Start of epoch 473\n",
      "Training loss at epoch 473: 0.0545\n",
      "\n",
      "Start of epoch 474\n",
      "Training loss at epoch 474: 0.0544\n",
      "\n",
      "Start of epoch 475\n",
      "Training loss at epoch 475: 0.0544\n",
      "\n",
      "Start of epoch 476\n",
      "Training loss at epoch 476: 0.0544\n",
      "\n",
      "Start of epoch 477\n",
      "Training loss at epoch 477: 0.0544\n",
      "\n",
      "Start of epoch 478\n",
      "Training loss at epoch 478: 0.0544\n",
      "\n",
      "Start of epoch 479\n",
      "Training loss at epoch 479: 0.0544\n",
      "\n",
      "Start of epoch 480\n",
      "Training loss at epoch 480: 0.0544\n",
      "\n",
      "Start of epoch 481\n",
      "Training loss at epoch 481: 0.0544\n",
      "\n",
      "Start of epoch 482\n",
      "Training loss at epoch 482: 0.0543\n",
      "\n",
      "Start of epoch 483\n",
      "Training loss at epoch 483: 0.0543\n",
      "\n",
      "Start of epoch 484\n",
      "Training loss at epoch 484: 0.0543\n",
      "\n",
      "Start of epoch 485\n",
      "Training loss at epoch 485: 0.0543\n",
      "\n",
      "Start of epoch 486\n",
      "Training loss at epoch 486: 0.0543\n",
      "\n",
      "Start of epoch 487\n",
      "Training loss at epoch 487: 0.0543\n",
      "\n",
      "Start of epoch 488\n",
      "Training loss at epoch 488: 0.0543\n",
      "\n",
      "Start of epoch 489\n",
      "Training loss at epoch 489: 0.0543\n",
      "\n",
      "Start of epoch 490\n",
      "Training loss at epoch 490: 0.0542\n",
      "\n",
      "Start of epoch 491\n",
      "Training loss at epoch 491: 0.0542\n",
      "\n",
      "Start of epoch 492\n",
      "Training loss at epoch 492: 0.0542\n",
      "\n",
      "Start of epoch 493\n",
      "Training loss at epoch 493: 0.0542\n",
      "\n",
      "Start of epoch 494\n",
      "Training loss at epoch 494: 0.0542\n",
      "\n",
      "Start of epoch 495\n",
      "Training loss at epoch 495: 0.0542\n",
      "\n",
      "Start of epoch 496\n",
      "Training loss at epoch 496: 0.0542\n",
      "\n",
      "Start of epoch 497\n",
      "Training loss at epoch 497: 0.0542\n",
      "\n",
      "Start of epoch 498\n",
      "Training loss at epoch 498: 0.0541\n",
      "\n",
      "Start of epoch 499\n",
      "Training loss at epoch 499: 0.0541\n",
      "[<tf.Variable 'parameters:0' shape=(60,) dtype=float32, numpy=\n",
      "array([5.3938303 , 0.21499251, 4.688564  , 5.8655787 , 5.981266  ,\n",
      "       4.5638247 , 3.1074107 , 2.7311585 , 3.920667  , 5.76327   ,\n",
      "       2.6502297 , 2.2022526 , 5.9203563 , 1.5882424 , 4.5330057 ,\n",
      "       6.229135  , 3.1852505 , 6.252638  , 0.03806414, 6.2542996 ,\n",
      "       3.4274037 , 0.73906344, 1.8826064 , 0.9955978 , 4.1365395 ,\n",
      "       4.52645   , 0.8336834 , 2.6982887 , 3.2022943 , 2.6485355 ,\n",
      "       3.9985428 , 1.31072   , 2.0915146 , 2.824201  , 5.472858  ,\n",
      "       3.5685263 , 2.9387343 , 2.0232203 , 3.159796  , 3.6153224 ,\n",
      "       5.679466  , 1.6177438 , 5.1348524 , 1.7816813 , 1.7037584 ,\n",
      "       1.3606695 , 3.0811646 , 2.4778135 , 3.128933  , 2.008896  ,\n",
      "       4.167744  , 1.3651553 , 2.3575263 , 3.0689983 , 3.2073135 ,\n",
      "       5.9082546 , 0.26744297, 0.48604497, 5.962202  , 1.3474958 ],\n",
      "      dtype=float32)>]\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.0155\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 0.9152\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.8257\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.7565\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.7078\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.6736\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.6482\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.6273\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.6073\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.5870\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.5662\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.5461\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.5287\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.5158\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.5075\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.5028\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.5004\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.4988\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.4972\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.4945\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.4904\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.4847\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.4782\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.4715\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.4652\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.4600\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.4556\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.4518\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.4483\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.4446\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.4407\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.4365\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.4319\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.4271\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.4221\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.4171\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.4124\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.4080\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.4040\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.4004\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.3973\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.3945\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.3922\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.3901\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.3884\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.3867\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.3850\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.3832\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.3813\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.3792\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.3770\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.3748\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.3727\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.3706\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.3686\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.3666\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.3646\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.3628\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.3610\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.3591\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.3574\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.3556\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.3540\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.3524\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.3509\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.3495\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.3481\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.3467\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.3454\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.3441\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.3428\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.3415\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.3402\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.3390\n",
      "\n",
      "Start of epoch 74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 74: 0.3378\n",
      "\n",
      "Start of epoch 75\n",
      "Training loss at epoch 75: 0.3366\n",
      "\n",
      "Start of epoch 76\n",
      "Training loss at epoch 76: 0.3355\n",
      "\n",
      "Start of epoch 77\n",
      "Training loss at epoch 77: 0.3344\n",
      "\n",
      "Start of epoch 78\n",
      "Training loss at epoch 78: 0.3333\n",
      "\n",
      "Start of epoch 79\n",
      "Training loss at epoch 79: 0.3323\n",
      "\n",
      "Start of epoch 80\n",
      "Training loss at epoch 80: 0.3313\n",
      "\n",
      "Start of epoch 81\n",
      "Training loss at epoch 81: 0.3304\n",
      "\n",
      "Start of epoch 82\n",
      "Training loss at epoch 82: 0.3294\n",
      "\n",
      "Start of epoch 83\n",
      "Training loss at epoch 83: 0.3285\n",
      "\n",
      "Start of epoch 84\n",
      "Training loss at epoch 84: 0.3276\n",
      "\n",
      "Start of epoch 85\n",
      "Training loss at epoch 85: 0.3267\n",
      "\n",
      "Start of epoch 86\n",
      "Training loss at epoch 86: 0.3258\n",
      "\n",
      "Start of epoch 87\n",
      "Training loss at epoch 87: 0.3248\n",
      "\n",
      "Start of epoch 88\n",
      "Training loss at epoch 88: 0.3239\n",
      "\n",
      "Start of epoch 89\n",
      "Training loss at epoch 89: 0.3230\n",
      "\n",
      "Start of epoch 90\n",
      "Training loss at epoch 90: 0.3221\n",
      "\n",
      "Start of epoch 91\n",
      "Training loss at epoch 91: 0.3211\n",
      "\n",
      "Start of epoch 92\n",
      "Training loss at epoch 92: 0.3202\n",
      "\n",
      "Start of epoch 93\n",
      "Training loss at epoch 93: 0.3193\n",
      "\n",
      "Start of epoch 94\n",
      "Training loss at epoch 94: 0.3184\n",
      "\n",
      "Start of epoch 95\n",
      "Training loss at epoch 95: 0.3174\n",
      "\n",
      "Start of epoch 96\n",
      "Training loss at epoch 96: 0.3165\n",
      "\n",
      "Start of epoch 97\n",
      "Training loss at epoch 97: 0.3155\n",
      "\n",
      "Start of epoch 98\n",
      "Training loss at epoch 98: 0.3145\n",
      "\n",
      "Start of epoch 99\n",
      "Training loss at epoch 99: 0.3136\n",
      "\n",
      "Start of epoch 100\n",
      "Training loss at epoch 100: 0.3125\n",
      "\n",
      "Start of epoch 101\n",
      "Training loss at epoch 101: 0.3115\n",
      "\n",
      "Start of epoch 102\n",
      "Training loss at epoch 102: 0.3104\n",
      "\n",
      "Start of epoch 103\n",
      "Training loss at epoch 103: 0.3093\n",
      "\n",
      "Start of epoch 104\n",
      "Training loss at epoch 104: 0.3082\n",
      "\n",
      "Start of epoch 105\n",
      "Training loss at epoch 105: 0.3071\n",
      "\n",
      "Start of epoch 106\n",
      "Training loss at epoch 106: 0.3059\n",
      "\n",
      "Start of epoch 107\n",
      "Training loss at epoch 107: 0.3048\n",
      "\n",
      "Start of epoch 108\n",
      "Training loss at epoch 108: 0.3036\n",
      "\n",
      "Start of epoch 109\n",
      "Training loss at epoch 109: 0.3023\n",
      "\n",
      "Start of epoch 110\n",
      "Training loss at epoch 110: 0.3011\n",
      "\n",
      "Start of epoch 111\n",
      "Training loss at epoch 111: 0.2999\n",
      "\n",
      "Start of epoch 112\n",
      "Training loss at epoch 112: 0.2986\n",
      "\n",
      "Start of epoch 113\n",
      "Training loss at epoch 113: 0.2973\n",
      "\n",
      "Start of epoch 114\n",
      "Training loss at epoch 114: 0.2960\n",
      "\n",
      "Start of epoch 115\n",
      "Training loss at epoch 115: 0.2947\n",
      "\n",
      "Start of epoch 116\n",
      "Training loss at epoch 116: 0.2934\n",
      "\n",
      "Start of epoch 117\n",
      "Training loss at epoch 117: 0.2921\n",
      "\n",
      "Start of epoch 118\n",
      "Training loss at epoch 118: 0.2908\n",
      "\n",
      "Start of epoch 119\n",
      "Training loss at epoch 119: 0.2895\n",
      "\n",
      "Start of epoch 120\n",
      "Training loss at epoch 120: 0.2882\n",
      "\n",
      "Start of epoch 121\n",
      "Training loss at epoch 121: 0.2870\n",
      "\n",
      "Start of epoch 122\n",
      "Training loss at epoch 122: 0.2857\n",
      "\n",
      "Start of epoch 123\n",
      "Training loss at epoch 123: 0.2845\n",
      "\n",
      "Start of epoch 124\n",
      "Training loss at epoch 124: 0.2832\n",
      "\n",
      "Start of epoch 125\n",
      "Training loss at epoch 125: 0.2820\n",
      "\n",
      "Start of epoch 126\n",
      "Training loss at epoch 126: 0.2808\n",
      "\n",
      "Start of epoch 127\n",
      "Training loss at epoch 127: 0.2797\n",
      "\n",
      "Start of epoch 128\n",
      "Training loss at epoch 128: 0.2785\n",
      "\n",
      "Start of epoch 129\n",
      "Training loss at epoch 129: 0.2774\n",
      "\n",
      "Start of epoch 130\n",
      "Training loss at epoch 130: 0.2763\n",
      "\n",
      "Start of epoch 131\n",
      "Training loss at epoch 131: 0.2753\n",
      "\n",
      "Start of epoch 132\n",
      "Training loss at epoch 132: 0.2743\n",
      "\n",
      "Start of epoch 133\n",
      "Training loss at epoch 133: 0.2734\n",
      "\n",
      "Start of epoch 134\n",
      "Training loss at epoch 134: 0.2725\n",
      "\n",
      "Start of epoch 135\n",
      "Training loss at epoch 135: 0.2717\n",
      "\n",
      "Start of epoch 136\n",
      "Training loss at epoch 136: 0.2709\n",
      "\n",
      "Start of epoch 137\n",
      "Training loss at epoch 137: 0.2702\n",
      "\n",
      "Start of epoch 138\n",
      "Training loss at epoch 138: 0.2695\n",
      "\n",
      "Start of epoch 139\n",
      "Training loss at epoch 139: 0.2689\n",
      "\n",
      "Start of epoch 140\n",
      "Training loss at epoch 140: 0.2684\n",
      "\n",
      "Start of epoch 141\n",
      "Training loss at epoch 141: 0.2678\n",
      "\n",
      "Start of epoch 142\n",
      "Training loss at epoch 142: 0.2673\n",
      "\n",
      "Start of epoch 143\n",
      "Training loss at epoch 143: 0.2668\n",
      "\n",
      "Start of epoch 144\n",
      "Training loss at epoch 144: 0.2664\n",
      "\n",
      "Start of epoch 145\n",
      "Training loss at epoch 145: 0.2659\n",
      "\n",
      "Start of epoch 146\n",
      "Training loss at epoch 146: 0.2655\n",
      "\n",
      "Start of epoch 147\n",
      "Training loss at epoch 147: 0.2650\n",
      "\n",
      "Start of epoch 148\n",
      "Training loss at epoch 148: 0.2646\n",
      "\n",
      "Start of epoch 149\n",
      "Training loss at epoch 149: 0.2641\n",
      "\n",
      "Start of epoch 150\n",
      "Training loss at epoch 150: 0.2637\n",
      "\n",
      "Start of epoch 151\n",
      "Training loss at epoch 151: 0.2633\n",
      "\n",
      "Start of epoch 152\n",
      "Training loss at epoch 152: 0.2628\n",
      "\n",
      "Start of epoch 153\n",
      "Training loss at epoch 153: 0.2624\n",
      "\n",
      "Start of epoch 154\n",
      "Training loss at epoch 154: 0.2620\n",
      "\n",
      "Start of epoch 155\n",
      "Training loss at epoch 155: 0.2616\n",
      "\n",
      "Start of epoch 156\n",
      "Training loss at epoch 156: 0.2611\n",
      "\n",
      "Start of epoch 157\n",
      "Training loss at epoch 157: 0.2607\n",
      "\n",
      "Start of epoch 158\n",
      "Training loss at epoch 158: 0.2603\n",
      "\n",
      "Start of epoch 159\n",
      "Training loss at epoch 159: 0.2598\n",
      "\n",
      "Start of epoch 160\n",
      "Training loss at epoch 160: 0.2594\n",
      "\n",
      "Start of epoch 161\n",
      "Training loss at epoch 161: 0.2589\n",
      "\n",
      "Start of epoch 162\n",
      "Training loss at epoch 162: 0.2585\n",
      "\n",
      "Start of epoch 163\n",
      "Training loss at epoch 163: 0.2580\n",
      "\n",
      "Start of epoch 164\n",
      "Training loss at epoch 164: 0.2576\n",
      "\n",
      "Start of epoch 165\n",
      "Training loss at epoch 165: 0.2571\n",
      "\n",
      "Start of epoch 166\n",
      "Training loss at epoch 166: 0.2567\n",
      "\n",
      "Start of epoch 167\n",
      "Training loss at epoch 167: 0.2563\n",
      "\n",
      "Start of epoch 168\n",
      "Training loss at epoch 168: 0.2558\n",
      "\n",
      "Start of epoch 169\n",
      "Training loss at epoch 169: 0.2554\n",
      "\n",
      "Start of epoch 170\n",
      "Training loss at epoch 170: 0.2550\n",
      "\n",
      "Start of epoch 171\n",
      "Training loss at epoch 171: 0.2546\n",
      "\n",
      "Start of epoch 172\n",
      "Training loss at epoch 172: 0.2542\n",
      "\n",
      "Start of epoch 173\n",
      "Training loss at epoch 173: 0.2538\n",
      "\n",
      "Start of epoch 174\n",
      "Training loss at epoch 174: 0.2534\n",
      "\n",
      "Start of epoch 175\n",
      "Training loss at epoch 175: 0.2530\n",
      "\n",
      "Start of epoch 176\n",
      "Training loss at epoch 176: 0.2526\n",
      "\n",
      "Start of epoch 177\n",
      "Training loss at epoch 177: 0.2523\n",
      "\n",
      "Start of epoch 178\n",
      "Training loss at epoch 178: 0.2519\n",
      "\n",
      "Start of epoch 179\n",
      "Training loss at epoch 179: 0.2516\n",
      "\n",
      "Start of epoch 180\n",
      "Training loss at epoch 180: 0.2513\n",
      "\n",
      "Start of epoch 181\n",
      "Training loss at epoch 181: 0.2510\n",
      "\n",
      "Start of epoch 182\n",
      "Training loss at epoch 182: 0.2506\n",
      "\n",
      "Start of epoch 183\n",
      "Training loss at epoch 183: 0.2504\n",
      "\n",
      "Start of epoch 184\n",
      "Training loss at epoch 184: 0.2501\n",
      "\n",
      "Start of epoch 185\n",
      "Training loss at epoch 185: 0.2498\n",
      "\n",
      "Start of epoch 186\n",
      "Training loss at epoch 186: 0.2495\n",
      "\n",
      "Start of epoch 187\n",
      "Training loss at epoch 187: 0.2492\n",
      "\n",
      "Start of epoch 188\n",
      "Training loss at epoch 188: 0.2490\n",
      "\n",
      "Start of epoch 189\n",
      "Training loss at epoch 189: 0.2487\n",
      "\n",
      "Start of epoch 190\n",
      "Training loss at epoch 190: 0.2485\n",
      "\n",
      "Start of epoch 191\n",
      "Training loss at epoch 191: 0.2483\n",
      "\n",
      "Start of epoch 192\n",
      "Training loss at epoch 192: 0.2481\n",
      "\n",
      "Start of epoch 193\n",
      "Training loss at epoch 193: 0.2478\n",
      "\n",
      "Start of epoch 194\n",
      "Training loss at epoch 194: 0.2476\n",
      "\n",
      "Start of epoch 195\n",
      "Training loss at epoch 195: 0.2474\n",
      "\n",
      "Start of epoch 196\n",
      "Training loss at epoch 196: 0.2472\n",
      "\n",
      "Start of epoch 197\n",
      "Training loss at epoch 197: 0.2470\n",
      "\n",
      "Start of epoch 198\n",
      "Training loss at epoch 198: 0.2468\n",
      "\n",
      "Start of epoch 199\n",
      "Training loss at epoch 199: 0.2466\n",
      "\n",
      "Start of epoch 200\n",
      "Training loss at epoch 200: 0.2464\n",
      "\n",
      "Start of epoch 201\n",
      "Training loss at epoch 201: 0.2462\n",
      "\n",
      "Start of epoch 202\n",
      "Training loss at epoch 202: 0.2460\n",
      "\n",
      "Start of epoch 203\n",
      "Training loss at epoch 203: 0.2458\n",
      "\n",
      "Start of epoch 204\n",
      "Training loss at epoch 204: 0.2456\n",
      "\n",
      "Start of epoch 205\n",
      "Training loss at epoch 205: 0.2454\n",
      "\n",
      "Start of epoch 206\n",
      "Training loss at epoch 206: 0.2452\n",
      "\n",
      "Start of epoch 207\n",
      "Training loss at epoch 207: 0.2450\n",
      "\n",
      "Start of epoch 208\n",
      "Training loss at epoch 208: 0.2448\n",
      "\n",
      "Start of epoch 209\n",
      "Training loss at epoch 209: 0.2446\n",
      "\n",
      "Start of epoch 210\n",
      "Training loss at epoch 210: 0.2444\n",
      "\n",
      "Start of epoch 211\n",
      "Training loss at epoch 211: 0.2442\n",
      "\n",
      "Start of epoch 212\n",
      "Training loss at epoch 212: 0.2439\n",
      "\n",
      "Start of epoch 213\n",
      "Training loss at epoch 213: 0.2437\n",
      "\n",
      "Start of epoch 214\n",
      "Training loss at epoch 214: 0.2434\n",
      "\n",
      "Start of epoch 215\n",
      "Training loss at epoch 215: 0.2432\n",
      "\n",
      "Start of epoch 216\n",
      "Training loss at epoch 216: 0.2429\n",
      "\n",
      "Start of epoch 217\n",
      "Training loss at epoch 217: 0.2427\n",
      "\n",
      "Start of epoch 218\n",
      "Training loss at epoch 218: 0.2424\n",
      "\n",
      "Start of epoch 219\n",
      "Training loss at epoch 219: 0.2421\n",
      "\n",
      "Start of epoch 220\n",
      "Training loss at epoch 220: 0.2417\n",
      "\n",
      "Start of epoch 221\n",
      "Training loss at epoch 221: 0.2414\n",
      "\n",
      "Start of epoch 222\n",
      "Training loss at epoch 222: 0.2410\n",
      "\n",
      "Start of epoch 223\n",
      "Training loss at epoch 223: 0.2407\n",
      "\n",
      "Start of epoch 224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 224: 0.2403\n",
      "\n",
      "Start of epoch 225\n",
      "Training loss at epoch 225: 0.2398\n",
      "\n",
      "Start of epoch 226\n",
      "Training loss at epoch 226: 0.2394\n",
      "\n",
      "Start of epoch 227\n",
      "Training loss at epoch 227: 0.2389\n",
      "\n",
      "Start of epoch 228\n",
      "Training loss at epoch 228: 0.2384\n",
      "\n",
      "Start of epoch 229\n",
      "Training loss at epoch 229: 0.2378\n",
      "\n",
      "Start of epoch 230\n",
      "Training loss at epoch 230: 0.2372\n",
      "\n",
      "Start of epoch 231\n",
      "Training loss at epoch 231: 0.2366\n",
      "\n",
      "Start of epoch 232\n",
      "Training loss at epoch 232: 0.2360\n",
      "\n",
      "Start of epoch 233\n",
      "Training loss at epoch 233: 0.2353\n",
      "\n",
      "Start of epoch 234\n",
      "Training loss at epoch 234: 0.2346\n",
      "\n",
      "Start of epoch 235\n",
      "Training loss at epoch 235: 0.2338\n",
      "\n",
      "Start of epoch 236\n",
      "Training loss at epoch 236: 0.2330\n",
      "\n",
      "Start of epoch 237\n",
      "Training loss at epoch 237: 0.2322\n",
      "\n",
      "Start of epoch 238\n",
      "Training loss at epoch 238: 0.2313\n",
      "\n",
      "Start of epoch 239\n",
      "Training loss at epoch 239: 0.2305\n",
      "\n",
      "Start of epoch 240\n",
      "Training loss at epoch 240: 0.2296\n",
      "\n",
      "Start of epoch 241\n",
      "Training loss at epoch 241: 0.2287\n",
      "\n",
      "Start of epoch 242\n",
      "Training loss at epoch 242: 0.2277\n",
      "\n",
      "Start of epoch 243\n",
      "Training loss at epoch 243: 0.2268\n",
      "\n",
      "Start of epoch 244\n",
      "Training loss at epoch 244: 0.2258\n",
      "\n",
      "Start of epoch 245\n",
      "Training loss at epoch 245: 0.2249\n",
      "\n",
      "Start of epoch 246\n",
      "Training loss at epoch 246: 0.2239\n",
      "\n",
      "Start of epoch 247\n",
      "Training loss at epoch 247: 0.2229\n",
      "\n",
      "Start of epoch 248\n",
      "Training loss at epoch 248: 0.2220\n",
      "\n",
      "Start of epoch 249\n",
      "Training loss at epoch 249: 0.2210\n",
      "\n",
      "Start of epoch 250\n",
      "Training loss at epoch 250: 0.2200\n",
      "\n",
      "Start of epoch 251\n",
      "Training loss at epoch 251: 0.2191\n",
      "\n",
      "Start of epoch 252\n",
      "Training loss at epoch 252: 0.2182\n",
      "\n",
      "Start of epoch 253\n",
      "Training loss at epoch 253: 0.2173\n",
      "\n",
      "Start of epoch 254\n",
      "Training loss at epoch 254: 0.2164\n",
      "\n",
      "Start of epoch 255\n",
      "Training loss at epoch 255: 0.2156\n",
      "\n",
      "Start of epoch 256\n",
      "Training loss at epoch 256: 0.2148\n",
      "\n",
      "Start of epoch 257\n",
      "Training loss at epoch 257: 0.2140\n",
      "\n",
      "Start of epoch 258\n",
      "Training loss at epoch 258: 0.2132\n",
      "\n",
      "Start of epoch 259\n",
      "Training loss at epoch 259: 0.2125\n",
      "\n",
      "Start of epoch 260\n",
      "Training loss at epoch 260: 0.2118\n",
      "\n",
      "Start of epoch 261\n",
      "Training loss at epoch 261: 0.2112\n",
      "\n",
      "Start of epoch 262\n",
      "Training loss at epoch 262: 0.2106\n",
      "\n",
      "Start of epoch 263\n",
      "Training loss at epoch 263: 0.2100\n",
      "\n",
      "Start of epoch 264\n",
      "Training loss at epoch 264: 0.2094\n",
      "\n",
      "Start of epoch 265\n",
      "Training loss at epoch 265: 0.2089\n",
      "\n",
      "Start of epoch 266\n",
      "Training loss at epoch 266: 0.2084\n",
      "\n",
      "Start of epoch 267\n",
      "Training loss at epoch 267: 0.2079\n",
      "\n",
      "Start of epoch 268\n",
      "Training loss at epoch 268: 0.2075\n",
      "\n",
      "Start of epoch 269\n",
      "Training loss at epoch 269: 0.2071\n",
      "\n",
      "Start of epoch 270\n",
      "Training loss at epoch 270: 0.2067\n",
      "\n",
      "Start of epoch 271\n",
      "Training loss at epoch 271: 0.2063\n",
      "\n",
      "Start of epoch 272\n",
      "Training loss at epoch 272: 0.2060\n",
      "\n",
      "Start of epoch 273\n",
      "Training loss at epoch 273: 0.2056\n",
      "\n",
      "Start of epoch 274\n",
      "Training loss at epoch 274: 0.2053\n",
      "\n",
      "Start of epoch 275\n",
      "Training loss at epoch 275: 0.2051\n",
      "\n",
      "Start of epoch 276\n",
      "Training loss at epoch 276: 0.2048\n",
      "\n",
      "Start of epoch 277\n",
      "Training loss at epoch 277: 0.2046\n",
      "\n",
      "Start of epoch 278\n",
      "Training loss at epoch 278: 0.2043\n",
      "\n",
      "Start of epoch 279\n",
      "Training loss at epoch 279: 0.2041\n",
      "\n",
      "Start of epoch 280\n",
      "Training loss at epoch 280: 0.2039\n",
      "\n",
      "Start of epoch 281\n",
      "Training loss at epoch 281: 0.2038\n",
      "\n",
      "Start of epoch 282\n",
      "Training loss at epoch 282: 0.2036\n",
      "\n",
      "Start of epoch 283\n",
      "Training loss at epoch 283: 0.2034\n",
      "\n",
      "Start of epoch 284\n",
      "Training loss at epoch 284: 0.2033\n",
      "\n",
      "Start of epoch 285\n",
      "Training loss at epoch 285: 0.2031\n",
      "\n",
      "Start of epoch 286\n",
      "Training loss at epoch 286: 0.2030\n",
      "\n",
      "Start of epoch 287\n",
      "Training loss at epoch 287: 0.2029\n",
      "\n",
      "Start of epoch 288\n",
      "Training loss at epoch 288: 0.2028\n",
      "\n",
      "Start of epoch 289\n",
      "Training loss at epoch 289: 0.2027\n",
      "\n",
      "Start of epoch 290\n",
      "Training loss at epoch 290: 0.2026\n",
      "\n",
      "Start of epoch 291\n",
      "Training loss at epoch 291: 0.2025\n",
      "\n",
      "Start of epoch 292\n",
      "Training loss at epoch 292: 0.2024\n",
      "\n",
      "Start of epoch 293\n",
      "Training loss at epoch 293: 0.2023\n",
      "\n",
      "Start of epoch 294\n",
      "Training loss at epoch 294: 0.2022\n",
      "\n",
      "Start of epoch 295\n",
      "Training loss at epoch 295: 0.2022\n",
      "\n",
      "Start of epoch 296\n",
      "Training loss at epoch 296: 0.2021\n",
      "\n",
      "Start of epoch 297\n",
      "Training loss at epoch 297: 0.2020\n",
      "\n",
      "Start of epoch 298\n",
      "Training loss at epoch 298: 0.2020\n",
      "\n",
      "Start of epoch 299\n",
      "Training loss at epoch 299: 0.2019\n",
      "\n",
      "Start of epoch 300\n",
      "Training loss at epoch 300: 0.2018\n",
      "\n",
      "Start of epoch 301\n",
      "Training loss at epoch 301: 0.2018\n",
      "\n",
      "Start of epoch 302\n",
      "Training loss at epoch 302: 0.2017\n",
      "\n",
      "Start of epoch 303\n",
      "Training loss at epoch 303: 0.2016\n",
      "\n",
      "Start of epoch 304\n",
      "Training loss at epoch 304: 0.2016\n",
      "\n",
      "Start of epoch 305\n",
      "Training loss at epoch 305: 0.2015\n",
      "\n",
      "Start of epoch 306\n",
      "Training loss at epoch 306: 0.2014\n",
      "\n",
      "Start of epoch 307\n",
      "Training loss at epoch 307: 0.2014\n",
      "\n",
      "Start of epoch 308\n",
      "Training loss at epoch 308: 0.2013\n",
      "\n",
      "Start of epoch 309\n",
      "Training loss at epoch 309: 0.2012\n",
      "\n",
      "Start of epoch 310\n",
      "Training loss at epoch 310: 0.2012\n",
      "\n",
      "Start of epoch 311\n",
      "Training loss at epoch 311: 0.2011\n",
      "\n",
      "Start of epoch 312\n",
      "Training loss at epoch 312: 0.2011\n",
      "\n",
      "Start of epoch 313\n",
      "Training loss at epoch 313: 0.2010\n",
      "\n",
      "Start of epoch 314\n",
      "Training loss at epoch 314: 0.2009\n",
      "\n",
      "Start of epoch 315\n",
      "Training loss at epoch 315: 0.2009\n",
      "\n",
      "Start of epoch 316\n",
      "Training loss at epoch 316: 0.2008\n",
      "\n",
      "Start of epoch 317\n",
      "Training loss at epoch 317: 0.2007\n",
      "\n",
      "Start of epoch 318\n",
      "Training loss at epoch 318: 0.2007\n",
      "\n",
      "Start of epoch 319\n",
      "Training loss at epoch 319: 0.2006\n",
      "\n",
      "Start of epoch 320\n",
      "Training loss at epoch 320: 0.2006\n",
      "\n",
      "Start of epoch 321\n",
      "Training loss at epoch 321: 0.2005\n",
      "\n",
      "Start of epoch 322\n",
      "Training loss at epoch 322: 0.2005\n",
      "\n",
      "Start of epoch 323\n",
      "Training loss at epoch 323: 0.2004\n",
      "\n",
      "Start of epoch 324\n",
      "Training loss at epoch 324: 0.2003\n",
      "\n",
      "Start of epoch 325\n",
      "Training loss at epoch 325: 0.2003\n",
      "\n",
      "Start of epoch 326\n",
      "Training loss at epoch 326: 0.2002\n",
      "\n",
      "Start of epoch 327\n",
      "Training loss at epoch 327: 0.2002\n",
      "\n",
      "Start of epoch 328\n",
      "Training loss at epoch 328: 0.2001\n",
      "\n",
      "Start of epoch 329\n",
      "Training loss at epoch 329: 0.2000\n",
      "\n",
      "Start of epoch 330\n",
      "Training loss at epoch 330: 0.2000\n",
      "\n",
      "Start of epoch 331\n",
      "Training loss at epoch 331: 0.1999\n",
      "\n",
      "Start of epoch 332\n",
      "Training loss at epoch 332: 0.1999\n",
      "\n",
      "Start of epoch 333\n",
      "Training loss at epoch 333: 0.1998\n",
      "\n",
      "Start of epoch 334\n",
      "Training loss at epoch 334: 0.1997\n",
      "\n",
      "Start of epoch 335\n",
      "Training loss at epoch 335: 0.1997\n",
      "\n",
      "Start of epoch 336\n",
      "Training loss at epoch 336: 0.1996\n",
      "\n",
      "Start of epoch 337\n",
      "Training loss at epoch 337: 0.1996\n",
      "\n",
      "Start of epoch 338\n",
      "Training loss at epoch 338: 0.1995\n",
      "\n",
      "Start of epoch 339\n",
      "Training loss at epoch 339: 0.1994\n",
      "\n",
      "Start of epoch 340\n",
      "Training loss at epoch 340: 0.1994\n",
      "\n",
      "Start of epoch 341\n",
      "Training loss at epoch 341: 0.1993\n",
      "\n",
      "Start of epoch 342\n",
      "Training loss at epoch 342: 0.1993\n",
      "\n",
      "Start of epoch 343\n",
      "Training loss at epoch 343: 0.1992\n",
      "\n",
      "Start of epoch 344\n",
      "Training loss at epoch 344: 0.1992\n",
      "\n",
      "Start of epoch 345\n",
      "Training loss at epoch 345: 0.1991\n",
      "\n",
      "Start of epoch 346\n",
      "Training loss at epoch 346: 0.1990\n",
      "\n",
      "Start of epoch 347\n",
      "Training loss at epoch 347: 0.1990\n",
      "\n",
      "Start of epoch 348\n",
      "Training loss at epoch 348: 0.1989\n",
      "\n",
      "Start of epoch 349\n",
      "Training loss at epoch 349: 0.1989\n",
      "\n",
      "Start of epoch 350\n",
      "Training loss at epoch 350: 0.1988\n",
      "\n",
      "Start of epoch 351\n",
      "Training loss at epoch 351: 0.1988\n",
      "\n",
      "Start of epoch 352\n",
      "Training loss at epoch 352: 0.1987\n",
      "\n",
      "Start of epoch 353\n",
      "Training loss at epoch 353: 0.1986\n",
      "\n",
      "Start of epoch 354\n",
      "Training loss at epoch 354: 0.1986\n",
      "\n",
      "Start of epoch 355\n",
      "Training loss at epoch 355: 0.1985\n",
      "\n",
      "Start of epoch 356\n",
      "Training loss at epoch 356: 0.1985\n",
      "\n",
      "Start of epoch 357\n",
      "Training loss at epoch 357: 0.1984\n",
      "\n",
      "Start of epoch 358\n",
      "Training loss at epoch 358: 0.1984\n",
      "\n",
      "Start of epoch 359\n",
      "Training loss at epoch 359: 0.1983\n",
      "\n",
      "Start of epoch 360\n",
      "Training loss at epoch 360: 0.1983\n",
      "\n",
      "Start of epoch 361\n",
      "Training loss at epoch 361: 0.1982\n",
      "\n",
      "Start of epoch 362\n",
      "Training loss at epoch 362: 0.1981\n",
      "\n",
      "Start of epoch 363\n",
      "Training loss at epoch 363: 0.1981\n",
      "\n",
      "Start of epoch 364\n",
      "Training loss at epoch 364: 0.1980\n",
      "\n",
      "Start of epoch 365\n",
      "Training loss at epoch 365: 0.1980\n",
      "\n",
      "Start of epoch 366\n",
      "Training loss at epoch 366: 0.1979\n",
      "\n",
      "Start of epoch 367\n",
      "Training loss at epoch 367: 0.1979\n",
      "\n",
      "Start of epoch 368\n",
      "Training loss at epoch 368: 0.1978\n",
      "\n",
      "Start of epoch 369\n",
      "Training loss at epoch 369: 0.1978\n",
      "\n",
      "Start of epoch 370\n",
      "Training loss at epoch 370: 0.1977\n",
      "\n",
      "Start of epoch 371\n",
      "Training loss at epoch 371: 0.1977\n",
      "\n",
      "Start of epoch 372\n",
      "Training loss at epoch 372: 0.1976\n",
      "\n",
      "Start of epoch 373\n",
      "Training loss at epoch 373: 0.1976\n",
      "\n",
      "Start of epoch 374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 374: 0.1975\n",
      "\n",
      "Start of epoch 375\n",
      "Training loss at epoch 375: 0.1975\n",
      "\n",
      "Start of epoch 376\n",
      "Training loss at epoch 376: 0.1975\n",
      "\n",
      "Start of epoch 377\n",
      "Training loss at epoch 377: 0.1974\n",
      "\n",
      "Start of epoch 378\n",
      "Training loss at epoch 378: 0.1974\n",
      "\n",
      "Start of epoch 379\n",
      "Training loss at epoch 379: 0.1973\n",
      "\n",
      "Start of epoch 380\n",
      "Training loss at epoch 380: 0.1973\n",
      "\n",
      "Start of epoch 381\n",
      "Training loss at epoch 381: 0.1972\n",
      "\n",
      "Start of epoch 382\n",
      "Training loss at epoch 382: 0.1972\n",
      "\n",
      "Start of epoch 383\n",
      "Training loss at epoch 383: 0.1971\n",
      "\n",
      "Start of epoch 384\n",
      "Training loss at epoch 384: 0.1971\n",
      "\n",
      "Start of epoch 385\n",
      "Training loss at epoch 385: 0.1970\n",
      "\n",
      "Start of epoch 386\n",
      "Training loss at epoch 386: 0.1970\n",
      "\n",
      "Start of epoch 387\n",
      "Training loss at epoch 387: 0.1970\n",
      "\n",
      "Start of epoch 388\n",
      "Training loss at epoch 388: 0.1969\n",
      "\n",
      "Start of epoch 389\n",
      "Training loss at epoch 389: 0.1969\n",
      "\n",
      "Start of epoch 390\n",
      "Training loss at epoch 390: 0.1968\n",
      "\n",
      "Start of epoch 391\n",
      "Training loss at epoch 391: 0.1968\n",
      "\n",
      "Start of epoch 392\n",
      "Training loss at epoch 392: 0.1968\n",
      "\n",
      "Start of epoch 393\n",
      "Training loss at epoch 393: 0.1967\n",
      "\n",
      "Start of epoch 394\n",
      "Training loss at epoch 394: 0.1967\n",
      "\n",
      "Start of epoch 395\n",
      "Training loss at epoch 395: 0.1967\n",
      "\n",
      "Start of epoch 396\n",
      "Training loss at epoch 396: 0.1966\n",
      "\n",
      "Start of epoch 397\n",
      "Training loss at epoch 397: 0.1966\n",
      "\n",
      "Start of epoch 398\n",
      "Training loss at epoch 398: 0.1965\n",
      "\n",
      "Start of epoch 399\n",
      "Training loss at epoch 399: 0.1965\n",
      "\n",
      "Start of epoch 400\n",
      "Training loss at epoch 400: 0.1965\n",
      "\n",
      "Start of epoch 401\n",
      "Training loss at epoch 401: 0.1964\n",
      "\n",
      "Start of epoch 402\n",
      "Training loss at epoch 402: 0.1964\n",
      "\n",
      "Start of epoch 403\n",
      "Training loss at epoch 403: 0.1964\n",
      "\n",
      "Start of epoch 404\n",
      "Training loss at epoch 404: 0.1963\n",
      "\n",
      "Start of epoch 405\n",
      "Training loss at epoch 405: 0.1963\n",
      "\n",
      "Start of epoch 406\n",
      "Training loss at epoch 406: 0.1963\n",
      "\n",
      "Start of epoch 407\n",
      "Training loss at epoch 407: 0.1962\n",
      "\n",
      "Start of epoch 408\n",
      "Training loss at epoch 408: 0.1962\n",
      "\n",
      "Start of epoch 409\n",
      "Training loss at epoch 409: 0.1962\n",
      "\n",
      "Start of epoch 410\n",
      "Training loss at epoch 410: 0.1961\n",
      "\n",
      "Start of epoch 411\n",
      "Training loss at epoch 411: 0.1961\n",
      "\n",
      "Start of epoch 412\n",
      "Training loss at epoch 412: 0.1961\n",
      "\n",
      "Start of epoch 413\n",
      "Training loss at epoch 413: 0.1961\n",
      "\n",
      "Start of epoch 414\n",
      "Training loss at epoch 414: 0.1960\n",
      "\n",
      "Start of epoch 415\n",
      "Training loss at epoch 415: 0.1960\n",
      "\n",
      "Start of epoch 416\n",
      "Training loss at epoch 416: 0.1960\n",
      "\n",
      "Start of epoch 417\n",
      "Training loss at epoch 417: 0.1959\n",
      "\n",
      "Start of epoch 418\n",
      "Training loss at epoch 418: 0.1959\n",
      "\n",
      "Start of epoch 419\n",
      "Training loss at epoch 419: 0.1959\n",
      "\n",
      "Start of epoch 420\n",
      "Training loss at epoch 420: 0.1959\n",
      "\n",
      "Start of epoch 421\n",
      "Training loss at epoch 421: 0.1958\n",
      "\n",
      "Start of epoch 422\n",
      "Training loss at epoch 422: 0.1958\n",
      "\n",
      "Start of epoch 423\n",
      "Training loss at epoch 423: 0.1958\n",
      "\n",
      "Start of epoch 424\n",
      "Training loss at epoch 424: 0.1957\n",
      "\n",
      "Start of epoch 425\n",
      "Training loss at epoch 425: 0.1957\n",
      "\n",
      "Start of epoch 426\n",
      "Training loss at epoch 426: 0.1957\n",
      "\n",
      "Start of epoch 427\n",
      "Training loss at epoch 427: 0.1957\n",
      "\n",
      "Start of epoch 428\n",
      "Training loss at epoch 428: 0.1956\n",
      "\n",
      "Start of epoch 429\n",
      "Training loss at epoch 429: 0.1956\n",
      "\n",
      "Start of epoch 430\n",
      "Training loss at epoch 430: 0.1956\n",
      "\n",
      "Start of epoch 431\n",
      "Training loss at epoch 431: 0.1956\n",
      "\n",
      "Start of epoch 432\n",
      "Training loss at epoch 432: 0.1955\n",
      "\n",
      "Start of epoch 433\n",
      "Training loss at epoch 433: 0.1955\n",
      "\n",
      "Start of epoch 434\n",
      "Training loss at epoch 434: 0.1955\n",
      "\n",
      "Start of epoch 435\n",
      "Training loss at epoch 435: 0.1954\n",
      "\n",
      "Start of epoch 436\n",
      "Training loss at epoch 436: 0.1954\n",
      "\n",
      "Start of epoch 437\n",
      "Training loss at epoch 437: 0.1954\n",
      "\n",
      "Start of epoch 438\n",
      "Training loss at epoch 438: 0.1954\n",
      "\n",
      "Start of epoch 439\n",
      "Training loss at epoch 439: 0.1953\n",
      "\n",
      "Start of epoch 440\n",
      "Training loss at epoch 440: 0.1953\n",
      "\n",
      "Start of epoch 441\n",
      "Training loss at epoch 441: 0.1953\n",
      "\n",
      "Start of epoch 442\n",
      "Training loss at epoch 442: 0.1952\n",
      "\n",
      "Start of epoch 443\n",
      "Training loss at epoch 443: 0.1952\n",
      "\n",
      "Start of epoch 444\n",
      "Training loss at epoch 444: 0.1952\n",
      "\n",
      "Start of epoch 445\n",
      "Training loss at epoch 445: 0.1951\n",
      "\n",
      "Start of epoch 446\n",
      "Training loss at epoch 446: 0.1951\n",
      "\n",
      "Start of epoch 447\n",
      "Training loss at epoch 447: 0.1951\n",
      "\n",
      "Start of epoch 448\n",
      "Training loss at epoch 448: 0.1951\n",
      "\n",
      "Start of epoch 449\n",
      "Training loss at epoch 449: 0.1950\n",
      "\n",
      "Start of epoch 450\n",
      "Training loss at epoch 450: 0.1950\n",
      "\n",
      "Start of epoch 451\n",
      "Training loss at epoch 451: 0.1950\n",
      "\n",
      "Start of epoch 452\n",
      "Training loss at epoch 452: 0.1949\n",
      "\n",
      "Start of epoch 453\n",
      "Training loss at epoch 453: 0.1949\n",
      "\n",
      "Start of epoch 454\n",
      "Training loss at epoch 454: 0.1948\n",
      "\n",
      "Start of epoch 455\n",
      "Training loss at epoch 455: 0.1948\n",
      "\n",
      "Start of epoch 456\n",
      "Training loss at epoch 456: 0.1948\n",
      "\n",
      "Start of epoch 457\n",
      "Training loss at epoch 457: 0.1947\n",
      "\n",
      "Start of epoch 458\n",
      "Training loss at epoch 458: 0.1947\n",
      "\n",
      "Start of epoch 459\n",
      "Training loss at epoch 459: 0.1947\n",
      "\n",
      "Start of epoch 460\n",
      "Training loss at epoch 460: 0.1946\n",
      "\n",
      "Start of epoch 461\n",
      "Training loss at epoch 461: 0.1946\n",
      "\n",
      "Start of epoch 462\n",
      "Training loss at epoch 462: 0.1945\n",
      "\n",
      "Start of epoch 463\n",
      "Training loss at epoch 463: 0.1945\n",
      "\n",
      "Start of epoch 464\n",
      "Training loss at epoch 464: 0.1944\n",
      "\n",
      "Start of epoch 465\n",
      "Training loss at epoch 465: 0.1944\n",
      "\n",
      "Start of epoch 466\n",
      "Training loss at epoch 466: 0.1943\n",
      "\n",
      "Start of epoch 467\n",
      "Training loss at epoch 467: 0.1943\n",
      "\n",
      "Start of epoch 468\n",
      "Training loss at epoch 468: 0.1942\n",
      "\n",
      "Start of epoch 469\n",
      "Training loss at epoch 469: 0.1942\n",
      "\n",
      "Start of epoch 470\n",
      "Training loss at epoch 470: 0.1941\n",
      "\n",
      "Start of epoch 471\n",
      "Training loss at epoch 471: 0.1941\n",
      "\n",
      "Start of epoch 472\n",
      "Training loss at epoch 472: 0.1940\n",
      "\n",
      "Start of epoch 473\n",
      "Training loss at epoch 473: 0.1940\n",
      "\n",
      "Start of epoch 474\n",
      "Training loss at epoch 474: 0.1939\n",
      "\n",
      "Start of epoch 475\n",
      "Training loss at epoch 475: 0.1939\n",
      "\n",
      "Start of epoch 476\n",
      "Training loss at epoch 476: 0.1938\n",
      "\n",
      "Start of epoch 477\n",
      "Training loss at epoch 477: 0.1937\n",
      "\n",
      "Start of epoch 478\n",
      "Training loss at epoch 478: 0.1937\n",
      "\n",
      "Start of epoch 479\n",
      "Training loss at epoch 479: 0.1936\n",
      "\n",
      "Start of epoch 480\n",
      "Training loss at epoch 480: 0.1935\n",
      "\n",
      "Start of epoch 481\n",
      "Training loss at epoch 481: 0.1935\n",
      "\n",
      "Start of epoch 482\n",
      "Training loss at epoch 482: 0.1934\n",
      "\n",
      "Start of epoch 483\n",
      "Training loss at epoch 483: 0.1933\n",
      "\n",
      "Start of epoch 484\n",
      "Training loss at epoch 484: 0.1933\n",
      "\n",
      "Start of epoch 485\n",
      "Training loss at epoch 485: 0.1932\n",
      "\n",
      "Start of epoch 486\n",
      "Training loss at epoch 486: 0.1931\n",
      "\n",
      "Start of epoch 487\n",
      "Training loss at epoch 487: 0.1930\n",
      "\n",
      "Start of epoch 488\n",
      "Training loss at epoch 488: 0.1930\n",
      "\n",
      "Start of epoch 489\n",
      "Training loss at epoch 489: 0.1929\n",
      "\n",
      "Start of epoch 490\n",
      "Training loss at epoch 490: 0.1928\n",
      "\n",
      "Start of epoch 491\n",
      "Training loss at epoch 491: 0.1927\n",
      "\n",
      "Start of epoch 492\n",
      "Training loss at epoch 492: 0.1927\n",
      "\n",
      "Start of epoch 493\n",
      "Training loss at epoch 493: 0.1926\n",
      "\n",
      "Start of epoch 494\n",
      "Training loss at epoch 494: 0.1925\n",
      "\n",
      "Start of epoch 495\n",
      "Training loss at epoch 495: 0.1924\n",
      "\n",
      "Start of epoch 496\n",
      "Training loss at epoch 496: 0.1923\n",
      "\n",
      "Start of epoch 497\n",
      "Training loss at epoch 497: 0.1923\n",
      "\n",
      "Start of epoch 498\n",
      "Training loss at epoch 498: 0.1922\n",
      "\n",
      "Start of epoch 499\n",
      "Training loss at epoch 499: 0.1921\n",
      "[<tf.Variable 'parameters:0' shape=(60,) dtype=float32, numpy=\n",
      "array([4.1280875 , 2.2728233 , 2.046398  , 5.163893  , 1.9884601 ,\n",
      "       4.6965346 , 1.2012006 , 4.3973117 , 5.3162894 , 1.2133347 ,\n",
      "       3.6608677 , 0.05699698, 3.8499227 , 6.1796207 , 2.1525886 ,\n",
      "       1.035133  , 1.4300821 , 3.7518206 , 4.7248573 , 4.1230426 ,\n",
      "       5.9430456 , 5.5986114 , 0.9860276 , 4.203304  , 3.7999454 ,\n",
      "       4.692082  , 4.076708  , 0.10694573, 5.8856153 , 5.9473596 ,\n",
      "       0.8960905 , 0.24508265, 2.3952804 , 2.8147993 , 0.68617254,\n",
      "       2.2621453 , 2.5121806 , 5.0004425 , 3.8012831 , 0.89188176,\n",
      "       0.7333792 , 0.30420458, 3.7376409 , 2.531878  , 5.29776   ,\n",
      "       3.548744  , 0.34236234, 3.2472413 , 5.458235  , 1.0757452 ,\n",
      "       2.426653  , 5.895566  , 0.14106332, 0.5752653 , 5.9255013 ,\n",
      "       4.6934595 , 2.9609253 , 4.1465945 , 0.27921373, 3.8215995 ],\n",
      "      dtype=float32)>]\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.0143\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 0.9265\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.8631\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.8132\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.7672\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.7254\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.6912\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.6655\n",
      "\n",
      "Start of epoch 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 8: 0.6450\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.6264\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.6081\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.5900\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.5720\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.5541\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.5356\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.5167\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.4980\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.4808\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.4659\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.4531\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.4418\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.4314\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.4219\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.4144\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.4094\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.4065\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.4046\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.4027\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.4008\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.3988\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.3964\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.3930\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.3885\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.3836\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.3789\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.3745\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.3703\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.3658\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.3615\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.3575\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.3539\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.3503\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.3463\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.3419\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.3375\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.3333\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.3295\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.3260\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.3227\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.3195\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.3162\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.3126\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.3087\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.3047\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.3005\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.2960\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.2910\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.2854\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.2792\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.2723\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.2645\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.2558\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.2457\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.2342\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.2213\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.2071\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.1918\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.1759\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.1596\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.1435\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.1283\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.1146\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.1027\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.0929\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.0848\n",
      "\n",
      "Start of epoch 75\n",
      "Training loss at epoch 75: 0.0782\n",
      "\n",
      "Start of epoch 76\n",
      "Training loss at epoch 76: 0.0736\n",
      "\n",
      "Start of epoch 77\n",
      "Training loss at epoch 77: 0.0714\n",
      "\n",
      "Start of epoch 78\n",
      "Training loss at epoch 78: 0.0713\n",
      "\n",
      "Start of epoch 79\n",
      "Training loss at epoch 79: 0.0713\n",
      "\n",
      "Start of epoch 80\n",
      "Training loss at epoch 80: 0.0700\n",
      "\n",
      "Start of epoch 81\n",
      "Training loss at epoch 81: 0.0679\n",
      "\n",
      "Start of epoch 82\n",
      "Training loss at epoch 82: 0.0658\n",
      "\n",
      "Start of epoch 83\n",
      "Training loss at epoch 83: 0.0638\n",
      "\n",
      "Start of epoch 84\n",
      "Training loss at epoch 84: 0.0616\n",
      "\n",
      "Start of epoch 85\n",
      "Training loss at epoch 85: 0.0589\n",
      "\n",
      "Start of epoch 86\n",
      "Training loss at epoch 86: 0.0561\n",
      "\n",
      "Start of epoch 87\n",
      "Training loss at epoch 87: 0.0532\n",
      "\n",
      "Start of epoch 88\n",
      "Training loss at epoch 88: 0.0508\n",
      "\n",
      "Start of epoch 89\n",
      "Training loss at epoch 89: 0.0489\n",
      "\n",
      "Start of epoch 90\n",
      "Training loss at epoch 90: 0.0474\n",
      "\n",
      "Start of epoch 91\n",
      "Training loss at epoch 91: 0.0461\n",
      "\n",
      "Start of epoch 92\n",
      "Training loss at epoch 92: 0.0448\n",
      "\n",
      "Start of epoch 93\n",
      "Training loss at epoch 93: 0.0435\n",
      "\n",
      "Start of epoch 94\n",
      "Training loss at epoch 94: 0.0423\n",
      "\n",
      "Start of epoch 95\n",
      "Training loss at epoch 95: 0.0413\n",
      "\n",
      "Start of epoch 96\n",
      "Training loss at epoch 96: 0.0404\n",
      "\n",
      "Start of epoch 97\n",
      "Training loss at epoch 97: 0.0393\n",
      "\n",
      "Start of epoch 98\n",
      "Training loss at epoch 98: 0.0382\n",
      "\n",
      "Start of epoch 99\n",
      "Training loss at epoch 99: 0.0371\n",
      "\n",
      "Start of epoch 100\n",
      "Training loss at epoch 100: 0.0361\n",
      "\n",
      "Start of epoch 101\n",
      "Training loss at epoch 101: 0.0352\n",
      "\n",
      "Start of epoch 102\n",
      "Training loss at epoch 102: 0.0343\n",
      "\n",
      "Start of epoch 103\n",
      "Training loss at epoch 103: 0.0333\n",
      "\n",
      "Start of epoch 104\n",
      "Training loss at epoch 104: 0.0322\n",
      "\n",
      "Start of epoch 105\n",
      "Training loss at epoch 105: 0.0311\n",
      "\n",
      "Start of epoch 106\n",
      "Training loss at epoch 106: 0.0299\n",
      "\n",
      "Start of epoch 107\n",
      "Training loss at epoch 107: 0.0288\n",
      "\n",
      "Start of epoch 108\n",
      "Training loss at epoch 108: 0.0276\n",
      "\n",
      "Start of epoch 109\n",
      "Training loss at epoch 109: 0.0265\n",
      "\n",
      "Start of epoch 110\n",
      "Training loss at epoch 110: 0.0255\n",
      "\n",
      "Start of epoch 111\n",
      "Training loss at epoch 111: 0.0246\n",
      "\n",
      "Start of epoch 112\n",
      "Training loss at epoch 112: 0.0236\n",
      "\n",
      "Start of epoch 113\n",
      "Training loss at epoch 113: 0.0226\n",
      "\n",
      "Start of epoch 114\n",
      "Training loss at epoch 114: 0.0216\n",
      "\n",
      "Start of epoch 115\n",
      "Training loss at epoch 115: 0.0207\n",
      "\n",
      "Start of epoch 116\n",
      "Training loss at epoch 116: 0.0198\n",
      "\n",
      "Start of epoch 117\n",
      "Training loss at epoch 117: 0.0189\n",
      "\n",
      "Start of epoch 118\n",
      "Training loss at epoch 118: 0.0181\n",
      "\n",
      "Start of epoch 119\n",
      "Training loss at epoch 119: 0.0174\n",
      "\n",
      "Start of epoch 120\n",
      "Training loss at epoch 120: 0.0166\n",
      "\n",
      "Start of epoch 121\n",
      "Training loss at epoch 121: 0.0160\n",
      "\n",
      "Start of epoch 122\n",
      "Training loss at epoch 122: 0.0153\n",
      "\n",
      "Start of epoch 123\n",
      "Training loss at epoch 123: 0.0148\n",
      "\n",
      "Start of epoch 124\n",
      "Training loss at epoch 124: 0.0142\n",
      "\n",
      "Start of epoch 125\n",
      "Training loss at epoch 125: 0.0137\n",
      "\n",
      "Start of epoch 126\n",
      "Training loss at epoch 126: 0.0133\n",
      "\n",
      "Start of epoch 127\n",
      "Training loss at epoch 127: 0.0129\n",
      "\n",
      "Start of epoch 128\n",
      "Training loss at epoch 128: 0.0125\n",
      "\n",
      "Start of epoch 129\n",
      "Training loss at epoch 129: 0.0122\n",
      "\n",
      "Start of epoch 130\n",
      "Training loss at epoch 130: 0.0119\n",
      "\n",
      "Start of epoch 131\n",
      "Training loss at epoch 131: 0.0116\n",
      "\n",
      "Start of epoch 132\n",
      "Training loss at epoch 132: 0.0113\n",
      "\n",
      "Start of epoch 133\n",
      "Training loss at epoch 133: 0.0111\n",
      "\n",
      "Start of epoch 134\n",
      "Training loss at epoch 134: 0.0109\n",
      "\n",
      "Start of epoch 135\n",
      "Training loss at epoch 135: 0.0106\n",
      "\n",
      "Start of epoch 136\n",
      "Training loss at epoch 136: 0.0104\n",
      "\n",
      "Start of epoch 137\n",
      "Training loss at epoch 137: 0.0103\n",
      "\n",
      "Start of epoch 138\n",
      "Training loss at epoch 138: 0.0101\n",
      "\n",
      "Start of epoch 139\n",
      "Training loss at epoch 139: 0.0099\n",
      "\n",
      "Start of epoch 140\n",
      "Training loss at epoch 140: 0.0097\n",
      "\n",
      "Start of epoch 141\n",
      "Training loss at epoch 141: 0.0096\n",
      "\n",
      "Start of epoch 142\n",
      "Training loss at epoch 142: 0.0094\n",
      "\n",
      "Start of epoch 143\n",
      "Training loss at epoch 143: 0.0092\n",
      "\n",
      "Start of epoch 144\n",
      "Training loss at epoch 144: 0.0091\n",
      "\n",
      "Start of epoch 145\n",
      "Training loss at epoch 145: 0.0090\n",
      "\n",
      "Start of epoch 146\n",
      "Training loss at epoch 146: 0.0088\n",
      "\n",
      "Start of epoch 147\n",
      "Training loss at epoch 147: 0.0087\n",
      "\n",
      "Start of epoch 148\n",
      "Training loss at epoch 148: 0.0085\n",
      "\n",
      "Start of epoch 149\n",
      "Training loss at epoch 149: 0.0084\n",
      "\n",
      "Start of epoch 150\n",
      "Training loss at epoch 150: 0.0083\n",
      "\n",
      "Start of epoch 151\n",
      "Training loss at epoch 151: 0.0081\n",
      "\n",
      "Start of epoch 152\n",
      "Training loss at epoch 152: 0.0080\n",
      "\n",
      "Start of epoch 153\n",
      "Training loss at epoch 153: 0.0079\n",
      "\n",
      "Start of epoch 154\n",
      "Training loss at epoch 154: 0.0078\n",
      "\n",
      "Start of epoch 155\n",
      "Training loss at epoch 155: 0.0077\n",
      "\n",
      "Start of epoch 156\n",
      "Training loss at epoch 156: 0.0075\n",
      "\n",
      "Start of epoch 157\n",
      "Training loss at epoch 157: 0.0074\n",
      "\n",
      "Start of epoch 158\n",
      "Training loss at epoch 158: 0.0073\n",
      "\n",
      "Start of epoch 159\n",
      "Training loss at epoch 159: 0.0072\n",
      "\n",
      "Start of epoch 160\n",
      "Training loss at epoch 160: 0.0071\n",
      "\n",
      "Start of epoch 161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 161: 0.0070\n",
      "\n",
      "Start of epoch 162\n",
      "Training loss at epoch 162: 0.0069\n",
      "\n",
      "Start of epoch 163\n",
      "Training loss at epoch 163: 0.0068\n",
      "\n",
      "Start of epoch 164\n",
      "Training loss at epoch 164: 0.0066\n",
      "\n",
      "Start of epoch 165\n",
      "Training loss at epoch 165: 0.0065\n",
      "\n",
      "Start of epoch 166\n",
      "Training loss at epoch 166: 0.0064\n",
      "\n",
      "Start of epoch 167\n",
      "Training loss at epoch 167: 0.0063\n",
      "\n",
      "Start of epoch 168\n",
      "Training loss at epoch 168: 0.0062\n",
      "\n",
      "Start of epoch 169\n",
      "Training loss at epoch 169: 0.0061\n",
      "\n",
      "Start of epoch 170\n",
      "Training loss at epoch 170: 0.0060\n",
      "\n",
      "Start of epoch 171\n",
      "Training loss at epoch 171: 0.0059\n",
      "\n",
      "Start of epoch 172\n",
      "Training loss at epoch 172: 0.0058\n",
      "\n",
      "Start of epoch 173\n",
      "Training loss at epoch 173: 0.0057\n",
      "\n",
      "Start of epoch 174\n",
      "Training loss at epoch 174: 0.0056\n",
      "\n",
      "Start of epoch 175\n",
      "Training loss at epoch 175: 0.0055\n",
      "\n",
      "Start of epoch 176\n",
      "Training loss at epoch 176: 0.0054\n",
      "\n",
      "Start of epoch 177\n",
      "Training loss at epoch 177: 0.0053\n",
      "\n",
      "Start of epoch 178\n",
      "Training loss at epoch 178: 0.0053\n",
      "\n",
      "Start of epoch 179\n",
      "Training loss at epoch 179: 0.0052\n",
      "\n",
      "Start of epoch 180\n",
      "Training loss at epoch 180: 0.0051\n",
      "\n",
      "Start of epoch 181\n",
      "Training loss at epoch 181: 0.0050\n",
      "\n",
      "Start of epoch 182\n",
      "Training loss at epoch 182: 0.0049\n",
      "\n",
      "Start of epoch 183\n",
      "Training loss at epoch 183: 0.0048\n",
      "\n",
      "Start of epoch 184\n",
      "Training loss at epoch 184: 0.0047\n",
      "\n",
      "Start of epoch 185\n",
      "Training loss at epoch 185: 0.0047\n",
      "\n",
      "Start of epoch 186\n",
      "Training loss at epoch 186: 0.0046\n",
      "\n",
      "Start of epoch 187\n",
      "Training loss at epoch 187: 0.0045\n",
      "\n",
      "Start of epoch 188\n",
      "Training loss at epoch 188: 0.0044\n",
      "\n",
      "Start of epoch 189\n",
      "Training loss at epoch 189: 0.0044\n",
      "\n",
      "Start of epoch 190\n",
      "Training loss at epoch 190: 0.0043\n",
      "\n",
      "Start of epoch 191\n",
      "Training loss at epoch 191: 0.0042\n",
      "\n",
      "Start of epoch 192\n",
      "Training loss at epoch 192: 0.0042\n",
      "\n",
      "Start of epoch 193\n",
      "Training loss at epoch 193: 0.0041\n",
      "\n",
      "Start of epoch 194\n",
      "Training loss at epoch 194: 0.0041\n",
      "\n",
      "Start of epoch 195\n",
      "Training loss at epoch 195: 0.0040\n",
      "\n",
      "Start of epoch 196\n",
      "Training loss at epoch 196: 0.0040\n",
      "\n",
      "Start of epoch 197\n",
      "Training loss at epoch 197: 0.0039\n",
      "\n",
      "Start of epoch 198\n",
      "Training loss at epoch 198: 0.0039\n",
      "\n",
      "Start of epoch 199\n",
      "Training loss at epoch 199: 0.0038\n",
      "\n",
      "Start of epoch 200\n",
      "Training loss at epoch 200: 0.0038\n",
      "\n",
      "Start of epoch 201\n",
      "Training loss at epoch 201: 0.0037\n",
      "\n",
      "Start of epoch 202\n",
      "Training loss at epoch 202: 0.0037\n",
      "\n",
      "Start of epoch 203\n",
      "Training loss at epoch 203: 0.0036\n",
      "\n",
      "Start of epoch 204\n",
      "Training loss at epoch 204: 0.0036\n",
      "\n",
      "Start of epoch 205\n",
      "Training loss at epoch 205: 0.0036\n",
      "\n",
      "Start of epoch 206\n",
      "Training loss at epoch 206: 0.0035\n",
      "\n",
      "Start of epoch 207\n",
      "Training loss at epoch 207: 0.0035\n",
      "\n",
      "Start of epoch 208\n",
      "Training loss at epoch 208: 0.0035\n",
      "\n",
      "Start of epoch 209\n",
      "Training loss at epoch 209: 0.0034\n",
      "\n",
      "Start of epoch 210\n",
      "Training loss at epoch 210: 0.0034\n",
      "\n",
      "Start of epoch 211\n",
      "Training loss at epoch 211: 0.0034\n",
      "\n",
      "Start of epoch 212\n",
      "Training loss at epoch 212: 0.0033\n",
      "\n",
      "Start of epoch 213\n",
      "Training loss at epoch 213: 0.0033\n",
      "\n",
      "Start of epoch 214\n",
      "Training loss at epoch 214: 0.0033\n",
      "\n",
      "Start of epoch 215\n",
      "Training loss at epoch 215: 0.0033\n",
      "\n",
      "Start of epoch 216\n",
      "Training loss at epoch 216: 0.0032\n",
      "\n",
      "Start of epoch 217\n",
      "Training loss at epoch 217: 0.0032\n",
      "\n",
      "Start of epoch 218\n",
      "Training loss at epoch 218: 0.0032\n",
      "\n",
      "Start of epoch 219\n",
      "Training loss at epoch 219: 0.0032\n",
      "\n",
      "Start of epoch 220\n",
      "Training loss at epoch 220: 0.0031\n",
      "\n",
      "Start of epoch 221\n",
      "Training loss at epoch 221: 0.0031\n",
      "\n",
      "Start of epoch 222\n",
      "Training loss at epoch 222: 0.0031\n",
      "\n",
      "Start of epoch 223\n",
      "Training loss at epoch 223: 0.0031\n",
      "\n",
      "Start of epoch 224\n",
      "Training loss at epoch 224: 0.0031\n",
      "\n",
      "Start of epoch 225\n",
      "Training loss at epoch 225: 0.0030\n",
      "\n",
      "Start of epoch 226\n",
      "Training loss at epoch 226: 0.0030\n",
      "\n",
      "Start of epoch 227\n",
      "Training loss at epoch 227: 0.0030\n",
      "\n",
      "Start of epoch 228\n",
      "Training loss at epoch 228: 0.0030\n",
      "\n",
      "Start of epoch 229\n",
      "Training loss at epoch 229: 0.0030\n",
      "\n",
      "Start of epoch 230\n",
      "Training loss at epoch 230: 0.0029\n",
      "\n",
      "Start of epoch 231\n",
      "Training loss at epoch 231: 0.0029\n",
      "\n",
      "Start of epoch 232\n",
      "Training loss at epoch 232: 0.0029\n",
      "\n",
      "Start of epoch 233\n",
      "Training loss at epoch 233: 0.0029\n",
      "\n",
      "Start of epoch 234\n",
      "Training loss at epoch 234: 0.0029\n",
      "\n",
      "Start of epoch 235\n",
      "Training loss at epoch 235: 0.0029\n",
      "\n",
      "Start of epoch 236\n",
      "Training loss at epoch 236: 0.0028\n",
      "\n",
      "Start of epoch 237\n",
      "Training loss at epoch 237: 0.0028\n",
      "\n",
      "Start of epoch 238\n",
      "Training loss at epoch 238: 0.0028\n",
      "\n",
      "Start of epoch 239\n",
      "Training loss at epoch 239: 0.0028\n",
      "\n",
      "Start of epoch 240\n",
      "Training loss at epoch 240: 0.0028\n",
      "\n",
      "Start of epoch 241\n",
      "Training loss at epoch 241: 0.0028\n",
      "\n",
      "Start of epoch 242\n",
      "Training loss at epoch 242: 0.0028\n",
      "\n",
      "Start of epoch 243\n",
      "Training loss at epoch 243: 0.0028\n",
      "\n",
      "Start of epoch 244\n",
      "Training loss at epoch 244: 0.0027\n",
      "\n",
      "Start of epoch 245\n",
      "Training loss at epoch 245: 0.0027\n",
      "\n",
      "Start of epoch 246\n",
      "Training loss at epoch 246: 0.0027\n",
      "\n",
      "Start of epoch 247\n",
      "Training loss at epoch 247: 0.0027\n",
      "\n",
      "Start of epoch 248\n",
      "Training loss at epoch 248: 0.0027\n",
      "\n",
      "Start of epoch 249\n",
      "Training loss at epoch 249: 0.0027\n",
      "\n",
      "Start of epoch 250\n",
      "Training loss at epoch 250: 0.0027\n",
      "\n",
      "Start of epoch 251\n",
      "Training loss at epoch 251: 0.0027\n",
      "\n",
      "Start of epoch 252\n",
      "Training loss at epoch 252: 0.0026\n",
      "\n",
      "Start of epoch 253\n",
      "Training loss at epoch 253: 0.0026\n",
      "\n",
      "Start of epoch 254\n",
      "Training loss at epoch 254: 0.0026\n",
      "\n",
      "Start of epoch 255\n",
      "Training loss at epoch 255: 0.0026\n",
      "\n",
      "Start of epoch 256\n",
      "Training loss at epoch 256: 0.0026\n",
      "\n",
      "Start of epoch 257\n",
      "Training loss at epoch 257: 0.0026\n",
      "\n",
      "Start of epoch 258\n",
      "Training loss at epoch 258: 0.0026\n",
      "\n",
      "Start of epoch 259\n",
      "Training loss at epoch 259: 0.0026\n",
      "\n",
      "Start of epoch 260\n",
      "Training loss at epoch 260: 0.0026\n",
      "\n",
      "Start of epoch 261\n",
      "Training loss at epoch 261: 0.0025\n",
      "\n",
      "Start of epoch 262\n",
      "Training loss at epoch 262: 0.0025\n",
      "\n",
      "Start of epoch 263\n",
      "Training loss at epoch 263: 0.0025\n",
      "\n",
      "Start of epoch 264\n",
      "Training loss at epoch 264: 0.0025\n",
      "\n",
      "Start of epoch 265\n",
      "Training loss at epoch 265: 0.0025\n",
      "\n",
      "Start of epoch 266\n",
      "Training loss at epoch 266: 0.0025\n",
      "\n",
      "Start of epoch 267\n",
      "Training loss at epoch 267: 0.0025\n",
      "\n",
      "Start of epoch 268\n",
      "Training loss at epoch 268: 0.0025\n",
      "\n",
      "Start of epoch 269\n",
      "Training loss at epoch 269: 0.0025\n",
      "\n",
      "Start of epoch 270\n",
      "Training loss at epoch 270: 0.0025\n",
      "\n",
      "Start of epoch 271\n",
      "Training loss at epoch 271: 0.0025\n",
      "\n",
      "Start of epoch 272\n",
      "Training loss at epoch 272: 0.0024\n",
      "\n",
      "Start of epoch 273\n",
      "Training loss at epoch 273: 0.0024\n",
      "\n",
      "Start of epoch 274\n",
      "Training loss at epoch 274: 0.0024\n",
      "\n",
      "Start of epoch 275\n",
      "Training loss at epoch 275: 0.0024\n",
      "\n",
      "Start of epoch 276\n",
      "Training loss at epoch 276: 0.0024\n",
      "\n",
      "Start of epoch 277\n",
      "Training loss at epoch 277: 0.0024\n",
      "\n",
      "Start of epoch 278\n",
      "Training loss at epoch 278: 0.0024\n",
      "\n",
      "Start of epoch 279\n",
      "Training loss at epoch 279: 0.0024\n",
      "\n",
      "Start of epoch 280\n",
      "Training loss at epoch 280: 0.0024\n",
      "\n",
      "Start of epoch 281\n",
      "Training loss at epoch 281: 0.0024\n",
      "\n",
      "Start of epoch 282\n",
      "Training loss at epoch 282: 0.0024\n",
      "\n",
      "Start of epoch 283\n",
      "Training loss at epoch 283: 0.0024\n",
      "\n",
      "Start of epoch 284\n",
      "Training loss at epoch 284: 0.0023\n",
      "\n",
      "Start of epoch 285\n",
      "Training loss at epoch 285: 0.0023\n",
      "\n",
      "Start of epoch 286\n",
      "Training loss at epoch 286: 0.0023\n",
      "\n",
      "Start of epoch 287\n",
      "Training loss at epoch 287: 0.0023\n",
      "\n",
      "Start of epoch 288\n",
      "Training loss at epoch 288: 0.0023\n",
      "\n",
      "Start of epoch 289\n",
      "Training loss at epoch 289: 0.0023\n",
      "\n",
      "Start of epoch 290\n",
      "Training loss at epoch 290: 0.0023\n",
      "\n",
      "Start of epoch 291\n",
      "Training loss at epoch 291: 0.0023\n",
      "\n",
      "Start of epoch 292\n",
      "Training loss at epoch 292: 0.0023\n",
      "\n",
      "Start of epoch 293\n",
      "Training loss at epoch 293: 0.0023\n",
      "\n",
      "Start of epoch 294\n",
      "Training loss at epoch 294: 0.0023\n",
      "\n",
      "Start of epoch 295\n",
      "Training loss at epoch 295: 0.0023\n",
      "\n",
      "Start of epoch 296\n",
      "Training loss at epoch 296: 0.0022\n",
      "\n",
      "Start of epoch 297\n",
      "Training loss at epoch 297: 0.0022\n",
      "\n",
      "Start of epoch 298\n",
      "Training loss at epoch 298: 0.0022\n",
      "\n",
      "Start of epoch 299\n",
      "Training loss at epoch 299: 0.0022\n",
      "\n",
      "Start of epoch 300\n",
      "Training loss at epoch 300: 0.0022\n",
      "\n",
      "Start of epoch 301\n",
      "Training loss at epoch 301: 0.0022\n",
      "\n",
      "Start of epoch 302\n",
      "Training loss at epoch 302: 0.0022\n",
      "\n",
      "Start of epoch 303\n",
      "Training loss at epoch 303: 0.0022\n",
      "\n",
      "Start of epoch 304\n",
      "Training loss at epoch 304: 0.0022\n",
      "\n",
      "Start of epoch 305\n",
      "Training loss at epoch 305: 0.0022\n",
      "\n",
      "Start of epoch 306\n",
      "Training loss at epoch 306: 0.0022\n",
      "\n",
      "Start of epoch 307\n",
      "Training loss at epoch 307: 0.0022\n",
      "\n",
      "Start of epoch 308\n",
      "Training loss at epoch 308: 0.0022\n",
      "\n",
      "Start of epoch 309\n",
      "Training loss at epoch 309: 0.0022\n",
      "\n",
      "Start of epoch 310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 310: 0.0022\n",
      "\n",
      "Start of epoch 311\n",
      "Training loss at epoch 311: 0.0021\n",
      "\n",
      "Start of epoch 312\n",
      "Training loss at epoch 312: 0.0021\n",
      "\n",
      "Start of epoch 313\n",
      "Training loss at epoch 313: 0.0021\n",
      "\n",
      "Start of epoch 314\n",
      "Training loss at epoch 314: 0.0021\n",
      "\n",
      "Start of epoch 315\n",
      "Training loss at epoch 315: 0.0021\n",
      "\n",
      "Start of epoch 316\n",
      "Training loss at epoch 316: 0.0021\n",
      "\n",
      "Start of epoch 317\n",
      "Training loss at epoch 317: 0.0021\n",
      "\n",
      "Start of epoch 318\n",
      "Training loss at epoch 318: 0.0021\n",
      "\n",
      "Start of epoch 319\n",
      "Training loss at epoch 319: 0.0021\n",
      "\n",
      "Start of epoch 320\n",
      "Training loss at epoch 320: 0.0021\n",
      "\n",
      "Start of epoch 321\n",
      "Training loss at epoch 321: 0.0021\n",
      "\n",
      "Start of epoch 322\n",
      "Training loss at epoch 322: 0.0021\n",
      "\n",
      "Start of epoch 323\n",
      "Training loss at epoch 323: 0.0021\n",
      "\n",
      "Start of epoch 324\n",
      "Training loss at epoch 324: 0.0021\n",
      "\n",
      "Start of epoch 325\n",
      "Training loss at epoch 325: 0.0021\n",
      "\n",
      "Start of epoch 326\n",
      "Training loss at epoch 326: 0.0020\n",
      "\n",
      "Start of epoch 327\n",
      "Training loss at epoch 327: 0.0020\n",
      "\n",
      "Start of epoch 328\n",
      "Training loss at epoch 328: 0.0020\n",
      "\n",
      "Start of epoch 329\n",
      "Training loss at epoch 329: 0.0020\n",
      "\n",
      "Start of epoch 330\n",
      "Training loss at epoch 330: 0.0020\n",
      "\n",
      "Start of epoch 331\n",
      "Training loss at epoch 331: 0.0020\n",
      "\n",
      "Start of epoch 332\n",
      "Training loss at epoch 332: 0.0020\n",
      "\n",
      "Start of epoch 333\n",
      "Training loss at epoch 333: 0.0020\n",
      "\n",
      "Start of epoch 334\n",
      "Training loss at epoch 334: 0.0020\n",
      "\n",
      "Start of epoch 335\n",
      "Training loss at epoch 335: 0.0020\n",
      "\n",
      "Start of epoch 336\n",
      "Training loss at epoch 336: 0.0020\n",
      "\n",
      "Start of epoch 337\n",
      "Training loss at epoch 337: 0.0020\n",
      "\n",
      "Start of epoch 338\n",
      "Training loss at epoch 338: 0.0020\n",
      "\n",
      "Start of epoch 339\n",
      "Training loss at epoch 339: 0.0020\n",
      "\n",
      "Start of epoch 340\n",
      "Training loss at epoch 340: 0.0020\n",
      "\n",
      "Start of epoch 341\n",
      "Training loss at epoch 341: 0.0020\n",
      "\n",
      "Start of epoch 342\n",
      "Training loss at epoch 342: 0.0020\n",
      "\n",
      "Start of epoch 343\n",
      "Training loss at epoch 343: 0.0019\n",
      "\n",
      "Start of epoch 344\n",
      "Training loss at epoch 344: 0.0019\n",
      "\n",
      "Start of epoch 345\n",
      "Training loss at epoch 345: 0.0019\n",
      "\n",
      "Start of epoch 346\n",
      "Training loss at epoch 346: 0.0019\n",
      "\n",
      "Start of epoch 347\n",
      "Training loss at epoch 347: 0.0019\n",
      "\n",
      "Start of epoch 348\n",
      "Training loss at epoch 348: 0.0019\n",
      "\n",
      "Start of epoch 349\n",
      "Training loss at epoch 349: 0.0019\n",
      "\n",
      "Start of epoch 350\n",
      "Training loss at epoch 350: 0.0019\n",
      "\n",
      "Start of epoch 351\n",
      "Training loss at epoch 351: 0.0019\n",
      "\n",
      "Start of epoch 352\n",
      "Training loss at epoch 352: 0.0019\n",
      "\n",
      "Start of epoch 353\n",
      "Training loss at epoch 353: 0.0019\n",
      "\n",
      "Start of epoch 354\n",
      "Training loss at epoch 354: 0.0019\n",
      "\n",
      "Start of epoch 355\n",
      "Training loss at epoch 355: 0.0019\n",
      "\n",
      "Start of epoch 356\n",
      "Training loss at epoch 356: 0.0019\n",
      "\n",
      "Start of epoch 357\n",
      "Training loss at epoch 357: 0.0019\n",
      "\n",
      "Start of epoch 358\n",
      "Training loss at epoch 358: 0.0019\n",
      "\n",
      "Start of epoch 359\n",
      "Training loss at epoch 359: 0.0019\n",
      "\n",
      "Start of epoch 360\n",
      "Training loss at epoch 360: 0.0019\n",
      "\n",
      "Start of epoch 361\n",
      "Training loss at epoch 361: 0.0018\n",
      "\n",
      "Start of epoch 362\n",
      "Training loss at epoch 362: 0.0018\n",
      "\n",
      "Start of epoch 363\n",
      "Training loss at epoch 363: 0.0018\n",
      "\n",
      "Start of epoch 364\n",
      "Training loss at epoch 364: 0.0018\n",
      "\n",
      "Start of epoch 365\n",
      "Training loss at epoch 365: 0.0018\n",
      "\n",
      "Start of epoch 366\n",
      "Training loss at epoch 366: 0.0018\n",
      "\n",
      "Start of epoch 367\n",
      "Training loss at epoch 367: 0.0018\n",
      "\n",
      "Start of epoch 368\n",
      "Training loss at epoch 368: 0.0018\n",
      "\n",
      "Start of epoch 369\n",
      "Training loss at epoch 369: 0.0018\n",
      "\n",
      "Start of epoch 370\n",
      "Training loss at epoch 370: 0.0018\n",
      "\n",
      "Start of epoch 371\n",
      "Training loss at epoch 371: 0.0018\n",
      "\n",
      "Start of epoch 372\n",
      "Training loss at epoch 372: 0.0018\n",
      "\n",
      "Start of epoch 373\n",
      "Training loss at epoch 373: 0.0018\n",
      "\n",
      "Start of epoch 374\n",
      "Training loss at epoch 374: 0.0018\n",
      "\n",
      "Start of epoch 375\n",
      "Training loss at epoch 375: 0.0018\n",
      "\n",
      "Start of epoch 376\n",
      "Training loss at epoch 376: 0.0018\n",
      "\n",
      "Start of epoch 377\n",
      "Training loss at epoch 377: 0.0018\n",
      "\n",
      "Start of epoch 378\n",
      "Training loss at epoch 378: 0.0018\n",
      "\n",
      "Start of epoch 379\n",
      "Training loss at epoch 379: 0.0018\n",
      "\n",
      "Start of epoch 380\n",
      "Training loss at epoch 380: 0.0018\n",
      "\n",
      "Start of epoch 381\n",
      "Training loss at epoch 381: 0.0017\n",
      "\n",
      "Start of epoch 382\n",
      "Training loss at epoch 382: 0.0017\n",
      "\n",
      "Start of epoch 383\n",
      "Training loss at epoch 383: 0.0017\n",
      "\n",
      "Start of epoch 384\n",
      "Training loss at epoch 384: 0.0017\n",
      "\n",
      "Start of epoch 385\n",
      "Training loss at epoch 385: 0.0017\n",
      "\n",
      "Start of epoch 386\n",
      "Training loss at epoch 386: 0.0017\n",
      "\n",
      "Start of epoch 387\n",
      "Training loss at epoch 387: 0.0017\n",
      "\n",
      "Start of epoch 388\n",
      "Training loss at epoch 388: 0.0017\n",
      "\n",
      "Start of epoch 389\n",
      "Training loss at epoch 389: 0.0017\n",
      "\n",
      "Start of epoch 390\n",
      "Training loss at epoch 390: 0.0017\n",
      "\n",
      "Start of epoch 391\n",
      "Training loss at epoch 391: 0.0017\n",
      "\n",
      "Start of epoch 392\n",
      "Training loss at epoch 392: 0.0017\n",
      "\n",
      "Start of epoch 393\n",
      "Training loss at epoch 393: 0.0017\n",
      "\n",
      "Start of epoch 394\n",
      "Training loss at epoch 394: 0.0017\n",
      "\n",
      "Start of epoch 395\n",
      "Training loss at epoch 395: 0.0017\n",
      "\n",
      "Start of epoch 396\n",
      "Training loss at epoch 396: 0.0017\n",
      "\n",
      "Start of epoch 397\n",
      "Training loss at epoch 397: 0.0017\n",
      "\n",
      "Start of epoch 398\n",
      "Training loss at epoch 398: 0.0017\n",
      "\n",
      "Start of epoch 399\n",
      "Training loss at epoch 399: 0.0017\n",
      "\n",
      "Start of epoch 400\n",
      "Training loss at epoch 400: 0.0017\n",
      "\n",
      "Start of epoch 401\n",
      "Training loss at epoch 401: 0.0017\n",
      "\n",
      "Start of epoch 402\n",
      "Training loss at epoch 402: 0.0017\n",
      "\n",
      "Start of epoch 403\n",
      "Training loss at epoch 403: 0.0017\n",
      "\n",
      "Start of epoch 404\n",
      "Training loss at epoch 404: 0.0017\n",
      "\n",
      "Start of epoch 405\n",
      "Training loss at epoch 405: 0.0016\n",
      "\n",
      "Start of epoch 406\n",
      "Training loss at epoch 406: 0.0016\n",
      "\n",
      "Start of epoch 407\n",
      "Training loss at epoch 407: 0.0016\n",
      "\n",
      "Start of epoch 408\n",
      "Training loss at epoch 408: 0.0016\n",
      "\n",
      "Start of epoch 409\n",
      "Training loss at epoch 409: 0.0016\n",
      "\n",
      "Start of epoch 410\n",
      "Training loss at epoch 410: 0.0016\n",
      "\n",
      "Start of epoch 411\n",
      "Training loss at epoch 411: 0.0016\n",
      "\n",
      "Start of epoch 412\n",
      "Training loss at epoch 412: 0.0016\n",
      "\n",
      "Start of epoch 413\n",
      "Training loss at epoch 413: 0.0016\n",
      "\n",
      "Start of epoch 414\n",
      "Training loss at epoch 414: 0.0016\n",
      "\n",
      "Start of epoch 415\n",
      "Training loss at epoch 415: 0.0016\n",
      "\n",
      "Start of epoch 416\n",
      "Training loss at epoch 416: 0.0016\n",
      "\n",
      "Start of epoch 417\n",
      "Training loss at epoch 417: 0.0016\n",
      "\n",
      "Start of epoch 418\n",
      "Training loss at epoch 418: 0.0016\n",
      "\n",
      "Start of epoch 419\n",
      "Training loss at epoch 419: 0.0016\n",
      "\n",
      "Start of epoch 420\n",
      "Training loss at epoch 420: 0.0016\n",
      "\n",
      "Start of epoch 421\n",
      "Training loss at epoch 421: 0.0016\n",
      "\n",
      "Start of epoch 422\n",
      "Training loss at epoch 422: 0.0016\n",
      "\n",
      "Start of epoch 423\n",
      "Training loss at epoch 423: 0.0016\n",
      "\n",
      "Start of epoch 424\n",
      "Training loss at epoch 424: 0.0016\n",
      "\n",
      "Start of epoch 425\n",
      "Training loss at epoch 425: 0.0016\n",
      "\n",
      "Start of epoch 426\n",
      "Training loss at epoch 426: 0.0016\n",
      "\n",
      "Start of epoch 427\n",
      "Training loss at epoch 427: 0.0016\n",
      "\n",
      "Start of epoch 428\n",
      "Training loss at epoch 428: 0.0016\n",
      "\n",
      "Start of epoch 429\n",
      "Training loss at epoch 429: 0.0016\n",
      "\n",
      "Start of epoch 430\n",
      "Training loss at epoch 430: 0.0016\n",
      "\n",
      "Start of epoch 431\n",
      "Training loss at epoch 431: 0.0016\n",
      "\n",
      "Start of epoch 432\n",
      "Training loss at epoch 432: 0.0015\n",
      "\n",
      "Start of epoch 433\n",
      "Training loss at epoch 433: 0.0015\n",
      "\n",
      "Start of epoch 434\n",
      "Training loss at epoch 434: 0.0015\n",
      "\n",
      "Start of epoch 435\n",
      "Training loss at epoch 435: 0.0015\n",
      "\n",
      "Start of epoch 436\n",
      "Training loss at epoch 436: 0.0015\n",
      "\n",
      "Start of epoch 437\n",
      "Training loss at epoch 437: 0.0015\n",
      "\n",
      "Start of epoch 438\n",
      "Training loss at epoch 438: 0.0015\n",
      "\n",
      "Start of epoch 439\n",
      "Training loss at epoch 439: 0.0015\n",
      "\n",
      "Start of epoch 440\n",
      "Training loss at epoch 440: 0.0015\n",
      "\n",
      "Start of epoch 441\n",
      "Training loss at epoch 441: 0.0015\n",
      "\n",
      "Start of epoch 442\n",
      "Training loss at epoch 442: 0.0015\n",
      "\n",
      "Start of epoch 443\n",
      "Training loss at epoch 443: 0.0015\n",
      "\n",
      "Start of epoch 444\n",
      "Training loss at epoch 444: 0.0015\n",
      "\n",
      "Start of epoch 445\n",
      "Training loss at epoch 445: 0.0015\n",
      "\n",
      "Start of epoch 446\n",
      "Training loss at epoch 446: 0.0015\n",
      "\n",
      "Start of epoch 447\n",
      "Training loss at epoch 447: 0.0015\n",
      "\n",
      "Start of epoch 448\n",
      "Training loss at epoch 448: 0.0015\n",
      "\n",
      "Start of epoch 449\n",
      "Training loss at epoch 449: 0.0015\n",
      "\n",
      "Start of epoch 450\n",
      "Training loss at epoch 450: 0.0015\n",
      "\n",
      "Start of epoch 451\n",
      "Training loss at epoch 451: 0.0015\n",
      "\n",
      "Start of epoch 452\n",
      "Training loss at epoch 452: 0.0015\n",
      "\n",
      "Start of epoch 453\n",
      "Training loss at epoch 453: 0.0015\n",
      "\n",
      "Start of epoch 454\n",
      "Training loss at epoch 454: 0.0015\n",
      "\n",
      "Start of epoch 455\n",
      "Training loss at epoch 455: 0.0015\n",
      "\n",
      "Start of epoch 456\n",
      "Training loss at epoch 456: 0.0015\n",
      "\n",
      "Start of epoch 457\n",
      "Training loss at epoch 457: 0.0015\n",
      "\n",
      "Start of epoch 458\n",
      "Training loss at epoch 458: 0.0015\n",
      "\n",
      "Start of epoch 459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 459: 0.0015\n",
      "\n",
      "Start of epoch 460\n",
      "Training loss at epoch 460: 0.0015\n",
      "\n",
      "Start of epoch 461\n",
      "Training loss at epoch 461: 0.0015\n",
      "\n",
      "Start of epoch 462\n",
      "Training loss at epoch 462: 0.0015\n",
      "\n",
      "Start of epoch 463\n",
      "Training loss at epoch 463: 0.0015\n",
      "\n",
      "Start of epoch 464\n",
      "Training loss at epoch 464: 0.0014\n",
      "\n",
      "Start of epoch 465\n",
      "Training loss at epoch 465: 0.0014\n",
      "\n",
      "Start of epoch 466\n",
      "Training loss at epoch 466: 0.0014\n",
      "\n",
      "Start of epoch 467\n",
      "Training loss at epoch 467: 0.0014\n",
      "\n",
      "Start of epoch 468\n",
      "Training loss at epoch 468: 0.0014\n",
      "\n",
      "Start of epoch 469\n",
      "Training loss at epoch 469: 0.0014\n",
      "\n",
      "Start of epoch 470\n",
      "Training loss at epoch 470: 0.0014\n",
      "\n",
      "Start of epoch 471\n",
      "Training loss at epoch 471: 0.0014\n",
      "\n",
      "Start of epoch 472\n",
      "Training loss at epoch 472: 0.0014\n",
      "\n",
      "Start of epoch 473\n",
      "Training loss at epoch 473: 0.0014\n",
      "\n",
      "Start of epoch 474\n",
      "Training loss at epoch 474: 0.0014\n",
      "\n",
      "Start of epoch 475\n",
      "Training loss at epoch 475: 0.0014\n",
      "\n",
      "Start of epoch 476\n",
      "Training loss at epoch 476: 0.0014\n",
      "\n",
      "Start of epoch 477\n",
      "Training loss at epoch 477: 0.0014\n",
      "\n",
      "Start of epoch 478\n",
      "Training loss at epoch 478: 0.0014\n",
      "\n",
      "Start of epoch 479\n",
      "Training loss at epoch 479: 0.0014\n",
      "\n",
      "Start of epoch 480\n",
      "Training loss at epoch 480: 0.0014\n",
      "\n",
      "Start of epoch 481\n",
      "Training loss at epoch 481: 0.0014\n",
      "\n",
      "Start of epoch 482\n",
      "Training loss at epoch 482: 0.0014\n",
      "\n",
      "Start of epoch 483\n",
      "Training loss at epoch 483: 0.0014\n",
      "\n",
      "Start of epoch 484\n",
      "Training loss at epoch 484: 0.0014\n",
      "\n",
      "Start of epoch 485\n",
      "Training loss at epoch 485: 0.0014\n",
      "\n",
      "Start of epoch 486\n",
      "Training loss at epoch 486: 0.0014\n",
      "\n",
      "Start of epoch 487\n",
      "Training loss at epoch 487: 0.0014\n",
      "\n",
      "Start of epoch 488\n",
      "Training loss at epoch 488: 0.0014\n",
      "\n",
      "Start of epoch 489\n",
      "Training loss at epoch 489: 0.0014\n",
      "\n",
      "Start of epoch 490\n",
      "Training loss at epoch 490: 0.0014\n",
      "\n",
      "Start of epoch 491\n",
      "Training loss at epoch 491: 0.0014\n",
      "\n",
      "Start of epoch 492\n",
      "Training loss at epoch 492: 0.0014\n",
      "\n",
      "Start of epoch 493\n",
      "Training loss at epoch 493: 0.0014\n",
      "\n",
      "Start of epoch 494\n",
      "Training loss at epoch 494: 0.0014\n",
      "\n",
      "Start of epoch 495\n",
      "Training loss at epoch 495: 0.0014\n",
      "\n",
      "Start of epoch 496\n",
      "Training loss at epoch 496: 0.0014\n",
      "\n",
      "Start of epoch 497\n",
      "Training loss at epoch 497: 0.0014\n",
      "\n",
      "Start of epoch 498\n",
      "Training loss at epoch 498: 0.0014\n",
      "\n",
      "Start of epoch 499\n",
      "Training loss at epoch 499: 0.0014\n",
      "[<tf.Variable 'parameters:0' shape=(60,) dtype=float32, numpy=\n",
      "array([2.763283  , 2.646577  , 0.65287364, 2.745753  , 3.4746523 ,\n",
      "       4.7984943 , 2.3615448 , 4.148323  , 1.4898549 , 3.0329475 ,\n",
      "       2.42456   , 0.0166386 , 5.5031614 , 4.6834807 , 2.1066186 ,\n",
      "       2.0278208 , 3.5840795 , 5.392487  , 6.0083957 , 5.8617773 ,\n",
      "       4.133457  , 5.9418344 , 0.4451241 , 4.417979  , 4.476498  ,\n",
      "       0.2648948 , 0.736877  , 4.516981  , 0.575293  , 0.25224397,\n",
      "       1.6986793 , 1.8964033 , 5.1772895 , 6.2545133 , 0.5324943 ,\n",
      "       5.4114456 , 1.2155712 , 2.0089006 , 4.0365    , 2.2555428 ,\n",
      "       5.923117  , 2.9817734 , 6.078668  , 6.070571  , 4.3648314 ,\n",
      "       5.8416734 , 2.9206276 , 2.7714825 , 2.8741932 , 4.611476  ,\n",
      "       0.6511277 , 1.1296166 , 4.8435025 , 0.87521994, 2.0132997 ,\n",
      "       3.9701042 , 0.69475627, 0.1887096 , 5.950352  , 2.3490288 ],\n",
      "      dtype=float32)>]\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.2069\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 1.0989\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 1.0294\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.9900\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.9557\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.9163\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.8746\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.8362\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.8042\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.7772\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.7510\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.7241\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.6986\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.6768\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.6590\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.6449\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.6334\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.6233\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.6133\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.6030\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.5928\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.5834\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.5746\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.5660\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.5573\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.5488\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.5406\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.5325\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.5236\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.5136\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.5028\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.4922\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.4829\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.4756\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.4700\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.4656\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.4613\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.4567\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.4516\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.4463\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.4412\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.4365\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.4321\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.4279\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.4236\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.4192\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.4146\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.4100\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.4054\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.4013\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.3978\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.3948\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.3923\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.3900\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.3878\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.3856\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.3834\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.3813\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.3791\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.3769\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.3748\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.3727\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.3706\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.3685\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.3663\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.3642\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.3621\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.3601\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.3583\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.3564\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.3546\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.3527\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.3510\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.3494\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.3479\n",
      "\n",
      "Start of epoch 75\n",
      "Training loss at epoch 75: 0.3466\n",
      "\n",
      "Start of epoch 76\n",
      "Training loss at epoch 76: 0.3453\n",
      "\n",
      "Start of epoch 77\n",
      "Training loss at epoch 77: 0.3440\n",
      "\n",
      "Start of epoch 78\n",
      "Training loss at epoch 78: 0.3427\n",
      "\n",
      "Start of epoch 79\n",
      "Training loss at epoch 79: 0.3413\n",
      "\n",
      "Start of epoch 80\n",
      "Training loss at epoch 80: 0.3400\n",
      "\n",
      "Start of epoch 81\n",
      "Training loss at epoch 81: 0.3387\n",
      "\n",
      "Start of epoch 82\n",
      "Training loss at epoch 82: 0.3374\n",
      "\n",
      "Start of epoch 83\n",
      "Training loss at epoch 83: 0.3361\n",
      "\n",
      "Start of epoch 84\n",
      "Training loss at epoch 84: 0.3350\n",
      "\n",
      "Start of epoch 85\n",
      "Training loss at epoch 85: 0.3339\n",
      "\n",
      "Start of epoch 86\n",
      "Training loss at epoch 86: 0.3328\n",
      "\n",
      "Start of epoch 87\n",
      "Training loss at epoch 87: 0.3318\n",
      "\n",
      "Start of epoch 88\n",
      "Training loss at epoch 88: 0.3309\n",
      "\n",
      "Start of epoch 89\n",
      "Training loss at epoch 89: 0.3300\n",
      "\n",
      "Start of epoch 90\n",
      "Training loss at epoch 90: 0.3291\n",
      "\n",
      "Start of epoch 91\n",
      "Training loss at epoch 91: 0.3281\n",
      "\n",
      "Start of epoch 92\n",
      "Training loss at epoch 92: 0.3272\n",
      "\n",
      "Start of epoch 93\n",
      "Training loss at epoch 93: 0.3262\n",
      "\n",
      "Start of epoch 94\n",
      "Training loss at epoch 94: 0.3253\n",
      "\n",
      "Start of epoch 95\n",
      "Training loss at epoch 95: 0.3243\n",
      "\n",
      "Start of epoch 96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 96: 0.3233\n",
      "\n",
      "Start of epoch 97\n",
      "Training loss at epoch 97: 0.3223\n",
      "\n",
      "Start of epoch 98\n",
      "Training loss at epoch 98: 0.3212\n",
      "\n",
      "Start of epoch 99\n",
      "Training loss at epoch 99: 0.3202\n",
      "\n",
      "Start of epoch 100\n",
      "Training loss at epoch 100: 0.3192\n",
      "\n",
      "Start of epoch 101\n",
      "Training loss at epoch 101: 0.3181\n",
      "\n",
      "Start of epoch 102\n",
      "Training loss at epoch 102: 0.3171\n",
      "\n",
      "Start of epoch 103\n",
      "Training loss at epoch 103: 0.3160\n",
      "\n",
      "Start of epoch 104\n",
      "Training loss at epoch 104: 0.3150\n",
      "\n",
      "Start of epoch 105\n",
      "Training loss at epoch 105: 0.3140\n",
      "\n",
      "Start of epoch 106\n",
      "Training loss at epoch 106: 0.3129\n",
      "\n",
      "Start of epoch 107\n",
      "Training loss at epoch 107: 0.3118\n",
      "\n",
      "Start of epoch 108\n",
      "Training loss at epoch 108: 0.3107\n",
      "\n",
      "Start of epoch 109\n",
      "Training loss at epoch 109: 0.3096\n",
      "\n",
      "Start of epoch 110\n",
      "Training loss at epoch 110: 0.3084\n",
      "\n",
      "Start of epoch 111\n",
      "Training loss at epoch 111: 0.3072\n",
      "\n",
      "Start of epoch 112\n",
      "Training loss at epoch 112: 0.3060\n",
      "\n",
      "Start of epoch 113\n",
      "Training loss at epoch 113: 0.3047\n",
      "\n",
      "Start of epoch 114\n",
      "Training loss at epoch 114: 0.3033\n",
      "\n",
      "Start of epoch 115\n",
      "Training loss at epoch 115: 0.3019\n",
      "\n",
      "Start of epoch 116\n",
      "Training loss at epoch 116: 0.3004\n",
      "\n",
      "Start of epoch 117\n",
      "Training loss at epoch 117: 0.2988\n",
      "\n",
      "Start of epoch 118\n",
      "Training loss at epoch 118: 0.2970\n",
      "\n",
      "Start of epoch 119\n",
      "Training loss at epoch 119: 0.2952\n",
      "\n",
      "Start of epoch 120\n",
      "Training loss at epoch 120: 0.2932\n",
      "\n",
      "Start of epoch 121\n",
      "Training loss at epoch 121: 0.2911\n",
      "\n",
      "Start of epoch 122\n",
      "Training loss at epoch 122: 0.2888\n",
      "\n",
      "Start of epoch 123\n",
      "Training loss at epoch 123: 0.2864\n",
      "\n",
      "Start of epoch 124\n",
      "Training loss at epoch 124: 0.2839\n",
      "\n",
      "Start of epoch 125\n",
      "Training loss at epoch 125: 0.2813\n",
      "\n",
      "Start of epoch 126\n",
      "Training loss at epoch 126: 0.2786\n",
      "\n",
      "Start of epoch 127\n",
      "Training loss at epoch 127: 0.2758\n",
      "\n",
      "Start of epoch 128\n",
      "Training loss at epoch 128: 0.2729\n",
      "\n",
      "Start of epoch 129\n",
      "Training loss at epoch 129: 0.2700\n",
      "\n",
      "Start of epoch 130\n",
      "Training loss at epoch 130: 0.2672\n",
      "\n",
      "Start of epoch 131\n",
      "Training loss at epoch 131: 0.2644\n",
      "\n",
      "Start of epoch 132\n",
      "Training loss at epoch 132: 0.2618\n",
      "\n",
      "Start of epoch 133\n",
      "Training loss at epoch 133: 0.2593\n",
      "\n",
      "Start of epoch 134\n",
      "Training loss at epoch 134: 0.2570\n",
      "\n",
      "Start of epoch 135\n",
      "Training loss at epoch 135: 0.2549\n",
      "\n",
      "Start of epoch 136\n",
      "Training loss at epoch 136: 0.2530\n",
      "\n",
      "Start of epoch 137\n",
      "Training loss at epoch 137: 0.2513\n",
      "\n",
      "Start of epoch 138\n",
      "Training loss at epoch 138: 0.2499\n",
      "\n",
      "Start of epoch 139\n",
      "Training loss at epoch 139: 0.2486\n",
      "\n",
      "Start of epoch 140\n",
      "Training loss at epoch 140: 0.2474\n",
      "\n",
      "Start of epoch 141\n",
      "Training loss at epoch 141: 0.2463\n",
      "\n",
      "Start of epoch 142\n",
      "Training loss at epoch 142: 0.2453\n",
      "\n",
      "Start of epoch 143\n",
      "Training loss at epoch 143: 0.2442\n",
      "\n",
      "Start of epoch 144\n",
      "Training loss at epoch 144: 0.2432\n",
      "\n",
      "Start of epoch 145\n",
      "Training loss at epoch 145: 0.2422\n",
      "\n",
      "Start of epoch 146\n",
      "Training loss at epoch 146: 0.2412\n",
      "\n",
      "Start of epoch 147\n",
      "Training loss at epoch 147: 0.2401\n",
      "\n",
      "Start of epoch 148\n",
      "Training loss at epoch 148: 0.2391\n",
      "\n",
      "Start of epoch 149\n",
      "Training loss at epoch 149: 0.2381\n",
      "\n",
      "Start of epoch 150\n",
      "Training loss at epoch 150: 0.2371\n",
      "\n",
      "Start of epoch 151\n",
      "Training loss at epoch 151: 0.2361\n",
      "\n",
      "Start of epoch 152\n",
      "Training loss at epoch 152: 0.2352\n",
      "\n",
      "Start of epoch 153\n",
      "Training loss at epoch 153: 0.2344\n",
      "\n",
      "Start of epoch 154\n",
      "Training loss at epoch 154: 0.2335\n",
      "\n",
      "Start of epoch 155\n",
      "Training loss at epoch 155: 0.2327\n",
      "\n",
      "Start of epoch 156\n",
      "Training loss at epoch 156: 0.2319\n",
      "\n",
      "Start of epoch 157\n",
      "Training loss at epoch 157: 0.2311\n",
      "\n",
      "Start of epoch 158\n",
      "Training loss at epoch 158: 0.2302\n",
      "\n",
      "Start of epoch 159\n",
      "Training loss at epoch 159: 0.2294\n",
      "\n",
      "Start of epoch 160\n",
      "Training loss at epoch 160: 0.2285\n",
      "\n",
      "Start of epoch 161\n",
      "Training loss at epoch 161: 0.2276\n",
      "\n",
      "Start of epoch 162\n",
      "Training loss at epoch 162: 0.2267\n",
      "\n",
      "Start of epoch 163\n",
      "Training loss at epoch 163: 0.2257\n",
      "\n",
      "Start of epoch 164\n",
      "Training loss at epoch 164: 0.2247\n",
      "\n",
      "Start of epoch 165\n",
      "Training loss at epoch 165: 0.2237\n",
      "\n",
      "Start of epoch 166\n",
      "Training loss at epoch 166: 0.2227\n",
      "\n",
      "Start of epoch 167\n",
      "Training loss at epoch 167: 0.2216\n",
      "\n",
      "Start of epoch 168\n",
      "Training loss at epoch 168: 0.2205\n",
      "\n",
      "Start of epoch 169\n",
      "Training loss at epoch 169: 0.2194\n",
      "\n",
      "Start of epoch 170\n",
      "Training loss at epoch 170: 0.2183\n",
      "\n",
      "Start of epoch 171\n",
      "Training loss at epoch 171: 0.2172\n",
      "\n",
      "Start of epoch 172\n",
      "Training loss at epoch 172: 0.2161\n",
      "\n",
      "Start of epoch 173\n",
      "Training loss at epoch 173: 0.2151\n",
      "\n",
      "Start of epoch 174\n",
      "Training loss at epoch 174: 0.2141\n",
      "\n",
      "Start of epoch 175\n",
      "Training loss at epoch 175: 0.2131\n",
      "\n",
      "Start of epoch 176\n",
      "Training loss at epoch 176: 0.2123\n",
      "\n",
      "Start of epoch 177\n",
      "Training loss at epoch 177: 0.2115\n",
      "\n",
      "Start of epoch 178\n",
      "Training loss at epoch 178: 0.2108\n",
      "\n",
      "Start of epoch 179\n",
      "Training loss at epoch 179: 0.2102\n",
      "\n",
      "Start of epoch 180\n",
      "Training loss at epoch 180: 0.2096\n",
      "\n",
      "Start of epoch 181\n",
      "Training loss at epoch 181: 0.2091\n",
      "\n",
      "Start of epoch 182\n",
      "Training loss at epoch 182: 0.2087\n",
      "\n",
      "Start of epoch 183\n",
      "Training loss at epoch 183: 0.2083\n",
      "\n",
      "Start of epoch 184\n",
      "Training loss at epoch 184: 0.2080\n",
      "\n",
      "Start of epoch 185\n",
      "Training loss at epoch 185: 0.2076\n",
      "\n",
      "Start of epoch 186\n",
      "Training loss at epoch 186: 0.2073\n",
      "\n",
      "Start of epoch 187\n",
      "Training loss at epoch 187: 0.2069\n",
      "\n",
      "Start of epoch 188\n",
      "Training loss at epoch 188: 0.2066\n",
      "\n",
      "Start of epoch 189\n",
      "Training loss at epoch 189: 0.2062\n",
      "\n",
      "Start of epoch 190\n",
      "Training loss at epoch 190: 0.2058\n",
      "\n",
      "Start of epoch 191\n",
      "Training loss at epoch 191: 0.2054\n",
      "\n",
      "Start of epoch 192\n",
      "Training loss at epoch 192: 0.2051\n",
      "\n",
      "Start of epoch 193\n",
      "Training loss at epoch 193: 0.2047\n",
      "\n",
      "Start of epoch 194\n",
      "Training loss at epoch 194: 0.2043\n",
      "\n",
      "Start of epoch 195\n",
      "Training loss at epoch 195: 0.2039\n",
      "\n",
      "Start of epoch 196\n",
      "Training loss at epoch 196: 0.2036\n",
      "\n",
      "Start of epoch 197\n",
      "Training loss at epoch 197: 0.2033\n",
      "\n",
      "Start of epoch 198\n",
      "Training loss at epoch 198: 0.2029\n",
      "\n",
      "Start of epoch 199\n",
      "Training loss at epoch 199: 0.2026\n",
      "\n",
      "Start of epoch 200\n",
      "Training loss at epoch 200: 0.2023\n",
      "\n",
      "Start of epoch 201\n",
      "Training loss at epoch 201: 0.2020\n",
      "\n",
      "Start of epoch 202\n",
      "Training loss at epoch 202: 0.2017\n",
      "\n",
      "Start of epoch 203\n",
      "Training loss at epoch 203: 0.2014\n",
      "\n",
      "Start of epoch 204\n",
      "Training loss at epoch 204: 0.2012\n",
      "\n",
      "Start of epoch 205\n",
      "Training loss at epoch 205: 0.2009\n",
      "\n",
      "Start of epoch 206\n",
      "Training loss at epoch 206: 0.2007\n",
      "\n",
      "Start of epoch 207\n",
      "Training loss at epoch 207: 0.2004\n",
      "\n",
      "Start of epoch 208\n",
      "Training loss at epoch 208: 0.2002\n",
      "\n",
      "Start of epoch 209\n",
      "Training loss at epoch 209: 0.2000\n",
      "\n",
      "Start of epoch 210\n",
      "Training loss at epoch 210: 0.1998\n",
      "\n",
      "Start of epoch 211\n",
      "Training loss at epoch 211: 0.1996\n",
      "\n",
      "Start of epoch 212\n",
      "Training loss at epoch 212: 0.1994\n",
      "\n",
      "Start of epoch 213\n",
      "Training loss at epoch 213: 0.1992\n",
      "\n",
      "Start of epoch 214\n",
      "Training loss at epoch 214: 0.1990\n",
      "\n",
      "Start of epoch 215\n",
      "Training loss at epoch 215: 0.1988\n",
      "\n",
      "Start of epoch 216\n",
      "Training loss at epoch 216: 0.1987\n",
      "\n",
      "Start of epoch 217\n",
      "Training loss at epoch 217: 0.1985\n",
      "\n",
      "Start of epoch 218\n",
      "Training loss at epoch 218: 0.1984\n",
      "\n",
      "Start of epoch 219\n",
      "Training loss at epoch 219: 0.1982\n",
      "\n",
      "Start of epoch 220\n",
      "Training loss at epoch 220: 0.1981\n",
      "\n",
      "Start of epoch 221\n",
      "Training loss at epoch 221: 0.1979\n",
      "\n",
      "Start of epoch 222\n",
      "Training loss at epoch 222: 0.1978\n",
      "\n",
      "Start of epoch 223\n",
      "Training loss at epoch 223: 0.1976\n",
      "\n",
      "Start of epoch 224\n",
      "Training loss at epoch 224: 0.1975\n",
      "\n",
      "Start of epoch 225\n",
      "Training loss at epoch 225: 0.1973\n",
      "\n",
      "Start of epoch 226\n",
      "Training loss at epoch 226: 0.1972\n",
      "\n",
      "Start of epoch 227\n",
      "Training loss at epoch 227: 0.1970\n",
      "\n",
      "Start of epoch 228\n",
      "Training loss at epoch 228: 0.1969\n",
      "\n",
      "Start of epoch 229\n",
      "Training loss at epoch 229: 0.1968\n",
      "\n",
      "Start of epoch 230\n",
      "Training loss at epoch 230: 0.1966\n",
      "\n",
      "Start of epoch 231\n",
      "Training loss at epoch 231: 0.1965\n",
      "\n",
      "Start of epoch 232\n",
      "Training loss at epoch 232: 0.1963\n",
      "\n",
      "Start of epoch 233\n",
      "Training loss at epoch 233: 0.1962\n",
      "\n",
      "Start of epoch 234\n",
      "Training loss at epoch 234: 0.1961\n",
      "\n",
      "Start of epoch 235\n",
      "Training loss at epoch 235: 0.1959\n",
      "\n",
      "Start of epoch 236\n",
      "Training loss at epoch 236: 0.1958\n",
      "\n",
      "Start of epoch 237\n",
      "Training loss at epoch 237: 0.1956\n",
      "\n",
      "Start of epoch 238\n",
      "Training loss at epoch 238: 0.1955\n",
      "\n",
      "Start of epoch 239\n",
      "Training loss at epoch 239: 0.1954\n",
      "\n",
      "Start of epoch 240\n",
      "Training loss at epoch 240: 0.1952\n",
      "\n",
      "Start of epoch 241\n",
      "Training loss at epoch 241: 0.1951\n",
      "\n",
      "Start of epoch 242\n",
      "Training loss at epoch 242: 0.1950\n",
      "\n",
      "Start of epoch 243\n",
      "Training loss at epoch 243: 0.1948\n",
      "\n",
      "Start of epoch 244\n",
      "Training loss at epoch 244: 0.1947\n",
      "\n",
      "Start of epoch 245\n",
      "Training loss at epoch 245: 0.1946\n",
      "\n",
      "Start of epoch 246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 246: 0.1944\n",
      "\n",
      "Start of epoch 247\n",
      "Training loss at epoch 247: 0.1943\n",
      "\n",
      "Start of epoch 248\n",
      "Training loss at epoch 248: 0.1942\n",
      "\n",
      "Start of epoch 249\n",
      "Training loss at epoch 249: 0.1940\n",
      "\n",
      "Start of epoch 250\n",
      "Training loss at epoch 250: 0.1939\n",
      "\n",
      "Start of epoch 251\n",
      "Training loss at epoch 251: 0.1938\n",
      "\n",
      "Start of epoch 252\n",
      "Training loss at epoch 252: 0.1936\n",
      "\n",
      "Start of epoch 253\n",
      "Training loss at epoch 253: 0.1935\n",
      "\n",
      "Start of epoch 254\n",
      "Training loss at epoch 254: 0.1934\n",
      "\n",
      "Start of epoch 255\n",
      "Training loss at epoch 255: 0.1933\n",
      "\n",
      "Start of epoch 256\n",
      "Training loss at epoch 256: 0.1931\n",
      "\n",
      "Start of epoch 257\n",
      "Training loss at epoch 257: 0.1930\n",
      "\n",
      "Start of epoch 258\n",
      "Training loss at epoch 258: 0.1929\n",
      "\n",
      "Start of epoch 259\n",
      "Training loss at epoch 259: 0.1928\n",
      "\n",
      "Start of epoch 260\n",
      "Training loss at epoch 260: 0.1926\n",
      "\n",
      "Start of epoch 261\n",
      "Training loss at epoch 261: 0.1925\n",
      "\n",
      "Start of epoch 262\n",
      "Training loss at epoch 262: 0.1924\n",
      "\n",
      "Start of epoch 263\n",
      "Training loss at epoch 263: 0.1922\n",
      "\n",
      "Start of epoch 264\n",
      "Training loss at epoch 264: 0.1921\n",
      "\n",
      "Start of epoch 265\n",
      "Training loss at epoch 265: 0.1920\n",
      "\n",
      "Start of epoch 266\n",
      "Training loss at epoch 266: 0.1919\n",
      "\n",
      "Start of epoch 267\n",
      "Training loss at epoch 267: 0.1917\n",
      "\n",
      "Start of epoch 268\n",
      "Training loss at epoch 268: 0.1916\n",
      "\n",
      "Start of epoch 269\n",
      "Training loss at epoch 269: 0.1915\n",
      "\n",
      "Start of epoch 270\n",
      "Training loss at epoch 270: 0.1913\n",
      "\n",
      "Start of epoch 271\n",
      "Training loss at epoch 271: 0.1912\n",
      "\n",
      "Start of epoch 272\n",
      "Training loss at epoch 272: 0.1911\n",
      "\n",
      "Start of epoch 273\n",
      "Training loss at epoch 273: 0.1910\n",
      "\n",
      "Start of epoch 274\n",
      "Training loss at epoch 274: 0.1908\n",
      "\n",
      "Start of epoch 275\n",
      "Training loss at epoch 275: 0.1907\n",
      "\n",
      "Start of epoch 276\n",
      "Training loss at epoch 276: 0.1906\n",
      "\n",
      "Start of epoch 277\n",
      "Training loss at epoch 277: 0.1904\n",
      "\n",
      "Start of epoch 278\n",
      "Training loss at epoch 278: 0.1903\n",
      "\n",
      "Start of epoch 279\n",
      "Training loss at epoch 279: 0.1902\n",
      "\n",
      "Start of epoch 280\n",
      "Training loss at epoch 280: 0.1900\n",
      "\n",
      "Start of epoch 281\n",
      "Training loss at epoch 281: 0.1899\n",
      "\n",
      "Start of epoch 282\n",
      "Training loss at epoch 282: 0.1897\n",
      "\n",
      "Start of epoch 283\n",
      "Training loss at epoch 283: 0.1896\n",
      "\n",
      "Start of epoch 284\n",
      "Training loss at epoch 284: 0.1895\n",
      "\n",
      "Start of epoch 285\n",
      "Training loss at epoch 285: 0.1893\n",
      "\n",
      "Start of epoch 286\n",
      "Training loss at epoch 286: 0.1892\n",
      "\n",
      "Start of epoch 287\n",
      "Training loss at epoch 287: 0.1890\n",
      "\n",
      "Start of epoch 288\n",
      "Training loss at epoch 288: 0.1889\n",
      "\n",
      "Start of epoch 289\n",
      "Training loss at epoch 289: 0.1887\n",
      "\n",
      "Start of epoch 290\n",
      "Training loss at epoch 290: 0.1886\n",
      "\n",
      "Start of epoch 291\n",
      "Training loss at epoch 291: 0.1885\n",
      "\n",
      "Start of epoch 292\n",
      "Training loss at epoch 292: 0.1883\n",
      "\n",
      "Start of epoch 293\n",
      "Training loss at epoch 293: 0.1882\n",
      "\n",
      "Start of epoch 294\n",
      "Training loss at epoch 294: 0.1880\n",
      "\n",
      "Start of epoch 295\n",
      "Training loss at epoch 295: 0.1879\n",
      "\n",
      "Start of epoch 296\n",
      "Training loss at epoch 296: 0.1877\n",
      "\n",
      "Start of epoch 297\n",
      "Training loss at epoch 297: 0.1876\n",
      "\n",
      "Start of epoch 298\n",
      "Training loss at epoch 298: 0.1874\n",
      "\n",
      "Start of epoch 299\n",
      "Training loss at epoch 299: 0.1873\n",
      "\n",
      "Start of epoch 300\n",
      "Training loss at epoch 300: 0.1871\n",
      "\n",
      "Start of epoch 301\n",
      "Training loss at epoch 301: 0.1870\n",
      "\n",
      "Start of epoch 302\n",
      "Training loss at epoch 302: 0.1868\n",
      "\n",
      "Start of epoch 303\n",
      "Training loss at epoch 303: 0.1867\n",
      "\n",
      "Start of epoch 304\n",
      "Training loss at epoch 304: 0.1866\n",
      "\n",
      "Start of epoch 305\n",
      "Training loss at epoch 305: 0.1864\n",
      "\n",
      "Start of epoch 306\n",
      "Training loss at epoch 306: 0.1863\n",
      "\n",
      "Start of epoch 307\n",
      "Training loss at epoch 307: 0.1861\n",
      "\n",
      "Start of epoch 308\n",
      "Training loss at epoch 308: 0.1860\n",
      "\n",
      "Start of epoch 309\n",
      "Training loss at epoch 309: 0.1859\n",
      "\n",
      "Start of epoch 310\n",
      "Training loss at epoch 310: 0.1857\n",
      "\n",
      "Start of epoch 311\n",
      "Training loss at epoch 311: 0.1856\n",
      "\n",
      "Start of epoch 312\n",
      "Training loss at epoch 312: 0.1854\n",
      "\n",
      "Start of epoch 313\n",
      "Training loss at epoch 313: 0.1853\n",
      "\n",
      "Start of epoch 314\n",
      "Training loss at epoch 314: 0.1852\n",
      "\n",
      "Start of epoch 315\n",
      "Training loss at epoch 315: 0.1850\n",
      "\n",
      "Start of epoch 316\n",
      "Training loss at epoch 316: 0.1849\n",
      "\n",
      "Start of epoch 317\n",
      "Training loss at epoch 317: 0.1848\n",
      "\n",
      "Start of epoch 318\n",
      "Training loss at epoch 318: 0.1847\n",
      "\n",
      "Start of epoch 319\n",
      "Training loss at epoch 319: 0.1845\n",
      "\n",
      "Start of epoch 320\n",
      "Training loss at epoch 320: 0.1844\n",
      "\n",
      "Start of epoch 321\n",
      "Training loss at epoch 321: 0.1843\n",
      "\n",
      "Start of epoch 322\n",
      "Training loss at epoch 322: 0.1842\n",
      "\n",
      "Start of epoch 323\n",
      "Training loss at epoch 323: 0.1840\n",
      "\n",
      "Start of epoch 324\n",
      "Training loss at epoch 324: 0.1839\n",
      "\n",
      "Start of epoch 325\n",
      "Training loss at epoch 325: 0.1838\n",
      "\n",
      "Start of epoch 326\n",
      "Training loss at epoch 326: 0.1837\n",
      "\n",
      "Start of epoch 327\n",
      "Training loss at epoch 327: 0.1836\n",
      "\n",
      "Start of epoch 328\n",
      "Training loss at epoch 328: 0.1835\n",
      "\n",
      "Start of epoch 329\n",
      "Training loss at epoch 329: 0.1834\n",
      "\n",
      "Start of epoch 330\n",
      "Training loss at epoch 330: 0.1832\n",
      "\n",
      "Start of epoch 331\n",
      "Training loss at epoch 331: 0.1831\n",
      "\n",
      "Start of epoch 332\n",
      "Training loss at epoch 332: 0.1830\n",
      "\n",
      "Start of epoch 333\n",
      "Training loss at epoch 333: 0.1829\n",
      "\n",
      "Start of epoch 334\n",
      "Training loss at epoch 334: 0.1828\n",
      "\n",
      "Start of epoch 335\n",
      "Training loss at epoch 335: 0.1827\n",
      "\n",
      "Start of epoch 336\n",
      "Training loss at epoch 336: 0.1826\n",
      "\n",
      "Start of epoch 337\n",
      "Training loss at epoch 337: 0.1825\n",
      "\n",
      "Start of epoch 338\n",
      "Training loss at epoch 338: 0.1824\n",
      "\n",
      "Start of epoch 339\n",
      "Training loss at epoch 339: 0.1823\n",
      "\n",
      "Start of epoch 340\n",
      "Training loss at epoch 340: 0.1823\n",
      "\n",
      "Start of epoch 341\n",
      "Training loss at epoch 341: 0.1822\n",
      "\n",
      "Start of epoch 342\n",
      "Training loss at epoch 342: 0.1821\n",
      "\n",
      "Start of epoch 343\n",
      "Training loss at epoch 343: 0.1820\n",
      "\n",
      "Start of epoch 344\n",
      "Training loss at epoch 344: 0.1819\n",
      "\n",
      "Start of epoch 345\n",
      "Training loss at epoch 345: 0.1818\n",
      "\n",
      "Start of epoch 346\n",
      "Training loss at epoch 346: 0.1818\n",
      "\n",
      "Start of epoch 347\n",
      "Training loss at epoch 347: 0.1817\n",
      "\n",
      "Start of epoch 348\n",
      "Training loss at epoch 348: 0.1816\n",
      "\n",
      "Start of epoch 349\n",
      "Training loss at epoch 349: 0.1815\n",
      "\n",
      "Start of epoch 350\n",
      "Training loss at epoch 350: 0.1815\n",
      "\n",
      "Start of epoch 351\n",
      "Training loss at epoch 351: 0.1814\n",
      "\n",
      "Start of epoch 352\n",
      "Training loss at epoch 352: 0.1813\n",
      "\n",
      "Start of epoch 353\n",
      "Training loss at epoch 353: 0.1812\n",
      "\n",
      "Start of epoch 354\n",
      "Training loss at epoch 354: 0.1812\n",
      "\n",
      "Start of epoch 355\n",
      "Training loss at epoch 355: 0.1811\n",
      "\n",
      "Start of epoch 356\n",
      "Training loss at epoch 356: 0.1811\n",
      "\n",
      "Start of epoch 357\n",
      "Training loss at epoch 357: 0.1810\n",
      "\n",
      "Start of epoch 358\n",
      "Training loss at epoch 358: 0.1809\n",
      "\n",
      "Start of epoch 359\n",
      "Training loss at epoch 359: 0.1809\n",
      "\n",
      "Start of epoch 360\n",
      "Training loss at epoch 360: 0.1808\n",
      "\n",
      "Start of epoch 361\n",
      "Training loss at epoch 361: 0.1808\n",
      "\n",
      "Start of epoch 362\n",
      "Training loss at epoch 362: 0.1807\n",
      "\n",
      "Start of epoch 363\n",
      "Training loss at epoch 363: 0.1807\n",
      "\n",
      "Start of epoch 364\n",
      "Training loss at epoch 364: 0.1806\n",
      "\n",
      "Start of epoch 365\n",
      "Training loss at epoch 365: 0.1806\n",
      "\n",
      "Start of epoch 366\n",
      "Training loss at epoch 366: 0.1805\n",
      "\n",
      "Start of epoch 367\n",
      "Training loss at epoch 367: 0.1805\n",
      "\n",
      "Start of epoch 368\n",
      "Training loss at epoch 368: 0.1804\n",
      "\n",
      "Start of epoch 369\n",
      "Training loss at epoch 369: 0.1804\n",
      "\n",
      "Start of epoch 370\n",
      "Training loss at epoch 370: 0.1804\n",
      "\n",
      "Start of epoch 371\n",
      "Training loss at epoch 371: 0.1803\n",
      "\n",
      "Start of epoch 372\n",
      "Training loss at epoch 372: 0.1803\n",
      "\n",
      "Start of epoch 373\n",
      "Training loss at epoch 373: 0.1802\n",
      "\n",
      "Start of epoch 374\n",
      "Training loss at epoch 374: 0.1802\n",
      "\n",
      "Start of epoch 375\n",
      "Training loss at epoch 375: 0.1802\n",
      "\n",
      "Start of epoch 376\n",
      "Training loss at epoch 376: 0.1801\n",
      "\n",
      "Start of epoch 377\n",
      "Training loss at epoch 377: 0.1801\n",
      "\n",
      "Start of epoch 378\n",
      "Training loss at epoch 378: 0.1801\n",
      "\n",
      "Start of epoch 379\n",
      "Training loss at epoch 379: 0.1800\n",
      "\n",
      "Start of epoch 380\n",
      "Training loss at epoch 380: 0.1800\n",
      "\n",
      "Start of epoch 381\n",
      "Training loss at epoch 381: 0.1800\n",
      "\n",
      "Start of epoch 382\n",
      "Training loss at epoch 382: 0.1799\n",
      "\n",
      "Start of epoch 383\n",
      "Training loss at epoch 383: 0.1799\n",
      "\n",
      "Start of epoch 384\n",
      "Training loss at epoch 384: 0.1799\n",
      "\n",
      "Start of epoch 385\n",
      "Training loss at epoch 385: 0.1798\n",
      "\n",
      "Start of epoch 386\n",
      "Training loss at epoch 386: 0.1798\n",
      "\n",
      "Start of epoch 387\n",
      "Training loss at epoch 387: 0.1798\n",
      "\n",
      "Start of epoch 388\n",
      "Training loss at epoch 388: 0.1798\n",
      "\n",
      "Start of epoch 389\n",
      "Training loss at epoch 389: 0.1797\n",
      "\n",
      "Start of epoch 390\n",
      "Training loss at epoch 390: 0.1797\n",
      "\n",
      "Start of epoch 391\n",
      "Training loss at epoch 391: 0.1797\n",
      "\n",
      "Start of epoch 392\n",
      "Training loss at epoch 392: 0.1797\n",
      "\n",
      "Start of epoch 393\n",
      "Training loss at epoch 393: 0.1796\n",
      "\n",
      "Start of epoch 394\n",
      "Training loss at epoch 394: 0.1796\n",
      "\n",
      "Start of epoch 395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 395: 0.1796\n",
      "\n",
      "Start of epoch 396\n",
      "Training loss at epoch 396: 0.1796\n",
      "\n",
      "Start of epoch 397\n",
      "Training loss at epoch 397: 0.1796\n",
      "\n",
      "Start of epoch 398\n",
      "Training loss at epoch 398: 0.1795\n",
      "\n",
      "Start of epoch 399\n",
      "Training loss at epoch 399: 0.1795\n",
      "\n",
      "Start of epoch 400\n",
      "Training loss at epoch 400: 0.1795\n",
      "\n",
      "Start of epoch 401\n",
      "Training loss at epoch 401: 0.1795\n",
      "\n",
      "Start of epoch 402\n",
      "Training loss at epoch 402: 0.1795\n",
      "\n",
      "Start of epoch 403\n",
      "Training loss at epoch 403: 0.1794\n",
      "\n",
      "Start of epoch 404\n",
      "Training loss at epoch 404: 0.1794\n",
      "\n",
      "Start of epoch 405\n",
      "Training loss at epoch 405: 0.1794\n",
      "\n",
      "Start of epoch 406\n",
      "Training loss at epoch 406: 0.1794\n",
      "\n",
      "Start of epoch 407\n",
      "Training loss at epoch 407: 0.1794\n",
      "\n",
      "Start of epoch 408\n",
      "Training loss at epoch 408: 0.1793\n",
      "\n",
      "Start of epoch 409\n",
      "Training loss at epoch 409: 0.1793\n",
      "\n",
      "Start of epoch 410\n",
      "Training loss at epoch 410: 0.1793\n",
      "\n",
      "Start of epoch 411\n",
      "Training loss at epoch 411: 0.1793\n",
      "\n",
      "Start of epoch 412\n",
      "Training loss at epoch 412: 0.1793\n",
      "\n",
      "Start of epoch 413\n",
      "Training loss at epoch 413: 0.1793\n",
      "\n",
      "Start of epoch 414\n",
      "Training loss at epoch 414: 0.1793\n",
      "\n",
      "Start of epoch 415\n",
      "Training loss at epoch 415: 0.1792\n",
      "\n",
      "Start of epoch 416\n",
      "Training loss at epoch 416: 0.1792\n",
      "\n",
      "Start of epoch 417\n",
      "Training loss at epoch 417: 0.1792\n",
      "\n",
      "Start of epoch 418\n",
      "Training loss at epoch 418: 0.1792\n",
      "\n",
      "Start of epoch 419\n",
      "Training loss at epoch 419: 0.1792\n",
      "\n",
      "Start of epoch 420\n",
      "Training loss at epoch 420: 0.1792\n",
      "\n",
      "Start of epoch 421\n",
      "Training loss at epoch 421: 0.1792\n",
      "\n",
      "Start of epoch 422\n",
      "Training loss at epoch 422: 0.1791\n",
      "\n",
      "Start of epoch 423\n",
      "Training loss at epoch 423: 0.1791\n",
      "\n",
      "Start of epoch 424\n",
      "Training loss at epoch 424: 0.1791\n",
      "\n",
      "Start of epoch 425\n",
      "Training loss at epoch 425: 0.1791\n",
      "\n",
      "Start of epoch 426\n",
      "Training loss at epoch 426: 0.1791\n",
      "\n",
      "Start of epoch 427\n",
      "Training loss at epoch 427: 0.1791\n",
      "\n",
      "Start of epoch 428\n",
      "Training loss at epoch 428: 0.1791\n",
      "\n",
      "Start of epoch 429\n",
      "Training loss at epoch 429: 0.1791\n",
      "\n",
      "Start of epoch 430\n",
      "Training loss at epoch 430: 0.1791\n",
      "\n",
      "Start of epoch 431\n",
      "Training loss at epoch 431: 0.1790\n",
      "\n",
      "Start of epoch 432\n",
      "Training loss at epoch 432: 0.1790\n",
      "\n",
      "Start of epoch 433\n",
      "Training loss at epoch 433: 0.1790\n",
      "\n",
      "Start of epoch 434\n",
      "Training loss at epoch 434: 0.1790\n",
      "\n",
      "Start of epoch 435\n",
      "Training loss at epoch 435: 0.1790\n",
      "\n",
      "Start of epoch 436\n",
      "Training loss at epoch 436: 0.1790\n",
      "\n",
      "Start of epoch 437\n",
      "Training loss at epoch 437: 0.1790\n",
      "\n",
      "Start of epoch 438\n",
      "Training loss at epoch 438: 0.1790\n",
      "\n",
      "Start of epoch 439\n",
      "Training loss at epoch 439: 0.1790\n",
      "\n",
      "Start of epoch 440\n",
      "Training loss at epoch 440: 0.1790\n",
      "\n",
      "Start of epoch 441\n",
      "Training loss at epoch 441: 0.1789\n",
      "\n",
      "Start of epoch 442\n",
      "Training loss at epoch 442: 0.1789\n",
      "\n",
      "Start of epoch 443\n",
      "Training loss at epoch 443: 0.1789\n",
      "\n",
      "Start of epoch 444\n",
      "Training loss at epoch 444: 0.1789\n",
      "\n",
      "Start of epoch 445\n",
      "Training loss at epoch 445: 0.1789\n",
      "\n",
      "Start of epoch 446\n",
      "Training loss at epoch 446: 0.1789\n",
      "\n",
      "Start of epoch 447\n",
      "Training loss at epoch 447: 0.1789\n",
      "\n",
      "Start of epoch 448\n",
      "Training loss at epoch 448: 0.1789\n",
      "\n",
      "Start of epoch 449\n",
      "Training loss at epoch 449: 0.1789\n",
      "\n",
      "Start of epoch 450\n",
      "Training loss at epoch 450: 0.1789\n",
      "\n",
      "Start of epoch 451\n",
      "Training loss at epoch 451: 0.1789\n",
      "\n",
      "Start of epoch 452\n",
      "Training loss at epoch 452: 0.1789\n",
      "\n",
      "Start of epoch 453\n",
      "Training loss at epoch 453: 0.1788\n",
      "\n",
      "Start of epoch 454\n",
      "Training loss at epoch 454: 0.1788\n",
      "\n",
      "Start of epoch 455\n",
      "Training loss at epoch 455: 0.1788\n",
      "\n",
      "Start of epoch 456\n",
      "Training loss at epoch 456: 0.1788\n",
      "\n",
      "Start of epoch 457\n",
      "Training loss at epoch 457: 0.1788\n",
      "\n",
      "Start of epoch 458\n",
      "Training loss at epoch 458: 0.1788\n",
      "\n",
      "Start of epoch 459\n",
      "Training loss at epoch 459: 0.1788\n",
      "\n",
      "Start of epoch 460\n",
      "Training loss at epoch 460: 0.1788\n",
      "\n",
      "Start of epoch 461\n",
      "Training loss at epoch 461: 0.1788\n",
      "\n",
      "Start of epoch 462\n",
      "Training loss at epoch 462: 0.1788\n",
      "\n",
      "Start of epoch 463\n",
      "Training loss at epoch 463: 0.1788\n",
      "\n",
      "Start of epoch 464\n",
      "Training loss at epoch 464: 0.1788\n",
      "\n",
      "Start of epoch 465\n",
      "Training loss at epoch 465: 0.1788\n",
      "\n",
      "Start of epoch 466\n",
      "Training loss at epoch 466: 0.1788\n",
      "\n",
      "Start of epoch 467\n",
      "Training loss at epoch 467: 0.1787\n",
      "\n",
      "Start of epoch 468\n",
      "Training loss at epoch 468: 0.1787\n",
      "\n",
      "Start of epoch 469\n",
      "Training loss at epoch 469: 0.1787\n",
      "\n",
      "Start of epoch 470\n",
      "Training loss at epoch 470: 0.1787\n",
      "\n",
      "Start of epoch 471\n",
      "Training loss at epoch 471: 0.1787\n",
      "\n",
      "Start of epoch 472\n",
      "Training loss at epoch 472: 0.1787\n",
      "\n",
      "Start of epoch 473\n",
      "Training loss at epoch 473: 0.1787\n",
      "\n",
      "Start of epoch 474\n",
      "Training loss at epoch 474: 0.1787\n",
      "\n",
      "Start of epoch 475\n",
      "Training loss at epoch 475: 0.1787\n",
      "\n",
      "Start of epoch 476\n",
      "Training loss at epoch 476: 0.1787\n",
      "\n",
      "Start of epoch 477\n",
      "Training loss at epoch 477: 0.1787\n",
      "\n",
      "Start of epoch 478\n",
      "Training loss at epoch 478: 0.1787\n",
      "\n",
      "Start of epoch 479\n",
      "Training loss at epoch 479: 0.1787\n",
      "\n",
      "Start of epoch 480\n",
      "Training loss at epoch 480: 0.1787\n",
      "\n",
      "Start of epoch 481\n",
      "Training loss at epoch 481: 0.1787\n",
      "\n",
      "Start of epoch 482\n",
      "Training loss at epoch 482: 0.1787\n",
      "\n",
      "Start of epoch 483\n",
      "Training loss at epoch 483: 0.1786\n",
      "\n",
      "Start of epoch 484\n",
      "Training loss at epoch 484: 0.1786\n",
      "\n",
      "Start of epoch 485\n",
      "Training loss at epoch 485: 0.1786\n",
      "\n",
      "Start of epoch 486\n",
      "Training loss at epoch 486: 0.1786\n",
      "\n",
      "Start of epoch 487\n",
      "Training loss at epoch 487: 0.1786\n",
      "\n",
      "Start of epoch 488\n",
      "Training loss at epoch 488: 0.1786\n",
      "\n",
      "Start of epoch 489\n",
      "Training loss at epoch 489: 0.1786\n",
      "\n",
      "Start of epoch 490\n",
      "Training loss at epoch 490: 0.1786\n",
      "\n",
      "Start of epoch 491\n",
      "Training loss at epoch 491: 0.1786\n",
      "\n",
      "Start of epoch 492\n",
      "Training loss at epoch 492: 0.1786\n",
      "\n",
      "Start of epoch 493\n",
      "Training loss at epoch 493: 0.1786\n",
      "\n",
      "Start of epoch 494\n",
      "Training loss at epoch 494: 0.1786\n",
      "\n",
      "Start of epoch 495\n",
      "Training loss at epoch 495: 0.1786\n",
      "\n",
      "Start of epoch 496\n",
      "Training loss at epoch 496: 0.1786\n",
      "\n",
      "Start of epoch 497\n",
      "Training loss at epoch 497: 0.1786\n",
      "\n",
      "Start of epoch 498\n",
      "Training loss at epoch 498: 0.1786\n",
      "\n",
      "Start of epoch 499\n",
      "Training loss at epoch 499: 0.1786\n",
      "[<tf.Variable 'parameters:0' shape=(60,) dtype=float32, numpy=\n",
      "array([2.04321  , 4.0231943, 4.325763 , 4.512126 , 6.2555604, 4.395446 ,\n",
      "       1.6192224, 3.9987638, 2.5673685, 5.640563 , 6.042333 , 6.1935587,\n",
      "       2.4081604, 1.4729077, 3.2051952, 4.1324635, 5.858535 , 2.485288 ,\n",
      "       1.4966567, 6.2751374, 4.0988717, 5.6323333, 3.0097709, 1.665635 ,\n",
      "       6.003474 , 3.928495 , 5.497338 , 3.3974888, 5.1819572, 5.1074677,\n",
      "       6.051938 , 6.2252374, 5.176177 , 6.2767305, 2.1704938, 5.6880937,\n",
      "       2.137997 , 2.5728874, 2.5026417, 4.42675  , 0.7290648, 4.630127 ,\n",
      "       1.472125 , 4.8059816, 4.332599 , 4.750284 , 3.21645  , 2.9937532,\n",
      "       1.5097338, 0.1253138, 4.8856854, 2.3560784, 1.8928552, 5.2311187,\n",
      "       5.272    , 5.4201174, 6.2565923, 5.6952868, 4.318882 , 0.7431126],\n",
      "      dtype=float32)>]\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.0749\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 0.9292\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.8303\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.7830\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.7632\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.7488\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.7348\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.7220\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.7109\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.6999\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.6874\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.6736\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.6599\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.6474\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.6363\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.6260\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.6161\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.6064\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.5972\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.5886\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.5806\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.5729\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.5652\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.5574\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.5492\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.5407\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.5320\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.5232\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.5148\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.5072\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.5006\n",
      "\n",
      "Start of epoch 31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 31: 0.4951\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.4906\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.4867\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.4831\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.4792\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.4746\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.4694\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.4641\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.4590\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.4546\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.4510\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.4478\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.4449\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.4417\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.4381\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.4341\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.4295\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.4248\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.4198\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.4149\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.4099\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.4048\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.3998\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.3950\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.3905\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.3864\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.3826\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.3790\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.3755\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.3720\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.3686\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.3651\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.3618\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.3585\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.3554\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.3522\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.3489\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.3457\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.3425\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.3395\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.3368\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.3344\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.3322\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.3303\n",
      "\n",
      "Start of epoch 75\n",
      "Training loss at epoch 75: 0.3285\n",
      "\n",
      "Start of epoch 76\n",
      "Training loss at epoch 76: 0.3268\n",
      "\n",
      "Start of epoch 77\n",
      "Training loss at epoch 77: 0.3253\n",
      "\n",
      "Start of epoch 78\n",
      "Training loss at epoch 78: 0.3238\n",
      "\n",
      "Start of epoch 79\n",
      "Training loss at epoch 79: 0.3224\n",
      "\n",
      "Start of epoch 80\n",
      "Training loss at epoch 80: 0.3210\n",
      "\n",
      "Start of epoch 81\n",
      "Training loss at epoch 81: 0.3197\n",
      "\n",
      "Start of epoch 82\n",
      "Training loss at epoch 82: 0.3183\n",
      "\n",
      "Start of epoch 83\n",
      "Training loss at epoch 83: 0.3169\n",
      "\n",
      "Start of epoch 84\n",
      "Training loss at epoch 84: 0.3154\n",
      "\n",
      "Start of epoch 85\n",
      "Training loss at epoch 85: 0.3140\n",
      "\n",
      "Start of epoch 86\n",
      "Training loss at epoch 86: 0.3125\n",
      "\n",
      "Start of epoch 87\n",
      "Training loss at epoch 87: 0.3112\n",
      "\n",
      "Start of epoch 88\n",
      "Training loss at epoch 88: 0.3099\n",
      "\n",
      "Start of epoch 89\n",
      "Training loss at epoch 89: 0.3087\n",
      "\n",
      "Start of epoch 90\n",
      "Training loss at epoch 90: 0.3076\n",
      "\n",
      "Start of epoch 91\n",
      "Training loss at epoch 91: 0.3065\n",
      "\n",
      "Start of epoch 92\n",
      "Training loss at epoch 92: 0.3055\n",
      "\n",
      "Start of epoch 93\n",
      "Training loss at epoch 93: 0.3046\n",
      "\n",
      "Start of epoch 94\n",
      "Training loss at epoch 94: 0.3037\n",
      "\n",
      "Start of epoch 95\n",
      "Training loss at epoch 95: 0.3029\n",
      "\n",
      "Start of epoch 96\n",
      "Training loss at epoch 96: 0.3021\n",
      "\n",
      "Start of epoch 97\n",
      "Training loss at epoch 97: 0.3013\n",
      "\n",
      "Start of epoch 98\n",
      "Training loss at epoch 98: 0.3006\n",
      "\n",
      "Start of epoch 99\n",
      "Training loss at epoch 99: 0.2999\n",
      "\n",
      "Start of epoch 100\n",
      "Training loss at epoch 100: 0.2993\n",
      "\n",
      "Start of epoch 101\n",
      "Training loss at epoch 101: 0.2987\n",
      "\n",
      "Start of epoch 102\n",
      "Training loss at epoch 102: 0.2981\n",
      "\n",
      "Start of epoch 103\n",
      "Training loss at epoch 103: 0.2975\n",
      "\n",
      "Start of epoch 104\n",
      "Training loss at epoch 104: 0.2970\n",
      "\n",
      "Start of epoch 105\n",
      "Training loss at epoch 105: 0.2964\n",
      "\n",
      "Start of epoch 106\n",
      "Training loss at epoch 106: 0.2959\n",
      "\n",
      "Start of epoch 107\n",
      "Training loss at epoch 107: 0.2953\n",
      "\n",
      "Start of epoch 108\n",
      "Training loss at epoch 108: 0.2947\n",
      "\n",
      "Start of epoch 109\n",
      "Training loss at epoch 109: 0.2940\n",
      "\n",
      "Start of epoch 110\n",
      "Training loss at epoch 110: 0.2934\n",
      "\n",
      "Start of epoch 111\n",
      "Training loss at epoch 111: 0.2927\n",
      "\n",
      "Start of epoch 112\n",
      "Training loss at epoch 112: 0.2919\n",
      "\n",
      "Start of epoch 113\n",
      "Training loss at epoch 113: 0.2911\n",
      "\n",
      "Start of epoch 114\n",
      "Training loss at epoch 114: 0.2903\n",
      "\n",
      "Start of epoch 115\n",
      "Training loss at epoch 115: 0.2894\n",
      "\n",
      "Start of epoch 116\n",
      "Training loss at epoch 116: 0.2885\n",
      "\n",
      "Start of epoch 117\n",
      "Training loss at epoch 117: 0.2876\n",
      "\n",
      "Start of epoch 118\n",
      "Training loss at epoch 118: 0.2866\n",
      "\n",
      "Start of epoch 119\n",
      "Training loss at epoch 119: 0.2856\n",
      "\n",
      "Start of epoch 120\n",
      "Training loss at epoch 120: 0.2845\n",
      "\n",
      "Start of epoch 121\n",
      "Training loss at epoch 121: 0.2835\n",
      "\n",
      "Start of epoch 122\n",
      "Training loss at epoch 122: 0.2824\n",
      "\n",
      "Start of epoch 123\n",
      "Training loss at epoch 123: 0.2813\n",
      "\n",
      "Start of epoch 124\n",
      "Training loss at epoch 124: 0.2802\n",
      "\n",
      "Start of epoch 125\n",
      "Training loss at epoch 125: 0.2791\n",
      "\n",
      "Start of epoch 126\n",
      "Training loss at epoch 126: 0.2781\n",
      "\n",
      "Start of epoch 127\n",
      "Training loss at epoch 127: 0.2770\n",
      "\n",
      "Start of epoch 128\n",
      "Training loss at epoch 128: 0.2760\n",
      "\n",
      "Start of epoch 129\n",
      "Training loss at epoch 129: 0.2751\n",
      "\n",
      "Start of epoch 130\n",
      "Training loss at epoch 130: 0.2742\n",
      "\n",
      "Start of epoch 131\n",
      "Training loss at epoch 131: 0.2733\n",
      "\n",
      "Start of epoch 132\n",
      "Training loss at epoch 132: 0.2725\n",
      "\n",
      "Start of epoch 133\n",
      "Training loss at epoch 133: 0.2717\n",
      "\n",
      "Start of epoch 134\n",
      "Training loss at epoch 134: 0.2710\n",
      "\n",
      "Start of epoch 135\n",
      "Training loss at epoch 135: 0.2703\n",
      "\n",
      "Start of epoch 136\n",
      "Training loss at epoch 136: 0.2696\n",
      "\n",
      "Start of epoch 137\n",
      "Training loss at epoch 137: 0.2690\n",
      "\n",
      "Start of epoch 138\n",
      "Training loss at epoch 138: 0.2684\n",
      "\n",
      "Start of epoch 139\n",
      "Training loss at epoch 139: 0.2678\n",
      "\n",
      "Start of epoch 140\n",
      "Training loss at epoch 140: 0.2673\n",
      "\n",
      "Start of epoch 141\n",
      "Training loss at epoch 141: 0.2668\n",
      "\n",
      "Start of epoch 142\n",
      "Training loss at epoch 142: 0.2663\n",
      "\n",
      "Start of epoch 143\n",
      "Training loss at epoch 143: 0.2659\n",
      "\n",
      "Start of epoch 144\n",
      "Training loss at epoch 144: 0.2655\n",
      "\n",
      "Start of epoch 145\n",
      "Training loss at epoch 145: 0.2651\n",
      "\n",
      "Start of epoch 146\n",
      "Training loss at epoch 146: 0.2648\n",
      "\n",
      "Start of epoch 147\n",
      "Training loss at epoch 147: 0.2645\n",
      "\n",
      "Start of epoch 148\n",
      "Training loss at epoch 148: 0.2642\n",
      "\n",
      "Start of epoch 149\n",
      "Training loss at epoch 149: 0.2639\n",
      "\n",
      "Start of epoch 150\n",
      "Training loss at epoch 150: 0.2637\n",
      "\n",
      "Start of epoch 151\n",
      "Training loss at epoch 151: 0.2634\n",
      "\n",
      "Start of epoch 152\n",
      "Training loss at epoch 152: 0.2632\n",
      "\n",
      "Start of epoch 153\n",
      "Training loss at epoch 153: 0.2631\n",
      "\n",
      "Start of epoch 154\n",
      "Training loss at epoch 154: 0.2629\n",
      "\n",
      "Start of epoch 155\n",
      "Training loss at epoch 155: 0.2628\n",
      "\n",
      "Start of epoch 156\n",
      "Training loss at epoch 156: 0.2626\n",
      "\n",
      "Start of epoch 157\n",
      "Training loss at epoch 157: 0.2625\n",
      "\n",
      "Start of epoch 158\n",
      "Training loss at epoch 158: 0.2624\n",
      "\n",
      "Start of epoch 159\n",
      "Training loss at epoch 159: 0.2623\n",
      "\n",
      "Start of epoch 160\n",
      "Training loss at epoch 160: 0.2622\n",
      "\n",
      "Start of epoch 161\n",
      "Training loss at epoch 161: 0.2621\n",
      "\n",
      "Start of epoch 162\n",
      "Training loss at epoch 162: 0.2620\n",
      "\n",
      "Start of epoch 163\n",
      "Training loss at epoch 163: 0.2620\n",
      "\n",
      "Start of epoch 164\n",
      "Training loss at epoch 164: 0.2619\n",
      "\n",
      "Start of epoch 165\n",
      "Training loss at epoch 165: 0.2618\n",
      "\n",
      "Start of epoch 166\n",
      "Training loss at epoch 166: 0.2618\n",
      "\n",
      "Start of epoch 167\n",
      "Training loss at epoch 167: 0.2617\n",
      "\n",
      "Start of epoch 168\n",
      "Training loss at epoch 168: 0.2617\n",
      "\n",
      "Start of epoch 169\n",
      "Training loss at epoch 169: 0.2616\n",
      "\n",
      "Start of epoch 170\n",
      "Training loss at epoch 170: 0.2616\n",
      "\n",
      "Start of epoch 171\n",
      "Training loss at epoch 171: 0.2615\n",
      "\n",
      "Start of epoch 172\n",
      "Training loss at epoch 172: 0.2615\n",
      "\n",
      "Start of epoch 173\n",
      "Training loss at epoch 173: 0.2614\n",
      "\n",
      "Start of epoch 174\n",
      "Training loss at epoch 174: 0.2614\n",
      "\n",
      "Start of epoch 175\n",
      "Training loss at epoch 175: 0.2614\n",
      "\n",
      "Start of epoch 176\n",
      "Training loss at epoch 176: 0.2613\n",
      "\n",
      "Start of epoch 177\n",
      "Training loss at epoch 177: 0.2613\n",
      "\n",
      "Start of epoch 178\n",
      "Training loss at epoch 178: 0.2612\n",
      "\n",
      "Start of epoch 179\n",
      "Training loss at epoch 179: 0.2612\n",
      "\n",
      "Start of epoch 180\n",
      "Training loss at epoch 180: 0.2612\n",
      "\n",
      "Start of epoch 181\n",
      "Training loss at epoch 181: 0.2611\n",
      "\n",
      "Start of epoch 182\n",
      "Training loss at epoch 182: 0.2611\n",
      "\n",
      "Start of epoch 183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 183: 0.2611\n",
      "\n",
      "Start of epoch 184\n",
      "Training loss at epoch 184: 0.2610\n",
      "\n",
      "Start of epoch 185\n",
      "Training loss at epoch 185: 0.2610\n",
      "\n",
      "Start of epoch 186\n",
      "Training loss at epoch 186: 0.2610\n",
      "\n",
      "Start of epoch 187\n",
      "Training loss at epoch 187: 0.2609\n",
      "\n",
      "Start of epoch 188\n",
      "Training loss at epoch 188: 0.2609\n",
      "\n",
      "Start of epoch 189\n",
      "Training loss at epoch 189: 0.2609\n",
      "\n",
      "Start of epoch 190\n",
      "Training loss at epoch 190: 0.2608\n",
      "\n",
      "Start of epoch 191\n",
      "Training loss at epoch 191: 0.2608\n",
      "\n",
      "Start of epoch 192\n",
      "Training loss at epoch 192: 0.2608\n",
      "\n",
      "Start of epoch 193\n",
      "Training loss at epoch 193: 0.2607\n",
      "\n",
      "Start of epoch 194\n",
      "Training loss at epoch 194: 0.2607\n",
      "\n",
      "Start of epoch 195\n",
      "Training loss at epoch 195: 0.2607\n",
      "\n",
      "Start of epoch 196\n",
      "Training loss at epoch 196: 0.2607\n",
      "\n",
      "Start of epoch 197\n",
      "Training loss at epoch 197: 0.2606\n",
      "\n",
      "Start of epoch 198\n",
      "Training loss at epoch 198: 0.2606\n",
      "\n",
      "Start of epoch 199\n",
      "Training loss at epoch 199: 0.2606\n",
      "\n",
      "Start of epoch 200\n",
      "Training loss at epoch 200: 0.2605\n",
      "\n",
      "Start of epoch 201\n",
      "Training loss at epoch 201: 0.2605\n",
      "\n",
      "Start of epoch 202\n",
      "Training loss at epoch 202: 0.2605\n",
      "\n",
      "Start of epoch 203\n",
      "Training loss at epoch 203: 0.2605\n",
      "\n",
      "Start of epoch 204\n",
      "Training loss at epoch 204: 0.2604\n",
      "\n",
      "Start of epoch 205\n",
      "Training loss at epoch 205: 0.2604\n",
      "\n",
      "Start of epoch 206\n",
      "Training loss at epoch 206: 0.2604\n",
      "\n",
      "Start of epoch 207\n",
      "Training loss at epoch 207: 0.2603\n",
      "\n",
      "Start of epoch 208\n",
      "Training loss at epoch 208: 0.2603\n",
      "\n",
      "Start of epoch 209\n",
      "Training loss at epoch 209: 0.2603\n",
      "\n",
      "Start of epoch 210\n",
      "Training loss at epoch 210: 0.2603\n",
      "\n",
      "Start of epoch 211\n",
      "Training loss at epoch 211: 0.2602\n",
      "\n",
      "Start of epoch 212\n",
      "Training loss at epoch 212: 0.2602\n",
      "\n",
      "Start of epoch 213\n",
      "Training loss at epoch 213: 0.2602\n",
      "\n",
      "Start of epoch 214\n",
      "Training loss at epoch 214: 0.2602\n",
      "\n",
      "Start of epoch 215\n",
      "Training loss at epoch 215: 0.2601\n",
      "\n",
      "Start of epoch 216\n",
      "Training loss at epoch 216: 0.2601\n",
      "\n",
      "Start of epoch 217\n",
      "Training loss at epoch 217: 0.2601\n",
      "\n",
      "Start of epoch 218\n",
      "Training loss at epoch 218: 0.2600\n",
      "\n",
      "Start of epoch 219\n",
      "Training loss at epoch 219: 0.2600\n",
      "\n",
      "Start of epoch 220\n",
      "Training loss at epoch 220: 0.2600\n",
      "\n",
      "Start of epoch 221\n",
      "Training loss at epoch 221: 0.2600\n",
      "\n",
      "Start of epoch 222\n",
      "Training loss at epoch 222: 0.2599\n",
      "\n",
      "Start of epoch 223\n",
      "Training loss at epoch 223: 0.2599\n",
      "\n",
      "Start of epoch 224\n",
      "Training loss at epoch 224: 0.2599\n",
      "\n",
      "Start of epoch 225\n",
      "Training loss at epoch 225: 0.2599\n",
      "\n",
      "Start of epoch 226\n",
      "Training loss at epoch 226: 0.2598\n",
      "\n",
      "Start of epoch 227\n",
      "Training loss at epoch 227: 0.2598\n",
      "\n",
      "Start of epoch 228\n",
      "Training loss at epoch 228: 0.2598\n",
      "\n",
      "Start of epoch 229\n",
      "Training loss at epoch 229: 0.2597\n",
      "\n",
      "Start of epoch 230\n",
      "Training loss at epoch 230: 0.2597\n",
      "\n",
      "Start of epoch 231\n",
      "Training loss at epoch 231: 0.2597\n",
      "\n",
      "Start of epoch 232\n",
      "Training loss at epoch 232: 0.2597\n",
      "\n",
      "Start of epoch 233\n",
      "Training loss at epoch 233: 0.2596\n",
      "\n",
      "Start of epoch 234\n",
      "Training loss at epoch 234: 0.2596\n",
      "\n",
      "Start of epoch 235\n",
      "Training loss at epoch 235: 0.2596\n",
      "\n",
      "Start of epoch 236\n",
      "Training loss at epoch 236: 0.2595\n",
      "\n",
      "Start of epoch 237\n",
      "Training loss at epoch 237: 0.2595\n",
      "\n",
      "Start of epoch 238\n",
      "Training loss at epoch 238: 0.2595\n",
      "\n",
      "Start of epoch 239\n",
      "Training loss at epoch 239: 0.2595\n",
      "\n",
      "Start of epoch 240\n",
      "Training loss at epoch 240: 0.2594\n",
      "\n",
      "Start of epoch 241\n",
      "Training loss at epoch 241: 0.2594\n",
      "\n",
      "Start of epoch 242\n",
      "Training loss at epoch 242: 0.2594\n",
      "\n",
      "Start of epoch 243\n",
      "Training loss at epoch 243: 0.2593\n",
      "\n",
      "Start of epoch 244\n",
      "Training loss at epoch 244: 0.2593\n",
      "\n",
      "Start of epoch 245\n",
      "Training loss at epoch 245: 0.2593\n",
      "\n",
      "Start of epoch 246\n",
      "Training loss at epoch 246: 0.2592\n",
      "\n",
      "Start of epoch 247\n",
      "Training loss at epoch 247: 0.2592\n",
      "\n",
      "Start of epoch 248\n",
      "Training loss at epoch 248: 0.2592\n",
      "\n",
      "Start of epoch 249\n",
      "Training loss at epoch 249: 0.2591\n",
      "\n",
      "Start of epoch 250\n",
      "Training loss at epoch 250: 0.2591\n",
      "\n",
      "Start of epoch 251\n",
      "Training loss at epoch 251: 0.2591\n",
      "\n",
      "Start of epoch 252\n",
      "Training loss at epoch 252: 0.2590\n",
      "\n",
      "Start of epoch 253\n",
      "Training loss at epoch 253: 0.2590\n",
      "\n",
      "Start of epoch 254\n",
      "Training loss at epoch 254: 0.2590\n",
      "\n",
      "Start of epoch 255\n",
      "Training loss at epoch 255: 0.2589\n",
      "\n",
      "Start of epoch 256\n",
      "Training loss at epoch 256: 0.2589\n",
      "\n",
      "Start of epoch 257\n",
      "Training loss at epoch 257: 0.2589\n",
      "\n",
      "Start of epoch 258\n",
      "Training loss at epoch 258: 0.2588\n",
      "\n",
      "Start of epoch 259\n",
      "Training loss at epoch 259: 0.2588\n",
      "\n",
      "Start of epoch 260\n",
      "Training loss at epoch 260: 0.2588\n",
      "\n",
      "Start of epoch 261\n",
      "Training loss at epoch 261: 0.2587\n",
      "\n",
      "Start of epoch 262\n",
      "Training loss at epoch 262: 0.2587\n",
      "\n",
      "Start of epoch 263\n",
      "Training loss at epoch 263: 0.2587\n",
      "\n",
      "Start of epoch 264\n",
      "Training loss at epoch 264: 0.2586\n",
      "\n",
      "Start of epoch 265\n",
      "Training loss at epoch 265: 0.2586\n",
      "\n",
      "Start of epoch 266\n",
      "Training loss at epoch 266: 0.2586\n",
      "\n",
      "Start of epoch 267\n",
      "Training loss at epoch 267: 0.2585\n",
      "\n",
      "Start of epoch 268\n",
      "Training loss at epoch 268: 0.2585\n",
      "\n",
      "Start of epoch 269\n",
      "Training loss at epoch 269: 0.2585\n",
      "\n",
      "Start of epoch 270\n",
      "Training loss at epoch 270: 0.2584\n",
      "\n",
      "Start of epoch 271\n",
      "Training loss at epoch 271: 0.2584\n",
      "\n",
      "Start of epoch 272\n",
      "Training loss at epoch 272: 0.2584\n",
      "\n",
      "Start of epoch 273\n",
      "Training loss at epoch 273: 0.2583\n",
      "\n",
      "Start of epoch 274\n",
      "Training loss at epoch 274: 0.2583\n",
      "\n",
      "Start of epoch 275\n",
      "Training loss at epoch 275: 0.2582\n",
      "\n",
      "Start of epoch 276\n",
      "Training loss at epoch 276: 0.2582\n",
      "\n",
      "Start of epoch 277\n",
      "Training loss at epoch 277: 0.2582\n",
      "\n",
      "Start of epoch 278\n",
      "Training loss at epoch 278: 0.2581\n",
      "\n",
      "Start of epoch 279\n",
      "Training loss at epoch 279: 0.2581\n",
      "\n",
      "Start of epoch 280\n",
      "Training loss at epoch 280: 0.2580\n",
      "\n",
      "Start of epoch 281\n",
      "Training loss at epoch 281: 0.2580\n",
      "\n",
      "Start of epoch 282\n",
      "Training loss at epoch 282: 0.2580\n",
      "\n",
      "Start of epoch 283\n",
      "Training loss at epoch 283: 0.2579\n",
      "\n",
      "Start of epoch 284\n",
      "Training loss at epoch 284: 0.2579\n",
      "\n",
      "Start of epoch 285\n",
      "Training loss at epoch 285: 0.2578\n",
      "\n",
      "Start of epoch 286\n",
      "Training loss at epoch 286: 0.2578\n",
      "\n",
      "Start of epoch 287\n",
      "Training loss at epoch 287: 0.2578\n",
      "\n",
      "Start of epoch 288\n",
      "Training loss at epoch 288: 0.2577\n",
      "\n",
      "Start of epoch 289\n",
      "Training loss at epoch 289: 0.2577\n",
      "\n",
      "Start of epoch 290\n",
      "Training loss at epoch 290: 0.2576\n",
      "\n",
      "Start of epoch 291\n",
      "Training loss at epoch 291: 0.2576\n",
      "\n",
      "Start of epoch 292\n",
      "Training loss at epoch 292: 0.2575\n",
      "\n",
      "Start of epoch 293\n",
      "Training loss at epoch 293: 0.2575\n",
      "\n",
      "Start of epoch 294\n",
      "Training loss at epoch 294: 0.2574\n",
      "\n",
      "Start of epoch 295\n",
      "Training loss at epoch 295: 0.2574\n",
      "\n",
      "Start of epoch 296\n",
      "Training loss at epoch 296: 0.2573\n",
      "\n",
      "Start of epoch 297\n",
      "Training loss at epoch 297: 0.2573\n",
      "\n",
      "Start of epoch 298\n",
      "Training loss at epoch 298: 0.2573\n",
      "\n",
      "Start of epoch 299\n",
      "Training loss at epoch 299: 0.2572\n",
      "\n",
      "Start of epoch 300\n",
      "Training loss at epoch 300: 0.2572\n",
      "\n",
      "Start of epoch 301\n",
      "Training loss at epoch 301: 0.2571\n",
      "\n",
      "Start of epoch 302\n",
      "Training loss at epoch 302: 0.2571\n",
      "\n",
      "Start of epoch 303\n",
      "Training loss at epoch 303: 0.2570\n",
      "\n",
      "Start of epoch 304\n",
      "Training loss at epoch 304: 0.2570\n",
      "\n",
      "Start of epoch 305\n",
      "Training loss at epoch 305: 0.2569\n",
      "\n",
      "Start of epoch 306\n",
      "Training loss at epoch 306: 0.2568\n",
      "\n",
      "Start of epoch 307\n",
      "Training loss at epoch 307: 0.2568\n",
      "\n",
      "Start of epoch 308\n",
      "Training loss at epoch 308: 0.2567\n",
      "\n",
      "Start of epoch 309\n",
      "Training loss at epoch 309: 0.2567\n",
      "\n",
      "Start of epoch 310\n",
      "Training loss at epoch 310: 0.2566\n",
      "\n",
      "Start of epoch 311\n",
      "Training loss at epoch 311: 0.2566\n",
      "\n",
      "Start of epoch 312\n",
      "Training loss at epoch 312: 0.2565\n",
      "\n",
      "Start of epoch 313\n",
      "Training loss at epoch 313: 0.2564\n",
      "\n",
      "Start of epoch 314\n",
      "Training loss at epoch 314: 0.2564\n",
      "\n",
      "Start of epoch 315\n",
      "Training loss at epoch 315: 0.2563\n",
      "\n",
      "Start of epoch 316\n",
      "Training loss at epoch 316: 0.2562\n",
      "\n",
      "Start of epoch 317\n",
      "Training loss at epoch 317: 0.2562\n",
      "\n",
      "Start of epoch 318\n",
      "Training loss at epoch 318: 0.2561\n",
      "\n",
      "Start of epoch 319\n",
      "Training loss at epoch 319: 0.2561\n",
      "\n",
      "Start of epoch 320\n",
      "Training loss at epoch 320: 0.2560\n",
      "\n",
      "Start of epoch 321\n",
      "Training loss at epoch 321: 0.2559\n",
      "\n",
      "Start of epoch 322\n",
      "Training loss at epoch 322: 0.2558\n",
      "\n",
      "Start of epoch 323\n",
      "Training loss at epoch 323: 0.2558\n",
      "\n",
      "Start of epoch 324\n",
      "Training loss at epoch 324: 0.2557\n",
      "\n",
      "Start of epoch 325\n",
      "Training loss at epoch 325: 0.2556\n",
      "\n",
      "Start of epoch 326\n",
      "Training loss at epoch 326: 0.2555\n",
      "\n",
      "Start of epoch 327\n",
      "Training loss at epoch 327: 0.2555\n",
      "\n",
      "Start of epoch 328\n",
      "Training loss at epoch 328: 0.2554\n",
      "\n",
      "Start of epoch 329\n",
      "Training loss at epoch 329: 0.2553\n",
      "\n",
      "Start of epoch 330\n",
      "Training loss at epoch 330: 0.2552\n",
      "\n",
      "Start of epoch 331\n",
      "Training loss at epoch 331: 0.2551\n",
      "\n",
      "Start of epoch 332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 332: 0.2550\n",
      "\n",
      "Start of epoch 333\n",
      "Training loss at epoch 333: 0.2549\n",
      "\n",
      "Start of epoch 334\n",
      "Training loss at epoch 334: 0.2548\n",
      "\n",
      "Start of epoch 335\n",
      "Training loss at epoch 335: 0.2547\n",
      "\n",
      "Start of epoch 336\n",
      "Training loss at epoch 336: 0.2546\n",
      "\n",
      "Start of epoch 337\n",
      "Training loss at epoch 337: 0.2545\n",
      "\n",
      "Start of epoch 338\n",
      "Training loss at epoch 338: 0.2544\n",
      "\n",
      "Start of epoch 339\n",
      "Training loss at epoch 339: 0.2543\n",
      "\n",
      "Start of epoch 340\n",
      "Training loss at epoch 340: 0.2542\n",
      "\n",
      "Start of epoch 341\n",
      "Training loss at epoch 341: 0.2540\n",
      "\n",
      "Start of epoch 342\n",
      "Training loss at epoch 342: 0.2539\n",
      "\n",
      "Start of epoch 343\n",
      "Training loss at epoch 343: 0.2538\n",
      "\n",
      "Start of epoch 344\n",
      "Training loss at epoch 344: 0.2536\n",
      "\n",
      "Start of epoch 345\n",
      "Training loss at epoch 345: 0.2535\n",
      "\n",
      "Start of epoch 346\n",
      "Training loss at epoch 346: 0.2534\n",
      "\n",
      "Start of epoch 347\n",
      "Training loss at epoch 347: 0.2532\n",
      "\n",
      "Start of epoch 348\n",
      "Training loss at epoch 348: 0.2530\n",
      "\n",
      "Start of epoch 349\n",
      "Training loss at epoch 349: 0.2529\n",
      "\n",
      "Start of epoch 350\n",
      "Training loss at epoch 350: 0.2527\n",
      "\n",
      "Start of epoch 351\n",
      "Training loss at epoch 351: 0.2525\n",
      "\n",
      "Start of epoch 352\n",
      "Training loss at epoch 352: 0.2523\n",
      "\n",
      "Start of epoch 353\n",
      "Training loss at epoch 353: 0.2522\n",
      "\n",
      "Start of epoch 354\n",
      "Training loss at epoch 354: 0.2520\n",
      "\n",
      "Start of epoch 355\n",
      "Training loss at epoch 355: 0.2517\n",
      "\n",
      "Start of epoch 356\n",
      "Training loss at epoch 356: 0.2515\n",
      "\n",
      "Start of epoch 357\n",
      "Training loss at epoch 357: 0.2513\n",
      "\n",
      "Start of epoch 358\n",
      "Training loss at epoch 358: 0.2511\n",
      "\n",
      "Start of epoch 359\n",
      "Training loss at epoch 359: 0.2508\n",
      "\n",
      "Start of epoch 360\n",
      "Training loss at epoch 360: 0.2505\n",
      "\n",
      "Start of epoch 361\n",
      "Training loss at epoch 361: 0.2503\n",
      "\n",
      "Start of epoch 362\n",
      "Training loss at epoch 362: 0.2500\n",
      "\n",
      "Start of epoch 363\n",
      "Training loss at epoch 363: 0.2497\n",
      "\n",
      "Start of epoch 364\n",
      "Training loss at epoch 364: 0.2494\n",
      "\n",
      "Start of epoch 365\n",
      "Training loss at epoch 365: 0.2491\n",
      "\n",
      "Start of epoch 366\n",
      "Training loss at epoch 366: 0.2488\n",
      "\n",
      "Start of epoch 367\n",
      "Training loss at epoch 367: 0.2484\n",
      "\n",
      "Start of epoch 368\n",
      "Training loss at epoch 368: 0.2481\n",
      "\n",
      "Start of epoch 369\n",
      "Training loss at epoch 369: 0.2477\n",
      "\n",
      "Start of epoch 370\n",
      "Training loss at epoch 370: 0.2474\n",
      "\n",
      "Start of epoch 371\n",
      "Training loss at epoch 371: 0.2470\n",
      "\n",
      "Start of epoch 372\n",
      "Training loss at epoch 372: 0.2466\n",
      "\n",
      "Start of epoch 373\n",
      "Training loss at epoch 373: 0.2462\n",
      "\n",
      "Start of epoch 374\n",
      "Training loss at epoch 374: 0.2458\n",
      "\n",
      "Start of epoch 375\n",
      "Training loss at epoch 375: 0.2454\n",
      "\n",
      "Start of epoch 376\n",
      "Training loss at epoch 376: 0.2450\n",
      "\n",
      "Start of epoch 377\n",
      "Training loss at epoch 377: 0.2446\n",
      "\n",
      "Start of epoch 378\n",
      "Training loss at epoch 378: 0.2442\n",
      "\n",
      "Start of epoch 379\n",
      "Training loss at epoch 379: 0.2438\n",
      "\n",
      "Start of epoch 380\n",
      "Training loss at epoch 380: 0.2434\n",
      "\n",
      "Start of epoch 381\n",
      "Training loss at epoch 381: 0.2430\n",
      "\n",
      "Start of epoch 382\n",
      "Training loss at epoch 382: 0.2427\n",
      "\n",
      "Start of epoch 383\n",
      "Training loss at epoch 383: 0.2423\n",
      "\n",
      "Start of epoch 384\n",
      "Training loss at epoch 384: 0.2419\n",
      "\n",
      "Start of epoch 385\n",
      "Training loss at epoch 385: 0.2416\n",
      "\n",
      "Start of epoch 386\n",
      "Training loss at epoch 386: 0.2413\n",
      "\n",
      "Start of epoch 387\n",
      "Training loss at epoch 387: 0.2409\n",
      "\n",
      "Start of epoch 388\n",
      "Training loss at epoch 388: 0.2406\n",
      "\n",
      "Start of epoch 389\n",
      "Training loss at epoch 389: 0.2403\n",
      "\n",
      "Start of epoch 390\n",
      "Training loss at epoch 390: 0.2401\n",
      "\n",
      "Start of epoch 391\n",
      "Training loss at epoch 391: 0.2398\n",
      "\n",
      "Start of epoch 392\n",
      "Training loss at epoch 392: 0.2395\n",
      "\n",
      "Start of epoch 393\n",
      "Training loss at epoch 393: 0.2393\n",
      "\n",
      "Start of epoch 394\n",
      "Training loss at epoch 394: 0.2391\n",
      "\n",
      "Start of epoch 395\n",
      "Training loss at epoch 395: 0.2388\n",
      "\n",
      "Start of epoch 396\n",
      "Training loss at epoch 396: 0.2386\n",
      "\n",
      "Start of epoch 397\n",
      "Training loss at epoch 397: 0.2384\n",
      "\n",
      "Start of epoch 398\n",
      "Training loss at epoch 398: 0.2382\n",
      "\n",
      "Start of epoch 399\n",
      "Training loss at epoch 399: 0.2381\n",
      "\n",
      "Start of epoch 400\n",
      "Training loss at epoch 400: 0.2379\n",
      "\n",
      "Start of epoch 401\n",
      "Training loss at epoch 401: 0.2377\n",
      "\n",
      "Start of epoch 402\n",
      "Training loss at epoch 402: 0.2376\n",
      "\n",
      "Start of epoch 403\n",
      "Training loss at epoch 403: 0.2374\n",
      "\n",
      "Start of epoch 404\n",
      "Training loss at epoch 404: 0.2373\n",
      "\n",
      "Start of epoch 405\n",
      "Training loss at epoch 405: 0.2371\n",
      "\n",
      "Start of epoch 406\n",
      "Training loss at epoch 406: 0.2370\n",
      "\n",
      "Start of epoch 407\n",
      "Training loss at epoch 407: 0.2368\n",
      "\n",
      "Start of epoch 408\n",
      "Training loss at epoch 408: 0.2367\n",
      "\n",
      "Start of epoch 409\n",
      "Training loss at epoch 409: 0.2365\n",
      "\n",
      "Start of epoch 410\n",
      "Training loss at epoch 410: 0.2364\n",
      "\n",
      "Start of epoch 411\n",
      "Training loss at epoch 411: 0.2363\n",
      "\n",
      "Start of epoch 412\n",
      "Training loss at epoch 412: 0.2361\n",
      "\n",
      "Start of epoch 413\n",
      "Training loss at epoch 413: 0.2360\n",
      "\n",
      "Start of epoch 414\n",
      "Training loss at epoch 414: 0.2359\n",
      "\n",
      "Start of epoch 415\n",
      "Training loss at epoch 415: 0.2357\n",
      "\n",
      "Start of epoch 416\n",
      "Training loss at epoch 416: 0.2356\n",
      "\n",
      "Start of epoch 417\n",
      "Training loss at epoch 417: 0.2355\n",
      "\n",
      "Start of epoch 418\n",
      "Training loss at epoch 418: 0.2353\n",
      "\n",
      "Start of epoch 419\n",
      "Training loss at epoch 419: 0.2352\n",
      "\n",
      "Start of epoch 420\n",
      "Training loss at epoch 420: 0.2351\n",
      "\n",
      "Start of epoch 421\n",
      "Training loss at epoch 421: 0.2349\n",
      "\n",
      "Start of epoch 422\n",
      "Training loss at epoch 422: 0.2348\n",
      "\n",
      "Start of epoch 423\n",
      "Training loss at epoch 423: 0.2347\n",
      "\n",
      "Start of epoch 424\n",
      "Training loss at epoch 424: 0.2346\n",
      "\n",
      "Start of epoch 425\n",
      "Training loss at epoch 425: 0.2344\n",
      "\n",
      "Start of epoch 426\n",
      "Training loss at epoch 426: 0.2343\n",
      "\n",
      "Start of epoch 427\n",
      "Training loss at epoch 427: 0.2342\n",
      "\n",
      "Start of epoch 428\n",
      "Training loss at epoch 428: 0.2341\n",
      "\n",
      "Start of epoch 429\n",
      "Training loss at epoch 429: 0.2340\n",
      "\n",
      "Start of epoch 430\n",
      "Training loss at epoch 430: 0.2338\n",
      "\n",
      "Start of epoch 431\n",
      "Training loss at epoch 431: 0.2337\n",
      "\n",
      "Start of epoch 432\n",
      "Training loss at epoch 432: 0.2336\n",
      "\n",
      "Start of epoch 433\n",
      "Training loss at epoch 433: 0.2335\n",
      "\n",
      "Start of epoch 434\n",
      "Training loss at epoch 434: 0.2334\n",
      "\n",
      "Start of epoch 435\n",
      "Training loss at epoch 435: 0.2333\n",
      "\n",
      "Start of epoch 436\n",
      "Training loss at epoch 436: 0.2332\n",
      "\n",
      "Start of epoch 437\n",
      "Training loss at epoch 437: 0.2331\n",
      "\n",
      "Start of epoch 438\n",
      "Training loss at epoch 438: 0.2330\n",
      "\n",
      "Start of epoch 439\n",
      "Training loss at epoch 439: 0.2329\n",
      "\n",
      "Start of epoch 440\n",
      "Training loss at epoch 440: 0.2329\n",
      "\n",
      "Start of epoch 441\n",
      "Training loss at epoch 441: 0.2328\n",
      "\n",
      "Start of epoch 442\n",
      "Training loss at epoch 442: 0.2327\n",
      "\n",
      "Start of epoch 443\n",
      "Training loss at epoch 443: 0.2326\n",
      "\n",
      "Start of epoch 444\n",
      "Training loss at epoch 444: 0.2325\n",
      "\n",
      "Start of epoch 445\n",
      "Training loss at epoch 445: 0.2324\n",
      "\n",
      "Start of epoch 446\n",
      "Training loss at epoch 446: 0.2324\n",
      "\n",
      "Start of epoch 447\n",
      "Training loss at epoch 447: 0.2323\n",
      "\n",
      "Start of epoch 448\n",
      "Training loss at epoch 448: 0.2322\n",
      "\n",
      "Start of epoch 449\n",
      "Training loss at epoch 449: 0.2322\n",
      "\n",
      "Start of epoch 450\n",
      "Training loss at epoch 450: 0.2321\n",
      "\n",
      "Start of epoch 451\n",
      "Training loss at epoch 451: 0.2320\n",
      "\n",
      "Start of epoch 452\n",
      "Training loss at epoch 452: 0.2320\n",
      "\n",
      "Start of epoch 453\n",
      "Training loss at epoch 453: 0.2319\n",
      "\n",
      "Start of epoch 454\n",
      "Training loss at epoch 454: 0.2319\n",
      "\n",
      "Start of epoch 455\n",
      "Training loss at epoch 455: 0.2318\n",
      "\n",
      "Start of epoch 456\n",
      "Training loss at epoch 456: 0.2317\n",
      "\n",
      "Start of epoch 457\n",
      "Training loss at epoch 457: 0.2317\n",
      "\n",
      "Start of epoch 458\n",
      "Training loss at epoch 458: 0.2316\n",
      "\n",
      "Start of epoch 459\n",
      "Training loss at epoch 459: 0.2316\n",
      "\n",
      "Start of epoch 460\n",
      "Training loss at epoch 460: 0.2315\n",
      "\n",
      "Start of epoch 461\n",
      "Training loss at epoch 461: 0.2315\n",
      "\n",
      "Start of epoch 462\n",
      "Training loss at epoch 462: 0.2315\n",
      "\n",
      "Start of epoch 463\n",
      "Training loss at epoch 463: 0.2314\n",
      "\n",
      "Start of epoch 464\n",
      "Training loss at epoch 464: 0.2314\n",
      "\n",
      "Start of epoch 465\n",
      "Training loss at epoch 465: 0.2313\n",
      "\n",
      "Start of epoch 466\n",
      "Training loss at epoch 466: 0.2313\n",
      "\n",
      "Start of epoch 467\n",
      "Training loss at epoch 467: 0.2312\n",
      "\n",
      "Start of epoch 468\n",
      "Training loss at epoch 468: 0.2312\n",
      "\n",
      "Start of epoch 469\n",
      "Training loss at epoch 469: 0.2312\n",
      "\n",
      "Start of epoch 470\n",
      "Training loss at epoch 470: 0.2311\n",
      "\n",
      "Start of epoch 471\n",
      "Training loss at epoch 471: 0.2311\n",
      "\n",
      "Start of epoch 472\n",
      "Training loss at epoch 472: 0.2311\n",
      "\n",
      "Start of epoch 473\n",
      "Training loss at epoch 473: 0.2310\n",
      "\n",
      "Start of epoch 474\n",
      "Training loss at epoch 474: 0.2310\n",
      "\n",
      "Start of epoch 475\n",
      "Training loss at epoch 475: 0.2310\n",
      "\n",
      "Start of epoch 476\n",
      "Training loss at epoch 476: 0.2309\n",
      "\n",
      "Start of epoch 477\n",
      "Training loss at epoch 477: 0.2309\n",
      "\n",
      "Start of epoch 478\n",
      "Training loss at epoch 478: 0.2309\n",
      "\n",
      "Start of epoch 479\n",
      "Training loss at epoch 479: 0.2308\n",
      "\n",
      "Start of epoch 480\n",
      "Training loss at epoch 480: 0.2308\n",
      "\n",
      "Start of epoch 481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 481: 0.2308\n",
      "\n",
      "Start of epoch 482\n",
      "Training loss at epoch 482: 0.2308\n",
      "\n",
      "Start of epoch 483\n",
      "Training loss at epoch 483: 0.2307\n",
      "\n",
      "Start of epoch 484\n",
      "Training loss at epoch 484: 0.2307\n",
      "\n",
      "Start of epoch 485\n",
      "Training loss at epoch 485: 0.2307\n",
      "\n",
      "Start of epoch 486\n",
      "Training loss at epoch 486: 0.2306\n",
      "\n",
      "Start of epoch 487\n",
      "Training loss at epoch 487: 0.2306\n",
      "\n",
      "Start of epoch 488\n",
      "Training loss at epoch 488: 0.2306\n",
      "\n",
      "Start of epoch 489\n",
      "Training loss at epoch 489: 0.2306\n",
      "\n",
      "Start of epoch 490\n",
      "Training loss at epoch 490: 0.2305\n",
      "\n",
      "Start of epoch 491\n",
      "Training loss at epoch 491: 0.2305\n",
      "\n",
      "Start of epoch 492\n",
      "Training loss at epoch 492: 0.2305\n",
      "\n",
      "Start of epoch 493\n",
      "Training loss at epoch 493: 0.2305\n",
      "\n",
      "Start of epoch 494\n",
      "Training loss at epoch 494: 0.2304\n",
      "\n",
      "Start of epoch 495\n",
      "Training loss at epoch 495: 0.2304\n",
      "\n",
      "Start of epoch 496\n",
      "Training loss at epoch 496: 0.2304\n",
      "\n",
      "Start of epoch 497\n",
      "Training loss at epoch 497: 0.2304\n",
      "\n",
      "Start of epoch 498\n",
      "Training loss at epoch 498: 0.2303\n",
      "\n",
      "Start of epoch 499\n",
      "Training loss at epoch 499: 0.2303\n",
      "[<tf.Variable 'parameters:0' shape=(60,) dtype=float32, numpy=\n",
      "array([4.392847  , 4.2102485 , 4.42534   , 0.7494807 , 4.424077  ,\n",
      "       3.0890322 , 1.4521068 , 5.7638955 , 5.2670813 , 5.228478  ,\n",
      "       4.4865823 , 4.0084724 , 1.0906154 , 3.9810765 , 1.2600491 ,\n",
      "       5.262027  , 0.8785306 , 0.30048048, 6.244194  , 2.7601175 ,\n",
      "       1.5701672 , 2.7385025 , 5.6419644 , 2.055395  , 5.354486  ,\n",
      "       5.2027183 , 3.6024957 , 2.2495484 , 5.4979634 , 4.159619  ,\n",
      "       3.1243033 , 2.8160636 , 4.421408  , 1.7328223 , 4.8764377 ,\n",
      "       4.7717805 , 5.4105506 , 1.7523671 , 4.3066025 , 5.8527374 ,\n",
      "       4.8264694 , 0.8147333 , 1.6133943 , 5.564036  , 3.5581336 ,\n",
      "       3.0065043 , 4.368161  , 1.4854875 , 0.42762563, 4.9017105 ,\n",
      "       1.4166665 , 4.8400226 , 3.104456  , 3.0706618 , 5.6366854 ,\n",
      "       3.2792406 , 6.2622175 , 2.4486198 , 1.637747  , 3.6967163 ],\n",
      "      dtype=float32)>]\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 0.9945\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 0.9020\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.8310\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.7773\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.7424\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.7237\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.7125\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.7020\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.6904\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.6776\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.6640\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.6502\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.6358\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.6195\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.6013\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.5824\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.5640\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.5463\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.5301\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.5158\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.5030\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.4908\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.4784\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.4662\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.4546\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.4441\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.4347\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.4261\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.4180\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.4102\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.4026\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.3948\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.3865\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.3779\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.3693\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.3614\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.3550\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.3499\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.3456\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.3413\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.3365\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.3314\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.3265\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.3221\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.3184\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.3150\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.3119\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.3088\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.3056\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.3023\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.2991\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.2962\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.2937\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.2913\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.2887\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.2860\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.2835\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.2813\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.2794\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.2777\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.2762\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.2748\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.2732\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.2716\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.2700\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.2683\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.2665\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.2647\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.2628\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.2609\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.2590\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.2571\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.2553\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.2536\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.2519\n",
      "\n",
      "Start of epoch 75\n",
      "Training loss at epoch 75: 0.2503\n",
      "\n",
      "Start of epoch 76\n",
      "Training loss at epoch 76: 0.2485\n",
      "\n",
      "Start of epoch 77\n",
      "Training loss at epoch 77: 0.2467\n",
      "\n",
      "Start of epoch 78\n",
      "Training loss at epoch 78: 0.2446\n",
      "\n",
      "Start of epoch 79\n",
      "Training loss at epoch 79: 0.2424\n",
      "\n",
      "Start of epoch 80\n",
      "Training loss at epoch 80: 0.2401\n",
      "\n",
      "Start of epoch 81\n",
      "Training loss at epoch 81: 0.2375\n",
      "\n",
      "Start of epoch 82\n",
      "Training loss at epoch 82: 0.2348\n",
      "\n",
      "Start of epoch 83\n",
      "Training loss at epoch 83: 0.2318\n",
      "\n",
      "Start of epoch 84\n",
      "Training loss at epoch 84: 0.2287\n",
      "\n",
      "Start of epoch 85\n",
      "Training loss at epoch 85: 0.2253\n",
      "\n",
      "Start of epoch 86\n",
      "Training loss at epoch 86: 0.2216\n",
      "\n",
      "Start of epoch 87\n",
      "Training loss at epoch 87: 0.2177\n",
      "\n",
      "Start of epoch 88\n",
      "Training loss at epoch 88: 0.2136\n",
      "\n",
      "Start of epoch 89\n",
      "Training loss at epoch 89: 0.2092\n",
      "\n",
      "Start of epoch 90\n",
      "Training loss at epoch 90: 0.2046\n",
      "\n",
      "Start of epoch 91\n",
      "Training loss at epoch 91: 0.1997\n",
      "\n",
      "Start of epoch 92\n",
      "Training loss at epoch 92: 0.1946\n",
      "\n",
      "Start of epoch 93\n",
      "Training loss at epoch 93: 0.1893\n",
      "\n",
      "Start of epoch 94\n",
      "Training loss at epoch 94: 0.1839\n",
      "\n",
      "Start of epoch 95\n",
      "Training loss at epoch 95: 0.1784\n",
      "\n",
      "Start of epoch 96\n",
      "Training loss at epoch 96: 0.1729\n",
      "\n",
      "Start of epoch 97\n",
      "Training loss at epoch 97: 0.1674\n",
      "\n",
      "Start of epoch 98\n",
      "Training loss at epoch 98: 0.1620\n",
      "\n",
      "Start of epoch 99\n",
      "Training loss at epoch 99: 0.1569\n",
      "\n",
      "Start of epoch 100\n",
      "Training loss at epoch 100: 0.1520\n",
      "\n",
      "Start of epoch 101\n",
      "Training loss at epoch 101: 0.1473\n",
      "\n",
      "Start of epoch 102\n",
      "Training loss at epoch 102: 0.1428\n",
      "\n",
      "Start of epoch 103\n",
      "Training loss at epoch 103: 0.1385\n",
      "\n",
      "Start of epoch 104\n",
      "Training loss at epoch 104: 0.1344\n",
      "\n",
      "Start of epoch 105\n",
      "Training loss at epoch 105: 0.1304\n",
      "\n",
      "Start of epoch 106\n",
      "Training loss at epoch 106: 0.1265\n",
      "\n",
      "Start of epoch 107\n",
      "Training loss at epoch 107: 0.1226\n",
      "\n",
      "Start of epoch 108\n",
      "Training loss at epoch 108: 0.1187\n",
      "\n",
      "Start of epoch 109\n",
      "Training loss at epoch 109: 0.1146\n",
      "\n",
      "Start of epoch 110\n",
      "Training loss at epoch 110: 0.1105\n",
      "\n",
      "Start of epoch 111\n",
      "Training loss at epoch 111: 0.1063\n",
      "\n",
      "Start of epoch 112\n",
      "Training loss at epoch 112: 0.1020\n",
      "\n",
      "Start of epoch 113\n",
      "Training loss at epoch 113: 0.0976\n",
      "\n",
      "Start of epoch 114\n",
      "Training loss at epoch 114: 0.0933\n",
      "\n",
      "Start of epoch 115\n",
      "Training loss at epoch 115: 0.0890\n",
      "\n",
      "Start of epoch 116\n",
      "Training loss at epoch 116: 0.0849\n",
      "\n",
      "Start of epoch 117\n",
      "Training loss at epoch 117: 0.0808\n",
      "\n",
      "Start of epoch 118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 118: 0.0770\n",
      "\n",
      "Start of epoch 119\n",
      "Training loss at epoch 119: 0.0733\n",
      "\n",
      "Start of epoch 120\n",
      "Training loss at epoch 120: 0.0699\n",
      "\n",
      "Start of epoch 121\n",
      "Training loss at epoch 121: 0.0667\n",
      "\n",
      "Start of epoch 122\n",
      "Training loss at epoch 122: 0.0638\n",
      "\n",
      "Start of epoch 123\n",
      "Training loss at epoch 123: 0.0612\n",
      "\n",
      "Start of epoch 124\n",
      "Training loss at epoch 124: 0.0589\n",
      "\n",
      "Start of epoch 125\n",
      "Training loss at epoch 125: 0.0568\n",
      "\n",
      "Start of epoch 126\n",
      "Training loss at epoch 126: 0.0550\n",
      "\n",
      "Start of epoch 127\n",
      "Training loss at epoch 127: 0.0533\n",
      "\n",
      "Start of epoch 128\n",
      "Training loss at epoch 128: 0.0519\n",
      "\n",
      "Start of epoch 129\n",
      "Training loss at epoch 129: 0.0505\n",
      "\n",
      "Start of epoch 130\n",
      "Training loss at epoch 130: 0.0493\n",
      "\n",
      "Start of epoch 131\n",
      "Training loss at epoch 131: 0.0481\n",
      "\n",
      "Start of epoch 132\n",
      "Training loss at epoch 132: 0.0470\n",
      "\n",
      "Start of epoch 133\n",
      "Training loss at epoch 133: 0.0460\n",
      "\n",
      "Start of epoch 134\n",
      "Training loss at epoch 134: 0.0450\n",
      "\n",
      "Start of epoch 135\n",
      "Training loss at epoch 135: 0.0440\n",
      "\n",
      "Start of epoch 136\n",
      "Training loss at epoch 136: 0.0431\n",
      "\n",
      "Start of epoch 137\n",
      "Training loss at epoch 137: 0.0422\n",
      "\n",
      "Start of epoch 138\n",
      "Training loss at epoch 138: 0.0414\n",
      "\n",
      "Start of epoch 139\n",
      "Training loss at epoch 139: 0.0405\n",
      "\n",
      "Start of epoch 140\n",
      "Training loss at epoch 140: 0.0397\n",
      "\n",
      "Start of epoch 141\n",
      "Training loss at epoch 141: 0.0389\n",
      "\n",
      "Start of epoch 142\n",
      "Training loss at epoch 142: 0.0382\n",
      "\n",
      "Start of epoch 143\n",
      "Training loss at epoch 143: 0.0375\n",
      "\n",
      "Start of epoch 144\n",
      "Training loss at epoch 144: 0.0367\n",
      "\n",
      "Start of epoch 145\n",
      "Training loss at epoch 145: 0.0361\n",
      "\n",
      "Start of epoch 146\n",
      "Training loss at epoch 146: 0.0354\n",
      "\n",
      "Start of epoch 147\n",
      "Training loss at epoch 147: 0.0348\n",
      "\n",
      "Start of epoch 148\n",
      "Training loss at epoch 148: 0.0341\n",
      "\n",
      "Start of epoch 149\n",
      "Training loss at epoch 149: 0.0335\n",
      "\n",
      "Start of epoch 150\n",
      "Training loss at epoch 150: 0.0329\n",
      "\n",
      "Start of epoch 151\n",
      "Training loss at epoch 151: 0.0323\n",
      "\n",
      "Start of epoch 152\n",
      "Training loss at epoch 152: 0.0317\n",
      "\n",
      "Start of epoch 153\n",
      "Training loss at epoch 153: 0.0312\n",
      "\n",
      "Start of epoch 154\n",
      "Training loss at epoch 154: 0.0306\n",
      "\n",
      "Start of epoch 155\n",
      "Training loss at epoch 155: 0.0301\n",
      "\n",
      "Start of epoch 156\n",
      "Training loss at epoch 156: 0.0296\n",
      "\n",
      "Start of epoch 157\n",
      "Training loss at epoch 157: 0.0291\n",
      "\n",
      "Start of epoch 158\n",
      "Training loss at epoch 158: 0.0286\n",
      "\n",
      "Start of epoch 159\n",
      "Training loss at epoch 159: 0.0281\n",
      "\n",
      "Start of epoch 160\n",
      "Training loss at epoch 160: 0.0277\n",
      "\n",
      "Start of epoch 161\n",
      "Training loss at epoch 161: 0.0272\n",
      "\n",
      "Start of epoch 162\n",
      "Training loss at epoch 162: 0.0268\n",
      "\n",
      "Start of epoch 163\n",
      "Training loss at epoch 163: 0.0263\n",
      "\n",
      "Start of epoch 164\n",
      "Training loss at epoch 164: 0.0259\n",
      "\n",
      "Start of epoch 165\n",
      "Training loss at epoch 165: 0.0255\n",
      "\n",
      "Start of epoch 166\n",
      "Training loss at epoch 166: 0.0250\n",
      "\n",
      "Start of epoch 167\n",
      "Training loss at epoch 167: 0.0246\n",
      "\n",
      "Start of epoch 168\n",
      "Training loss at epoch 168: 0.0242\n",
      "\n",
      "Start of epoch 169\n",
      "Training loss at epoch 169: 0.0238\n",
      "\n",
      "Start of epoch 170\n",
      "Training loss at epoch 170: 0.0234\n",
      "\n",
      "Start of epoch 171\n",
      "Training loss at epoch 171: 0.0230\n",
      "\n",
      "Start of epoch 172\n",
      "Training loss at epoch 172: 0.0226\n",
      "\n",
      "Start of epoch 173\n",
      "Training loss at epoch 173: 0.0222\n",
      "\n",
      "Start of epoch 174\n",
      "Training loss at epoch 174: 0.0219\n",
      "\n",
      "Start of epoch 175\n",
      "Training loss at epoch 175: 0.0215\n",
      "\n",
      "Start of epoch 176\n",
      "Training loss at epoch 176: 0.0211\n",
      "\n",
      "Start of epoch 177\n",
      "Training loss at epoch 177: 0.0208\n",
      "\n",
      "Start of epoch 178\n",
      "Training loss at epoch 178: 0.0204\n",
      "\n",
      "Start of epoch 179\n",
      "Training loss at epoch 179: 0.0201\n",
      "\n",
      "Start of epoch 180\n",
      "Training loss at epoch 180: 0.0197\n",
      "\n",
      "Start of epoch 181\n",
      "Training loss at epoch 181: 0.0194\n",
      "\n",
      "Start of epoch 182\n",
      "Training loss at epoch 182: 0.0191\n",
      "\n",
      "Start of epoch 183\n",
      "Training loss at epoch 183: 0.0188\n",
      "\n",
      "Start of epoch 184\n",
      "Training loss at epoch 184: 0.0185\n",
      "\n",
      "Start of epoch 185\n",
      "Training loss at epoch 185: 0.0182\n",
      "\n",
      "Start of epoch 186\n",
      "Training loss at epoch 186: 0.0179\n",
      "\n",
      "Start of epoch 187\n",
      "Training loss at epoch 187: 0.0176\n",
      "\n",
      "Start of epoch 188\n",
      "Training loss at epoch 188: 0.0173\n",
      "\n",
      "Start of epoch 189\n",
      "Training loss at epoch 189: 0.0170\n",
      "\n",
      "Start of epoch 190\n",
      "Training loss at epoch 190: 0.0167\n",
      "\n",
      "Start of epoch 191\n",
      "Training loss at epoch 191: 0.0165\n",
      "\n",
      "Start of epoch 192\n",
      "Training loss at epoch 192: 0.0162\n",
      "\n",
      "Start of epoch 193\n",
      "Training loss at epoch 193: 0.0160\n",
      "\n",
      "Start of epoch 194\n",
      "Training loss at epoch 194: 0.0157\n",
      "\n",
      "Start of epoch 195\n",
      "Training loss at epoch 195: 0.0155\n",
      "\n",
      "Start of epoch 196\n",
      "Training loss at epoch 196: 0.0152\n",
      "\n",
      "Start of epoch 197\n",
      "Training loss at epoch 197: 0.0150\n",
      "\n",
      "Start of epoch 198\n",
      "Training loss at epoch 198: 0.0148\n",
      "\n",
      "Start of epoch 199\n",
      "Training loss at epoch 199: 0.0145\n",
      "\n",
      "Start of epoch 200\n",
      "Training loss at epoch 200: 0.0143\n",
      "\n",
      "Start of epoch 201\n",
      "Training loss at epoch 201: 0.0141\n",
      "\n",
      "Start of epoch 202\n",
      "Training loss at epoch 202: 0.0139\n",
      "\n",
      "Start of epoch 203\n",
      "Training loss at epoch 203: 0.0137\n",
      "\n",
      "Start of epoch 204\n",
      "Training loss at epoch 204: 0.0135\n",
      "\n",
      "Start of epoch 205\n",
      "Training loss at epoch 205: 0.0133\n",
      "\n",
      "Start of epoch 206\n",
      "Training loss at epoch 206: 0.0131\n",
      "\n",
      "Start of epoch 207\n",
      "Training loss at epoch 207: 0.0130\n",
      "\n",
      "Start of epoch 208\n",
      "Training loss at epoch 208: 0.0128\n",
      "\n",
      "Start of epoch 209\n",
      "Training loss at epoch 209: 0.0126\n",
      "\n",
      "Start of epoch 210\n",
      "Training loss at epoch 210: 0.0124\n",
      "\n",
      "Start of epoch 211\n",
      "Training loss at epoch 211: 0.0123\n",
      "\n",
      "Start of epoch 212\n",
      "Training loss at epoch 212: 0.0121\n",
      "\n",
      "Start of epoch 213\n",
      "Training loss at epoch 213: 0.0119\n",
      "\n",
      "Start of epoch 214\n",
      "Training loss at epoch 214: 0.0118\n",
      "\n",
      "Start of epoch 215\n",
      "Training loss at epoch 215: 0.0116\n",
      "\n",
      "Start of epoch 216\n",
      "Training loss at epoch 216: 0.0115\n",
      "\n",
      "Start of epoch 217\n",
      "Training loss at epoch 217: 0.0113\n",
      "\n",
      "Start of epoch 218\n",
      "Training loss at epoch 218: 0.0112\n",
      "\n",
      "Start of epoch 219\n",
      "Training loss at epoch 219: 0.0111\n",
      "\n",
      "Start of epoch 220\n",
      "Training loss at epoch 220: 0.0109\n",
      "\n",
      "Start of epoch 221\n",
      "Training loss at epoch 221: 0.0108\n",
      "\n",
      "Start of epoch 222\n",
      "Training loss at epoch 222: 0.0107\n",
      "\n",
      "Start of epoch 223\n",
      "Training loss at epoch 223: 0.0105\n",
      "\n",
      "Start of epoch 224\n",
      "Training loss at epoch 224: 0.0104\n",
      "\n",
      "Start of epoch 225\n",
      "Training loss at epoch 225: 0.0103\n",
      "\n",
      "Start of epoch 226\n",
      "Training loss at epoch 226: 0.0101\n",
      "\n",
      "Start of epoch 227\n",
      "Training loss at epoch 227: 0.0100\n",
      "\n",
      "Start of epoch 228\n",
      "Training loss at epoch 228: 0.0099\n",
      "\n",
      "Start of epoch 229\n",
      "Training loss at epoch 229: 0.0098\n",
      "\n",
      "Start of epoch 230\n",
      "Training loss at epoch 230: 0.0097\n",
      "\n",
      "Start of epoch 231\n",
      "Training loss at epoch 231: 0.0096\n",
      "\n",
      "Start of epoch 232\n",
      "Training loss at epoch 232: 0.0095\n",
      "\n",
      "Start of epoch 233\n",
      "Training loss at epoch 233: 0.0094\n",
      "\n",
      "Start of epoch 234\n",
      "Training loss at epoch 234: 0.0093\n",
      "\n",
      "Start of epoch 235\n",
      "Training loss at epoch 235: 0.0091\n",
      "\n",
      "Start of epoch 236\n",
      "Training loss at epoch 236: 0.0090\n",
      "\n",
      "Start of epoch 237\n",
      "Training loss at epoch 237: 0.0089\n",
      "\n",
      "Start of epoch 238\n",
      "Training loss at epoch 238: 0.0088\n",
      "\n",
      "Start of epoch 239\n",
      "Training loss at epoch 239: 0.0087\n",
      "\n",
      "Start of epoch 240\n",
      "Training loss at epoch 240: 0.0086\n",
      "\n",
      "Start of epoch 241\n",
      "Training loss at epoch 241: 0.0086\n",
      "\n",
      "Start of epoch 242\n",
      "Training loss at epoch 242: 0.0085\n",
      "\n",
      "Start of epoch 243\n",
      "Training loss at epoch 243: 0.0084\n",
      "\n",
      "Start of epoch 244\n",
      "Training loss at epoch 244: 0.0083\n",
      "\n",
      "Start of epoch 245\n",
      "Training loss at epoch 245: 0.0082\n",
      "\n",
      "Start of epoch 246\n",
      "Training loss at epoch 246: 0.0081\n",
      "\n",
      "Start of epoch 247\n",
      "Training loss at epoch 247: 0.0080\n",
      "\n",
      "Start of epoch 248\n",
      "Training loss at epoch 248: 0.0079\n",
      "\n",
      "Start of epoch 249\n",
      "Training loss at epoch 249: 0.0078\n",
      "\n",
      "Start of epoch 250\n",
      "Training loss at epoch 250: 0.0078\n",
      "\n",
      "Start of epoch 251\n",
      "Training loss at epoch 251: 0.0077\n",
      "\n",
      "Start of epoch 252\n",
      "Training loss at epoch 252: 0.0076\n",
      "\n",
      "Start of epoch 253\n",
      "Training loss at epoch 253: 0.0075\n",
      "\n",
      "Start of epoch 254\n",
      "Training loss at epoch 254: 0.0074\n",
      "\n",
      "Start of epoch 255\n",
      "Training loss at epoch 255: 0.0074\n",
      "\n",
      "Start of epoch 256\n",
      "Training loss at epoch 256: 0.0073\n",
      "\n",
      "Start of epoch 257\n",
      "Training loss at epoch 257: 0.0072\n",
      "\n",
      "Start of epoch 258\n",
      "Training loss at epoch 258: 0.0071\n",
      "\n",
      "Start of epoch 259\n",
      "Training loss at epoch 259: 0.0071\n",
      "\n",
      "Start of epoch 260\n",
      "Training loss at epoch 260: 0.0070\n",
      "\n",
      "Start of epoch 261\n",
      "Training loss at epoch 261: 0.0069\n",
      "\n",
      "Start of epoch 262\n",
      "Training loss at epoch 262: 0.0069\n",
      "\n",
      "Start of epoch 263\n",
      "Training loss at epoch 263: 0.0068\n",
      "\n",
      "Start of epoch 264\n",
      "Training loss at epoch 264: 0.0067\n",
      "\n",
      "Start of epoch 265\n",
      "Training loss at epoch 265: 0.0067\n",
      "\n",
      "Start of epoch 266\n",
      "Training loss at epoch 266: 0.0066\n",
      "\n",
      "Start of epoch 267\n",
      "Training loss at epoch 267: 0.0065\n",
      "\n",
      "Start of epoch 268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 268: 0.0065\n",
      "\n",
      "Start of epoch 269\n",
      "Training loss at epoch 269: 0.0064\n",
      "\n",
      "Start of epoch 270\n",
      "Training loss at epoch 270: 0.0064\n",
      "\n",
      "Start of epoch 271\n",
      "Training loss at epoch 271: 0.0063\n",
      "\n",
      "Start of epoch 272\n",
      "Training loss at epoch 272: 0.0063\n",
      "\n",
      "Start of epoch 273\n",
      "Training loss at epoch 273: 0.0062\n",
      "\n",
      "Start of epoch 274\n",
      "Training loss at epoch 274: 0.0062\n",
      "\n",
      "Start of epoch 275\n",
      "Training loss at epoch 275: 0.0061\n",
      "\n",
      "Start of epoch 276\n",
      "Training loss at epoch 276: 0.0061\n",
      "\n",
      "Start of epoch 277\n",
      "Training loss at epoch 277: 0.0060\n",
      "\n",
      "Start of epoch 278\n",
      "Training loss at epoch 278: 0.0060\n",
      "\n",
      "Start of epoch 279\n",
      "Training loss at epoch 279: 0.0059\n",
      "\n",
      "Start of epoch 280\n",
      "Training loss at epoch 280: 0.0059\n",
      "\n",
      "Start of epoch 281\n",
      "Training loss at epoch 281: 0.0058\n",
      "\n",
      "Start of epoch 282\n",
      "Training loss at epoch 282: 0.0058\n",
      "\n",
      "Start of epoch 283\n",
      "Training loss at epoch 283: 0.0057\n",
      "\n",
      "Start of epoch 284\n",
      "Training loss at epoch 284: 0.0057\n",
      "\n",
      "Start of epoch 285\n",
      "Training loss at epoch 285: 0.0057\n",
      "\n",
      "Start of epoch 286\n",
      "Training loss at epoch 286: 0.0056\n",
      "\n",
      "Start of epoch 287\n",
      "Training loss at epoch 287: 0.0056\n",
      "\n",
      "Start of epoch 288\n",
      "Training loss at epoch 288: 0.0055\n",
      "\n",
      "Start of epoch 289\n",
      "Training loss at epoch 289: 0.0055\n",
      "\n",
      "Start of epoch 290\n",
      "Training loss at epoch 290: 0.0055\n",
      "\n",
      "Start of epoch 291\n",
      "Training loss at epoch 291: 0.0054\n",
      "\n",
      "Start of epoch 292\n",
      "Training loss at epoch 292: 0.0054\n",
      "\n",
      "Start of epoch 293\n",
      "Training loss at epoch 293: 0.0054\n",
      "\n",
      "Start of epoch 294\n",
      "Training loss at epoch 294: 0.0053\n",
      "\n",
      "Start of epoch 295\n",
      "Training loss at epoch 295: 0.0053\n",
      "\n",
      "Start of epoch 296\n",
      "Training loss at epoch 296: 0.0053\n",
      "\n",
      "Start of epoch 297\n",
      "Training loss at epoch 297: 0.0052\n",
      "\n",
      "Start of epoch 298\n",
      "Training loss at epoch 298: 0.0052\n",
      "\n",
      "Start of epoch 299\n",
      "Training loss at epoch 299: 0.0052\n",
      "\n",
      "Start of epoch 300\n",
      "Training loss at epoch 300: 0.0052\n",
      "\n",
      "Start of epoch 301\n",
      "Training loss at epoch 301: 0.0051\n",
      "\n",
      "Start of epoch 302\n",
      "Training loss at epoch 302: 0.0051\n",
      "\n",
      "Start of epoch 303\n",
      "Training loss at epoch 303: 0.0051\n",
      "\n",
      "Start of epoch 304\n",
      "Training loss at epoch 304: 0.0051\n",
      "\n",
      "Start of epoch 305\n",
      "Training loss at epoch 305: 0.0050\n",
      "\n",
      "Start of epoch 306\n",
      "Training loss at epoch 306: 0.0050\n",
      "\n",
      "Start of epoch 307\n",
      "Training loss at epoch 307: 0.0050\n",
      "\n",
      "Start of epoch 308\n",
      "Training loss at epoch 308: 0.0050\n",
      "\n",
      "Start of epoch 309\n",
      "Training loss at epoch 309: 0.0050\n",
      "\n",
      "Start of epoch 310\n",
      "Training loss at epoch 310: 0.0049\n",
      "\n",
      "Start of epoch 311\n",
      "Training loss at epoch 311: 0.0049\n",
      "\n",
      "Start of epoch 312\n",
      "Training loss at epoch 312: 0.0049\n",
      "\n",
      "Start of epoch 313\n",
      "Training loss at epoch 313: 0.0049\n",
      "\n",
      "Start of epoch 314\n",
      "Training loss at epoch 314: 0.0049\n",
      "\n",
      "Start of epoch 315\n",
      "Training loss at epoch 315: 0.0048\n",
      "\n",
      "Start of epoch 316\n",
      "Training loss at epoch 316: 0.0048\n",
      "\n",
      "Start of epoch 317\n",
      "Training loss at epoch 317: 0.0048\n",
      "\n",
      "Start of epoch 318\n",
      "Training loss at epoch 318: 0.0048\n",
      "\n",
      "Start of epoch 319\n",
      "Training loss at epoch 319: 0.0048\n",
      "\n",
      "Start of epoch 320\n",
      "Training loss at epoch 320: 0.0048\n",
      "\n",
      "Start of epoch 321\n",
      "Training loss at epoch 321: 0.0047\n",
      "\n",
      "Start of epoch 322\n",
      "Training loss at epoch 322: 0.0047\n",
      "\n",
      "Start of epoch 323\n",
      "Training loss at epoch 323: 0.0047\n",
      "\n",
      "Start of epoch 324\n",
      "Training loss at epoch 324: 0.0047\n",
      "\n",
      "Start of epoch 325\n",
      "Training loss at epoch 325: 0.0047\n",
      "\n",
      "Start of epoch 326\n",
      "Training loss at epoch 326: 0.0047\n",
      "\n",
      "Start of epoch 327\n",
      "Training loss at epoch 327: 0.0047\n",
      "\n",
      "Start of epoch 328\n",
      "Training loss at epoch 328: 0.0046\n",
      "\n",
      "Start of epoch 329\n",
      "Training loss at epoch 329: 0.0046\n",
      "\n",
      "Start of epoch 330\n",
      "Training loss at epoch 330: 0.0046\n",
      "\n",
      "Start of epoch 331\n",
      "Training loss at epoch 331: 0.0046\n",
      "\n",
      "Start of epoch 332\n",
      "Training loss at epoch 332: 0.0046\n",
      "\n",
      "Start of epoch 333\n",
      "Training loss at epoch 333: 0.0046\n",
      "\n",
      "Start of epoch 334\n",
      "Training loss at epoch 334: 0.0046\n",
      "\n",
      "Start of epoch 335\n",
      "Training loss at epoch 335: 0.0046\n",
      "\n",
      "Start of epoch 336\n",
      "Training loss at epoch 336: 0.0045\n",
      "\n",
      "Start of epoch 337\n",
      "Training loss at epoch 337: 0.0045\n",
      "\n",
      "Start of epoch 338\n",
      "Training loss at epoch 338: 0.0045\n",
      "\n",
      "Start of epoch 339\n",
      "Training loss at epoch 339: 0.0045\n",
      "\n",
      "Start of epoch 340\n",
      "Training loss at epoch 340: 0.0045\n",
      "\n",
      "Start of epoch 341\n",
      "Training loss at epoch 341: 0.0045\n",
      "\n",
      "Start of epoch 342\n",
      "Training loss at epoch 342: 0.0045\n",
      "\n",
      "Start of epoch 343\n",
      "Training loss at epoch 343: 0.0045\n",
      "\n",
      "Start of epoch 344\n",
      "Training loss at epoch 344: 0.0045\n",
      "\n",
      "Start of epoch 345\n",
      "Training loss at epoch 345: 0.0045\n",
      "\n",
      "Start of epoch 346\n",
      "Training loss at epoch 346: 0.0044\n",
      "\n",
      "Start of epoch 347\n",
      "Training loss at epoch 347: 0.0044\n",
      "\n",
      "Start of epoch 348\n",
      "Training loss at epoch 348: 0.0044\n",
      "\n",
      "Start of epoch 349\n",
      "Training loss at epoch 349: 0.0044\n",
      "\n",
      "Start of epoch 350\n",
      "Training loss at epoch 350: 0.0044\n",
      "\n",
      "Start of epoch 351\n",
      "Training loss at epoch 351: 0.0044\n",
      "\n",
      "Start of epoch 352\n",
      "Training loss at epoch 352: 0.0044\n",
      "\n",
      "Start of epoch 353\n",
      "Training loss at epoch 353: 0.0044\n",
      "\n",
      "Start of epoch 354\n",
      "Training loss at epoch 354: 0.0044\n",
      "\n",
      "Start of epoch 355\n",
      "Training loss at epoch 355: 0.0044\n",
      "\n",
      "Start of epoch 356\n",
      "Training loss at epoch 356: 0.0044\n",
      "\n",
      "Start of epoch 357\n",
      "Training loss at epoch 357: 0.0044\n",
      "\n",
      "Start of epoch 358\n",
      "Training loss at epoch 358: 0.0043\n",
      "\n",
      "Start of epoch 359\n",
      "Training loss at epoch 359: 0.0043\n",
      "\n",
      "Start of epoch 360\n",
      "Training loss at epoch 360: 0.0043\n",
      "\n",
      "Start of epoch 361\n",
      "Training loss at epoch 361: 0.0043\n",
      "\n",
      "Start of epoch 362\n",
      "Training loss at epoch 362: 0.0043\n",
      "\n",
      "Start of epoch 363\n",
      "Training loss at epoch 363: 0.0043\n",
      "\n",
      "Start of epoch 364\n",
      "Training loss at epoch 364: 0.0043\n",
      "\n",
      "Start of epoch 365\n",
      "Training loss at epoch 365: 0.0043\n",
      "\n",
      "Start of epoch 366\n",
      "Training loss at epoch 366: 0.0043\n",
      "\n",
      "Start of epoch 367\n",
      "Training loss at epoch 367: 0.0043\n",
      "\n",
      "Start of epoch 368\n",
      "Training loss at epoch 368: 0.0043\n",
      "\n",
      "Start of epoch 369\n",
      "Training loss at epoch 369: 0.0043\n",
      "\n",
      "Start of epoch 370\n",
      "Training loss at epoch 370: 0.0043\n",
      "\n",
      "Start of epoch 371\n",
      "Training loss at epoch 371: 0.0043\n",
      "\n",
      "Start of epoch 372\n",
      "Training loss at epoch 372: 0.0042\n",
      "\n",
      "Start of epoch 373\n",
      "Training loss at epoch 373: 0.0042\n",
      "\n",
      "Start of epoch 374\n",
      "Training loss at epoch 374: 0.0042\n",
      "\n",
      "Start of epoch 375\n",
      "Training loss at epoch 375: 0.0042\n",
      "\n",
      "Start of epoch 376\n",
      "Training loss at epoch 376: 0.0042\n",
      "\n",
      "Start of epoch 377\n",
      "Training loss at epoch 377: 0.0042\n",
      "\n",
      "Start of epoch 378\n",
      "Training loss at epoch 378: 0.0042\n",
      "\n",
      "Start of epoch 379\n",
      "Training loss at epoch 379: 0.0042\n",
      "\n",
      "Start of epoch 380\n",
      "Training loss at epoch 380: 0.0042\n",
      "\n",
      "Start of epoch 381\n",
      "Training loss at epoch 381: 0.0042\n",
      "\n",
      "Start of epoch 382\n",
      "Training loss at epoch 382: 0.0042\n",
      "\n",
      "Start of epoch 383\n",
      "Training loss at epoch 383: 0.0042\n",
      "\n",
      "Start of epoch 384\n",
      "Training loss at epoch 384: 0.0042\n",
      "\n",
      "Start of epoch 385\n",
      "Training loss at epoch 385: 0.0042\n",
      "\n",
      "Start of epoch 386\n",
      "Training loss at epoch 386: 0.0042\n",
      "\n",
      "Start of epoch 387\n",
      "Training loss at epoch 387: 0.0042\n",
      "\n",
      "Start of epoch 388\n",
      "Training loss at epoch 388: 0.0041\n",
      "\n",
      "Start of epoch 389\n",
      "Training loss at epoch 389: 0.0041\n",
      "\n",
      "Start of epoch 390\n",
      "Training loss at epoch 390: 0.0041\n",
      "\n",
      "Start of epoch 391\n",
      "Training loss at epoch 391: 0.0041\n",
      "\n",
      "Start of epoch 392\n",
      "Training loss at epoch 392: 0.0041\n",
      "\n",
      "Start of epoch 393\n",
      "Training loss at epoch 393: 0.0041\n",
      "\n",
      "Start of epoch 394\n",
      "Training loss at epoch 394: 0.0041\n",
      "\n",
      "Start of epoch 395\n",
      "Training loss at epoch 395: 0.0041\n",
      "\n",
      "Start of epoch 396\n",
      "Training loss at epoch 396: 0.0041\n",
      "\n",
      "Start of epoch 397\n",
      "Training loss at epoch 397: 0.0041\n",
      "\n",
      "Start of epoch 398\n",
      "Training loss at epoch 398: 0.0041\n",
      "\n",
      "Start of epoch 399\n",
      "Training loss at epoch 399: 0.0041\n",
      "\n",
      "Start of epoch 400\n",
      "Training loss at epoch 400: 0.0041\n",
      "\n",
      "Start of epoch 401\n",
      "Training loss at epoch 401: 0.0041\n",
      "\n",
      "Start of epoch 402\n",
      "Training loss at epoch 402: 0.0041\n",
      "\n",
      "Start of epoch 403\n",
      "Training loss at epoch 403: 0.0041\n",
      "\n",
      "Start of epoch 404\n",
      "Training loss at epoch 404: 0.0041\n",
      "\n",
      "Start of epoch 405\n",
      "Training loss at epoch 405: 0.0041\n",
      "\n",
      "Start of epoch 406\n",
      "Training loss at epoch 406: 0.0040\n",
      "\n",
      "Start of epoch 407\n",
      "Training loss at epoch 407: 0.0040\n",
      "\n",
      "Start of epoch 408\n",
      "Training loss at epoch 408: 0.0040\n",
      "\n",
      "Start of epoch 409\n",
      "Training loss at epoch 409: 0.0040\n",
      "\n",
      "Start of epoch 410\n",
      "Training loss at epoch 410: 0.0040\n",
      "\n",
      "Start of epoch 411\n",
      "Training loss at epoch 411: 0.0040\n",
      "\n",
      "Start of epoch 412\n",
      "Training loss at epoch 412: 0.0040\n",
      "\n",
      "Start of epoch 413\n",
      "Training loss at epoch 413: 0.0040\n",
      "\n",
      "Start of epoch 414\n",
      "Training loss at epoch 414: 0.0040\n",
      "\n",
      "Start of epoch 415\n",
      "Training loss at epoch 415: 0.0040\n",
      "\n",
      "Start of epoch 416\n",
      "Training loss at epoch 416: 0.0040\n",
      "\n",
      "Start of epoch 417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 417: 0.0040\n",
      "\n",
      "Start of epoch 418\n",
      "Training loss at epoch 418: 0.0040\n",
      "\n",
      "Start of epoch 419\n",
      "Training loss at epoch 419: 0.0040\n",
      "\n",
      "Start of epoch 420\n",
      "Training loss at epoch 420: 0.0040\n",
      "\n",
      "Start of epoch 421\n",
      "Training loss at epoch 421: 0.0040\n",
      "\n",
      "Start of epoch 422\n",
      "Training loss at epoch 422: 0.0040\n",
      "\n",
      "Start of epoch 423\n",
      "Training loss at epoch 423: 0.0040\n",
      "\n",
      "Start of epoch 424\n",
      "Training loss at epoch 424: 0.0040\n",
      "\n",
      "Start of epoch 425\n",
      "Training loss at epoch 425: 0.0040\n",
      "\n",
      "Start of epoch 426\n",
      "Training loss at epoch 426: 0.0039\n",
      "\n",
      "Start of epoch 427\n",
      "Training loss at epoch 427: 0.0039\n",
      "\n",
      "Start of epoch 428\n",
      "Training loss at epoch 428: 0.0039\n",
      "\n",
      "Start of epoch 429\n",
      "Training loss at epoch 429: 0.0039\n",
      "\n",
      "Start of epoch 430\n",
      "Training loss at epoch 430: 0.0039\n",
      "\n",
      "Start of epoch 431\n",
      "Training loss at epoch 431: 0.0039\n",
      "\n",
      "Start of epoch 432\n",
      "Training loss at epoch 432: 0.0039\n",
      "\n",
      "Start of epoch 433\n",
      "Training loss at epoch 433: 0.0039\n",
      "\n",
      "Start of epoch 434\n",
      "Training loss at epoch 434: 0.0039\n",
      "\n",
      "Start of epoch 435\n",
      "Training loss at epoch 435: 0.0039\n",
      "\n",
      "Start of epoch 436\n",
      "Training loss at epoch 436: 0.0039\n",
      "\n",
      "Start of epoch 437\n",
      "Training loss at epoch 437: 0.0039\n",
      "\n",
      "Start of epoch 438\n",
      "Training loss at epoch 438: 0.0039\n",
      "\n",
      "Start of epoch 439\n",
      "Training loss at epoch 439: 0.0039\n",
      "\n",
      "Start of epoch 440\n",
      "Training loss at epoch 440: 0.0039\n",
      "\n",
      "Start of epoch 441\n",
      "Training loss at epoch 441: 0.0039\n",
      "\n",
      "Start of epoch 442\n",
      "Training loss at epoch 442: 0.0039\n",
      "\n",
      "Start of epoch 443\n",
      "Training loss at epoch 443: 0.0039\n",
      "\n",
      "Start of epoch 444\n",
      "Training loss at epoch 444: 0.0039\n",
      "\n",
      "Start of epoch 445\n",
      "Training loss at epoch 445: 0.0039\n",
      "\n",
      "Start of epoch 446\n",
      "Training loss at epoch 446: 0.0039\n",
      "\n",
      "Start of epoch 447\n",
      "Training loss at epoch 447: 0.0038\n",
      "\n",
      "Start of epoch 448\n",
      "Training loss at epoch 448: 0.0038\n",
      "\n",
      "Start of epoch 449\n",
      "Training loss at epoch 449: 0.0038\n",
      "\n",
      "Start of epoch 450\n",
      "Training loss at epoch 450: 0.0038\n",
      "\n",
      "Start of epoch 451\n",
      "Training loss at epoch 451: 0.0038\n",
      "\n",
      "Start of epoch 452\n",
      "Training loss at epoch 452: 0.0038\n",
      "\n",
      "Start of epoch 453\n",
      "Training loss at epoch 453: 0.0038\n",
      "\n",
      "Start of epoch 454\n",
      "Training loss at epoch 454: 0.0038\n",
      "\n",
      "Start of epoch 455\n",
      "Training loss at epoch 455: 0.0038\n",
      "\n",
      "Start of epoch 456\n",
      "Training loss at epoch 456: 0.0038\n",
      "\n",
      "Start of epoch 457\n",
      "Training loss at epoch 457: 0.0038\n",
      "\n",
      "Start of epoch 458\n",
      "Training loss at epoch 458: 0.0038\n",
      "\n",
      "Start of epoch 459\n",
      "Training loss at epoch 459: 0.0038\n",
      "\n",
      "Start of epoch 460\n",
      "Training loss at epoch 460: 0.0038\n",
      "\n",
      "Start of epoch 461\n",
      "Training loss at epoch 461: 0.0038\n",
      "\n",
      "Start of epoch 462\n",
      "Training loss at epoch 462: 0.0038\n",
      "\n",
      "Start of epoch 463\n",
      "Training loss at epoch 463: 0.0038\n",
      "\n",
      "Start of epoch 464\n",
      "Training loss at epoch 464: 0.0038\n",
      "\n",
      "Start of epoch 465\n",
      "Training loss at epoch 465: 0.0038\n",
      "\n",
      "Start of epoch 466\n",
      "Training loss at epoch 466: 0.0038\n",
      "\n",
      "Start of epoch 467\n",
      "Training loss at epoch 467: 0.0038\n",
      "\n",
      "Start of epoch 468\n",
      "Training loss at epoch 468: 0.0038\n",
      "\n",
      "Start of epoch 469\n",
      "Training loss at epoch 469: 0.0038\n",
      "\n",
      "Start of epoch 470\n",
      "Training loss at epoch 470: 0.0037\n",
      "\n",
      "Start of epoch 471\n",
      "Training loss at epoch 471: 0.0037\n",
      "\n",
      "Start of epoch 472\n",
      "Training loss at epoch 472: 0.0037\n",
      "\n",
      "Start of epoch 473\n",
      "Training loss at epoch 473: 0.0037\n",
      "\n",
      "Start of epoch 474\n",
      "Training loss at epoch 474: 0.0037\n",
      "\n",
      "Start of epoch 475\n",
      "Training loss at epoch 475: 0.0037\n",
      "\n",
      "Start of epoch 476\n",
      "Training loss at epoch 476: 0.0037\n",
      "\n",
      "Start of epoch 477\n",
      "Training loss at epoch 477: 0.0037\n",
      "\n",
      "Start of epoch 478\n",
      "Training loss at epoch 478: 0.0037\n",
      "\n",
      "Start of epoch 479\n",
      "Training loss at epoch 479: 0.0037\n",
      "\n",
      "Start of epoch 480\n",
      "Training loss at epoch 480: 0.0037\n",
      "\n",
      "Start of epoch 481\n",
      "Training loss at epoch 481: 0.0037\n",
      "\n",
      "Start of epoch 482\n",
      "Training loss at epoch 482: 0.0037\n",
      "\n",
      "Start of epoch 483\n",
      "Training loss at epoch 483: 0.0037\n",
      "\n",
      "Start of epoch 484\n",
      "Training loss at epoch 484: 0.0037\n",
      "\n",
      "Start of epoch 485\n",
      "Training loss at epoch 485: 0.0037\n",
      "\n",
      "Start of epoch 486\n",
      "Training loss at epoch 486: 0.0037\n",
      "\n",
      "Start of epoch 487\n",
      "Training loss at epoch 487: 0.0037\n",
      "\n",
      "Start of epoch 488\n",
      "Training loss at epoch 488: 0.0037\n",
      "\n",
      "Start of epoch 489\n",
      "Training loss at epoch 489: 0.0037\n",
      "\n",
      "Start of epoch 490\n",
      "Training loss at epoch 490: 0.0037\n",
      "\n",
      "Start of epoch 491\n",
      "Training loss at epoch 491: 0.0037\n",
      "\n",
      "Start of epoch 492\n",
      "Training loss at epoch 492: 0.0037\n",
      "\n",
      "Start of epoch 493\n",
      "Training loss at epoch 493: 0.0036\n",
      "\n",
      "Start of epoch 494\n",
      "Training loss at epoch 494: 0.0036\n",
      "\n",
      "Start of epoch 495\n",
      "Training loss at epoch 495: 0.0036\n",
      "\n",
      "Start of epoch 496\n",
      "Training loss at epoch 496: 0.0036\n",
      "\n",
      "Start of epoch 497\n",
      "Training loss at epoch 497: 0.0036\n",
      "\n",
      "Start of epoch 498\n",
      "Training loss at epoch 498: 0.0036\n",
      "\n",
      "Start of epoch 499\n",
      "Training loss at epoch 499: 0.0036\n",
      "[<tf.Variable 'parameters:0' shape=(75,) dtype=float32, numpy=\n",
      "array([4.4106007 , 2.911372  , 0.91078466, 5.715036  , 6.1871486 ,\n",
      "       3.8286963 , 3.2292867 , 3.7656097 , 2.342641  , 2.9875526 ,\n",
      "       4.504401  , 0.7072363 , 3.940288  , 0.35716662, 2.25995   ,\n",
      "       5.6931596 , 2.3848083 , 0.3032421 , 2.176861  , 5.5249405 ,\n",
      "       2.5248313 , 4.9620843 , 0.99670106, 2.5634587 , 0.259257  ,\n",
      "       2.5783641 , 0.845198  , 2.0208685 , 0.18915527, 5.8584414 ,\n",
      "       4.0181026 , 5.4258175 , 3.2800853 , 3.6571586 , 1.8734236 ,\n",
      "       6.1570344 , 5.826346  , 4.0840583 , 3.2792368 , 3.002143  ,\n",
      "       2.78023   , 3.0491824 , 3.9785118 , 2.8358219 , 4.843602  ,\n",
      "       3.3284996 , 0.0345273 , 1.3651485 , 5.773455  , 0.83559036,\n",
      "       3.9637    , 4.9312367 , 1.6602564 , 4.418358  , 1.3605878 ,\n",
      "       2.363499  , 2.417102  , 2.5133085 , 4.9418464 , 0.34834847,\n",
      "       0.64767694, 1.2684321 , 2.9394526 , 4.9587216 , 0.71447927,\n",
      "       0.87608355, 0.5783879 , 1.120827  , 5.3272796 , 1.6207144 ,\n",
      "       1.3759987 , 0.20937939, 4.8576403 , 1.0859776 , 4.3145547 ],\n",
      "      dtype=float32)>]\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 0.9307\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 0.8354\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.7803\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.7402\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.7138\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.6938\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.6718\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.6505\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.6332\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.6150\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.5922\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.5673\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.5445\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.5254\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.5098\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.4965\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.4845\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.4734\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.4643\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.4581\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.4539\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.4499\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.4449\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.4389\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.4324\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.4259\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.4192\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.4125\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.4060\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.4001\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.3953\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.3913\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.3879\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.3847\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.3816\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.3786\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.3760\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.3735\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.3712\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.3688\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.3663\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.3634\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.3605\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.3576\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.3548\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.3521\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.3496\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.3471\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.3449\n",
      "\n",
      "Start of epoch 49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 49: 0.3429\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.3408\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.3388\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.3368\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.3349\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.3332\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.3315\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.3299\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.3284\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.3269\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.3255\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.3242\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.3229\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.3216\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.3203\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.3190\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.3177\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.3165\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.3153\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.3142\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.3131\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.3121\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.3110\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.3100\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.3090\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.3081\n",
      "\n",
      "Start of epoch 75\n",
      "Training loss at epoch 75: 0.3071\n",
      "\n",
      "Start of epoch 76\n",
      "Training loss at epoch 76: 0.3061\n",
      "\n",
      "Start of epoch 77\n",
      "Training loss at epoch 77: 0.3051\n",
      "\n",
      "Start of epoch 78\n",
      "Training loss at epoch 78: 0.3041\n",
      "\n",
      "Start of epoch 79\n",
      "Training loss at epoch 79: 0.3031\n",
      "\n",
      "Start of epoch 80\n",
      "Training loss at epoch 80: 0.3021\n",
      "\n",
      "Start of epoch 81\n",
      "Training loss at epoch 81: 0.3011\n",
      "\n",
      "Start of epoch 82\n",
      "Training loss at epoch 82: 0.3000\n",
      "\n",
      "Start of epoch 83\n",
      "Training loss at epoch 83: 0.2990\n",
      "\n",
      "Start of epoch 84\n",
      "Training loss at epoch 84: 0.2979\n",
      "\n",
      "Start of epoch 85\n",
      "Training loss at epoch 85: 0.2968\n",
      "\n",
      "Start of epoch 86\n",
      "Training loss at epoch 86: 0.2956\n",
      "\n",
      "Start of epoch 87\n",
      "Training loss at epoch 87: 0.2945\n",
      "\n",
      "Start of epoch 88\n",
      "Training loss at epoch 88: 0.2932\n",
      "\n",
      "Start of epoch 89\n",
      "Training loss at epoch 89: 0.2920\n",
      "\n",
      "Start of epoch 90\n",
      "Training loss at epoch 90: 0.2906\n",
      "\n",
      "Start of epoch 91\n",
      "Training loss at epoch 91: 0.2891\n",
      "\n",
      "Start of epoch 92\n",
      "Training loss at epoch 92: 0.2876\n",
      "\n",
      "Start of epoch 93\n",
      "Training loss at epoch 93: 0.2861\n",
      "\n",
      "Start of epoch 94\n",
      "Training loss at epoch 94: 0.2844\n",
      "\n",
      "Start of epoch 95\n",
      "Training loss at epoch 95: 0.2827\n",
      "\n",
      "Start of epoch 96\n",
      "Training loss at epoch 96: 0.2810\n",
      "\n",
      "Start of epoch 97\n",
      "Training loss at epoch 97: 0.2791\n",
      "\n",
      "Start of epoch 98\n",
      "Training loss at epoch 98: 0.2773\n",
      "\n",
      "Start of epoch 99\n",
      "Training loss at epoch 99: 0.2754\n",
      "\n",
      "Start of epoch 100\n",
      "Training loss at epoch 100: 0.2736\n",
      "\n",
      "Start of epoch 101\n",
      "Training loss at epoch 101: 0.2717\n",
      "\n",
      "Start of epoch 102\n",
      "Training loss at epoch 102: 0.2699\n",
      "\n",
      "Start of epoch 103\n",
      "Training loss at epoch 103: 0.2682\n",
      "\n",
      "Start of epoch 104\n",
      "Training loss at epoch 104: 0.2665\n",
      "\n",
      "Start of epoch 105\n",
      "Training loss at epoch 105: 0.2649\n",
      "\n",
      "Start of epoch 106\n",
      "Training loss at epoch 106: 0.2633\n",
      "\n",
      "Start of epoch 107\n",
      "Training loss at epoch 107: 0.2618\n",
      "\n",
      "Start of epoch 108\n",
      "Training loss at epoch 108: 0.2603\n",
      "\n",
      "Start of epoch 109\n",
      "Training loss at epoch 109: 0.2589\n",
      "\n",
      "Start of epoch 110\n",
      "Training loss at epoch 110: 0.2576\n",
      "\n",
      "Start of epoch 111\n",
      "Training loss at epoch 111: 0.2563\n",
      "\n",
      "Start of epoch 112\n",
      "Training loss at epoch 112: 0.2551\n",
      "\n",
      "Start of epoch 113\n",
      "Training loss at epoch 113: 0.2539\n",
      "\n",
      "Start of epoch 114\n",
      "Training loss at epoch 114: 0.2529\n",
      "\n",
      "Start of epoch 115\n",
      "Training loss at epoch 115: 0.2519\n",
      "\n",
      "Start of epoch 116\n",
      "Training loss at epoch 116: 0.2509\n",
      "\n",
      "Start of epoch 117\n",
      "Training loss at epoch 117: 0.2500\n",
      "\n",
      "Start of epoch 118\n",
      "Training loss at epoch 118: 0.2491\n",
      "\n",
      "Start of epoch 119\n",
      "Training loss at epoch 119: 0.2482\n",
      "\n",
      "Start of epoch 120\n",
      "Training loss at epoch 120: 0.2473\n",
      "\n",
      "Start of epoch 121\n",
      "Training loss at epoch 121: 0.2464\n",
      "\n",
      "Start of epoch 122\n",
      "Training loss at epoch 122: 0.2456\n",
      "\n",
      "Start of epoch 123\n",
      "Training loss at epoch 123: 0.2448\n",
      "\n",
      "Start of epoch 124\n",
      "Training loss at epoch 124: 0.2440\n",
      "\n",
      "Start of epoch 125\n",
      "Training loss at epoch 125: 0.2432\n",
      "\n",
      "Start of epoch 126\n",
      "Training loss at epoch 126: 0.2425\n",
      "\n",
      "Start of epoch 127\n",
      "Training loss at epoch 127: 0.2419\n",
      "\n",
      "Start of epoch 128\n",
      "Training loss at epoch 128: 0.2412\n",
      "\n",
      "Start of epoch 129\n",
      "Training loss at epoch 129: 0.2407\n",
      "\n",
      "Start of epoch 130\n",
      "Training loss at epoch 130: 0.2401\n",
      "\n",
      "Start of epoch 131\n",
      "Training loss at epoch 131: 0.2396\n",
      "\n",
      "Start of epoch 132\n",
      "Training loss at epoch 132: 0.2391\n",
      "\n",
      "Start of epoch 133\n",
      "Training loss at epoch 133: 0.2386\n",
      "\n",
      "Start of epoch 134\n",
      "Training loss at epoch 134: 0.2382\n",
      "\n",
      "Start of epoch 135\n",
      "Training loss at epoch 135: 0.2377\n",
      "\n",
      "Start of epoch 136\n",
      "Training loss at epoch 136: 0.2373\n",
      "\n",
      "Start of epoch 137\n",
      "Training loss at epoch 137: 0.2369\n",
      "\n",
      "Start of epoch 138\n",
      "Training loss at epoch 138: 0.2365\n",
      "\n",
      "Start of epoch 139\n",
      "Training loss at epoch 139: 0.2361\n",
      "\n",
      "Start of epoch 140\n",
      "Training loss at epoch 140: 0.2357\n",
      "\n",
      "Start of epoch 141\n",
      "Training loss at epoch 141: 0.2353\n",
      "\n",
      "Start of epoch 142\n",
      "Training loss at epoch 142: 0.2349\n",
      "\n",
      "Start of epoch 143\n",
      "Training loss at epoch 143: 0.2346\n",
      "\n",
      "Start of epoch 144\n",
      "Training loss at epoch 144: 0.2342\n",
      "\n",
      "Start of epoch 145\n",
      "Training loss at epoch 145: 0.2338\n",
      "\n",
      "Start of epoch 146\n",
      "Training loss at epoch 146: 0.2335\n",
      "\n",
      "Start of epoch 147\n",
      "Training loss at epoch 147: 0.2332\n",
      "\n",
      "Start of epoch 148\n",
      "Training loss at epoch 148: 0.2328\n",
      "\n",
      "Start of epoch 149\n",
      "Training loss at epoch 149: 0.2325\n",
      "\n",
      "Start of epoch 150\n",
      "Training loss at epoch 150: 0.2322\n",
      "\n",
      "Start of epoch 151\n",
      "Training loss at epoch 151: 0.2319\n",
      "\n",
      "Start of epoch 152\n",
      "Training loss at epoch 152: 0.2316\n",
      "\n",
      "Start of epoch 153\n",
      "Training loss at epoch 153: 0.2312\n",
      "\n",
      "Start of epoch 154\n",
      "Training loss at epoch 154: 0.2309\n",
      "\n",
      "Start of epoch 155\n",
      "Training loss at epoch 155: 0.2306\n",
      "\n",
      "Start of epoch 156\n",
      "Training loss at epoch 156: 0.2303\n",
      "\n",
      "Start of epoch 157\n",
      "Training loss at epoch 157: 0.2301\n",
      "\n",
      "Start of epoch 158\n",
      "Training loss at epoch 158: 0.2298\n",
      "\n",
      "Start of epoch 159\n",
      "Training loss at epoch 159: 0.2295\n",
      "\n",
      "Start of epoch 160\n",
      "Training loss at epoch 160: 0.2292\n",
      "\n",
      "Start of epoch 161\n",
      "Training loss at epoch 161: 0.2289\n",
      "\n",
      "Start of epoch 162\n",
      "Training loss at epoch 162: 0.2286\n",
      "\n",
      "Start of epoch 163\n",
      "Training loss at epoch 163: 0.2284\n",
      "\n",
      "Start of epoch 164\n",
      "Training loss at epoch 164: 0.2281\n",
      "\n",
      "Start of epoch 165\n",
      "Training loss at epoch 165: 0.2278\n",
      "\n",
      "Start of epoch 166\n",
      "Training loss at epoch 166: 0.2276\n",
      "\n",
      "Start of epoch 167\n",
      "Training loss at epoch 167: 0.2273\n",
      "\n",
      "Start of epoch 168\n",
      "Training loss at epoch 168: 0.2270\n",
      "\n",
      "Start of epoch 169\n",
      "Training loss at epoch 169: 0.2268\n",
      "\n",
      "Start of epoch 170\n",
      "Training loss at epoch 170: 0.2265\n",
      "\n",
      "Start of epoch 171\n",
      "Training loss at epoch 171: 0.2263\n",
      "\n",
      "Start of epoch 172\n",
      "Training loss at epoch 172: 0.2261\n",
      "\n",
      "Start of epoch 173\n",
      "Training loss at epoch 173: 0.2258\n",
      "\n",
      "Start of epoch 174\n",
      "Training loss at epoch 174: 0.2256\n",
      "\n",
      "Start of epoch 175\n",
      "Training loss at epoch 175: 0.2253\n",
      "\n",
      "Start of epoch 176\n",
      "Training loss at epoch 176: 0.2251\n",
      "\n",
      "Start of epoch 177\n",
      "Training loss at epoch 177: 0.2248\n",
      "\n",
      "Start of epoch 178\n",
      "Training loss at epoch 178: 0.2246\n",
      "\n",
      "Start of epoch 179\n",
      "Training loss at epoch 179: 0.2244\n",
      "\n",
      "Start of epoch 180\n",
      "Training loss at epoch 180: 0.2241\n",
      "\n",
      "Start of epoch 181\n",
      "Training loss at epoch 181: 0.2239\n",
      "\n",
      "Start of epoch 182\n",
      "Training loss at epoch 182: 0.2236\n",
      "\n",
      "Start of epoch 183\n",
      "Training loss at epoch 183: 0.2234\n",
      "\n",
      "Start of epoch 184\n",
      "Training loss at epoch 184: 0.2232\n",
      "\n",
      "Start of epoch 185\n",
      "Training loss at epoch 185: 0.2229\n",
      "\n",
      "Start of epoch 186\n",
      "Training loss at epoch 186: 0.2227\n",
      "\n",
      "Start of epoch 187\n",
      "Training loss at epoch 187: 0.2225\n",
      "\n",
      "Start of epoch 188\n",
      "Training loss at epoch 188: 0.2223\n",
      "\n",
      "Start of epoch 189\n",
      "Training loss at epoch 189: 0.2221\n",
      "\n",
      "Start of epoch 190\n",
      "Training loss at epoch 190: 0.2218\n",
      "\n",
      "Start of epoch 191\n",
      "Training loss at epoch 191: 0.2216\n",
      "\n",
      "Start of epoch 192\n",
      "Training loss at epoch 192: 0.2214\n",
      "\n",
      "Start of epoch 193\n",
      "Training loss at epoch 193: 0.2212\n",
      "\n",
      "Start of epoch 194\n",
      "Training loss at epoch 194: 0.2210\n",
      "\n",
      "Start of epoch 195\n",
      "Training loss at epoch 195: 0.2208\n",
      "\n",
      "Start of epoch 196\n",
      "Training loss at epoch 196: 0.2206\n",
      "\n",
      "Start of epoch 197\n",
      "Training loss at epoch 197: 0.2204\n",
      "\n",
      "Start of epoch 198\n",
      "Training loss at epoch 198: 0.2202\n",
      "\n",
      "Start of epoch 199\n",
      "Training loss at epoch 199: 0.2200\n",
      "\n",
      "Start of epoch 200\n",
      "Training loss at epoch 200: 0.2199\n",
      "\n",
      "Start of epoch 201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 201: 0.2197\n",
      "\n",
      "Start of epoch 202\n",
      "Training loss at epoch 202: 0.2195\n",
      "\n",
      "Start of epoch 203\n",
      "Training loss at epoch 203: 0.2193\n",
      "\n",
      "Start of epoch 204\n",
      "Training loss at epoch 204: 0.2192\n",
      "\n",
      "Start of epoch 205\n",
      "Training loss at epoch 205: 0.2190\n",
      "\n",
      "Start of epoch 206\n",
      "Training loss at epoch 206: 0.2189\n",
      "\n",
      "Start of epoch 207\n",
      "Training loss at epoch 207: 0.2187\n",
      "\n",
      "Start of epoch 208\n",
      "Training loss at epoch 208: 0.2185\n",
      "\n",
      "Start of epoch 209\n",
      "Training loss at epoch 209: 0.2184\n",
      "\n",
      "Start of epoch 210\n",
      "Training loss at epoch 210: 0.2182\n",
      "\n",
      "Start of epoch 211\n",
      "Training loss at epoch 211: 0.2181\n",
      "\n",
      "Start of epoch 212\n",
      "Training loss at epoch 212: 0.2179\n",
      "\n",
      "Start of epoch 213\n",
      "Training loss at epoch 213: 0.2178\n",
      "\n",
      "Start of epoch 214\n",
      "Training loss at epoch 214: 0.2177\n",
      "\n",
      "Start of epoch 215\n",
      "Training loss at epoch 215: 0.2175\n",
      "\n",
      "Start of epoch 216\n",
      "Training loss at epoch 216: 0.2174\n",
      "\n",
      "Start of epoch 217\n",
      "Training loss at epoch 217: 0.2172\n",
      "\n",
      "Start of epoch 218\n",
      "Training loss at epoch 218: 0.2171\n",
      "\n",
      "Start of epoch 219\n",
      "Training loss at epoch 219: 0.2170\n",
      "\n",
      "Start of epoch 220\n",
      "Training loss at epoch 220: 0.2168\n",
      "\n",
      "Start of epoch 221\n",
      "Training loss at epoch 221: 0.2167\n",
      "\n",
      "Start of epoch 222\n",
      "Training loss at epoch 222: 0.2166\n",
      "\n",
      "Start of epoch 223\n",
      "Training loss at epoch 223: 0.2165\n",
      "\n",
      "Start of epoch 224\n",
      "Training loss at epoch 224: 0.2163\n",
      "\n",
      "Start of epoch 225\n",
      "Training loss at epoch 225: 0.2162\n",
      "\n",
      "Start of epoch 226\n",
      "Training loss at epoch 226: 0.2161\n",
      "\n",
      "Start of epoch 227\n",
      "Training loss at epoch 227: 0.2160\n",
      "\n",
      "Start of epoch 228\n",
      "Training loss at epoch 228: 0.2158\n",
      "\n",
      "Start of epoch 229\n",
      "Training loss at epoch 229: 0.2157\n",
      "\n",
      "Start of epoch 230\n",
      "Training loss at epoch 230: 0.2156\n",
      "\n",
      "Start of epoch 231\n",
      "Training loss at epoch 231: 0.2155\n",
      "\n",
      "Start of epoch 232\n",
      "Training loss at epoch 232: 0.2154\n",
      "\n",
      "Start of epoch 233\n",
      "Training loss at epoch 233: 0.2153\n",
      "\n",
      "Start of epoch 234\n",
      "Training loss at epoch 234: 0.2152\n",
      "\n",
      "Start of epoch 235\n",
      "Training loss at epoch 235: 0.2151\n",
      "\n",
      "Start of epoch 236\n",
      "Training loss at epoch 236: 0.2149\n",
      "\n",
      "Start of epoch 237\n",
      "Training loss at epoch 237: 0.2148\n",
      "\n",
      "Start of epoch 238\n",
      "Training loss at epoch 238: 0.2147\n",
      "\n",
      "Start of epoch 239\n",
      "Training loss at epoch 239: 0.2146\n",
      "\n",
      "Start of epoch 240\n",
      "Training loss at epoch 240: 0.2145\n",
      "\n",
      "Start of epoch 241\n",
      "Training loss at epoch 241: 0.2144\n",
      "\n",
      "Start of epoch 242\n",
      "Training loss at epoch 242: 0.2143\n",
      "\n",
      "Start of epoch 243\n",
      "Training loss at epoch 243: 0.2142\n",
      "\n",
      "Start of epoch 244\n",
      "Training loss at epoch 244: 0.2141\n",
      "\n",
      "Start of epoch 245\n",
      "Training loss at epoch 245: 0.2140\n",
      "\n",
      "Start of epoch 246\n",
      "Training loss at epoch 246: 0.2139\n",
      "\n",
      "Start of epoch 247\n",
      "Training loss at epoch 247: 0.2138\n",
      "\n",
      "Start of epoch 248\n",
      "Training loss at epoch 248: 0.2138\n",
      "\n",
      "Start of epoch 249\n",
      "Training loss at epoch 249: 0.2137\n",
      "\n",
      "Start of epoch 250\n",
      "Training loss at epoch 250: 0.2136\n",
      "\n",
      "Start of epoch 251\n",
      "Training loss at epoch 251: 0.2135\n",
      "\n",
      "Start of epoch 252\n",
      "Training loss at epoch 252: 0.2134\n",
      "\n",
      "Start of epoch 253\n",
      "Training loss at epoch 253: 0.2133\n",
      "\n",
      "Start of epoch 254\n",
      "Training loss at epoch 254: 0.2132\n",
      "\n",
      "Start of epoch 255\n",
      "Training loss at epoch 255: 0.2131\n",
      "\n",
      "Start of epoch 256\n",
      "Training loss at epoch 256: 0.2131\n",
      "\n",
      "Start of epoch 257\n",
      "Training loss at epoch 257: 0.2130\n",
      "\n",
      "Start of epoch 258\n",
      "Training loss at epoch 258: 0.2129\n",
      "\n",
      "Start of epoch 259\n",
      "Training loss at epoch 259: 0.2128\n",
      "\n",
      "Start of epoch 260\n",
      "Training loss at epoch 260: 0.2127\n",
      "\n",
      "Start of epoch 261\n",
      "Training loss at epoch 261: 0.2127\n",
      "\n",
      "Start of epoch 262\n",
      "Training loss at epoch 262: 0.2126\n",
      "\n",
      "Start of epoch 263\n",
      "Training loss at epoch 263: 0.2125\n",
      "\n",
      "Start of epoch 264\n",
      "Training loss at epoch 264: 0.2124\n",
      "\n",
      "Start of epoch 265\n",
      "Training loss at epoch 265: 0.2124\n",
      "\n",
      "Start of epoch 266\n",
      "Training loss at epoch 266: 0.2123\n",
      "\n",
      "Start of epoch 267\n",
      "Training loss at epoch 267: 0.2122\n",
      "\n",
      "Start of epoch 268\n",
      "Training loss at epoch 268: 0.2122\n",
      "\n",
      "Start of epoch 269\n",
      "Training loss at epoch 269: 0.2121\n",
      "\n",
      "Start of epoch 270\n",
      "Training loss at epoch 270: 0.2120\n",
      "\n",
      "Start of epoch 271\n",
      "Training loss at epoch 271: 0.2120\n",
      "\n",
      "Start of epoch 272\n",
      "Training loss at epoch 272: 0.2119\n",
      "\n",
      "Start of epoch 273\n",
      "Training loss at epoch 273: 0.2118\n",
      "\n",
      "Start of epoch 274\n",
      "Training loss at epoch 274: 0.2118\n",
      "\n",
      "Start of epoch 275\n",
      "Training loss at epoch 275: 0.2117\n",
      "\n",
      "Start of epoch 276\n",
      "Training loss at epoch 276: 0.2117\n",
      "\n",
      "Start of epoch 277\n",
      "Training loss at epoch 277: 0.2116\n",
      "\n",
      "Start of epoch 278\n",
      "Training loss at epoch 278: 0.2115\n",
      "\n",
      "Start of epoch 279\n",
      "Training loss at epoch 279: 0.2115\n",
      "\n",
      "Start of epoch 280\n",
      "Training loss at epoch 280: 0.2114\n",
      "\n",
      "Start of epoch 281\n",
      "Training loss at epoch 281: 0.2114\n",
      "\n",
      "Start of epoch 282\n",
      "Training loss at epoch 282: 0.2113\n",
      "\n",
      "Start of epoch 283\n",
      "Training loss at epoch 283: 0.2113\n",
      "\n",
      "Start of epoch 284\n",
      "Training loss at epoch 284: 0.2112\n",
      "\n",
      "Start of epoch 285\n",
      "Training loss at epoch 285: 0.2112\n",
      "\n",
      "Start of epoch 286\n",
      "Training loss at epoch 286: 0.2111\n",
      "\n",
      "Start of epoch 287\n",
      "Training loss at epoch 287: 0.2111\n",
      "\n",
      "Start of epoch 288\n",
      "Training loss at epoch 288: 0.2110\n",
      "\n",
      "Start of epoch 289\n",
      "Training loss at epoch 289: 0.2110\n",
      "\n",
      "Start of epoch 290\n",
      "Training loss at epoch 290: 0.2109\n",
      "\n",
      "Start of epoch 291\n",
      "Training loss at epoch 291: 0.2109\n",
      "\n",
      "Start of epoch 292\n",
      "Training loss at epoch 292: 0.2108\n",
      "\n",
      "Start of epoch 293\n",
      "Training loss at epoch 293: 0.2108\n",
      "\n",
      "Start of epoch 294\n",
      "Training loss at epoch 294: 0.2108\n",
      "\n",
      "Start of epoch 295\n",
      "Training loss at epoch 295: 0.2107\n",
      "\n",
      "Start of epoch 296\n",
      "Training loss at epoch 296: 0.2107\n",
      "\n",
      "Start of epoch 297\n",
      "Training loss at epoch 297: 0.2106\n",
      "\n",
      "Start of epoch 298\n",
      "Training loss at epoch 298: 0.2106\n",
      "\n",
      "Start of epoch 299\n",
      "Training loss at epoch 299: 0.2106\n",
      "\n",
      "Start of epoch 300\n",
      "Training loss at epoch 300: 0.2105\n",
      "\n",
      "Start of epoch 301\n",
      "Training loss at epoch 301: 0.2105\n",
      "\n",
      "Start of epoch 302\n",
      "Training loss at epoch 302: 0.2105\n",
      "\n",
      "Start of epoch 303\n",
      "Training loss at epoch 303: 0.2104\n",
      "\n",
      "Start of epoch 304\n",
      "Training loss at epoch 304: 0.2104\n",
      "\n",
      "Start of epoch 305\n",
      "Training loss at epoch 305: 0.2104\n",
      "\n",
      "Start of epoch 306\n",
      "Training loss at epoch 306: 0.2103\n",
      "\n",
      "Start of epoch 307\n",
      "Training loss at epoch 307: 0.2103\n",
      "\n",
      "Start of epoch 308\n",
      "Training loss at epoch 308: 0.2103\n",
      "\n",
      "Start of epoch 309\n",
      "Training loss at epoch 309: 0.2102\n",
      "\n",
      "Start of epoch 310\n",
      "Training loss at epoch 310: 0.2102\n",
      "\n",
      "Start of epoch 311\n",
      "Training loss at epoch 311: 0.2102\n",
      "\n",
      "Start of epoch 312\n",
      "Training loss at epoch 312: 0.2102\n",
      "\n",
      "Start of epoch 313\n",
      "Training loss at epoch 313: 0.2101\n",
      "\n",
      "Start of epoch 314\n",
      "Training loss at epoch 314: 0.2101\n",
      "\n",
      "Start of epoch 315\n",
      "Training loss at epoch 315: 0.2101\n",
      "\n",
      "Start of epoch 316\n",
      "Training loss at epoch 316: 0.2100\n",
      "\n",
      "Start of epoch 317\n",
      "Training loss at epoch 317: 0.2100\n",
      "\n",
      "Start of epoch 318\n",
      "Training loss at epoch 318: 0.2100\n",
      "\n",
      "Start of epoch 319\n",
      "Training loss at epoch 319: 0.2100\n",
      "\n",
      "Start of epoch 320\n",
      "Training loss at epoch 320: 0.2099\n",
      "\n",
      "Start of epoch 321\n",
      "Training loss at epoch 321: 0.2099\n",
      "\n",
      "Start of epoch 322\n",
      "Training loss at epoch 322: 0.2099\n",
      "\n",
      "Start of epoch 323\n",
      "Training loss at epoch 323: 0.2099\n",
      "\n",
      "Start of epoch 324\n",
      "Training loss at epoch 324: 0.2099\n",
      "\n",
      "Start of epoch 325\n",
      "Training loss at epoch 325: 0.2098\n",
      "\n",
      "Start of epoch 326\n",
      "Training loss at epoch 326: 0.2098\n",
      "\n",
      "Start of epoch 327\n",
      "Training loss at epoch 327: 0.2098\n",
      "\n",
      "Start of epoch 328\n",
      "Training loss at epoch 328: 0.2098\n",
      "\n",
      "Start of epoch 329\n",
      "Training loss at epoch 329: 0.2098\n",
      "\n",
      "Start of epoch 330\n",
      "Training loss at epoch 330: 0.2097\n",
      "\n",
      "Start of epoch 331\n",
      "Training loss at epoch 331: 0.2097\n",
      "\n",
      "Start of epoch 332\n",
      "Training loss at epoch 332: 0.2097\n",
      "\n",
      "Start of epoch 333\n",
      "Training loss at epoch 333: 0.2097\n",
      "\n",
      "Start of epoch 334\n",
      "Training loss at epoch 334: 0.2097\n",
      "\n",
      "Start of epoch 335\n",
      "Training loss at epoch 335: 0.2096\n",
      "\n",
      "Start of epoch 336\n",
      "Training loss at epoch 336: 0.2096\n",
      "\n",
      "Start of epoch 337\n",
      "Training loss at epoch 337: 0.2096\n",
      "\n",
      "Start of epoch 338\n",
      "Training loss at epoch 338: 0.2096\n",
      "\n",
      "Start of epoch 339\n",
      "Training loss at epoch 339: 0.2096\n",
      "\n",
      "Start of epoch 340\n",
      "Training loss at epoch 340: 0.2096\n",
      "\n",
      "Start of epoch 341\n",
      "Training loss at epoch 341: 0.2095\n",
      "\n",
      "Start of epoch 342\n",
      "Training loss at epoch 342: 0.2095\n",
      "\n",
      "Start of epoch 343\n",
      "Training loss at epoch 343: 0.2095\n",
      "\n",
      "Start of epoch 344\n",
      "Training loss at epoch 344: 0.2095\n",
      "\n",
      "Start of epoch 345\n",
      "Training loss at epoch 345: 0.2095\n",
      "\n",
      "Start of epoch 346\n",
      "Training loss at epoch 346: 0.2095\n",
      "\n",
      "Start of epoch 347\n",
      "Training loss at epoch 347: 0.2095\n",
      "\n",
      "Start of epoch 348\n",
      "Training loss at epoch 348: 0.2094\n",
      "\n",
      "Start of epoch 349\n",
      "Training loss at epoch 349: 0.2094\n",
      "\n",
      "Start of epoch 350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 350: 0.2094\n",
      "\n",
      "Start of epoch 351\n",
      "Training loss at epoch 351: 0.2094\n",
      "\n",
      "Start of epoch 352\n",
      "Training loss at epoch 352: 0.2094\n",
      "\n",
      "Start of epoch 353\n",
      "Training loss at epoch 353: 0.2094\n",
      "\n",
      "Start of epoch 354\n",
      "Training loss at epoch 354: 0.2094\n",
      "\n",
      "Start of epoch 355\n",
      "Training loss at epoch 355: 0.2094\n",
      "\n",
      "Start of epoch 356\n",
      "Training loss at epoch 356: 0.2093\n",
      "\n",
      "Start of epoch 357\n",
      "Training loss at epoch 357: 0.2093\n",
      "\n",
      "Start of epoch 358\n",
      "Training loss at epoch 358: 0.2093\n",
      "\n",
      "Start of epoch 359\n",
      "Training loss at epoch 359: 0.2093\n",
      "\n",
      "Start of epoch 360\n",
      "Training loss at epoch 360: 0.2093\n",
      "\n",
      "Start of epoch 361\n",
      "Training loss at epoch 361: 0.2093\n",
      "\n",
      "Start of epoch 362\n",
      "Training loss at epoch 362: 0.2093\n",
      "\n",
      "Start of epoch 363\n",
      "Training loss at epoch 363: 0.2093\n",
      "\n",
      "Start of epoch 364\n",
      "Training loss at epoch 364: 0.2092\n",
      "\n",
      "Start of epoch 365\n",
      "Training loss at epoch 365: 0.2092\n",
      "\n",
      "Start of epoch 366\n",
      "Training loss at epoch 366: 0.2092\n",
      "\n",
      "Start of epoch 367\n",
      "Training loss at epoch 367: 0.2092\n",
      "\n",
      "Start of epoch 368\n",
      "Training loss at epoch 368: 0.2092\n",
      "\n",
      "Start of epoch 369\n",
      "Training loss at epoch 369: 0.2092\n",
      "\n",
      "Start of epoch 370\n",
      "Training loss at epoch 370: 0.2092\n",
      "\n",
      "Start of epoch 371\n",
      "Training loss at epoch 371: 0.2092\n",
      "\n",
      "Start of epoch 372\n",
      "Training loss at epoch 372: 0.2092\n",
      "\n",
      "Start of epoch 373\n",
      "Training loss at epoch 373: 0.2091\n",
      "\n",
      "Start of epoch 374\n",
      "Training loss at epoch 374: 0.2091\n",
      "\n",
      "Start of epoch 375\n",
      "Training loss at epoch 375: 0.2091\n",
      "\n",
      "Start of epoch 376\n",
      "Training loss at epoch 376: 0.2091\n",
      "\n",
      "Start of epoch 377\n",
      "Training loss at epoch 377: 0.2091\n",
      "\n",
      "Start of epoch 378\n",
      "Training loss at epoch 378: 0.2091\n",
      "\n",
      "Start of epoch 379\n",
      "Training loss at epoch 379: 0.2091\n",
      "\n",
      "Start of epoch 380\n",
      "Training loss at epoch 380: 0.2091\n",
      "\n",
      "Start of epoch 381\n",
      "Training loss at epoch 381: 0.2091\n",
      "\n",
      "Start of epoch 382\n",
      "Training loss at epoch 382: 0.2090\n",
      "\n",
      "Start of epoch 383\n",
      "Training loss at epoch 383: 0.2090\n",
      "\n",
      "Start of epoch 384\n",
      "Training loss at epoch 384: 0.2090\n",
      "\n",
      "Start of epoch 385\n",
      "Training loss at epoch 385: 0.2090\n",
      "\n",
      "Start of epoch 386\n",
      "Training loss at epoch 386: 0.2090\n",
      "\n",
      "Start of epoch 387\n",
      "Training loss at epoch 387: 0.2090\n",
      "\n",
      "Start of epoch 388\n",
      "Training loss at epoch 388: 0.2090\n",
      "\n",
      "Start of epoch 389\n",
      "Training loss at epoch 389: 0.2090\n",
      "\n",
      "Start of epoch 390\n",
      "Training loss at epoch 390: 0.2090\n",
      "\n",
      "Start of epoch 391\n",
      "Training loss at epoch 391: 0.2090\n",
      "\n",
      "Start of epoch 392\n",
      "Training loss at epoch 392: 0.2089\n",
      "\n",
      "Start of epoch 393\n",
      "Training loss at epoch 393: 0.2089\n",
      "\n",
      "Start of epoch 394\n",
      "Training loss at epoch 394: 0.2089\n",
      "\n",
      "Start of epoch 395\n",
      "Training loss at epoch 395: 0.2089\n",
      "\n",
      "Start of epoch 396\n",
      "Training loss at epoch 396: 0.2089\n",
      "\n",
      "Start of epoch 397\n",
      "Training loss at epoch 397: 0.2089\n",
      "\n",
      "Start of epoch 398\n",
      "Training loss at epoch 398: 0.2089\n",
      "\n",
      "Start of epoch 399\n",
      "Training loss at epoch 399: 0.2089\n",
      "\n",
      "Start of epoch 400\n",
      "Training loss at epoch 400: 0.2089\n",
      "\n",
      "Start of epoch 401\n",
      "Training loss at epoch 401: 0.2089\n",
      "\n",
      "Start of epoch 402\n",
      "Training loss at epoch 402: 0.2088\n",
      "\n",
      "Start of epoch 403\n",
      "Training loss at epoch 403: 0.2088\n",
      "\n",
      "Start of epoch 404\n",
      "Training loss at epoch 404: 0.2088\n",
      "\n",
      "Start of epoch 405\n",
      "Training loss at epoch 405: 0.2088\n",
      "\n",
      "Start of epoch 406\n",
      "Training loss at epoch 406: 0.2088\n",
      "\n",
      "Start of epoch 407\n",
      "Training loss at epoch 407: 0.2088\n",
      "\n",
      "Start of epoch 408\n",
      "Training loss at epoch 408: 0.2088\n",
      "\n",
      "Start of epoch 409\n",
      "Training loss at epoch 409: 0.2088\n",
      "\n",
      "Start of epoch 410\n",
      "Training loss at epoch 410: 0.2088\n",
      "\n",
      "Start of epoch 411\n",
      "Training loss at epoch 411: 0.2087\n",
      "\n",
      "Start of epoch 412\n",
      "Training loss at epoch 412: 0.2087\n",
      "\n",
      "Start of epoch 413\n",
      "Training loss at epoch 413: 0.2087\n",
      "\n",
      "Start of epoch 414\n",
      "Training loss at epoch 414: 0.2087\n",
      "\n",
      "Start of epoch 415\n",
      "Training loss at epoch 415: 0.2087\n",
      "\n",
      "Start of epoch 416\n",
      "Training loss at epoch 416: 0.2087\n",
      "\n",
      "Start of epoch 417\n",
      "Training loss at epoch 417: 0.2087\n",
      "\n",
      "Start of epoch 418\n",
      "Training loss at epoch 418: 0.2087\n",
      "\n",
      "Start of epoch 419\n",
      "Training loss at epoch 419: 0.2087\n",
      "\n",
      "Start of epoch 420\n",
      "Training loss at epoch 420: 0.2087\n",
      "\n",
      "Start of epoch 421\n",
      "Training loss at epoch 421: 0.2086\n",
      "\n",
      "Start of epoch 422\n",
      "Training loss at epoch 422: 0.2086\n",
      "\n",
      "Start of epoch 423\n",
      "Training loss at epoch 423: 0.2086\n",
      "\n",
      "Start of epoch 424\n",
      "Training loss at epoch 424: 0.2086\n",
      "\n",
      "Start of epoch 425\n",
      "Training loss at epoch 425: 0.2086\n",
      "\n",
      "Start of epoch 426\n",
      "Training loss at epoch 426: 0.2086\n",
      "\n",
      "Start of epoch 427\n",
      "Training loss at epoch 427: 0.2086\n",
      "\n",
      "Start of epoch 428\n",
      "Training loss at epoch 428: 0.2086\n",
      "\n",
      "Start of epoch 429\n",
      "Training loss at epoch 429: 0.2086\n",
      "\n",
      "Start of epoch 430\n",
      "Training loss at epoch 430: 0.2085\n",
      "\n",
      "Start of epoch 431\n",
      "Training loss at epoch 431: 0.2085\n",
      "\n",
      "Start of epoch 432\n",
      "Training loss at epoch 432: 0.2085\n",
      "\n",
      "Start of epoch 433\n",
      "Training loss at epoch 433: 0.2085\n",
      "\n",
      "Start of epoch 434\n",
      "Training loss at epoch 434: 0.2085\n",
      "\n",
      "Start of epoch 435\n",
      "Training loss at epoch 435: 0.2085\n",
      "\n",
      "Start of epoch 436\n",
      "Training loss at epoch 436: 0.2085\n",
      "\n",
      "Start of epoch 437\n",
      "Training loss at epoch 437: 0.2085\n",
      "\n",
      "Start of epoch 438\n",
      "Training loss at epoch 438: 0.2085\n",
      "\n",
      "Start of epoch 439\n",
      "Training loss at epoch 439: 0.2084\n",
      "\n",
      "Start of epoch 440\n",
      "Training loss at epoch 440: 0.2084\n",
      "\n",
      "Start of epoch 441\n",
      "Training loss at epoch 441: 0.2084\n",
      "\n",
      "Start of epoch 442\n",
      "Training loss at epoch 442: 0.2084\n",
      "\n",
      "Start of epoch 443\n",
      "Training loss at epoch 443: 0.2084\n",
      "\n",
      "Start of epoch 444\n",
      "Training loss at epoch 444: 0.2084\n",
      "\n",
      "Start of epoch 445\n",
      "Training loss at epoch 445: 0.2084\n",
      "\n",
      "Start of epoch 446\n",
      "Training loss at epoch 446: 0.2084\n",
      "\n",
      "Start of epoch 447\n",
      "Training loss at epoch 447: 0.2084\n",
      "\n",
      "Start of epoch 448\n",
      "Training loss at epoch 448: 0.2083\n",
      "\n",
      "Start of epoch 449\n",
      "Training loss at epoch 449: 0.2083\n",
      "\n",
      "Start of epoch 450\n",
      "Training loss at epoch 450: 0.2083\n",
      "\n",
      "Start of epoch 451\n",
      "Training loss at epoch 451: 0.2083\n",
      "\n",
      "Start of epoch 452\n",
      "Training loss at epoch 452: 0.2083\n",
      "\n",
      "Start of epoch 453\n",
      "Training loss at epoch 453: 0.2083\n",
      "\n",
      "Start of epoch 454\n",
      "Training loss at epoch 454: 0.2083\n",
      "\n",
      "Start of epoch 455\n",
      "Training loss at epoch 455: 0.2083\n",
      "\n",
      "Start of epoch 456\n",
      "Training loss at epoch 456: 0.2082\n",
      "\n",
      "Start of epoch 457\n",
      "Training loss at epoch 457: 0.2082\n",
      "\n",
      "Start of epoch 458\n",
      "Training loss at epoch 458: 0.2082\n",
      "\n",
      "Start of epoch 459\n",
      "Training loss at epoch 459: 0.2082\n",
      "\n",
      "Start of epoch 460\n",
      "Training loss at epoch 460: 0.2082\n",
      "\n",
      "Start of epoch 461\n",
      "Training loss at epoch 461: 0.2082\n",
      "\n",
      "Start of epoch 462\n",
      "Training loss at epoch 462: 0.2082\n",
      "\n",
      "Start of epoch 463\n",
      "Training loss at epoch 463: 0.2082\n",
      "\n",
      "Start of epoch 464\n",
      "Training loss at epoch 464: 0.2081\n",
      "\n",
      "Start of epoch 465\n",
      "Training loss at epoch 465: 0.2081\n",
      "\n",
      "Start of epoch 466\n",
      "Training loss at epoch 466: 0.2081\n",
      "\n",
      "Start of epoch 467\n",
      "Training loss at epoch 467: 0.2081\n",
      "\n",
      "Start of epoch 468\n",
      "Training loss at epoch 468: 0.2081\n",
      "\n",
      "Start of epoch 469\n",
      "Training loss at epoch 469: 0.2081\n",
      "\n",
      "Start of epoch 470\n",
      "Training loss at epoch 470: 0.2081\n",
      "\n",
      "Start of epoch 471\n",
      "Training loss at epoch 471: 0.2081\n",
      "\n",
      "Start of epoch 472\n",
      "Training loss at epoch 472: 0.2080\n",
      "\n",
      "Start of epoch 473\n",
      "Training loss at epoch 473: 0.2080\n",
      "\n",
      "Start of epoch 474\n",
      "Training loss at epoch 474: 0.2080\n",
      "\n",
      "Start of epoch 475\n",
      "Training loss at epoch 475: 0.2080\n",
      "\n",
      "Start of epoch 476\n",
      "Training loss at epoch 476: 0.2080\n",
      "\n",
      "Start of epoch 477\n",
      "Training loss at epoch 477: 0.2080\n",
      "\n",
      "Start of epoch 478\n",
      "Training loss at epoch 478: 0.2080\n",
      "\n",
      "Start of epoch 479\n",
      "Training loss at epoch 479: 0.2079\n",
      "\n",
      "Start of epoch 480\n",
      "Training loss at epoch 480: 0.2079\n",
      "\n",
      "Start of epoch 481\n",
      "Training loss at epoch 481: 0.2079\n",
      "\n",
      "Start of epoch 482\n",
      "Training loss at epoch 482: 0.2079\n",
      "\n",
      "Start of epoch 483\n",
      "Training loss at epoch 483: 0.2079\n",
      "\n",
      "Start of epoch 484\n",
      "Training loss at epoch 484: 0.2079\n",
      "\n",
      "Start of epoch 485\n",
      "Training loss at epoch 485: 0.2079\n",
      "\n",
      "Start of epoch 486\n",
      "Training loss at epoch 486: 0.2078\n",
      "\n",
      "Start of epoch 487\n",
      "Training loss at epoch 487: 0.2078\n",
      "\n",
      "Start of epoch 488\n",
      "Training loss at epoch 488: 0.2078\n",
      "\n",
      "Start of epoch 489\n",
      "Training loss at epoch 489: 0.2078\n",
      "\n",
      "Start of epoch 490\n",
      "Training loss at epoch 490: 0.2078\n",
      "\n",
      "Start of epoch 491\n",
      "Training loss at epoch 491: 0.2078\n",
      "\n",
      "Start of epoch 492\n",
      "Training loss at epoch 492: 0.2078\n",
      "\n",
      "Start of epoch 493\n",
      "Training loss at epoch 493: 0.2077\n",
      "\n",
      "Start of epoch 494\n",
      "Training loss at epoch 494: 0.2077\n",
      "\n",
      "Start of epoch 495\n",
      "Training loss at epoch 495: 0.2077\n",
      "\n",
      "Start of epoch 496\n",
      "Training loss at epoch 496: 0.2077\n",
      "\n",
      "Start of epoch 497\n",
      "Training loss at epoch 497: 0.2077\n",
      "\n",
      "Start of epoch 498\n",
      "Training loss at epoch 498: 0.2077\n",
      "\n",
      "Start of epoch 499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 499: 0.2077\n",
      "[<tf.Variable 'parameters:0' shape=(75,) dtype=float32, numpy=\n",
      "array([3.2863188 , 5.3084726 , 0.53604764, 3.1146028 , 3.0047262 ,\n",
      "       3.1820006 , 2.9900477 , 2.0952327 , 1.2505862 , 1.1296563 ,\n",
      "       0.79966766, 3.0168114 , 4.156767  , 0.06791985, 6.1365757 ,\n",
      "       1.312018  , 3.3142922 , 5.8651013 , 0.61310774, 5.2607102 ,\n",
      "       0.21928886, 4.678175  , 4.66742   , 5.276525  , 5.041685  ,\n",
      "       4.1174006 , 2.2098372 , 4.5902944 , 3.0463684 , 5.864795  ,\n",
      "       0.69641155, 5.9462976 , 1.594946  , 1.4913903 , 1.0959266 ,\n",
      "       4.353504  , 6.038585  , 4.508874  , 1.0547758 , 3.181573  ,\n",
      "       5.7358365 , 6.163935  , 6.234346  , 5.362391  , 3.0040424 ,\n",
      "       1.2282842 , 6.0417047 , 4.880721  , 0.54862285, 4.103348  ,\n",
      "       3.8100579 , 0.9529459 , 3.9819093 , 4.5793395 , 5.775635  ,\n",
      "       1.5242436 , 0.0438308 , 2.417607  , 0.49442118, 1.0845588 ,\n",
      "       0.44112137, 4.16173   , 3.038499  , 3.6168706 , 1.4578278 ,\n",
      "       0.0729757 , 2.3978996 , 2.0023985 , 5.969553  , 0.7567132 ,\n",
      "       3.3772182 , 3.666036  , 3.9540625 , 5.5028214 , 4.357678  ],\n",
      "      dtype=float32)>]\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 0.9462\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 0.8697\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.8174\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.7707\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.7240\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.6766\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.6330\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.5989\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.5774\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.5658\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.5590\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.5526\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.5444\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.5340\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.5221\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.5098\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.4978\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.4862\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.4749\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.4640\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.4536\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.4436\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.4343\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.4258\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.4181\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.4111\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.4045\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.3980\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.3917\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.3855\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.3792\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.3726\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.3659\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.3592\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.3528\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.3469\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.3415\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.3366\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.3318\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.3270\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.3220\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.3171\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.3123\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.3078\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.3036\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.2996\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.2957\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.2920\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.2883\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.2848\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.2813\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.2778\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.2743\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.2710\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.2677\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.2645\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.2614\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.2584\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.2556\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.2529\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.2504\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.2480\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.2458\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.2437\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.2417\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.2398\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.2380\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.2365\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.2351\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.2338\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.2325\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.2312\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.2298\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.2285\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.2271\n",
      "\n",
      "Start of epoch 75\n",
      "Training loss at epoch 75: 0.2258\n",
      "\n",
      "Start of epoch 76\n",
      "Training loss at epoch 76: 0.2244\n",
      "\n",
      "Start of epoch 77\n",
      "Training loss at epoch 77: 0.2231\n",
      "\n",
      "Start of epoch 78\n",
      "Training loss at epoch 78: 0.2218\n",
      "\n",
      "Start of epoch 79\n",
      "Training loss at epoch 79: 0.2206\n",
      "\n",
      "Start of epoch 80\n",
      "Training loss at epoch 80: 0.2194\n",
      "\n",
      "Start of epoch 81\n",
      "Training loss at epoch 81: 0.2182\n",
      "\n",
      "Start of epoch 82\n",
      "Training loss at epoch 82: 0.2171\n",
      "\n",
      "Start of epoch 83\n",
      "Training loss at epoch 83: 0.2161\n",
      "\n",
      "Start of epoch 84\n",
      "Training loss at epoch 84: 0.2150\n",
      "\n",
      "Start of epoch 85\n",
      "Training loss at epoch 85: 0.2141\n",
      "\n",
      "Start of epoch 86\n",
      "Training loss at epoch 86: 0.2131\n",
      "\n",
      "Start of epoch 87\n",
      "Training loss at epoch 87: 0.2122\n",
      "\n",
      "Start of epoch 88\n",
      "Training loss at epoch 88: 0.2113\n",
      "\n",
      "Start of epoch 89\n",
      "Training loss at epoch 89: 0.2104\n",
      "\n",
      "Start of epoch 90\n",
      "Training loss at epoch 90: 0.2095\n",
      "\n",
      "Start of epoch 91\n",
      "Training loss at epoch 91: 0.2087\n",
      "\n",
      "Start of epoch 92\n",
      "Training loss at epoch 92: 0.2079\n",
      "\n",
      "Start of epoch 93\n",
      "Training loss at epoch 93: 0.2071\n",
      "\n",
      "Start of epoch 94\n",
      "Training loss at epoch 94: 0.2063\n",
      "\n",
      "Start of epoch 95\n",
      "Training loss at epoch 95: 0.2055\n",
      "\n",
      "Start of epoch 96\n",
      "Training loss at epoch 96: 0.2048\n",
      "\n",
      "Start of epoch 97\n",
      "Training loss at epoch 97: 0.2041\n",
      "\n",
      "Start of epoch 98\n",
      "Training loss at epoch 98: 0.2035\n",
      "\n",
      "Start of epoch 99\n",
      "Training loss at epoch 99: 0.2029\n",
      "\n",
      "Start of epoch 100\n",
      "Training loss at epoch 100: 0.2023\n",
      "\n",
      "Start of epoch 101\n",
      "Training loss at epoch 101: 0.2017\n",
      "\n",
      "Start of epoch 102\n",
      "Training loss at epoch 102: 0.2012\n",
      "\n",
      "Start of epoch 103\n",
      "Training loss at epoch 103: 0.2007\n",
      "\n",
      "Start of epoch 104\n",
      "Training loss at epoch 104: 0.2002\n",
      "\n",
      "Start of epoch 105\n",
      "Training loss at epoch 105: 0.1998\n",
      "\n",
      "Start of epoch 106\n",
      "Training loss at epoch 106: 0.1994\n",
      "\n",
      "Start of epoch 107\n",
      "Training loss at epoch 107: 0.1989\n",
      "\n",
      "Start of epoch 108\n",
      "Training loss at epoch 108: 0.1985\n",
      "\n",
      "Start of epoch 109\n",
      "Training loss at epoch 109: 0.1982\n",
      "\n",
      "Start of epoch 110\n",
      "Training loss at epoch 110: 0.1978\n",
      "\n",
      "Start of epoch 111\n",
      "Training loss at epoch 111: 0.1974\n",
      "\n",
      "Start of epoch 112\n",
      "Training loss at epoch 112: 0.1970\n",
      "\n",
      "Start of epoch 113\n",
      "Training loss at epoch 113: 0.1966\n",
      "\n",
      "Start of epoch 114\n",
      "Training loss at epoch 114: 0.1963\n",
      "\n",
      "Start of epoch 115\n",
      "Training loss at epoch 115: 0.1959\n",
      "\n",
      "Start of epoch 116\n",
      "Training loss at epoch 116: 0.1955\n",
      "\n",
      "Start of epoch 117\n",
      "Training loss at epoch 117: 0.1951\n",
      "\n",
      "Start of epoch 118\n",
      "Training loss at epoch 118: 0.1947\n",
      "\n",
      "Start of epoch 119\n",
      "Training loss at epoch 119: 0.1944\n",
      "\n",
      "Start of epoch 120\n",
      "Training loss at epoch 120: 0.1940\n",
      "\n",
      "Start of epoch 121\n",
      "Training loss at epoch 121: 0.1936\n",
      "\n",
      "Start of epoch 122\n",
      "Training loss at epoch 122: 0.1932\n",
      "\n",
      "Start of epoch 123\n",
      "Training loss at epoch 123: 0.1929\n",
      "\n",
      "Start of epoch 124\n",
      "Training loss at epoch 124: 0.1925\n",
      "\n",
      "Start of epoch 125\n",
      "Training loss at epoch 125: 0.1922\n",
      "\n",
      "Start of epoch 126\n",
      "Training loss at epoch 126: 0.1918\n",
      "\n",
      "Start of epoch 127\n",
      "Training loss at epoch 127: 0.1915\n",
      "\n",
      "Start of epoch 128\n",
      "Training loss at epoch 128: 0.1912\n",
      "\n",
      "Start of epoch 129\n",
      "Training loss at epoch 129: 0.1909\n",
      "\n",
      "Start of epoch 130\n",
      "Training loss at epoch 130: 0.1905\n",
      "\n",
      "Start of epoch 131\n",
      "Training loss at epoch 131: 0.1902\n",
      "\n",
      "Start of epoch 132\n",
      "Training loss at epoch 132: 0.1899\n",
      "\n",
      "Start of epoch 133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 133: 0.1896\n",
      "\n",
      "Start of epoch 134\n",
      "Training loss at epoch 134: 0.1893\n",
      "\n",
      "Start of epoch 135\n",
      "Training loss at epoch 135: 0.1890\n",
      "\n",
      "Start of epoch 136\n",
      "Training loss at epoch 136: 0.1887\n",
      "\n",
      "Start of epoch 137\n",
      "Training loss at epoch 137: 0.1883\n",
      "\n",
      "Start of epoch 138\n",
      "Training loss at epoch 138: 0.1880\n",
      "\n",
      "Start of epoch 139\n",
      "Training loss at epoch 139: 0.1877\n",
      "\n",
      "Start of epoch 140\n",
      "Training loss at epoch 140: 0.1874\n",
      "\n",
      "Start of epoch 141\n",
      "Training loss at epoch 141: 0.1870\n",
      "\n",
      "Start of epoch 142\n",
      "Training loss at epoch 142: 0.1867\n",
      "\n",
      "Start of epoch 143\n",
      "Training loss at epoch 143: 0.1864\n",
      "\n",
      "Start of epoch 144\n",
      "Training loss at epoch 144: 0.1861\n",
      "\n",
      "Start of epoch 145\n",
      "Training loss at epoch 145: 0.1857\n",
      "\n",
      "Start of epoch 146\n",
      "Training loss at epoch 146: 0.1854\n",
      "\n",
      "Start of epoch 147\n",
      "Training loss at epoch 147: 0.1851\n",
      "\n",
      "Start of epoch 148\n",
      "Training loss at epoch 148: 0.1847\n",
      "\n",
      "Start of epoch 149\n",
      "Training loss at epoch 149: 0.1844\n",
      "\n",
      "Start of epoch 150\n",
      "Training loss at epoch 150: 0.1840\n",
      "\n",
      "Start of epoch 151\n",
      "Training loss at epoch 151: 0.1837\n",
      "\n",
      "Start of epoch 152\n",
      "Training loss at epoch 152: 0.1833\n",
      "\n",
      "Start of epoch 153\n",
      "Training loss at epoch 153: 0.1830\n",
      "\n",
      "Start of epoch 154\n",
      "Training loss at epoch 154: 0.1826\n",
      "\n",
      "Start of epoch 155\n",
      "Training loss at epoch 155: 0.1822\n",
      "\n",
      "Start of epoch 156\n",
      "Training loss at epoch 156: 0.1819\n",
      "\n",
      "Start of epoch 157\n",
      "Training loss at epoch 157: 0.1815\n",
      "\n",
      "Start of epoch 158\n",
      "Training loss at epoch 158: 0.1811\n",
      "\n",
      "Start of epoch 159\n",
      "Training loss at epoch 159: 0.1807\n",
      "\n",
      "Start of epoch 160\n",
      "Training loss at epoch 160: 0.1804\n",
      "\n",
      "Start of epoch 161\n",
      "Training loss at epoch 161: 0.1800\n",
      "\n",
      "Start of epoch 162\n",
      "Training loss at epoch 162: 0.1796\n",
      "\n",
      "Start of epoch 163\n",
      "Training loss at epoch 163: 0.1792\n",
      "\n",
      "Start of epoch 164\n",
      "Training loss at epoch 164: 0.1788\n",
      "\n",
      "Start of epoch 165\n",
      "Training loss at epoch 165: 0.1785\n",
      "\n",
      "Start of epoch 166\n",
      "Training loss at epoch 166: 0.1781\n",
      "\n",
      "Start of epoch 167\n",
      "Training loss at epoch 167: 0.1777\n",
      "\n",
      "Start of epoch 168\n",
      "Training loss at epoch 168: 0.1774\n",
      "\n",
      "Start of epoch 169\n",
      "Training loss at epoch 169: 0.1770\n",
      "\n",
      "Start of epoch 170\n",
      "Training loss at epoch 170: 0.1766\n",
      "\n",
      "Start of epoch 171\n",
      "Training loss at epoch 171: 0.1763\n",
      "\n",
      "Start of epoch 172\n",
      "Training loss at epoch 172: 0.1760\n",
      "\n",
      "Start of epoch 173\n",
      "Training loss at epoch 173: 0.1756\n",
      "\n",
      "Start of epoch 174\n",
      "Training loss at epoch 174: 0.1753\n",
      "\n",
      "Start of epoch 175\n",
      "Training loss at epoch 175: 0.1750\n",
      "\n",
      "Start of epoch 176\n",
      "Training loss at epoch 176: 0.1747\n",
      "\n",
      "Start of epoch 177\n",
      "Training loss at epoch 177: 0.1744\n",
      "\n",
      "Start of epoch 178\n",
      "Training loss at epoch 178: 0.1741\n",
      "\n",
      "Start of epoch 179\n",
      "Training loss at epoch 179: 0.1738\n",
      "\n",
      "Start of epoch 180\n",
      "Training loss at epoch 180: 0.1736\n",
      "\n",
      "Start of epoch 181\n",
      "Training loss at epoch 181: 0.1733\n",
      "\n",
      "Start of epoch 182\n",
      "Training loss at epoch 182: 0.1731\n",
      "\n",
      "Start of epoch 183\n",
      "Training loss at epoch 183: 0.1728\n",
      "\n",
      "Start of epoch 184\n",
      "Training loss at epoch 184: 0.1726\n",
      "\n",
      "Start of epoch 185\n",
      "Training loss at epoch 185: 0.1724\n",
      "\n",
      "Start of epoch 186\n",
      "Training loss at epoch 186: 0.1722\n",
      "\n",
      "Start of epoch 187\n",
      "Training loss at epoch 187: 0.1720\n",
      "\n",
      "Start of epoch 188\n",
      "Training loss at epoch 188: 0.1718\n",
      "\n",
      "Start of epoch 189\n",
      "Training loss at epoch 189: 0.1716\n",
      "\n",
      "Start of epoch 190\n",
      "Training loss at epoch 190: 0.1714\n",
      "\n",
      "Start of epoch 191\n",
      "Training loss at epoch 191: 0.1713\n",
      "\n",
      "Start of epoch 192\n",
      "Training loss at epoch 192: 0.1711\n",
      "\n",
      "Start of epoch 193\n",
      "Training loss at epoch 193: 0.1710\n",
      "\n",
      "Start of epoch 194\n",
      "Training loss at epoch 194: 0.1708\n",
      "\n",
      "Start of epoch 195\n",
      "Training loss at epoch 195: 0.1707\n",
      "\n",
      "Start of epoch 196\n",
      "Training loss at epoch 196: 0.1706\n",
      "\n",
      "Start of epoch 197\n",
      "Training loss at epoch 197: 0.1704\n",
      "\n",
      "Start of epoch 198\n",
      "Training loss at epoch 198: 0.1703\n",
      "\n",
      "Start of epoch 199\n",
      "Training loss at epoch 199: 0.1702\n",
      "\n",
      "Start of epoch 200\n",
      "Training loss at epoch 200: 0.1701\n",
      "\n",
      "Start of epoch 201\n",
      "Training loss at epoch 201: 0.1700\n",
      "\n",
      "Start of epoch 202\n",
      "Training loss at epoch 202: 0.1699\n",
      "\n",
      "Start of epoch 203\n",
      "Training loss at epoch 203: 0.1698\n",
      "\n",
      "Start of epoch 204\n",
      "Training loss at epoch 204: 0.1697\n",
      "\n",
      "Start of epoch 205\n",
      "Training loss at epoch 205: 0.1696\n",
      "\n",
      "Start of epoch 206\n",
      "Training loss at epoch 206: 0.1695\n",
      "\n",
      "Start of epoch 207\n",
      "Training loss at epoch 207: 0.1694\n",
      "\n",
      "Start of epoch 208\n",
      "Training loss at epoch 208: 0.1694\n",
      "\n",
      "Start of epoch 209\n",
      "Training loss at epoch 209: 0.1693\n",
      "\n",
      "Start of epoch 210\n",
      "Training loss at epoch 210: 0.1692\n",
      "\n",
      "Start of epoch 211\n",
      "Training loss at epoch 211: 0.1692\n",
      "\n",
      "Start of epoch 212\n",
      "Training loss at epoch 212: 0.1691\n",
      "\n",
      "Start of epoch 213\n",
      "Training loss at epoch 213: 0.1690\n",
      "\n",
      "Start of epoch 214\n",
      "Training loss at epoch 214: 0.1690\n",
      "\n",
      "Start of epoch 215\n",
      "Training loss at epoch 215: 0.1689\n",
      "\n",
      "Start of epoch 216\n",
      "Training loss at epoch 216: 0.1689\n",
      "\n",
      "Start of epoch 217\n",
      "Training loss at epoch 217: 0.1688\n",
      "\n",
      "Start of epoch 218\n",
      "Training loss at epoch 218: 0.1688\n",
      "\n",
      "Start of epoch 219\n",
      "Training loss at epoch 219: 0.1687\n",
      "\n",
      "Start of epoch 220\n",
      "Training loss at epoch 220: 0.1687\n",
      "\n",
      "Start of epoch 221\n",
      "Training loss at epoch 221: 0.1686\n",
      "\n",
      "Start of epoch 222\n",
      "Training loss at epoch 222: 0.1686\n",
      "\n",
      "Start of epoch 223\n",
      "Training loss at epoch 223: 0.1685\n",
      "\n",
      "Start of epoch 224\n",
      "Training loss at epoch 224: 0.1685\n",
      "\n",
      "Start of epoch 225\n",
      "Training loss at epoch 225: 0.1684\n",
      "\n",
      "Start of epoch 226\n",
      "Training loss at epoch 226: 0.1684\n",
      "\n",
      "Start of epoch 227\n",
      "Training loss at epoch 227: 0.1684\n",
      "\n",
      "Start of epoch 228\n",
      "Training loss at epoch 228: 0.1683\n",
      "\n",
      "Start of epoch 229\n",
      "Training loss at epoch 229: 0.1683\n",
      "\n",
      "Start of epoch 230\n",
      "Training loss at epoch 230: 0.1683\n",
      "\n",
      "Start of epoch 231\n",
      "Training loss at epoch 231: 0.1682\n",
      "\n",
      "Start of epoch 232\n",
      "Training loss at epoch 232: 0.1682\n",
      "\n",
      "Start of epoch 233\n",
      "Training loss at epoch 233: 0.1682\n",
      "\n",
      "Start of epoch 234\n",
      "Training loss at epoch 234: 0.1681\n",
      "\n",
      "Start of epoch 235\n",
      "Training loss at epoch 235: 0.1681\n",
      "\n",
      "Start of epoch 236\n",
      "Training loss at epoch 236: 0.1681\n",
      "\n",
      "Start of epoch 237\n",
      "Training loss at epoch 237: 0.1681\n",
      "\n",
      "Start of epoch 238\n",
      "Training loss at epoch 238: 0.1680\n",
      "\n",
      "Start of epoch 239\n",
      "Training loss at epoch 239: 0.1680\n",
      "\n",
      "Start of epoch 240\n",
      "Training loss at epoch 240: 0.1680\n",
      "\n",
      "Start of epoch 241\n",
      "Training loss at epoch 241: 0.1680\n",
      "\n",
      "Start of epoch 242\n",
      "Training loss at epoch 242: 0.1679\n",
      "\n",
      "Start of epoch 243\n",
      "Training loss at epoch 243: 0.1679\n",
      "\n",
      "Start of epoch 244\n",
      "Training loss at epoch 244: 0.1679\n",
      "\n",
      "Start of epoch 245\n",
      "Training loss at epoch 245: 0.1679\n",
      "\n",
      "Start of epoch 246\n",
      "Training loss at epoch 246: 0.1679\n",
      "\n",
      "Start of epoch 247\n",
      "Training loss at epoch 247: 0.1678\n",
      "\n",
      "Start of epoch 248\n",
      "Training loss at epoch 248: 0.1678\n",
      "\n",
      "Start of epoch 249\n",
      "Training loss at epoch 249: 0.1678\n",
      "\n",
      "Start of epoch 250\n",
      "Training loss at epoch 250: 0.1678\n",
      "\n",
      "Start of epoch 251\n",
      "Training loss at epoch 251: 0.1678\n",
      "\n",
      "Start of epoch 252\n",
      "Training loss at epoch 252: 0.1677\n",
      "\n",
      "Start of epoch 253\n",
      "Training loss at epoch 253: 0.1677\n",
      "\n",
      "Start of epoch 254\n",
      "Training loss at epoch 254: 0.1677\n",
      "\n",
      "Start of epoch 255\n",
      "Training loss at epoch 255: 0.1677\n",
      "\n",
      "Start of epoch 256\n",
      "Training loss at epoch 256: 0.1677\n",
      "\n",
      "Start of epoch 257\n",
      "Training loss at epoch 257: 0.1677\n",
      "\n",
      "Start of epoch 258\n",
      "Training loss at epoch 258: 0.1676\n",
      "\n",
      "Start of epoch 259\n",
      "Training loss at epoch 259: 0.1676\n",
      "\n",
      "Start of epoch 260\n",
      "Training loss at epoch 260: 0.1676\n",
      "\n",
      "Start of epoch 261\n",
      "Training loss at epoch 261: 0.1676\n",
      "\n",
      "Start of epoch 262\n",
      "Training loss at epoch 262: 0.1676\n",
      "\n",
      "Start of epoch 263\n",
      "Training loss at epoch 263: 0.1676\n",
      "\n",
      "Start of epoch 264\n",
      "Training loss at epoch 264: 0.1676\n",
      "\n",
      "Start of epoch 265\n",
      "Training loss at epoch 265: 0.1675\n",
      "\n",
      "Start of epoch 266\n",
      "Training loss at epoch 266: 0.1675\n",
      "\n",
      "Start of epoch 267\n",
      "Training loss at epoch 267: 0.1675\n",
      "\n",
      "Start of epoch 268\n",
      "Training loss at epoch 268: 0.1675\n",
      "\n",
      "Start of epoch 269\n",
      "Training loss at epoch 269: 0.1675\n",
      "\n",
      "Start of epoch 270\n",
      "Training loss at epoch 270: 0.1675\n",
      "\n",
      "Start of epoch 271\n",
      "Training loss at epoch 271: 0.1675\n",
      "\n",
      "Start of epoch 272\n",
      "Training loss at epoch 272: 0.1674\n",
      "\n",
      "Start of epoch 273\n",
      "Training loss at epoch 273: 0.1674\n",
      "\n",
      "Start of epoch 274\n",
      "Training loss at epoch 274: 0.1674\n",
      "\n",
      "Start of epoch 275\n",
      "Training loss at epoch 275: 0.1674\n",
      "\n",
      "Start of epoch 276\n",
      "Training loss at epoch 276: 0.1674\n",
      "\n",
      "Start of epoch 277\n",
      "Training loss at epoch 277: 0.1674\n",
      "\n",
      "Start of epoch 278\n",
      "Training loss at epoch 278: 0.1674\n",
      "\n",
      "Start of epoch 279\n",
      "Training loss at epoch 279: 0.1674\n",
      "\n",
      "Start of epoch 280\n",
      "Training loss at epoch 280: 0.1674\n",
      "\n",
      "Start of epoch 281\n",
      "Training loss at epoch 281: 0.1673\n",
      "\n",
      "Start of epoch 282\n",
      "Training loss at epoch 282: 0.1673\n",
      "\n",
      "Start of epoch 283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 283: 0.1673\n",
      "\n",
      "Start of epoch 284\n",
      "Training loss at epoch 284: 0.1673\n",
      "\n",
      "Start of epoch 285\n",
      "Training loss at epoch 285: 0.1673\n",
      "\n",
      "Start of epoch 286\n",
      "Training loss at epoch 286: 0.1673\n",
      "\n",
      "Start of epoch 287\n",
      "Training loss at epoch 287: 0.1673\n",
      "\n",
      "Start of epoch 288\n",
      "Training loss at epoch 288: 0.1673\n",
      "\n",
      "Start of epoch 289\n",
      "Training loss at epoch 289: 0.1673\n",
      "\n",
      "Start of epoch 290\n",
      "Training loss at epoch 290: 0.1672\n",
      "\n",
      "Start of epoch 291\n",
      "Training loss at epoch 291: 0.1672\n",
      "\n",
      "Start of epoch 292\n",
      "Training loss at epoch 292: 0.1672\n",
      "\n",
      "Start of epoch 293\n",
      "Training loss at epoch 293: 0.1672\n",
      "\n",
      "Start of epoch 294\n",
      "Training loss at epoch 294: 0.1672\n",
      "\n",
      "Start of epoch 295\n",
      "Training loss at epoch 295: 0.1672\n",
      "\n",
      "Start of epoch 296\n",
      "Training loss at epoch 296: 0.1672\n",
      "\n",
      "Start of epoch 297\n",
      "Training loss at epoch 297: 0.1672\n",
      "\n",
      "Start of epoch 298\n",
      "Training loss at epoch 298: 0.1672\n",
      "\n",
      "Start of epoch 299\n",
      "Training loss at epoch 299: 0.1672\n",
      "\n",
      "Start of epoch 300\n",
      "Training loss at epoch 300: 0.1671\n",
      "\n",
      "Start of epoch 301\n",
      "Training loss at epoch 301: 0.1671\n",
      "\n",
      "Start of epoch 302\n",
      "Training loss at epoch 302: 0.1671\n",
      "\n",
      "Start of epoch 303\n",
      "Training loss at epoch 303: 0.1671\n",
      "\n",
      "Start of epoch 304\n",
      "Training loss at epoch 304: 0.1671\n",
      "\n",
      "Start of epoch 305\n",
      "Training loss at epoch 305: 0.1671\n",
      "\n",
      "Start of epoch 306\n",
      "Training loss at epoch 306: 0.1671\n",
      "\n",
      "Start of epoch 307\n",
      "Training loss at epoch 307: 0.1671\n",
      "\n",
      "Start of epoch 308\n",
      "Training loss at epoch 308: 0.1671\n",
      "\n",
      "Start of epoch 309\n",
      "Training loss at epoch 309: 0.1671\n",
      "\n",
      "Start of epoch 310\n",
      "Training loss at epoch 310: 0.1671\n",
      "\n",
      "Start of epoch 311\n",
      "Training loss at epoch 311: 0.1670\n",
      "\n",
      "Start of epoch 312\n",
      "Training loss at epoch 312: 0.1670\n",
      "\n",
      "Start of epoch 313\n",
      "Training loss at epoch 313: 0.1670\n",
      "\n",
      "Start of epoch 314\n",
      "Training loss at epoch 314: 0.1670\n",
      "\n",
      "Start of epoch 315\n",
      "Training loss at epoch 315: 0.1670\n",
      "\n",
      "Start of epoch 316\n",
      "Training loss at epoch 316: 0.1670\n",
      "\n",
      "Start of epoch 317\n",
      "Training loss at epoch 317: 0.1670\n",
      "\n",
      "Start of epoch 318\n",
      "Training loss at epoch 318: 0.1670\n",
      "\n",
      "Start of epoch 319\n",
      "Training loss at epoch 319: 0.1670\n",
      "\n",
      "Start of epoch 320\n",
      "Training loss at epoch 320: 0.1670\n",
      "\n",
      "Start of epoch 321\n",
      "Training loss at epoch 321: 0.1670\n",
      "\n",
      "Start of epoch 322\n",
      "Training loss at epoch 322: 0.1670\n",
      "\n",
      "Start of epoch 323\n",
      "Training loss at epoch 323: 0.1670\n",
      "\n",
      "Start of epoch 324\n",
      "Training loss at epoch 324: 0.1669\n",
      "\n",
      "Start of epoch 325\n",
      "Training loss at epoch 325: 0.1669\n",
      "\n",
      "Start of epoch 326\n",
      "Training loss at epoch 326: 0.1669\n",
      "\n",
      "Start of epoch 327\n",
      "Training loss at epoch 327: 0.1669\n",
      "\n",
      "Start of epoch 328\n",
      "Training loss at epoch 328: 0.1669\n",
      "\n",
      "Start of epoch 329\n",
      "Training loss at epoch 329: 0.1669\n",
      "\n",
      "Start of epoch 330\n",
      "Training loss at epoch 330: 0.1669\n",
      "\n",
      "Start of epoch 331\n",
      "Training loss at epoch 331: 0.1669\n",
      "\n",
      "Start of epoch 332\n",
      "Training loss at epoch 332: 0.1669\n",
      "\n",
      "Start of epoch 333\n",
      "Training loss at epoch 333: 0.1669\n",
      "\n",
      "Start of epoch 334\n",
      "Training loss at epoch 334: 0.1669\n",
      "\n",
      "Start of epoch 335\n",
      "Training loss at epoch 335: 0.1669\n",
      "\n",
      "Start of epoch 336\n",
      "Training loss at epoch 336: 0.1669\n",
      "\n",
      "Start of epoch 337\n",
      "Training loss at epoch 337: 0.1668\n",
      "\n",
      "Start of epoch 338\n",
      "Training loss at epoch 338: 0.1668\n",
      "\n",
      "Start of epoch 339\n",
      "Training loss at epoch 339: 0.1668\n",
      "\n",
      "Start of epoch 340\n",
      "Training loss at epoch 340: 0.1668\n",
      "\n",
      "Start of epoch 341\n",
      "Training loss at epoch 341: 0.1668\n",
      "\n",
      "Start of epoch 342\n",
      "Training loss at epoch 342: 0.1668\n",
      "\n",
      "Start of epoch 343\n",
      "Training loss at epoch 343: 0.1668\n",
      "\n",
      "Start of epoch 344\n",
      "Training loss at epoch 344: 0.1668\n",
      "\n",
      "Start of epoch 345\n",
      "Training loss at epoch 345: 0.1668\n",
      "\n",
      "Start of epoch 346\n",
      "Training loss at epoch 346: 0.1668\n",
      "\n",
      "Start of epoch 347\n",
      "Training loss at epoch 347: 0.1668\n",
      "\n",
      "Start of epoch 348\n",
      "Training loss at epoch 348: 0.1668\n",
      "\n",
      "Start of epoch 349\n",
      "Training loss at epoch 349: 0.1668\n",
      "\n",
      "Start of epoch 350\n",
      "Training loss at epoch 350: 0.1668\n",
      "\n",
      "Start of epoch 351\n",
      "Training loss at epoch 351: 0.1668\n",
      "\n",
      "Start of epoch 352\n",
      "Training loss at epoch 352: 0.1668\n",
      "\n",
      "Start of epoch 353\n",
      "Training loss at epoch 353: 0.1667\n",
      "\n",
      "Start of epoch 354\n",
      "Training loss at epoch 354: 0.1667\n",
      "\n",
      "Start of epoch 355\n",
      "Training loss at epoch 355: 0.1667\n",
      "\n",
      "Start of epoch 356\n",
      "Training loss at epoch 356: 0.1667\n",
      "\n",
      "Start of epoch 357\n",
      "Training loss at epoch 357: 0.1667\n",
      "\n",
      "Start of epoch 358\n",
      "Training loss at epoch 358: 0.1667\n",
      "\n",
      "Start of epoch 359\n",
      "Training loss at epoch 359: 0.1667\n",
      "\n",
      "Start of epoch 360\n",
      "Training loss at epoch 360: 0.1667\n",
      "\n",
      "Start of epoch 361\n",
      "Training loss at epoch 361: 0.1667\n",
      "\n",
      "Start of epoch 362\n",
      "Training loss at epoch 362: 0.1667\n",
      "\n",
      "Start of epoch 363\n",
      "Training loss at epoch 363: 0.1667\n",
      "\n",
      "Start of epoch 364\n",
      "Training loss at epoch 364: 0.1667\n",
      "\n",
      "Start of epoch 365\n",
      "Training loss at epoch 365: 0.1667\n",
      "\n",
      "Start of epoch 366\n",
      "Training loss at epoch 366: 0.1667\n",
      "\n",
      "Start of epoch 367\n",
      "Training loss at epoch 367: 0.1667\n",
      "\n",
      "Start of epoch 368\n",
      "Training loss at epoch 368: 0.1667\n",
      "\n",
      "Start of epoch 369\n",
      "Training loss at epoch 369: 0.1667\n",
      "\n",
      "Start of epoch 370\n",
      "Training loss at epoch 370: 0.1666\n",
      "\n",
      "Start of epoch 371\n",
      "Training loss at epoch 371: 0.1666\n",
      "\n",
      "Start of epoch 372\n",
      "Training loss at epoch 372: 0.1666\n",
      "\n",
      "Start of epoch 373\n",
      "Training loss at epoch 373: 0.1666\n",
      "\n",
      "Start of epoch 374\n",
      "Training loss at epoch 374: 0.1666\n",
      "\n",
      "Start of epoch 375\n",
      "Training loss at epoch 375: 0.1666\n",
      "\n",
      "Start of epoch 376\n",
      "Training loss at epoch 376: 0.1666\n",
      "\n",
      "Start of epoch 377\n",
      "Training loss at epoch 377: 0.1666\n",
      "\n",
      "Start of epoch 378\n",
      "Training loss at epoch 378: 0.1666\n",
      "\n",
      "Start of epoch 379\n",
      "Training loss at epoch 379: 0.1666\n",
      "\n",
      "Start of epoch 380\n",
      "Training loss at epoch 380: 0.1666\n",
      "\n",
      "Start of epoch 381\n",
      "Training loss at epoch 381: 0.1666\n",
      "\n",
      "Start of epoch 382\n",
      "Training loss at epoch 382: 0.1666\n",
      "\n",
      "Start of epoch 383\n",
      "Training loss at epoch 383: 0.1666\n",
      "\n",
      "Start of epoch 384\n",
      "Training loss at epoch 384: 0.1666\n",
      "\n",
      "Start of epoch 385\n",
      "Training loss at epoch 385: 0.1666\n",
      "\n",
      "Start of epoch 386\n",
      "Training loss at epoch 386: 0.1666\n",
      "\n",
      "Start of epoch 387\n",
      "Training loss at epoch 387: 0.1666\n",
      "\n",
      "Start of epoch 388\n",
      "Training loss at epoch 388: 0.1666\n",
      "\n",
      "Start of epoch 389\n",
      "Training loss at epoch 389: 0.1665\n",
      "\n",
      "Start of epoch 390\n",
      "Training loss at epoch 390: 0.1665\n",
      "\n",
      "Start of epoch 391\n",
      "Training loss at epoch 391: 0.1665\n",
      "\n",
      "Start of epoch 392\n",
      "Training loss at epoch 392: 0.1665\n",
      "\n",
      "Start of epoch 393\n",
      "Training loss at epoch 393: 0.1665\n",
      "\n",
      "Start of epoch 394\n",
      "Training loss at epoch 394: 0.1665\n",
      "\n",
      "Start of epoch 395\n",
      "Training loss at epoch 395: 0.1665\n",
      "\n",
      "Start of epoch 396\n",
      "Training loss at epoch 396: 0.1665\n",
      "\n",
      "Start of epoch 397\n",
      "Training loss at epoch 397: 0.1665\n",
      "\n",
      "Start of epoch 398\n",
      "Training loss at epoch 398: 0.1665\n",
      "\n",
      "Start of epoch 399\n",
      "Training loss at epoch 399: 0.1665\n",
      "\n",
      "Start of epoch 400\n",
      "Training loss at epoch 400: 0.1665\n",
      "\n",
      "Start of epoch 401\n",
      "Training loss at epoch 401: 0.1665\n",
      "\n",
      "Start of epoch 402\n",
      "Training loss at epoch 402: 0.1665\n",
      "\n",
      "Start of epoch 403\n",
      "Training loss at epoch 403: 0.1665\n",
      "\n",
      "Start of epoch 404\n",
      "Training loss at epoch 404: 0.1665\n",
      "\n",
      "Start of epoch 405\n",
      "Training loss at epoch 405: 0.1665\n",
      "\n",
      "Start of epoch 406\n",
      "Training loss at epoch 406: 0.1665\n",
      "\n",
      "Start of epoch 407\n",
      "Training loss at epoch 407: 0.1665\n",
      "\n",
      "Start of epoch 408\n",
      "Training loss at epoch 408: 0.1665\n",
      "\n",
      "Start of epoch 409\n",
      "Training loss at epoch 409: 0.1665\n",
      "\n",
      "Start of epoch 410\n",
      "Training loss at epoch 410: 0.1665\n",
      "\n",
      "Start of epoch 411\n",
      "Training loss at epoch 411: 0.1665\n",
      "\n",
      "Start of epoch 412\n",
      "Training loss at epoch 412: 0.1664\n",
      "\n",
      "Start of epoch 413\n",
      "Training loss at epoch 413: 0.1664\n",
      "\n",
      "Start of epoch 414\n",
      "Training loss at epoch 414: 0.1664\n",
      "\n",
      "Start of epoch 415\n",
      "Training loss at epoch 415: 0.1664\n",
      "\n",
      "Start of epoch 416\n",
      "Training loss at epoch 416: 0.1664\n",
      "\n",
      "Start of epoch 417\n",
      "Training loss at epoch 417: 0.1664\n",
      "\n",
      "Start of epoch 418\n",
      "Training loss at epoch 418: 0.1664\n",
      "\n",
      "Start of epoch 419\n",
      "Training loss at epoch 419: 0.1664\n",
      "\n",
      "Start of epoch 420\n",
      "Training loss at epoch 420: 0.1664\n",
      "\n",
      "Start of epoch 421\n",
      "Training loss at epoch 421: 0.1664\n",
      "\n",
      "Start of epoch 422\n",
      "Training loss at epoch 422: 0.1664\n",
      "\n",
      "Start of epoch 423\n",
      "Training loss at epoch 423: 0.1664\n",
      "\n",
      "Start of epoch 424\n",
      "Training loss at epoch 424: 0.1664\n",
      "\n",
      "Start of epoch 425\n",
      "Training loss at epoch 425: 0.1664\n",
      "\n",
      "Start of epoch 426\n",
      "Training loss at epoch 426: 0.1664\n",
      "\n",
      "Start of epoch 427\n",
      "Training loss at epoch 427: 0.1664\n",
      "\n",
      "Start of epoch 428\n",
      "Training loss at epoch 428: 0.1664\n",
      "\n",
      "Start of epoch 429\n",
      "Training loss at epoch 429: 0.1664\n",
      "\n",
      "Start of epoch 430\n",
      "Training loss at epoch 430: 0.1664\n",
      "\n",
      "Start of epoch 431\n",
      "Training loss at epoch 431: 0.1664\n",
      "\n",
      "Start of epoch 432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 432: 0.1664\n",
      "\n",
      "Start of epoch 433\n",
      "Training loss at epoch 433: 0.1664\n",
      "\n",
      "Start of epoch 434\n",
      "Training loss at epoch 434: 0.1664\n",
      "\n",
      "Start of epoch 435\n",
      "Training loss at epoch 435: 0.1664\n",
      "\n",
      "Start of epoch 436\n",
      "Training loss at epoch 436: 0.1664\n",
      "\n",
      "Start of epoch 437\n",
      "Training loss at epoch 437: 0.1664\n",
      "\n",
      "Start of epoch 438\n",
      "Training loss at epoch 438: 0.1664\n",
      "\n",
      "Start of epoch 439\n",
      "Training loss at epoch 439: 0.1664\n",
      "\n",
      "Start of epoch 440\n",
      "Training loss at epoch 440: 0.1663\n",
      "\n",
      "Start of epoch 441\n",
      "Training loss at epoch 441: 0.1663\n",
      "\n",
      "Start of epoch 442\n",
      "Training loss at epoch 442: 0.1663\n",
      "\n",
      "Start of epoch 443\n",
      "Training loss at epoch 443: 0.1663\n",
      "\n",
      "Start of epoch 444\n",
      "Training loss at epoch 444: 0.1663\n",
      "\n",
      "Start of epoch 445\n",
      "Training loss at epoch 445: 0.1663\n",
      "\n",
      "Start of epoch 446\n",
      "Training loss at epoch 446: 0.1663\n",
      "\n",
      "Start of epoch 447\n",
      "Training loss at epoch 447: 0.1663\n",
      "\n",
      "Start of epoch 448\n",
      "Training loss at epoch 448: 0.1663\n",
      "\n",
      "Start of epoch 449\n",
      "Training loss at epoch 449: 0.1663\n",
      "\n",
      "Start of epoch 450\n",
      "Training loss at epoch 450: 0.1663\n",
      "\n",
      "Start of epoch 451\n",
      "Training loss at epoch 451: 0.1663\n",
      "\n",
      "Start of epoch 452\n",
      "Training loss at epoch 452: 0.1663\n",
      "\n",
      "Start of epoch 453\n",
      "Training loss at epoch 453: 0.1663\n",
      "\n",
      "Start of epoch 454\n",
      "Training loss at epoch 454: 0.1663\n",
      "\n",
      "Start of epoch 455\n",
      "Training loss at epoch 455: 0.1663\n",
      "\n",
      "Start of epoch 456\n",
      "Training loss at epoch 456: 0.1663\n",
      "\n",
      "Start of epoch 457\n",
      "Training loss at epoch 457: 0.1663\n",
      "\n",
      "Start of epoch 458\n",
      "Training loss at epoch 458: 0.1663\n",
      "\n",
      "Start of epoch 459\n",
      "Training loss at epoch 459: 0.1663\n",
      "\n",
      "Start of epoch 460\n",
      "Training loss at epoch 460: 0.1663\n",
      "\n",
      "Start of epoch 461\n",
      "Training loss at epoch 461: 0.1663\n",
      "\n",
      "Start of epoch 462\n",
      "Training loss at epoch 462: 0.1663\n",
      "\n",
      "Start of epoch 463\n",
      "Training loss at epoch 463: 0.1663\n",
      "\n",
      "Start of epoch 464\n",
      "Training loss at epoch 464: 0.1663\n",
      "\n",
      "Start of epoch 465\n",
      "Training loss at epoch 465: 0.1663\n",
      "\n",
      "Start of epoch 466\n",
      "Training loss at epoch 466: 0.1663\n",
      "\n",
      "Start of epoch 467\n",
      "Training loss at epoch 467: 0.1663\n",
      "\n",
      "Start of epoch 468\n",
      "Training loss at epoch 468: 0.1663\n",
      "\n",
      "Start of epoch 469\n",
      "Training loss at epoch 469: 0.1663\n",
      "\n",
      "Start of epoch 470\n",
      "Training loss at epoch 470: 0.1663\n",
      "\n",
      "Start of epoch 471\n",
      "Training loss at epoch 471: 0.1662\n",
      "\n",
      "Start of epoch 472\n",
      "Training loss at epoch 472: 0.1662\n",
      "\n",
      "Start of epoch 473\n",
      "Training loss at epoch 473: 0.1662\n",
      "\n",
      "Start of epoch 474\n",
      "Training loss at epoch 474: 0.1662\n",
      "\n",
      "Start of epoch 475\n",
      "Training loss at epoch 475: 0.1662\n",
      "\n",
      "Start of epoch 476\n",
      "Training loss at epoch 476: 0.1662\n",
      "\n",
      "Start of epoch 477\n",
      "Training loss at epoch 477: 0.1662\n",
      "\n",
      "Start of epoch 478\n",
      "Training loss at epoch 478: 0.1662\n",
      "\n",
      "Start of epoch 479\n",
      "Training loss at epoch 479: 0.1662\n",
      "\n",
      "Start of epoch 480\n",
      "Training loss at epoch 480: 0.1662\n",
      "\n",
      "Start of epoch 481\n",
      "Training loss at epoch 481: 0.1662\n",
      "\n",
      "Start of epoch 482\n",
      "Training loss at epoch 482: 0.1662\n",
      "\n",
      "Start of epoch 483\n",
      "Training loss at epoch 483: 0.1662\n",
      "\n",
      "Start of epoch 484\n",
      "Training loss at epoch 484: 0.1662\n",
      "\n",
      "Start of epoch 485\n",
      "Training loss at epoch 485: 0.1662\n",
      "\n",
      "Start of epoch 486\n",
      "Training loss at epoch 486: 0.1662\n",
      "\n",
      "Start of epoch 487\n",
      "Training loss at epoch 487: 0.1662\n",
      "\n",
      "Start of epoch 488\n",
      "Training loss at epoch 488: 0.1662\n",
      "\n",
      "Start of epoch 489\n",
      "Training loss at epoch 489: 0.1662\n",
      "\n",
      "Start of epoch 490\n",
      "Training loss at epoch 490: 0.1662\n",
      "\n",
      "Start of epoch 491\n",
      "Training loss at epoch 491: 0.1662\n",
      "\n",
      "Start of epoch 492\n",
      "Training loss at epoch 492: 0.1662\n",
      "\n",
      "Start of epoch 493\n",
      "Training loss at epoch 493: 0.1662\n",
      "\n",
      "Start of epoch 494\n",
      "Training loss at epoch 494: 0.1662\n",
      "\n",
      "Start of epoch 495\n",
      "Training loss at epoch 495: 0.1662\n",
      "\n",
      "Start of epoch 496\n",
      "Training loss at epoch 496: 0.1662\n",
      "\n",
      "Start of epoch 497\n",
      "Training loss at epoch 497: 0.1662\n",
      "\n",
      "Start of epoch 498\n",
      "Training loss at epoch 498: 0.1662\n",
      "\n",
      "Start of epoch 499\n",
      "Training loss at epoch 499: 0.1662\n",
      "[<tf.Variable 'parameters:0' shape=(75,) dtype=float32, numpy=\n",
      "array([0.31217185, 2.739122  , 3.141449  , 4.5594788 , 1.8340081 ,\n",
      "       0.09336386, 5.721694  , 0.39621347, 3.0963335 , 5.448994  ,\n",
      "       2.6446939 , 1.4397473 , 4.8532224 , 4.899346  , 3.8046372 ,\n",
      "       0.8709858 , 5.638082  , 1.2291231 , 3.2086296 , 3.0606685 ,\n",
      "       5.687259  , 0.6854288 , 3.9980903 , 4.8913884 , 3.8078287 ,\n",
      "       0.7966933 , 6.240696  , 5.7857256 , 3.0120275 , 3.0561616 ,\n",
      "       0.07264014, 2.1646888 , 5.4257426 , 1.6993167 , 1.3552219 ,\n",
      "       2.2534306 , 3.7410998 , 0.57097495, 4.193842  , 2.0093186 ,\n",
      "       3.1491287 , 5.2977767 , 3.6970818 , 0.89300156, 3.6769679 ,\n",
      "       1.9345483 , 2.0212893 , 1.3112406 , 2.6079261 , 3.134015  ,\n",
      "       0.9903037 , 0.24237421, 2.0231297 , 4.3197117 , 0.49320778,\n",
      "       2.1256847 , 6.1569114 , 1.8698695 , 4.3050776 , 1.9991777 ,\n",
      "       4.0843287 , 3.4511018 , 2.3502495 , 3.1661725 , 5.2322702 ,\n",
      "       5.3016686 , 5.2062793 , 0.27409947, 4.1918316 , 4.860063  ,\n",
      "       0.25614408, 5.112531  , 1.2652369 , 5.4251285 , 3.3876462 ],\n",
      "      dtype=float32)>]\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 0.9680\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 0.8405\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.7135\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.6294\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.5965\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.5825\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.5618\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.5348\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.5137\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.5040\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.5010\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.4973\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.4893\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.4772\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.4641\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.4534\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.4467\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.4429\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.4394\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.4345\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.4282\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.4218\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.4161\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.4111\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.4058\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.3995\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.3918\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.3831\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.3741\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.3657\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.3585\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.3528\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.3483\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.3445\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.3409\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.3371\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.3330\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.3287\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.3245\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.3207\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.3174\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.3144\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.3117\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.3092\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.3068\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.3044\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.3021\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.2997\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.2976\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.2956\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.2940\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.2924\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.2910\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.2895\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.2881\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.2868\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.2857\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.2845\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.2831\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.2816\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.2800\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.2784\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.2768\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.2751\n",
      "\n",
      "Start of epoch 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 64: 0.2735\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.2717\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.2700\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.2683\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.2666\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.2650\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.2635\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.2620\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.2605\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.2591\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.2577\n",
      "\n",
      "Start of epoch 75\n",
      "Training loss at epoch 75: 0.2563\n",
      "\n",
      "Start of epoch 76\n",
      "Training loss at epoch 76: 0.2550\n",
      "\n",
      "Start of epoch 77\n",
      "Training loss at epoch 77: 0.2537\n",
      "\n",
      "Start of epoch 78\n",
      "Training loss at epoch 78: 0.2526\n",
      "\n",
      "Start of epoch 79\n",
      "Training loss at epoch 79: 0.2515\n",
      "\n",
      "Start of epoch 80\n",
      "Training loss at epoch 80: 0.2504\n",
      "\n",
      "Start of epoch 81\n",
      "Training loss at epoch 81: 0.2494\n",
      "\n",
      "Start of epoch 82\n",
      "Training loss at epoch 82: 0.2485\n",
      "\n",
      "Start of epoch 83\n",
      "Training loss at epoch 83: 0.2476\n",
      "\n",
      "Start of epoch 84\n",
      "Training loss at epoch 84: 0.2467\n",
      "\n",
      "Start of epoch 85\n",
      "Training loss at epoch 85: 0.2460\n",
      "\n",
      "Start of epoch 86\n",
      "Training loss at epoch 86: 0.2453\n",
      "\n",
      "Start of epoch 87\n",
      "Training loss at epoch 87: 0.2446\n",
      "\n",
      "Start of epoch 88\n",
      "Training loss at epoch 88: 0.2439\n",
      "\n",
      "Start of epoch 89\n",
      "Training loss at epoch 89: 0.2433\n",
      "\n",
      "Start of epoch 90\n",
      "Training loss at epoch 90: 0.2428\n",
      "\n",
      "Start of epoch 91\n",
      "Training loss at epoch 91: 0.2423\n",
      "\n",
      "Start of epoch 92\n",
      "Training loss at epoch 92: 0.2418\n",
      "\n",
      "Start of epoch 93\n",
      "Training loss at epoch 93: 0.2413\n",
      "\n",
      "Start of epoch 94\n",
      "Training loss at epoch 94: 0.2409\n",
      "\n",
      "Start of epoch 95\n",
      "Training loss at epoch 95: 0.2405\n",
      "\n",
      "Start of epoch 96\n",
      "Training loss at epoch 96: 0.2400\n",
      "\n",
      "Start of epoch 97\n",
      "Training loss at epoch 97: 0.2396\n",
      "\n",
      "Start of epoch 98\n",
      "Training loss at epoch 98: 0.2393\n",
      "\n",
      "Start of epoch 99\n",
      "Training loss at epoch 99: 0.2389\n",
      "\n",
      "Start of epoch 100\n",
      "Training loss at epoch 100: 0.2385\n",
      "\n",
      "Start of epoch 101\n",
      "Training loss at epoch 101: 0.2381\n",
      "\n",
      "Start of epoch 102\n",
      "Training loss at epoch 102: 0.2378\n",
      "\n",
      "Start of epoch 103\n",
      "Training loss at epoch 103: 0.2374\n",
      "\n",
      "Start of epoch 104\n",
      "Training loss at epoch 104: 0.2370\n",
      "\n",
      "Start of epoch 105\n",
      "Training loss at epoch 105: 0.2367\n",
      "\n",
      "Start of epoch 106\n",
      "Training loss at epoch 106: 0.2363\n",
      "\n",
      "Start of epoch 107\n",
      "Training loss at epoch 107: 0.2360\n",
      "\n",
      "Start of epoch 108\n",
      "Training loss at epoch 108: 0.2357\n",
      "\n",
      "Start of epoch 109\n",
      "Training loss at epoch 109: 0.2353\n",
      "\n",
      "Start of epoch 110\n",
      "Training loss at epoch 110: 0.2350\n",
      "\n",
      "Start of epoch 111\n",
      "Training loss at epoch 111: 0.2347\n",
      "\n",
      "Start of epoch 112\n",
      "Training loss at epoch 112: 0.2344\n",
      "\n",
      "Start of epoch 113\n",
      "Training loss at epoch 113: 0.2341\n",
      "\n",
      "Start of epoch 114\n",
      "Training loss at epoch 114: 0.2338\n",
      "\n",
      "Start of epoch 115\n",
      "Training loss at epoch 115: 0.2335\n",
      "\n",
      "Start of epoch 116\n",
      "Training loss at epoch 116: 0.2332\n",
      "\n",
      "Start of epoch 117\n",
      "Training loss at epoch 117: 0.2329\n",
      "\n",
      "Start of epoch 118\n",
      "Training loss at epoch 118: 0.2326\n",
      "\n",
      "Start of epoch 119\n",
      "Training loss at epoch 119: 0.2323\n",
      "\n",
      "Start of epoch 120\n",
      "Training loss at epoch 120: 0.2321\n",
      "\n",
      "Start of epoch 121\n",
      "Training loss at epoch 121: 0.2318\n",
      "\n",
      "Start of epoch 122\n",
      "Training loss at epoch 122: 0.2315\n",
      "\n",
      "Start of epoch 123\n",
      "Training loss at epoch 123: 0.2313\n",
      "\n",
      "Start of epoch 124\n",
      "Training loss at epoch 124: 0.2310\n",
      "\n",
      "Start of epoch 125\n",
      "Training loss at epoch 125: 0.2308\n",
      "\n",
      "Start of epoch 126\n",
      "Training loss at epoch 126: 0.2305\n",
      "\n",
      "Start of epoch 127\n",
      "Training loss at epoch 127: 0.2303\n",
      "\n",
      "Start of epoch 128\n",
      "Training loss at epoch 128: 0.2300\n",
      "\n",
      "Start of epoch 129\n",
      "Training loss at epoch 129: 0.2298\n",
      "\n",
      "Start of epoch 130\n",
      "Training loss at epoch 130: 0.2296\n",
      "\n",
      "Start of epoch 131\n",
      "Training loss at epoch 131: 0.2293\n",
      "\n",
      "Start of epoch 132\n",
      "Training loss at epoch 132: 0.2291\n",
      "\n",
      "Start of epoch 133\n",
      "Training loss at epoch 133: 0.2289\n",
      "\n",
      "Start of epoch 134\n",
      "Training loss at epoch 134: 0.2287\n",
      "\n",
      "Start of epoch 135\n",
      "Training loss at epoch 135: 0.2285\n",
      "\n",
      "Start of epoch 136\n",
      "Training loss at epoch 136: 0.2283\n",
      "\n",
      "Start of epoch 137\n",
      "Training loss at epoch 137: 0.2281\n",
      "\n",
      "Start of epoch 138\n",
      "Training loss at epoch 138: 0.2279\n",
      "\n",
      "Start of epoch 139\n",
      "Training loss at epoch 139: 0.2277\n",
      "\n",
      "Start of epoch 140\n",
      "Training loss at epoch 140: 0.2276\n",
      "\n",
      "Start of epoch 141\n",
      "Training loss at epoch 141: 0.2274\n",
      "\n",
      "Start of epoch 142\n",
      "Training loss at epoch 142: 0.2272\n",
      "\n",
      "Start of epoch 143\n",
      "Training loss at epoch 143: 0.2271\n",
      "\n",
      "Start of epoch 144\n",
      "Training loss at epoch 144: 0.2269\n",
      "\n",
      "Start of epoch 145\n",
      "Training loss at epoch 145: 0.2267\n",
      "\n",
      "Start of epoch 146\n",
      "Training loss at epoch 146: 0.2266\n",
      "\n",
      "Start of epoch 147\n",
      "Training loss at epoch 147: 0.2264\n",
      "\n",
      "Start of epoch 148\n",
      "Training loss at epoch 148: 0.2263\n",
      "\n",
      "Start of epoch 149\n",
      "Training loss at epoch 149: 0.2261\n",
      "\n",
      "Start of epoch 150\n",
      "Training loss at epoch 150: 0.2260\n",
      "\n",
      "Start of epoch 151\n",
      "Training loss at epoch 151: 0.2259\n",
      "\n",
      "Start of epoch 152\n",
      "Training loss at epoch 152: 0.2257\n",
      "\n",
      "Start of epoch 153\n",
      "Training loss at epoch 153: 0.2256\n",
      "\n",
      "Start of epoch 154\n",
      "Training loss at epoch 154: 0.2255\n",
      "\n",
      "Start of epoch 155\n",
      "Training loss at epoch 155: 0.2254\n",
      "\n",
      "Start of epoch 156\n",
      "Training loss at epoch 156: 0.2252\n",
      "\n",
      "Start of epoch 157\n",
      "Training loss at epoch 157: 0.2251\n",
      "\n",
      "Start of epoch 158\n",
      "Training loss at epoch 158: 0.2250\n",
      "\n",
      "Start of epoch 159\n",
      "Training loss at epoch 159: 0.2249\n",
      "\n",
      "Start of epoch 160\n",
      "Training loss at epoch 160: 0.2248\n",
      "\n",
      "Start of epoch 161\n",
      "Training loss at epoch 161: 0.2247\n",
      "\n",
      "Start of epoch 162\n",
      "Training loss at epoch 162: 0.2246\n",
      "\n",
      "Start of epoch 163\n",
      "Training loss at epoch 163: 0.2244\n",
      "\n",
      "Start of epoch 164\n",
      "Training loss at epoch 164: 0.2243\n",
      "\n",
      "Start of epoch 165\n",
      "Training loss at epoch 165: 0.2242\n",
      "\n",
      "Start of epoch 166\n",
      "Training loss at epoch 166: 0.2241\n",
      "\n",
      "Start of epoch 167\n",
      "Training loss at epoch 167: 0.2240\n",
      "\n",
      "Start of epoch 168\n",
      "Training loss at epoch 168: 0.2239\n",
      "\n",
      "Start of epoch 169\n",
      "Training loss at epoch 169: 0.2238\n",
      "\n",
      "Start of epoch 170\n",
      "Training loss at epoch 170: 0.2237\n",
      "\n",
      "Start of epoch 171\n",
      "Training loss at epoch 171: 0.2236\n",
      "\n",
      "Start of epoch 172\n",
      "Training loss at epoch 172: 0.2235\n",
      "\n",
      "Start of epoch 173\n",
      "Training loss at epoch 173: 0.2234\n",
      "\n",
      "Start of epoch 174\n",
      "Training loss at epoch 174: 0.2233\n",
      "\n",
      "Start of epoch 175\n",
      "Training loss at epoch 175: 0.2232\n",
      "\n",
      "Start of epoch 176\n",
      "Training loss at epoch 176: 0.2231\n",
      "\n",
      "Start of epoch 177\n",
      "Training loss at epoch 177: 0.2230\n",
      "\n",
      "Start of epoch 178\n",
      "Training loss at epoch 178: 0.2229\n",
      "\n",
      "Start of epoch 179\n",
      "Training loss at epoch 179: 0.2228\n",
      "\n",
      "Start of epoch 180\n",
      "Training loss at epoch 180: 0.2227\n",
      "\n",
      "Start of epoch 181\n",
      "Training loss at epoch 181: 0.2226\n",
      "\n",
      "Start of epoch 182\n",
      "Training loss at epoch 182: 0.2226\n",
      "\n",
      "Start of epoch 183\n",
      "Training loss at epoch 183: 0.2225\n",
      "\n",
      "Start of epoch 184\n",
      "Training loss at epoch 184: 0.2224\n",
      "\n",
      "Start of epoch 185\n",
      "Training loss at epoch 185: 0.2223\n",
      "\n",
      "Start of epoch 186\n",
      "Training loss at epoch 186: 0.2222\n",
      "\n",
      "Start of epoch 187\n",
      "Training loss at epoch 187: 0.2221\n",
      "\n",
      "Start of epoch 188\n",
      "Training loss at epoch 188: 0.2220\n",
      "\n",
      "Start of epoch 189\n",
      "Training loss at epoch 189: 0.2220\n",
      "\n",
      "Start of epoch 190\n",
      "Training loss at epoch 190: 0.2219\n",
      "\n",
      "Start of epoch 191\n",
      "Training loss at epoch 191: 0.2218\n",
      "\n",
      "Start of epoch 192\n",
      "Training loss at epoch 192: 0.2217\n",
      "\n",
      "Start of epoch 193\n",
      "Training loss at epoch 193: 0.2216\n",
      "\n",
      "Start of epoch 194\n",
      "Training loss at epoch 194: 0.2216\n",
      "\n",
      "Start of epoch 195\n",
      "Training loss at epoch 195: 0.2215\n",
      "\n",
      "Start of epoch 196\n",
      "Training loss at epoch 196: 0.2214\n",
      "\n",
      "Start of epoch 197\n",
      "Training loss at epoch 197: 0.2214\n",
      "\n",
      "Start of epoch 198\n",
      "Training loss at epoch 198: 0.2213\n",
      "\n",
      "Start of epoch 199\n",
      "Training loss at epoch 199: 0.2212\n",
      "\n",
      "Start of epoch 200\n",
      "Training loss at epoch 200: 0.2212\n",
      "\n",
      "Start of epoch 201\n",
      "Training loss at epoch 201: 0.2211\n",
      "\n",
      "Start of epoch 202\n",
      "Training loss at epoch 202: 0.2210\n",
      "\n",
      "Start of epoch 203\n",
      "Training loss at epoch 203: 0.2210\n",
      "\n",
      "Start of epoch 204\n",
      "Training loss at epoch 204: 0.2209\n",
      "\n",
      "Start of epoch 205\n",
      "Training loss at epoch 205: 0.2209\n",
      "\n",
      "Start of epoch 206\n",
      "Training loss at epoch 206: 0.2208\n",
      "\n",
      "Start of epoch 207\n",
      "Training loss at epoch 207: 0.2207\n",
      "\n",
      "Start of epoch 208\n",
      "Training loss at epoch 208: 0.2207\n",
      "\n",
      "Start of epoch 209\n",
      "Training loss at epoch 209: 0.2206\n",
      "\n",
      "Start of epoch 210\n",
      "Training loss at epoch 210: 0.2206\n",
      "\n",
      "Start of epoch 211\n",
      "Training loss at epoch 211: 0.2205\n",
      "\n",
      "Start of epoch 212\n",
      "Training loss at epoch 212: 0.2205\n",
      "\n",
      "Start of epoch 213\n",
      "Training loss at epoch 213: 0.2205\n",
      "\n",
      "Start of epoch 214\n",
      "Training loss at epoch 214: 0.2204\n",
      "\n",
      "Start of epoch 215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 215: 0.2204\n",
      "\n",
      "Start of epoch 216\n",
      "Training loss at epoch 216: 0.2203\n",
      "\n",
      "Start of epoch 217\n",
      "Training loss at epoch 217: 0.2203\n",
      "\n",
      "Start of epoch 218\n",
      "Training loss at epoch 218: 0.2203\n",
      "\n",
      "Start of epoch 219\n",
      "Training loss at epoch 219: 0.2202\n",
      "\n",
      "Start of epoch 220\n",
      "Training loss at epoch 220: 0.2202\n",
      "\n",
      "Start of epoch 221\n",
      "Training loss at epoch 221: 0.2202\n",
      "\n",
      "Start of epoch 222\n",
      "Training loss at epoch 222: 0.2201\n",
      "\n",
      "Start of epoch 223\n",
      "Training loss at epoch 223: 0.2201\n",
      "\n",
      "Start of epoch 224\n",
      "Training loss at epoch 224: 0.2201\n",
      "\n",
      "Start of epoch 225\n",
      "Training loss at epoch 225: 0.2200\n",
      "\n",
      "Start of epoch 226\n",
      "Training loss at epoch 226: 0.2200\n",
      "\n",
      "Start of epoch 227\n",
      "Training loss at epoch 227: 0.2200\n",
      "\n",
      "Start of epoch 228\n",
      "Training loss at epoch 228: 0.2199\n",
      "\n",
      "Start of epoch 229\n",
      "Training loss at epoch 229: 0.2199\n",
      "\n",
      "Start of epoch 230\n",
      "Training loss at epoch 230: 0.2199\n",
      "\n",
      "Start of epoch 231\n",
      "Training loss at epoch 231: 0.2199\n",
      "\n",
      "Start of epoch 232\n",
      "Training loss at epoch 232: 0.2198\n",
      "\n",
      "Start of epoch 233\n",
      "Training loss at epoch 233: 0.2198\n",
      "\n",
      "Start of epoch 234\n",
      "Training loss at epoch 234: 0.2198\n",
      "\n",
      "Start of epoch 235\n",
      "Training loss at epoch 235: 0.2198\n",
      "\n",
      "Start of epoch 236\n",
      "Training loss at epoch 236: 0.2198\n",
      "\n",
      "Start of epoch 237\n",
      "Training loss at epoch 237: 0.2197\n",
      "\n",
      "Start of epoch 238\n",
      "Training loss at epoch 238: 0.2197\n",
      "\n",
      "Start of epoch 239\n",
      "Training loss at epoch 239: 0.2197\n",
      "\n",
      "Start of epoch 240\n",
      "Training loss at epoch 240: 0.2197\n",
      "\n",
      "Start of epoch 241\n",
      "Training loss at epoch 241: 0.2197\n",
      "\n",
      "Start of epoch 242\n",
      "Training loss at epoch 242: 0.2197\n",
      "\n",
      "Start of epoch 243\n",
      "Training loss at epoch 243: 0.2196\n",
      "\n",
      "Start of epoch 244\n",
      "Training loss at epoch 244: 0.2196\n",
      "\n",
      "Start of epoch 245\n",
      "Training loss at epoch 245: 0.2196\n",
      "\n",
      "Start of epoch 246\n",
      "Training loss at epoch 246: 0.2196\n",
      "\n",
      "Start of epoch 247\n",
      "Training loss at epoch 247: 0.2196\n",
      "\n",
      "Start of epoch 248\n",
      "Training loss at epoch 248: 0.2196\n",
      "\n",
      "Start of epoch 249\n",
      "Training loss at epoch 249: 0.2196\n",
      "\n",
      "Start of epoch 250\n",
      "Training loss at epoch 250: 0.2196\n",
      "\n",
      "Start of epoch 251\n",
      "Training loss at epoch 251: 0.2195\n",
      "\n",
      "Start of epoch 252\n",
      "Training loss at epoch 252: 0.2195\n",
      "\n",
      "Start of epoch 253\n",
      "Training loss at epoch 253: 0.2195\n",
      "\n",
      "Start of epoch 254\n",
      "Training loss at epoch 254: 0.2195\n",
      "\n",
      "Start of epoch 255\n",
      "Training loss at epoch 255: 0.2195\n",
      "\n",
      "Start of epoch 256\n",
      "Training loss at epoch 256: 0.2195\n",
      "\n",
      "Start of epoch 257\n",
      "Training loss at epoch 257: 0.2195\n",
      "\n",
      "Start of epoch 258\n",
      "Training loss at epoch 258: 0.2195\n",
      "\n",
      "Start of epoch 259\n",
      "Training loss at epoch 259: 0.2195\n",
      "\n",
      "Start of epoch 260\n",
      "Training loss at epoch 260: 0.2195\n",
      "\n",
      "Start of epoch 261\n",
      "Training loss at epoch 261: 0.2194\n",
      "\n",
      "Start of epoch 262\n",
      "Training loss at epoch 262: 0.2194\n",
      "\n",
      "Start of epoch 263\n",
      "Training loss at epoch 263: 0.2194\n",
      "\n",
      "Start of epoch 264\n",
      "Training loss at epoch 264: 0.2194\n",
      "\n",
      "Start of epoch 265\n",
      "Training loss at epoch 265: 0.2194\n",
      "\n",
      "Start of epoch 266\n",
      "Training loss at epoch 266: 0.2194\n",
      "\n",
      "Start of epoch 267\n",
      "Training loss at epoch 267: 0.2194\n",
      "\n",
      "Start of epoch 268\n",
      "Training loss at epoch 268: 0.2194\n",
      "\n",
      "Start of epoch 269\n",
      "Training loss at epoch 269: 0.2194\n",
      "\n",
      "Start of epoch 270\n",
      "Training loss at epoch 270: 0.2194\n",
      "\n",
      "Start of epoch 271\n",
      "Training loss at epoch 271: 0.2194\n",
      "\n",
      "Start of epoch 272\n",
      "Training loss at epoch 272: 0.2194\n",
      "\n",
      "Start of epoch 273\n",
      "Training loss at epoch 273: 0.2194\n",
      "\n",
      "Start of epoch 274\n",
      "Training loss at epoch 274: 0.2194\n",
      "\n",
      "Start of epoch 275\n",
      "Training loss at epoch 275: 0.2193\n",
      "\n",
      "Start of epoch 276\n",
      "Training loss at epoch 276: 0.2193\n",
      "\n",
      "Start of epoch 277\n",
      "Training loss at epoch 277: 0.2193\n",
      "\n",
      "Start of epoch 278\n",
      "Training loss at epoch 278: 0.2193\n",
      "\n",
      "Start of epoch 279\n",
      "Training loss at epoch 279: 0.2193\n",
      "\n",
      "Start of epoch 280\n",
      "Training loss at epoch 280: 0.2193\n",
      "\n",
      "Start of epoch 281\n",
      "Training loss at epoch 281: 0.2193\n",
      "\n",
      "Start of epoch 282\n",
      "Training loss at epoch 282: 0.2193\n",
      "\n",
      "Start of epoch 283\n",
      "Training loss at epoch 283: 0.2193\n",
      "\n",
      "Start of epoch 284\n",
      "Training loss at epoch 284: 0.2193\n",
      "\n",
      "Start of epoch 285\n",
      "Training loss at epoch 285: 0.2193\n",
      "\n",
      "Start of epoch 286\n",
      "Training loss at epoch 286: 0.2193\n",
      "\n",
      "Start of epoch 287\n",
      "Training loss at epoch 287: 0.2193\n",
      "\n",
      "Start of epoch 288\n",
      "Training loss at epoch 288: 0.2193\n",
      "\n",
      "Start of epoch 289\n",
      "Training loss at epoch 289: 0.2193\n",
      "\n",
      "Start of epoch 290\n",
      "Training loss at epoch 290: 0.2193\n",
      "\n",
      "Start of epoch 291\n",
      "Training loss at epoch 291: 0.2193\n",
      "\n",
      "Start of epoch 292\n",
      "Training loss at epoch 292: 0.2193\n",
      "\n",
      "Start of epoch 293\n",
      "Training loss at epoch 293: 0.2193\n",
      "\n",
      "Start of epoch 294\n",
      "Training loss at epoch 294: 0.2193\n",
      "\n",
      "Start of epoch 295\n",
      "Training loss at epoch 295: 0.2192\n",
      "\n",
      "Start of epoch 296\n",
      "Training loss at epoch 296: 0.2192\n",
      "\n",
      "Start of epoch 297\n",
      "Training loss at epoch 297: 0.2192\n",
      "\n",
      "Start of epoch 298\n",
      "Training loss at epoch 298: 0.2192\n",
      "\n",
      "Start of epoch 299\n",
      "Training loss at epoch 299: 0.2192\n",
      "\n",
      "Start of epoch 300\n",
      "Training loss at epoch 300: 0.2192\n",
      "\n",
      "Start of epoch 301\n",
      "Training loss at epoch 301: 0.2192\n",
      "\n",
      "Start of epoch 302\n",
      "Training loss at epoch 302: 0.2192\n",
      "\n",
      "Start of epoch 303\n",
      "Training loss at epoch 303: 0.2192\n",
      "\n",
      "Start of epoch 304\n",
      "Training loss at epoch 304: 0.2192\n",
      "\n",
      "Start of epoch 305\n",
      "Training loss at epoch 305: 0.2192\n",
      "\n",
      "Start of epoch 306\n",
      "Training loss at epoch 306: 0.2192\n",
      "\n",
      "Start of epoch 307\n",
      "Training loss at epoch 307: 0.2192\n",
      "\n",
      "Start of epoch 308\n",
      "Training loss at epoch 308: 0.2192\n",
      "\n",
      "Start of epoch 309\n",
      "Training loss at epoch 309: 0.2192\n",
      "\n",
      "Start of epoch 310\n",
      "Training loss at epoch 310: 0.2192\n",
      "\n",
      "Start of epoch 311\n",
      "Training loss at epoch 311: 0.2192\n",
      "\n",
      "Start of epoch 312\n",
      "Training loss at epoch 312: 0.2192\n",
      "\n",
      "Start of epoch 313\n",
      "Training loss at epoch 313: 0.2192\n",
      "\n",
      "Start of epoch 314\n",
      "Training loss at epoch 314: 0.2192\n",
      "\n",
      "Start of epoch 315\n",
      "Training loss at epoch 315: 0.2192\n",
      "\n",
      "Start of epoch 316\n",
      "Training loss at epoch 316: 0.2192\n",
      "\n",
      "Start of epoch 317\n",
      "Training loss at epoch 317: 0.2192\n",
      "\n",
      "Start of epoch 318\n",
      "Training loss at epoch 318: 0.2192\n",
      "\n",
      "Start of epoch 319\n",
      "Training loss at epoch 319: 0.2192\n",
      "\n",
      "Start of epoch 320\n",
      "Training loss at epoch 320: 0.2192\n",
      "\n",
      "Start of epoch 321\n",
      "Training loss at epoch 321: 0.2191\n",
      "\n",
      "Start of epoch 322\n",
      "Training loss at epoch 322: 0.2191\n",
      "\n",
      "Start of epoch 323\n",
      "Training loss at epoch 323: 0.2191\n",
      "\n",
      "Start of epoch 324\n",
      "Training loss at epoch 324: 0.2191\n",
      "\n",
      "Start of epoch 325\n",
      "Training loss at epoch 325: 0.2191\n",
      "\n",
      "Start of epoch 326\n",
      "Training loss at epoch 326: 0.2191\n",
      "\n",
      "Start of epoch 327\n",
      "Training loss at epoch 327: 0.2191\n",
      "\n",
      "Start of epoch 328\n",
      "Training loss at epoch 328: 0.2191\n",
      "\n",
      "Start of epoch 329\n",
      "Training loss at epoch 329: 0.2191\n",
      "\n",
      "Start of epoch 330\n",
      "Training loss at epoch 330: 0.2191\n",
      "\n",
      "Start of epoch 331\n",
      "Training loss at epoch 331: 0.2191\n",
      "\n",
      "Start of epoch 332\n",
      "Training loss at epoch 332: 0.2191\n",
      "\n",
      "Start of epoch 333\n",
      "Training loss at epoch 333: 0.2191\n",
      "\n",
      "Start of epoch 334\n",
      "Training loss at epoch 334: 0.2191\n",
      "\n",
      "Start of epoch 335\n",
      "Training loss at epoch 335: 0.2191\n",
      "\n",
      "Start of epoch 336\n",
      "Training loss at epoch 336: 0.2191\n",
      "\n",
      "Start of epoch 337\n",
      "Training loss at epoch 337: 0.2191\n",
      "\n",
      "Start of epoch 338\n",
      "Training loss at epoch 338: 0.2191\n",
      "\n",
      "Start of epoch 339\n",
      "Training loss at epoch 339: 0.2191\n",
      "\n",
      "Start of epoch 340\n",
      "Training loss at epoch 340: 0.2191\n",
      "\n",
      "Start of epoch 341\n",
      "Training loss at epoch 341: 0.2191\n",
      "\n",
      "Start of epoch 342\n",
      "Training loss at epoch 342: 0.2191\n",
      "\n",
      "Start of epoch 343\n",
      "Training loss at epoch 343: 0.2191\n",
      "\n",
      "Start of epoch 344\n",
      "Training loss at epoch 344: 0.2191\n",
      "\n",
      "Start of epoch 345\n",
      "Training loss at epoch 345: 0.2191\n",
      "\n",
      "Start of epoch 346\n",
      "Training loss at epoch 346: 0.2191\n",
      "\n",
      "Start of epoch 347\n",
      "Training loss at epoch 347: 0.2191\n",
      "\n",
      "Start of epoch 348\n",
      "Training loss at epoch 348: 0.2191\n",
      "\n",
      "Start of epoch 349\n",
      "Training loss at epoch 349: 0.2191\n",
      "\n",
      "Start of epoch 350\n",
      "Training loss at epoch 350: 0.2190\n",
      "\n",
      "Start of epoch 351\n",
      "Training loss at epoch 351: 0.2190\n",
      "\n",
      "Start of epoch 352\n",
      "Training loss at epoch 352: 0.2190\n",
      "\n",
      "Start of epoch 353\n",
      "Training loss at epoch 353: 0.2190\n",
      "\n",
      "Start of epoch 354\n",
      "Training loss at epoch 354: 0.2190\n",
      "\n",
      "Start of epoch 355\n",
      "Training loss at epoch 355: 0.2190\n",
      "\n",
      "Start of epoch 356\n",
      "Training loss at epoch 356: 0.2190\n",
      "\n",
      "Start of epoch 357\n",
      "Training loss at epoch 357: 0.2190\n",
      "\n",
      "Start of epoch 358\n",
      "Training loss at epoch 358: 0.2190\n",
      "\n",
      "Start of epoch 359\n",
      "Training loss at epoch 359: 0.2190\n",
      "\n",
      "Start of epoch 360\n",
      "Training loss at epoch 360: 0.2190\n",
      "\n",
      "Start of epoch 361\n",
      "Training loss at epoch 361: 0.2190\n",
      "\n",
      "Start of epoch 362\n",
      "Training loss at epoch 362: 0.2190\n",
      "\n",
      "Start of epoch 363\n",
      "Training loss at epoch 363: 0.2190\n",
      "\n",
      "Start of epoch 364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 364: 0.2190\n",
      "\n",
      "Start of epoch 365\n",
      "Training loss at epoch 365: 0.2190\n",
      "\n",
      "Start of epoch 366\n",
      "Training loss at epoch 366: 0.2190\n",
      "\n",
      "Start of epoch 367\n",
      "Training loss at epoch 367: 0.2190\n",
      "\n",
      "Start of epoch 368\n",
      "Training loss at epoch 368: 0.2190\n",
      "\n",
      "Start of epoch 369\n",
      "Training loss at epoch 369: 0.2190\n",
      "\n",
      "Start of epoch 370\n",
      "Training loss at epoch 370: 0.2190\n",
      "\n",
      "Start of epoch 371\n",
      "Training loss at epoch 371: 0.2190\n",
      "\n",
      "Start of epoch 372\n",
      "Training loss at epoch 372: 0.2190\n",
      "\n",
      "Start of epoch 373\n",
      "Training loss at epoch 373: 0.2190\n",
      "\n",
      "Start of epoch 374\n",
      "Training loss at epoch 374: 0.2190\n",
      "\n",
      "Start of epoch 375\n",
      "Training loss at epoch 375: 0.2190\n",
      "\n",
      "Start of epoch 376\n",
      "Training loss at epoch 376: 0.2190\n",
      "\n",
      "Start of epoch 377\n",
      "Training loss at epoch 377: 0.2190\n",
      "\n",
      "Start of epoch 378\n",
      "Training loss at epoch 378: 0.2190\n",
      "\n",
      "Start of epoch 379\n",
      "Training loss at epoch 379: 0.2190\n",
      "\n",
      "Start of epoch 380\n",
      "Training loss at epoch 380: 0.2190\n",
      "\n",
      "Start of epoch 381\n",
      "Training loss at epoch 381: 0.2189\n",
      "\n",
      "Start of epoch 382\n",
      "Training loss at epoch 382: 0.2189\n",
      "\n",
      "Start of epoch 383\n",
      "Training loss at epoch 383: 0.2189\n",
      "\n",
      "Start of epoch 384\n",
      "Training loss at epoch 384: 0.2189\n",
      "\n",
      "Start of epoch 385\n",
      "Training loss at epoch 385: 0.2189\n",
      "\n",
      "Start of epoch 386\n",
      "Training loss at epoch 386: 0.2189\n",
      "\n",
      "Start of epoch 387\n",
      "Training loss at epoch 387: 0.2189\n",
      "\n",
      "Start of epoch 388\n",
      "Training loss at epoch 388: 0.2189\n",
      "\n",
      "Start of epoch 389\n",
      "Training loss at epoch 389: 0.2189\n",
      "\n",
      "Start of epoch 390\n",
      "Training loss at epoch 390: 0.2189\n",
      "\n",
      "Start of epoch 391\n",
      "Training loss at epoch 391: 0.2189\n",
      "\n",
      "Start of epoch 392\n",
      "Training loss at epoch 392: 0.2189\n",
      "\n",
      "Start of epoch 393\n",
      "Training loss at epoch 393: 0.2189\n",
      "\n",
      "Start of epoch 394\n",
      "Training loss at epoch 394: 0.2189\n",
      "\n",
      "Start of epoch 395\n",
      "Training loss at epoch 395: 0.2189\n",
      "\n",
      "Start of epoch 396\n",
      "Training loss at epoch 396: 0.2189\n",
      "\n",
      "Start of epoch 397\n",
      "Training loss at epoch 397: 0.2189\n",
      "\n",
      "Start of epoch 398\n",
      "Training loss at epoch 398: 0.2189\n",
      "\n",
      "Start of epoch 399\n",
      "Training loss at epoch 399: 0.2189\n",
      "\n",
      "Start of epoch 400\n",
      "Training loss at epoch 400: 0.2189\n",
      "\n",
      "Start of epoch 401\n",
      "Training loss at epoch 401: 0.2189\n",
      "\n",
      "Start of epoch 402\n",
      "Training loss at epoch 402: 0.2189\n",
      "\n",
      "Start of epoch 403\n",
      "Training loss at epoch 403: 0.2189\n",
      "\n",
      "Start of epoch 404\n",
      "Training loss at epoch 404: 0.2189\n",
      "\n",
      "Start of epoch 405\n",
      "Training loss at epoch 405: 0.2189\n",
      "\n",
      "Start of epoch 406\n",
      "Training loss at epoch 406: 0.2189\n",
      "\n",
      "Start of epoch 407\n",
      "Training loss at epoch 407: 0.2189\n",
      "\n",
      "Start of epoch 408\n",
      "Training loss at epoch 408: 0.2189\n",
      "\n",
      "Start of epoch 409\n",
      "Training loss at epoch 409: 0.2189\n",
      "\n",
      "Start of epoch 410\n",
      "Training loss at epoch 410: 0.2189\n",
      "\n",
      "Start of epoch 411\n",
      "Training loss at epoch 411: 0.2189\n",
      "\n",
      "Start of epoch 412\n",
      "Training loss at epoch 412: 0.2189\n",
      "\n",
      "Start of epoch 413\n",
      "Training loss at epoch 413: 0.2189\n",
      "\n",
      "Start of epoch 414\n",
      "Training loss at epoch 414: 0.2189\n",
      "\n",
      "Start of epoch 415\n",
      "Training loss at epoch 415: 0.2188\n",
      "\n",
      "Start of epoch 416\n",
      "Training loss at epoch 416: 0.2188\n",
      "\n",
      "Start of epoch 417\n",
      "Training loss at epoch 417: 0.2188\n",
      "\n",
      "Start of epoch 418\n",
      "Training loss at epoch 418: 0.2188\n",
      "\n",
      "Start of epoch 419\n",
      "Training loss at epoch 419: 0.2188\n",
      "\n",
      "Start of epoch 420\n",
      "Training loss at epoch 420: 0.2188\n",
      "\n",
      "Start of epoch 421\n",
      "Training loss at epoch 421: 0.2188\n",
      "\n",
      "Start of epoch 422\n",
      "Training loss at epoch 422: 0.2188\n",
      "\n",
      "Start of epoch 423\n",
      "Training loss at epoch 423: 0.2188\n",
      "\n",
      "Start of epoch 424\n",
      "Training loss at epoch 424: 0.2188\n",
      "\n",
      "Start of epoch 425\n",
      "Training loss at epoch 425: 0.2188\n",
      "\n",
      "Start of epoch 426\n",
      "Training loss at epoch 426: 0.2188\n",
      "\n",
      "Start of epoch 427\n",
      "Training loss at epoch 427: 0.2188\n",
      "\n",
      "Start of epoch 428\n",
      "Training loss at epoch 428: 0.2188\n",
      "\n",
      "Start of epoch 429\n",
      "Training loss at epoch 429: 0.2188\n",
      "\n",
      "Start of epoch 430\n",
      "Training loss at epoch 430: 0.2188\n",
      "\n",
      "Start of epoch 431\n",
      "Training loss at epoch 431: 0.2188\n",
      "\n",
      "Start of epoch 432\n",
      "Training loss at epoch 432: 0.2188\n",
      "\n",
      "Start of epoch 433\n",
      "Training loss at epoch 433: 0.2188\n",
      "\n",
      "Start of epoch 434\n",
      "Training loss at epoch 434: 0.2188\n",
      "\n",
      "Start of epoch 435\n",
      "Training loss at epoch 435: 0.2188\n",
      "\n",
      "Start of epoch 436\n",
      "Training loss at epoch 436: 0.2188\n",
      "\n",
      "Start of epoch 437\n",
      "Training loss at epoch 437: 0.2188\n",
      "\n",
      "Start of epoch 438\n",
      "Training loss at epoch 438: 0.2188\n",
      "\n",
      "Start of epoch 439\n",
      "Training loss at epoch 439: 0.2188\n",
      "\n",
      "Start of epoch 440\n",
      "Training loss at epoch 440: 0.2188\n",
      "\n",
      "Start of epoch 441\n",
      "Training loss at epoch 441: 0.2188\n",
      "\n",
      "Start of epoch 442\n",
      "Training loss at epoch 442: 0.2188\n",
      "\n",
      "Start of epoch 443\n",
      "Training loss at epoch 443: 0.2188\n",
      "\n",
      "Start of epoch 444\n",
      "Training loss at epoch 444: 0.2188\n",
      "\n",
      "Start of epoch 445\n",
      "Training loss at epoch 445: 0.2188\n",
      "\n",
      "Start of epoch 446\n",
      "Training loss at epoch 446: 0.2188\n",
      "\n",
      "Start of epoch 447\n",
      "Training loss at epoch 447: 0.2188\n",
      "\n",
      "Start of epoch 448\n",
      "Training loss at epoch 448: 0.2188\n",
      "\n",
      "Start of epoch 449\n",
      "Training loss at epoch 449: 0.2188\n",
      "\n",
      "Start of epoch 450\n",
      "Training loss at epoch 450: 0.2188\n",
      "\n",
      "Start of epoch 451\n",
      "Training loss at epoch 451: 0.2188\n",
      "\n",
      "Start of epoch 452\n",
      "Training loss at epoch 452: 0.2188\n",
      "\n",
      "Start of epoch 453\n",
      "Training loss at epoch 453: 0.2187\n",
      "\n",
      "Start of epoch 454\n",
      "Training loss at epoch 454: 0.2187\n",
      "\n",
      "Start of epoch 455\n",
      "Training loss at epoch 455: 0.2187\n",
      "\n",
      "Start of epoch 456\n",
      "Training loss at epoch 456: 0.2187\n",
      "\n",
      "Start of epoch 457\n",
      "Training loss at epoch 457: 0.2187\n",
      "\n",
      "Start of epoch 458\n",
      "Training loss at epoch 458: 0.2187\n",
      "\n",
      "Start of epoch 459\n",
      "Training loss at epoch 459: 0.2187\n",
      "\n",
      "Start of epoch 460\n",
      "Training loss at epoch 460: 0.2187\n",
      "\n",
      "Start of epoch 461\n",
      "Training loss at epoch 461: 0.2187\n",
      "\n",
      "Start of epoch 462\n",
      "Training loss at epoch 462: 0.2187\n",
      "\n",
      "Start of epoch 463\n",
      "Training loss at epoch 463: 0.2187\n",
      "\n",
      "Start of epoch 464\n",
      "Training loss at epoch 464: 0.2187\n",
      "\n",
      "Start of epoch 465\n",
      "Training loss at epoch 465: 0.2187\n",
      "\n",
      "Start of epoch 466\n",
      "Training loss at epoch 466: 0.2187\n",
      "\n",
      "Start of epoch 467\n",
      "Training loss at epoch 467: 0.2187\n",
      "\n",
      "Start of epoch 468\n",
      "Training loss at epoch 468: 0.2187\n",
      "\n",
      "Start of epoch 469\n",
      "Training loss at epoch 469: 0.2187\n",
      "\n",
      "Start of epoch 470\n",
      "Training loss at epoch 470: 0.2187\n",
      "\n",
      "Start of epoch 471\n",
      "Training loss at epoch 471: 0.2187\n",
      "\n",
      "Start of epoch 472\n",
      "Training loss at epoch 472: 0.2187\n",
      "\n",
      "Start of epoch 473\n",
      "Training loss at epoch 473: 0.2187\n",
      "\n",
      "Start of epoch 474\n",
      "Training loss at epoch 474: 0.2187\n",
      "\n",
      "Start of epoch 475\n",
      "Training loss at epoch 475: 0.2187\n",
      "\n",
      "Start of epoch 476\n",
      "Training loss at epoch 476: 0.2187\n",
      "\n",
      "Start of epoch 477\n",
      "Training loss at epoch 477: 0.2187\n",
      "\n",
      "Start of epoch 478\n",
      "Training loss at epoch 478: 0.2187\n",
      "\n",
      "Start of epoch 479\n",
      "Training loss at epoch 479: 0.2187\n",
      "\n",
      "Start of epoch 480\n",
      "Training loss at epoch 480: 0.2187\n",
      "\n",
      "Start of epoch 481\n",
      "Training loss at epoch 481: 0.2187\n",
      "\n",
      "Start of epoch 482\n",
      "Training loss at epoch 482: 0.2187\n",
      "\n",
      "Start of epoch 483\n",
      "Training loss at epoch 483: 0.2187\n",
      "\n",
      "Start of epoch 484\n",
      "Training loss at epoch 484: 0.2187\n",
      "\n",
      "Start of epoch 485\n",
      "Training loss at epoch 485: 0.2187\n",
      "\n",
      "Start of epoch 486\n",
      "Training loss at epoch 486: 0.2187\n",
      "\n",
      "Start of epoch 487\n",
      "Training loss at epoch 487: 0.2187\n",
      "\n",
      "Start of epoch 488\n",
      "Training loss at epoch 488: 0.2187\n",
      "\n",
      "Start of epoch 489\n",
      "Training loss at epoch 489: 0.2187\n",
      "\n",
      "Start of epoch 490\n",
      "Training loss at epoch 490: 0.2187\n",
      "\n",
      "Start of epoch 491\n",
      "Training loss at epoch 491: 0.2187\n",
      "\n",
      "Start of epoch 492\n",
      "Training loss at epoch 492: 0.2187\n",
      "\n",
      "Start of epoch 493\n",
      "Training loss at epoch 493: 0.2187\n",
      "\n",
      "Start of epoch 494\n",
      "Training loss at epoch 494: 0.2187\n",
      "\n",
      "Start of epoch 495\n",
      "Training loss at epoch 495: 0.2187\n",
      "\n",
      "Start of epoch 496\n",
      "Training loss at epoch 496: 0.2187\n",
      "\n",
      "Start of epoch 497\n",
      "Training loss at epoch 497: 0.2186\n",
      "\n",
      "Start of epoch 498\n",
      "Training loss at epoch 498: 0.2186\n",
      "\n",
      "Start of epoch 499\n",
      "Training loss at epoch 499: 0.2186\n",
      "[<tf.Variable 'parameters:0' shape=(75,) dtype=float32, numpy=\n",
      "array([3.1972961 , 3.5093474 , 1.6096418 , 0.08897014, 3.6663349 ,\n",
      "       2.660367  , 5.3921103 , 3.988028  , 1.4175653 , 0.39488322,\n",
      "       3.4734838 , 4.7942624 , 5.1414    , 2.8317091 , 5.2985415 ,\n",
      "       0.44825345, 2.0830717 , 4.86886   , 3.8728821 , 2.9949749 ,\n",
      "       4.390743  , 2.1981833 , 2.3102934 , 2.7662632 , 1.5247477 ,\n",
      "       3.6130311 , 1.0971094 , 4.1511006 , 1.0467621 , 4.053068  ,\n",
      "       5.836085  , 3.2493436 , 2.5594342 , 5.143399  , 5.279003  ,\n",
      "       2.5773296 , 3.7839885 , 5.8669615 , 4.1109204 , 4.925212  ,\n",
      "       1.4041774 , 5.646601  , 0.46856824, 6.1459603 , 1.7759461 ,\n",
      "       1.9511218 , 1.3657613 , 6.0277944 , 3.8784742 , 0.04607635,\n",
      "       4.9927826 , 3.6306121 , 3.1947367 , 5.367607  , 6.028363  ,\n",
      "       1.1539656 , 6.1817245 , 2.5301127 , 1.4190259 , 1.6753798 ,\n",
      "       3.1334314 , 3.6340964 , 1.6969955 , 4.8581257 , 5.893606  ,\n",
      "       0.10561698, 3.31696   , 5.0084453 , 0.76508415, 5.4915624 ,\n",
      "       6.0928245 , 3.3087494 , 0.6780884 , 1.4486681 , 3.8873749 ],\n",
      "      dtype=float32)>]\n",
      "\n",
      "Start of epoch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 0: 1.1857\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 1.0393\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.9142\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.8269\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.7715\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.7304\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.6910\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.6468\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.5991\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.5536\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.5145\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.4834\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.4599\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.4428\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.4312\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.4243\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.4212\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.4204\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.4200\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.4185\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.4147\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.4084\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.4001\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.3911\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.3828\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.3760\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.3711\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.3676\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.3650\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.3630\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.3612\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.3595\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.3577\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.3556\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.3529\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.3499\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.3467\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.3433\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.3398\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.3364\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.3331\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.3300\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.3272\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.3248\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.3227\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.3207\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.3187\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.3166\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.3144\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.3119\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.3094\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.3069\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.3044\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.3020\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.2997\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.2973\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.2950\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.2928\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.2906\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.2885\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.2864\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.2844\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.2825\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.2805\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.2786\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.2767\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.2747\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.2728\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.2708\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.2688\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.2668\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.2647\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.2625\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.2602\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.2578\n",
      "\n",
      "Start of epoch 75\n",
      "Training loss at epoch 75: 0.2553\n",
      "\n",
      "Start of epoch 76\n",
      "Training loss at epoch 76: 0.2528\n",
      "\n",
      "Start of epoch 77\n",
      "Training loss at epoch 77: 0.2501\n",
      "\n",
      "Start of epoch 78\n",
      "Training loss at epoch 78: 0.2474\n",
      "\n",
      "Start of epoch 79\n",
      "Training loss at epoch 79: 0.2446\n",
      "\n",
      "Start of epoch 80\n",
      "Training loss at epoch 80: 0.2417\n",
      "\n",
      "Start of epoch 81\n",
      "Training loss at epoch 81: 0.2388\n",
      "\n",
      "Start of epoch 82\n",
      "Training loss at epoch 82: 0.2358\n",
      "\n",
      "Start of epoch 83\n",
      "Training loss at epoch 83: 0.2330\n",
      "\n",
      "Start of epoch 84\n",
      "Training loss at epoch 84: 0.2302\n",
      "\n",
      "Start of epoch 85\n",
      "Training loss at epoch 85: 0.2277\n",
      "\n",
      "Start of epoch 86\n",
      "Training loss at epoch 86: 0.2254\n",
      "\n",
      "Start of epoch 87\n",
      "Training loss at epoch 87: 0.2234\n",
      "\n",
      "Start of epoch 88\n",
      "Training loss at epoch 88: 0.2217\n",
      "\n",
      "Start of epoch 89\n",
      "Training loss at epoch 89: 0.2203\n",
      "\n",
      "Start of epoch 90\n",
      "Training loss at epoch 90: 0.2191\n",
      "\n",
      "Start of epoch 91\n",
      "Training loss at epoch 91: 0.2180\n",
      "\n",
      "Start of epoch 92\n",
      "Training loss at epoch 92: 0.2169\n",
      "\n",
      "Start of epoch 93\n",
      "Training loss at epoch 93: 0.2159\n",
      "\n",
      "Start of epoch 94\n",
      "Training loss at epoch 94: 0.2149\n",
      "\n",
      "Start of epoch 95\n",
      "Training loss at epoch 95: 0.2139\n",
      "\n",
      "Start of epoch 96\n",
      "Training loss at epoch 96: 0.2129\n",
      "\n",
      "Start of epoch 97\n",
      "Training loss at epoch 97: 0.2119\n",
      "\n",
      "Start of epoch 98\n",
      "Training loss at epoch 98: 0.2109\n",
      "\n",
      "Start of epoch 99\n",
      "Training loss at epoch 99: 0.2099\n",
      "\n",
      "Start of epoch 100\n",
      "Training loss at epoch 100: 0.2089\n",
      "\n",
      "Start of epoch 101\n",
      "Training loss at epoch 101: 0.2080\n",
      "\n",
      "Start of epoch 102\n",
      "Training loss at epoch 102: 0.2071\n",
      "\n",
      "Start of epoch 103\n",
      "Training loss at epoch 103: 0.2062\n",
      "\n",
      "Start of epoch 104\n",
      "Training loss at epoch 104: 0.2055\n",
      "\n",
      "Start of epoch 105\n",
      "Training loss at epoch 105: 0.2048\n",
      "\n",
      "Start of epoch 106\n",
      "Training loss at epoch 106: 0.2041\n",
      "\n",
      "Start of epoch 107\n",
      "Training loss at epoch 107: 0.2035\n",
      "\n",
      "Start of epoch 108\n",
      "Training loss at epoch 108: 0.2029\n",
      "\n",
      "Start of epoch 109\n",
      "Training loss at epoch 109: 0.2023\n",
      "\n",
      "Start of epoch 110\n",
      "Training loss at epoch 110: 0.2018\n",
      "\n",
      "Start of epoch 111\n",
      "Training loss at epoch 111: 0.2013\n",
      "\n",
      "Start of epoch 112\n",
      "Training loss at epoch 112: 0.2009\n",
      "\n",
      "Start of epoch 113\n",
      "Training loss at epoch 113: 0.2004\n",
      "\n",
      "Start of epoch 114\n",
      "Training loss at epoch 114: 0.2000\n",
      "\n",
      "Start of epoch 115\n",
      "Training loss at epoch 115: 0.1995\n",
      "\n",
      "Start of epoch 116\n",
      "Training loss at epoch 116: 0.1991\n",
      "\n",
      "Start of epoch 117\n",
      "Training loss at epoch 117: 0.1987\n",
      "\n",
      "Start of epoch 118\n",
      "Training loss at epoch 118: 0.1982\n",
      "\n",
      "Start of epoch 119\n",
      "Training loss at epoch 119: 0.1978\n",
      "\n",
      "Start of epoch 120\n",
      "Training loss at epoch 120: 0.1974\n",
      "\n",
      "Start of epoch 121\n",
      "Training loss at epoch 121: 0.1970\n",
      "\n",
      "Start of epoch 122\n",
      "Training loss at epoch 122: 0.1967\n",
      "\n",
      "Start of epoch 123\n",
      "Training loss at epoch 123: 0.1963\n",
      "\n",
      "Start of epoch 124\n",
      "Training loss at epoch 124: 0.1959\n",
      "\n",
      "Start of epoch 125\n",
      "Training loss at epoch 125: 0.1956\n",
      "\n",
      "Start of epoch 126\n",
      "Training loss at epoch 126: 0.1953\n",
      "\n",
      "Start of epoch 127\n",
      "Training loss at epoch 127: 0.1949\n",
      "\n",
      "Start of epoch 128\n",
      "Training loss at epoch 128: 0.1946\n",
      "\n",
      "Start of epoch 129\n",
      "Training loss at epoch 129: 0.1943\n",
      "\n",
      "Start of epoch 130\n",
      "Training loss at epoch 130: 0.1939\n",
      "\n",
      "Start of epoch 131\n",
      "Training loss at epoch 131: 0.1936\n",
      "\n",
      "Start of epoch 132\n",
      "Training loss at epoch 132: 0.1932\n",
      "\n",
      "Start of epoch 133\n",
      "Training loss at epoch 133: 0.1929\n",
      "\n",
      "Start of epoch 134\n",
      "Training loss at epoch 134: 0.1925\n",
      "\n",
      "Start of epoch 135\n",
      "Training loss at epoch 135: 0.1922\n",
      "\n",
      "Start of epoch 136\n",
      "Training loss at epoch 136: 0.1918\n",
      "\n",
      "Start of epoch 137\n",
      "Training loss at epoch 137: 0.1915\n",
      "\n",
      "Start of epoch 138\n",
      "Training loss at epoch 138: 0.1911\n",
      "\n",
      "Start of epoch 139\n",
      "Training loss at epoch 139: 0.1907\n",
      "\n",
      "Start of epoch 140\n",
      "Training loss at epoch 140: 0.1904\n",
      "\n",
      "Start of epoch 141\n",
      "Training loss at epoch 141: 0.1900\n",
      "\n",
      "Start of epoch 142\n",
      "Training loss at epoch 142: 0.1896\n",
      "\n",
      "Start of epoch 143\n",
      "Training loss at epoch 143: 0.1892\n",
      "\n",
      "Start of epoch 144\n",
      "Training loss at epoch 144: 0.1888\n",
      "\n",
      "Start of epoch 145\n",
      "Training loss at epoch 145: 0.1884\n",
      "\n",
      "Start of epoch 146\n",
      "Training loss at epoch 146: 0.1880\n",
      "\n",
      "Start of epoch 147\n",
      "Training loss at epoch 147: 0.1875\n",
      "\n",
      "Start of epoch 148\n",
      "Training loss at epoch 148: 0.1871\n",
      "\n",
      "Start of epoch 149\n",
      "Training loss at epoch 149: 0.1866\n",
      "\n",
      "Start of epoch 150\n",
      "Training loss at epoch 150: 0.1861\n",
      "\n",
      "Start of epoch 151\n",
      "Training loss at epoch 151: 0.1856\n",
      "\n",
      "Start of epoch 152\n",
      "Training loss at epoch 152: 0.1851\n",
      "\n",
      "Start of epoch 153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 153: 0.1846\n",
      "\n",
      "Start of epoch 154\n",
      "Training loss at epoch 154: 0.1840\n",
      "\n",
      "Start of epoch 155\n",
      "Training loss at epoch 155: 0.1834\n",
      "\n",
      "Start of epoch 156\n",
      "Training loss at epoch 156: 0.1829\n",
      "\n",
      "Start of epoch 157\n",
      "Training loss at epoch 157: 0.1822\n",
      "\n",
      "Start of epoch 158\n",
      "Training loss at epoch 158: 0.1816\n",
      "\n",
      "Start of epoch 159\n",
      "Training loss at epoch 159: 0.1809\n",
      "\n",
      "Start of epoch 160\n",
      "Training loss at epoch 160: 0.1802\n",
      "\n",
      "Start of epoch 161\n",
      "Training loss at epoch 161: 0.1795\n",
      "\n",
      "Start of epoch 162\n",
      "Training loss at epoch 162: 0.1787\n",
      "\n",
      "Start of epoch 163\n",
      "Training loss at epoch 163: 0.1779\n",
      "\n",
      "Start of epoch 164\n",
      "Training loss at epoch 164: 0.1771\n",
      "\n",
      "Start of epoch 165\n",
      "Training loss at epoch 165: 0.1763\n",
      "\n",
      "Start of epoch 166\n",
      "Training loss at epoch 166: 0.1754\n",
      "\n",
      "Start of epoch 167\n",
      "Training loss at epoch 167: 0.1744\n",
      "\n",
      "Start of epoch 168\n",
      "Training loss at epoch 168: 0.1735\n",
      "\n",
      "Start of epoch 169\n",
      "Training loss at epoch 169: 0.1725\n",
      "\n",
      "Start of epoch 170\n",
      "Training loss at epoch 170: 0.1715\n",
      "\n",
      "Start of epoch 171\n",
      "Training loss at epoch 171: 0.1704\n",
      "\n",
      "Start of epoch 172\n",
      "Training loss at epoch 172: 0.1693\n",
      "\n",
      "Start of epoch 173\n",
      "Training loss at epoch 173: 0.1682\n",
      "\n",
      "Start of epoch 174\n",
      "Training loss at epoch 174: 0.1670\n",
      "\n",
      "Start of epoch 175\n",
      "Training loss at epoch 175: 0.1659\n",
      "\n",
      "Start of epoch 176\n",
      "Training loss at epoch 176: 0.1647\n",
      "\n",
      "Start of epoch 177\n",
      "Training loss at epoch 177: 0.1635\n",
      "\n",
      "Start of epoch 178\n",
      "Training loss at epoch 178: 0.1623\n",
      "\n",
      "Start of epoch 179\n",
      "Training loss at epoch 179: 0.1610\n",
      "\n",
      "Start of epoch 180\n",
      "Training loss at epoch 180: 0.1598\n",
      "\n",
      "Start of epoch 181\n",
      "Training loss at epoch 181: 0.1586\n",
      "\n",
      "Start of epoch 182\n",
      "Training loss at epoch 182: 0.1574\n",
      "\n",
      "Start of epoch 183\n",
      "Training loss at epoch 183: 0.1561\n",
      "\n",
      "Start of epoch 184\n",
      "Training loss at epoch 184: 0.1549\n",
      "\n",
      "Start of epoch 185\n",
      "Training loss at epoch 185: 0.1537\n",
      "\n",
      "Start of epoch 186\n",
      "Training loss at epoch 186: 0.1525\n",
      "\n",
      "Start of epoch 187\n",
      "Training loss at epoch 187: 0.1513\n",
      "\n",
      "Start of epoch 188\n",
      "Training loss at epoch 188: 0.1501\n",
      "\n",
      "Start of epoch 189\n",
      "Training loss at epoch 189: 0.1490\n",
      "\n",
      "Start of epoch 190\n",
      "Training loss at epoch 190: 0.1479\n",
      "\n",
      "Start of epoch 191\n",
      "Training loss at epoch 191: 0.1468\n",
      "\n",
      "Start of epoch 192\n",
      "Training loss at epoch 192: 0.1457\n",
      "\n",
      "Start of epoch 193\n",
      "Training loss at epoch 193: 0.1447\n",
      "\n",
      "Start of epoch 194\n",
      "Training loss at epoch 194: 0.1437\n",
      "\n",
      "Start of epoch 195\n",
      "Training loss at epoch 195: 0.1428\n",
      "\n",
      "Start of epoch 196\n",
      "Training loss at epoch 196: 0.1419\n",
      "\n",
      "Start of epoch 197\n",
      "Training loss at epoch 197: 0.1410\n",
      "\n",
      "Start of epoch 198\n",
      "Training loss at epoch 198: 0.1402\n",
      "\n",
      "Start of epoch 199\n",
      "Training loss at epoch 199: 0.1395\n",
      "\n",
      "Start of epoch 200\n",
      "Training loss at epoch 200: 0.1388\n",
      "\n",
      "Start of epoch 201\n",
      "Training loss at epoch 201: 0.1381\n",
      "\n",
      "Start of epoch 202\n",
      "Training loss at epoch 202: 0.1375\n",
      "\n",
      "Start of epoch 203\n",
      "Training loss at epoch 203: 0.1369\n",
      "\n",
      "Start of epoch 204\n",
      "Training loss at epoch 204: 0.1363\n",
      "\n",
      "Start of epoch 205\n",
      "Training loss at epoch 205: 0.1358\n",
      "\n",
      "Start of epoch 206\n",
      "Training loss at epoch 206: 0.1353\n",
      "\n",
      "Start of epoch 207\n",
      "Training loss at epoch 207: 0.1348\n",
      "\n",
      "Start of epoch 208\n",
      "Training loss at epoch 208: 0.1344\n",
      "\n",
      "Start of epoch 209\n",
      "Training loss at epoch 209: 0.1339\n",
      "\n",
      "Start of epoch 210\n",
      "Training loss at epoch 210: 0.1335\n",
      "\n",
      "Start of epoch 211\n",
      "Training loss at epoch 211: 0.1331\n",
      "\n",
      "Start of epoch 212\n",
      "Training loss at epoch 212: 0.1326\n",
      "\n",
      "Start of epoch 213\n",
      "Training loss at epoch 213: 0.1322\n",
      "\n",
      "Start of epoch 214\n",
      "Training loss at epoch 214: 0.1318\n",
      "\n",
      "Start of epoch 215\n",
      "Training loss at epoch 215: 0.1314\n",
      "\n",
      "Start of epoch 216\n",
      "Training loss at epoch 216: 0.1310\n",
      "\n",
      "Start of epoch 217\n",
      "Training loss at epoch 217: 0.1307\n",
      "\n",
      "Start of epoch 218\n",
      "Training loss at epoch 218: 0.1303\n",
      "\n",
      "Start of epoch 219\n",
      "Training loss at epoch 219: 0.1299\n",
      "\n",
      "Start of epoch 220\n",
      "Training loss at epoch 220: 0.1296\n",
      "\n",
      "Start of epoch 221\n",
      "Training loss at epoch 221: 0.1292\n",
      "\n",
      "Start of epoch 222\n",
      "Training loss at epoch 222: 0.1289\n",
      "\n",
      "Start of epoch 223\n",
      "Training loss at epoch 223: 0.1285\n",
      "\n",
      "Start of epoch 224\n",
      "Training loss at epoch 224: 0.1282\n",
      "\n",
      "Start of epoch 225\n",
      "Training loss at epoch 225: 0.1279\n",
      "\n",
      "Start of epoch 226\n",
      "Training loss at epoch 226: 0.1276\n",
      "\n",
      "Start of epoch 227\n",
      "Training loss at epoch 227: 0.1273\n",
      "\n",
      "Start of epoch 228\n",
      "Training loss at epoch 228: 0.1270\n",
      "\n",
      "Start of epoch 229\n",
      "Training loss at epoch 229: 0.1267\n",
      "\n",
      "Start of epoch 230\n",
      "Training loss at epoch 230: 0.1264\n",
      "\n",
      "Start of epoch 231\n",
      "Training loss at epoch 231: 0.1261\n",
      "\n",
      "Start of epoch 232\n",
      "Training loss at epoch 232: 0.1258\n",
      "\n",
      "Start of epoch 233\n",
      "Training loss at epoch 233: 0.1255\n",
      "\n",
      "Start of epoch 234\n",
      "Training loss at epoch 234: 0.1253\n",
      "\n",
      "Start of epoch 235\n",
      "Training loss at epoch 235: 0.1250\n",
      "\n",
      "Start of epoch 236\n",
      "Training loss at epoch 236: 0.1248\n",
      "\n",
      "Start of epoch 237\n",
      "Training loss at epoch 237: 0.1245\n",
      "\n",
      "Start of epoch 238\n",
      "Training loss at epoch 238: 0.1243\n",
      "\n",
      "Start of epoch 239\n",
      "Training loss at epoch 239: 0.1240\n",
      "\n",
      "Start of epoch 240\n",
      "Training loss at epoch 240: 0.1238\n",
      "\n",
      "Start of epoch 241\n",
      "Training loss at epoch 241: 0.1236\n",
      "\n",
      "Start of epoch 242\n",
      "Training loss at epoch 242: 0.1234\n",
      "\n",
      "Start of epoch 243\n",
      "Training loss at epoch 243: 0.1232\n",
      "\n",
      "Start of epoch 244\n",
      "Training loss at epoch 244: 0.1230\n",
      "\n",
      "Start of epoch 245\n",
      "Training loss at epoch 245: 0.1228\n",
      "\n",
      "Start of epoch 246\n",
      "Training loss at epoch 246: 0.1226\n",
      "\n",
      "Start of epoch 247\n",
      "Training loss at epoch 247: 0.1224\n",
      "\n",
      "Start of epoch 248\n",
      "Training loss at epoch 248: 0.1222\n",
      "\n",
      "Start of epoch 249\n",
      "Training loss at epoch 249: 0.1220\n",
      "\n",
      "Start of epoch 250\n",
      "Training loss at epoch 250: 0.1218\n",
      "\n",
      "Start of epoch 251\n",
      "Training loss at epoch 251: 0.1217\n",
      "\n",
      "Start of epoch 252\n",
      "Training loss at epoch 252: 0.1215\n",
      "\n",
      "Start of epoch 253\n",
      "Training loss at epoch 253: 0.1213\n",
      "\n",
      "Start of epoch 254\n",
      "Training loss at epoch 254: 0.1212\n",
      "\n",
      "Start of epoch 255\n",
      "Training loss at epoch 255: 0.1210\n",
      "\n",
      "Start of epoch 256\n",
      "Training loss at epoch 256: 0.1209\n",
      "\n",
      "Start of epoch 257\n",
      "Training loss at epoch 257: 0.1207\n",
      "\n",
      "Start of epoch 258\n",
      "Training loss at epoch 258: 0.1206\n",
      "\n",
      "Start of epoch 259\n",
      "Training loss at epoch 259: 0.1204\n",
      "\n",
      "Start of epoch 260\n",
      "Training loss at epoch 260: 0.1203\n",
      "\n",
      "Start of epoch 261\n",
      "Training loss at epoch 261: 0.1202\n",
      "\n",
      "Start of epoch 262\n",
      "Training loss at epoch 262: 0.1200\n",
      "\n",
      "Start of epoch 263\n",
      "Training loss at epoch 263: 0.1199\n",
      "\n",
      "Start of epoch 264\n",
      "Training loss at epoch 264: 0.1198\n",
      "\n",
      "Start of epoch 265\n",
      "Training loss at epoch 265: 0.1197\n",
      "\n",
      "Start of epoch 266\n",
      "Training loss at epoch 266: 0.1195\n",
      "\n",
      "Start of epoch 267\n",
      "Training loss at epoch 267: 0.1194\n",
      "\n",
      "Start of epoch 268\n",
      "Training loss at epoch 268: 0.1193\n",
      "\n",
      "Start of epoch 269\n",
      "Training loss at epoch 269: 0.1192\n",
      "\n",
      "Start of epoch 270\n",
      "Training loss at epoch 270: 0.1191\n",
      "\n",
      "Start of epoch 271\n",
      "Training loss at epoch 271: 0.1190\n",
      "\n",
      "Start of epoch 272\n",
      "Training loss at epoch 272: 0.1189\n",
      "\n",
      "Start of epoch 273\n",
      "Training loss at epoch 273: 0.1188\n",
      "\n",
      "Start of epoch 274\n",
      "Training loss at epoch 274: 0.1187\n",
      "\n",
      "Start of epoch 275\n",
      "Training loss at epoch 275: 0.1186\n",
      "\n",
      "Start of epoch 276\n",
      "Training loss at epoch 276: 0.1185\n",
      "\n",
      "Start of epoch 277\n",
      "Training loss at epoch 277: 0.1184\n",
      "\n",
      "Start of epoch 278\n",
      "Training loss at epoch 278: 0.1183\n",
      "\n",
      "Start of epoch 279\n",
      "Training loss at epoch 279: 0.1182\n",
      "\n",
      "Start of epoch 280\n",
      "Training loss at epoch 280: 0.1181\n",
      "\n",
      "Start of epoch 281\n",
      "Training loss at epoch 281: 0.1180\n",
      "\n",
      "Start of epoch 282\n",
      "Training loss at epoch 282: 0.1179\n",
      "\n",
      "Start of epoch 283\n",
      "Training loss at epoch 283: 0.1178\n",
      "\n",
      "Start of epoch 284\n",
      "Training loss at epoch 284: 0.1177\n",
      "\n",
      "Start of epoch 285\n",
      "Training loss at epoch 285: 0.1176\n",
      "\n",
      "Start of epoch 286\n",
      "Training loss at epoch 286: 0.1175\n",
      "\n",
      "Start of epoch 287\n",
      "Training loss at epoch 287: 0.1174\n",
      "\n",
      "Start of epoch 288\n",
      "Training loss at epoch 288: 0.1174\n",
      "\n",
      "Start of epoch 289\n",
      "Training loss at epoch 289: 0.1173\n",
      "\n",
      "Start of epoch 290\n",
      "Training loss at epoch 290: 0.1172\n",
      "\n",
      "Start of epoch 291\n",
      "Training loss at epoch 291: 0.1171\n",
      "\n",
      "Start of epoch 292\n",
      "Training loss at epoch 292: 0.1170\n",
      "\n",
      "Start of epoch 293\n",
      "Training loss at epoch 293: 0.1169\n",
      "\n",
      "Start of epoch 294\n",
      "Training loss at epoch 294: 0.1168\n",
      "\n",
      "Start of epoch 295\n",
      "Training loss at epoch 295: 0.1167\n",
      "\n",
      "Start of epoch 296\n",
      "Training loss at epoch 296: 0.1167\n",
      "\n",
      "Start of epoch 297\n",
      "Training loss at epoch 297: 0.1166\n",
      "\n",
      "Start of epoch 298\n",
      "Training loss at epoch 298: 0.1165\n",
      "\n",
      "Start of epoch 299\n",
      "Training loss at epoch 299: 0.1164\n",
      "\n",
      "Start of epoch 300\n",
      "Training loss at epoch 300: 0.1163\n",
      "\n",
      "Start of epoch 301\n",
      "Training loss at epoch 301: 0.1162\n",
      "\n",
      "Start of epoch 302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 302: 0.1161\n",
      "\n",
      "Start of epoch 303\n",
      "Training loss at epoch 303: 0.1160\n",
      "\n",
      "Start of epoch 304\n",
      "Training loss at epoch 304: 0.1160\n",
      "\n",
      "Start of epoch 305\n",
      "Training loss at epoch 305: 0.1159\n",
      "\n",
      "Start of epoch 306\n",
      "Training loss at epoch 306: 0.1158\n",
      "\n",
      "Start of epoch 307\n",
      "Training loss at epoch 307: 0.1157\n",
      "\n",
      "Start of epoch 308\n",
      "Training loss at epoch 308: 0.1156\n",
      "\n",
      "Start of epoch 309\n",
      "Training loss at epoch 309: 0.1155\n",
      "\n",
      "Start of epoch 310\n",
      "Training loss at epoch 310: 0.1154\n",
      "\n",
      "Start of epoch 311\n",
      "Training loss at epoch 311: 0.1153\n",
      "\n",
      "Start of epoch 312\n",
      "Training loss at epoch 312: 0.1152\n",
      "\n",
      "Start of epoch 313\n",
      "Training loss at epoch 313: 0.1151\n",
      "\n",
      "Start of epoch 314\n",
      "Training loss at epoch 314: 0.1150\n",
      "\n",
      "Start of epoch 315\n",
      "Training loss at epoch 315: 0.1149\n",
      "\n",
      "Start of epoch 316\n",
      "Training loss at epoch 316: 0.1148\n",
      "\n",
      "Start of epoch 317\n",
      "Training loss at epoch 317: 0.1147\n",
      "\n",
      "Start of epoch 318\n",
      "Training loss at epoch 318: 0.1146\n",
      "\n",
      "Start of epoch 319\n",
      "Training loss at epoch 319: 0.1145\n",
      "\n",
      "Start of epoch 320\n",
      "Training loss at epoch 320: 0.1144\n",
      "\n",
      "Start of epoch 321\n",
      "Training loss at epoch 321: 0.1143\n",
      "\n",
      "Start of epoch 322\n",
      "Training loss at epoch 322: 0.1142\n",
      "\n",
      "Start of epoch 323\n",
      "Training loss at epoch 323: 0.1141\n",
      "\n",
      "Start of epoch 324\n",
      "Training loss at epoch 324: 0.1140\n",
      "\n",
      "Start of epoch 325\n",
      "Training loss at epoch 325: 0.1139\n",
      "\n",
      "Start of epoch 326\n",
      "Training loss at epoch 326: 0.1138\n",
      "\n",
      "Start of epoch 327\n",
      "Training loss at epoch 327: 0.1136\n",
      "\n",
      "Start of epoch 328\n",
      "Training loss at epoch 328: 0.1135\n",
      "\n",
      "Start of epoch 329\n",
      "Training loss at epoch 329: 0.1134\n",
      "\n",
      "Start of epoch 330\n",
      "Training loss at epoch 330: 0.1133\n",
      "\n",
      "Start of epoch 331\n",
      "Training loss at epoch 331: 0.1132\n",
      "\n",
      "Start of epoch 332\n",
      "Training loss at epoch 332: 0.1130\n",
      "\n",
      "Start of epoch 333\n",
      "Training loss at epoch 333: 0.1129\n",
      "\n",
      "Start of epoch 334\n",
      "Training loss at epoch 334: 0.1128\n",
      "\n",
      "Start of epoch 335\n",
      "Training loss at epoch 335: 0.1127\n",
      "\n",
      "Start of epoch 336\n",
      "Training loss at epoch 336: 0.1125\n",
      "\n",
      "Start of epoch 337\n",
      "Training loss at epoch 337: 0.1124\n",
      "\n",
      "Start of epoch 338\n",
      "Training loss at epoch 338: 0.1123\n",
      "\n",
      "Start of epoch 339\n",
      "Training loss at epoch 339: 0.1121\n",
      "\n",
      "Start of epoch 340\n",
      "Training loss at epoch 340: 0.1120\n",
      "\n",
      "Start of epoch 341\n",
      "Training loss at epoch 341: 0.1119\n",
      "\n",
      "Start of epoch 342\n",
      "Training loss at epoch 342: 0.1117\n",
      "\n",
      "Start of epoch 343\n",
      "Training loss at epoch 343: 0.1116\n",
      "\n",
      "Start of epoch 344\n",
      "Training loss at epoch 344: 0.1114\n",
      "\n",
      "Start of epoch 345\n",
      "Training loss at epoch 345: 0.1113\n",
      "\n",
      "Start of epoch 346\n",
      "Training loss at epoch 346: 0.1112\n",
      "\n",
      "Start of epoch 347\n",
      "Training loss at epoch 347: 0.1110\n",
      "\n",
      "Start of epoch 348\n",
      "Training loss at epoch 348: 0.1109\n",
      "\n",
      "Start of epoch 349\n",
      "Training loss at epoch 349: 0.1107\n",
      "\n",
      "Start of epoch 350\n",
      "Training loss at epoch 350: 0.1106\n",
      "\n",
      "Start of epoch 351\n",
      "Training loss at epoch 351: 0.1104\n",
      "\n",
      "Start of epoch 352\n",
      "Training loss at epoch 352: 0.1103\n",
      "\n",
      "Start of epoch 353\n",
      "Training loss at epoch 353: 0.1101\n",
      "\n",
      "Start of epoch 354\n",
      "Training loss at epoch 354: 0.1100\n",
      "\n",
      "Start of epoch 355\n",
      "Training loss at epoch 355: 0.1098\n",
      "\n",
      "Start of epoch 356\n",
      "Training loss at epoch 356: 0.1097\n",
      "\n",
      "Start of epoch 357\n",
      "Training loss at epoch 357: 0.1095\n",
      "\n",
      "Start of epoch 358\n",
      "Training loss at epoch 358: 0.1094\n",
      "\n",
      "Start of epoch 359\n",
      "Training loss at epoch 359: 0.1092\n",
      "\n",
      "Start of epoch 360\n",
      "Training loss at epoch 360: 0.1090\n",
      "\n",
      "Start of epoch 361\n",
      "Training loss at epoch 361: 0.1089\n",
      "\n",
      "Start of epoch 362\n",
      "Training loss at epoch 362: 0.1087\n",
      "\n",
      "Start of epoch 363\n",
      "Training loss at epoch 363: 0.1086\n",
      "\n",
      "Start of epoch 364\n",
      "Training loss at epoch 364: 0.1084\n",
      "\n",
      "Start of epoch 365\n",
      "Training loss at epoch 365: 0.1082\n",
      "\n",
      "Start of epoch 366\n",
      "Training loss at epoch 366: 0.1081\n",
      "\n",
      "Start of epoch 367\n",
      "Training loss at epoch 367: 0.1079\n",
      "\n",
      "Start of epoch 368\n",
      "Training loss at epoch 368: 0.1077\n",
      "\n",
      "Start of epoch 369\n",
      "Training loss at epoch 369: 0.1076\n",
      "\n",
      "Start of epoch 370\n",
      "Training loss at epoch 370: 0.1074\n",
      "\n",
      "Start of epoch 371\n",
      "Training loss at epoch 371: 0.1072\n",
      "\n",
      "Start of epoch 372\n",
      "Training loss at epoch 372: 0.1070\n",
      "\n",
      "Start of epoch 373\n",
      "Training loss at epoch 373: 0.1069\n",
      "\n",
      "Start of epoch 374\n",
      "Training loss at epoch 374: 0.1067\n",
      "\n",
      "Start of epoch 375\n",
      "Training loss at epoch 375: 0.1065\n",
      "\n",
      "Start of epoch 376\n",
      "Training loss at epoch 376: 0.1063\n",
      "\n",
      "Start of epoch 377\n",
      "Training loss at epoch 377: 0.1061\n",
      "\n",
      "Start of epoch 378\n",
      "Training loss at epoch 378: 0.1059\n",
      "\n",
      "Start of epoch 379\n",
      "Training loss at epoch 379: 0.1058\n",
      "\n",
      "Start of epoch 380\n",
      "Training loss at epoch 380: 0.1056\n",
      "\n",
      "Start of epoch 381\n",
      "Training loss at epoch 381: 0.1054\n",
      "\n",
      "Start of epoch 382\n",
      "Training loss at epoch 382: 0.1052\n",
      "\n",
      "Start of epoch 383\n",
      "Training loss at epoch 383: 0.1050\n",
      "\n",
      "Start of epoch 384\n",
      "Training loss at epoch 384: 0.1048\n",
      "\n",
      "Start of epoch 385\n",
      "Training loss at epoch 385: 0.1046\n",
      "\n",
      "Start of epoch 386\n",
      "Training loss at epoch 386: 0.1044\n",
      "\n",
      "Start of epoch 387\n",
      "Training loss at epoch 387: 0.1042\n",
      "\n",
      "Start of epoch 388\n",
      "Training loss at epoch 388: 0.1040\n",
      "\n",
      "Start of epoch 389\n",
      "Training loss at epoch 389: 0.1038\n",
      "\n",
      "Start of epoch 390\n",
      "Training loss at epoch 390: 0.1036\n",
      "\n",
      "Start of epoch 391\n",
      "Training loss at epoch 391: 0.1034\n",
      "\n",
      "Start of epoch 392\n",
      "Training loss at epoch 392: 0.1032\n",
      "\n",
      "Start of epoch 393\n",
      "Training loss at epoch 393: 0.1030\n",
      "\n",
      "Start of epoch 394\n",
      "Training loss at epoch 394: 0.1028\n",
      "\n",
      "Start of epoch 395\n",
      "Training loss at epoch 395: 0.1027\n",
      "\n",
      "Start of epoch 396\n",
      "Training loss at epoch 396: 0.1025\n",
      "\n",
      "Start of epoch 397\n",
      "Training loss at epoch 397: 0.1023\n",
      "\n",
      "Start of epoch 398\n",
      "Training loss at epoch 398: 0.1021\n",
      "\n",
      "Start of epoch 399\n",
      "Training loss at epoch 399: 0.1019\n",
      "\n",
      "Start of epoch 400\n",
      "Training loss at epoch 400: 0.1017\n",
      "\n",
      "Start of epoch 401\n",
      "Training loss at epoch 401: 0.1016\n",
      "\n",
      "Start of epoch 402\n",
      "Training loss at epoch 402: 0.1014\n",
      "\n",
      "Start of epoch 403\n",
      "Training loss at epoch 403: 0.1012\n",
      "\n",
      "Start of epoch 404\n",
      "Training loss at epoch 404: 0.1011\n",
      "\n",
      "Start of epoch 405\n",
      "Training loss at epoch 405: 0.1009\n",
      "\n",
      "Start of epoch 406\n",
      "Training loss at epoch 406: 0.1008\n",
      "\n",
      "Start of epoch 407\n",
      "Training loss at epoch 407: 0.1006\n",
      "\n",
      "Start of epoch 408\n",
      "Training loss at epoch 408: 0.1005\n",
      "\n",
      "Start of epoch 409\n",
      "Training loss at epoch 409: 0.1003\n",
      "\n",
      "Start of epoch 410\n",
      "Training loss at epoch 410: 0.1002\n",
      "\n",
      "Start of epoch 411\n",
      "Training loss at epoch 411: 0.1001\n",
      "\n",
      "Start of epoch 412\n",
      "Training loss at epoch 412: 0.1000\n",
      "\n",
      "Start of epoch 413\n",
      "Training loss at epoch 413: 0.0999\n",
      "\n",
      "Start of epoch 414\n",
      "Training loss at epoch 414: 0.0998\n",
      "\n",
      "Start of epoch 415\n",
      "Training loss at epoch 415: 0.0997\n",
      "\n",
      "Start of epoch 416\n",
      "Training loss at epoch 416: 0.0996\n",
      "\n",
      "Start of epoch 417\n",
      "Training loss at epoch 417: 0.0995\n",
      "\n",
      "Start of epoch 418\n",
      "Training loss at epoch 418: 0.0994\n",
      "\n",
      "Start of epoch 419\n",
      "Training loss at epoch 419: 0.0993\n",
      "\n",
      "Start of epoch 420\n",
      "Training loss at epoch 420: 0.0993\n",
      "\n",
      "Start of epoch 421\n",
      "Training loss at epoch 421: 0.0992\n",
      "\n",
      "Start of epoch 422\n",
      "Training loss at epoch 422: 0.0991\n",
      "\n",
      "Start of epoch 423\n",
      "Training loss at epoch 423: 0.0991\n",
      "\n",
      "Start of epoch 424\n",
      "Training loss at epoch 424: 0.0990\n",
      "\n",
      "Start of epoch 425\n",
      "Training loss at epoch 425: 0.0990\n",
      "\n",
      "Start of epoch 426\n",
      "Training loss at epoch 426: 0.0989\n",
      "\n",
      "Start of epoch 427\n",
      "Training loss at epoch 427: 0.0989\n",
      "\n",
      "Start of epoch 428\n",
      "Training loss at epoch 428: 0.0988\n",
      "\n",
      "Start of epoch 429\n",
      "Training loss at epoch 429: 0.0988\n",
      "\n",
      "Start of epoch 430\n",
      "Training loss at epoch 430: 0.0987\n",
      "\n",
      "Start of epoch 431\n",
      "Training loss at epoch 431: 0.0987\n",
      "\n",
      "Start of epoch 432\n",
      "Training loss at epoch 432: 0.0986\n",
      "\n",
      "Start of epoch 433\n",
      "Training loss at epoch 433: 0.0986\n",
      "\n",
      "Start of epoch 434\n",
      "Training loss at epoch 434: 0.0986\n",
      "\n",
      "Start of epoch 435\n",
      "Training loss at epoch 435: 0.0985\n",
      "\n",
      "Start of epoch 436\n",
      "Training loss at epoch 436: 0.0985\n",
      "\n",
      "Start of epoch 437\n",
      "Training loss at epoch 437: 0.0985\n",
      "\n",
      "Start of epoch 438\n",
      "Training loss at epoch 438: 0.0985\n",
      "\n",
      "Start of epoch 439\n",
      "Training loss at epoch 439: 0.0984\n",
      "\n",
      "Start of epoch 440\n",
      "Training loss at epoch 440: 0.0984\n",
      "\n",
      "Start of epoch 441\n",
      "Training loss at epoch 441: 0.0984\n",
      "\n",
      "Start of epoch 442\n",
      "Training loss at epoch 442: 0.0984\n",
      "\n",
      "Start of epoch 443\n",
      "Training loss at epoch 443: 0.0983\n",
      "\n",
      "Start of epoch 444\n",
      "Training loss at epoch 444: 0.0983\n",
      "\n",
      "Start of epoch 445\n",
      "Training loss at epoch 445: 0.0983\n",
      "\n",
      "Start of epoch 446\n",
      "Training loss at epoch 446: 0.0983\n",
      "\n",
      "Start of epoch 447\n",
      "Training loss at epoch 447: 0.0983\n",
      "\n",
      "Start of epoch 448\n",
      "Training loss at epoch 448: 0.0983\n",
      "\n",
      "Start of epoch 449\n",
      "Training loss at epoch 449: 0.0982\n",
      "\n",
      "Start of epoch 450\n",
      "Training loss at epoch 450: 0.0982\n",
      "\n",
      "Start of epoch 451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 451: 0.0982\n",
      "\n",
      "Start of epoch 452\n",
      "Training loss at epoch 452: 0.0982\n",
      "\n",
      "Start of epoch 453\n",
      "Training loss at epoch 453: 0.0982\n",
      "\n",
      "Start of epoch 454\n",
      "Training loss at epoch 454: 0.0982\n",
      "\n",
      "Start of epoch 455\n",
      "Training loss at epoch 455: 0.0982\n",
      "\n",
      "Start of epoch 456\n",
      "Training loss at epoch 456: 0.0981\n",
      "\n",
      "Start of epoch 457\n",
      "Training loss at epoch 457: 0.0981\n",
      "\n",
      "Start of epoch 458\n",
      "Training loss at epoch 458: 0.0981\n",
      "\n",
      "Start of epoch 459\n",
      "Training loss at epoch 459: 0.0981\n",
      "\n",
      "Start of epoch 460\n",
      "Training loss at epoch 460: 0.0981\n",
      "\n",
      "Start of epoch 461\n",
      "Training loss at epoch 461: 0.0981\n",
      "\n",
      "Start of epoch 462\n",
      "Training loss at epoch 462: 0.0981\n",
      "\n",
      "Start of epoch 463\n",
      "Training loss at epoch 463: 0.0981\n",
      "\n",
      "Start of epoch 464\n",
      "Training loss at epoch 464: 0.0980\n",
      "\n",
      "Start of epoch 465\n",
      "Training loss at epoch 465: 0.0980\n",
      "\n",
      "Start of epoch 466\n",
      "Training loss at epoch 466: 0.0980\n",
      "\n",
      "Start of epoch 467\n",
      "Training loss at epoch 467: 0.0980\n",
      "\n",
      "Start of epoch 468\n",
      "Training loss at epoch 468: 0.0980\n",
      "\n",
      "Start of epoch 469\n",
      "Training loss at epoch 469: 0.0980\n",
      "\n",
      "Start of epoch 470\n",
      "Training loss at epoch 470: 0.0980\n",
      "\n",
      "Start of epoch 471\n",
      "Training loss at epoch 471: 0.0979\n",
      "\n",
      "Start of epoch 472\n",
      "Training loss at epoch 472: 0.0979\n",
      "\n",
      "Start of epoch 473\n",
      "Training loss at epoch 473: 0.0979\n",
      "\n",
      "Start of epoch 474\n",
      "Training loss at epoch 474: 0.0979\n",
      "\n",
      "Start of epoch 475\n",
      "Training loss at epoch 475: 0.0979\n",
      "\n",
      "Start of epoch 476\n",
      "Training loss at epoch 476: 0.0979\n",
      "\n",
      "Start of epoch 477\n",
      "Training loss at epoch 477: 0.0979\n",
      "\n",
      "Start of epoch 478\n",
      "Training loss at epoch 478: 0.0978\n",
      "\n",
      "Start of epoch 479\n",
      "Training loss at epoch 479: 0.0978\n",
      "\n",
      "Start of epoch 480\n",
      "Training loss at epoch 480: 0.0978\n",
      "\n",
      "Start of epoch 481\n",
      "Training loss at epoch 481: 0.0978\n",
      "\n",
      "Start of epoch 482\n",
      "Training loss at epoch 482: 0.0978\n",
      "\n",
      "Start of epoch 483\n",
      "Training loss at epoch 483: 0.0978\n",
      "\n",
      "Start of epoch 484\n",
      "Training loss at epoch 484: 0.0977\n",
      "\n",
      "Start of epoch 485\n",
      "Training loss at epoch 485: 0.0977\n",
      "\n",
      "Start of epoch 486\n",
      "Training loss at epoch 486: 0.0977\n",
      "\n",
      "Start of epoch 487\n",
      "Training loss at epoch 487: 0.0977\n",
      "\n",
      "Start of epoch 488\n",
      "Training loss at epoch 488: 0.0977\n",
      "\n",
      "Start of epoch 489\n",
      "Training loss at epoch 489: 0.0976\n",
      "\n",
      "Start of epoch 490\n",
      "Training loss at epoch 490: 0.0976\n",
      "\n",
      "Start of epoch 491\n",
      "Training loss at epoch 491: 0.0976\n",
      "\n",
      "Start of epoch 492\n",
      "Training loss at epoch 492: 0.0976\n",
      "\n",
      "Start of epoch 493\n",
      "Training loss at epoch 493: 0.0975\n",
      "\n",
      "Start of epoch 494\n",
      "Training loss at epoch 494: 0.0975\n",
      "\n",
      "Start of epoch 495\n",
      "Training loss at epoch 495: 0.0975\n",
      "\n",
      "Start of epoch 496\n",
      "Training loss at epoch 496: 0.0975\n",
      "\n",
      "Start of epoch 497\n",
      "Training loss at epoch 497: 0.0974\n",
      "\n",
      "Start of epoch 498\n",
      "Training loss at epoch 498: 0.0974\n",
      "\n",
      "Start of epoch 499\n",
      "Training loss at epoch 499: 0.0974\n",
      "[<tf.Variable 'parameters:0' shape=(75,) dtype=float32, numpy=\n",
      "array([4.5316176 , 4.5080147 , 1.8379726 , 5.742067  , 1.5183752 ,\n",
      "       0.8148464 , 0.8328812 , 6.0291715 , 1.1075716 , 4.3511133 ,\n",
      "       3.0309806 , 1.4796481 , 4.2446585 , 2.4395852 , 4.576817  ,\n",
      "       5.4449353 , 2.4281793 , 5.051676  , 0.30929264, 4.0702024 ,\n",
      "       2.1769674 , 6.1088862 , 1.5221    , 4.6466603 , 5.3002095 ,\n",
      "       2.3265157 , 3.2233295 , 3.031818  , 0.8179878 , 0.4737791 ,\n",
      "       2.974433  , 5.597613  , 4.624622  , 5.0227504 , 5.3530793 ,\n",
      "       0.64104295, 3.103599  , 4.328065  , 5.0891156 , 4.8376274 ,\n",
      "       1.5648409 , 3.0642495 , 5.3642793 , 0.44520348, 2.537614  ,\n",
      "       0.97719747, 5.156811  , 4.1227584 , 5.004732  , 1.6154324 ,\n",
      "       5.6541038 , 1.3032126 , 4.2931275 , 1.1387815 , 6.2210383 ,\n",
      "       1.8354732 , 1.780578  , 1.9298251 , 3.1566465 , 5.382514  ,\n",
      "       2.128737  , 5.424984  , 4.6536665 , 5.1359477 , 2.91244   ,\n",
      "       1.033166  , 3.7359931 , 2.254101  , 0.93459505, 3.9509122 ,\n",
      "       3.4268    , 0.6792614 , 0.8768805 , 0.5343616 , 4.999892  ],\n",
      "      dtype=float32)>]\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.0741\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 0.9569\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.9021\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.8641\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.8261\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.7789\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.7259\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.6750\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.6319\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.6005\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.5793\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.5617\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.5444\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.5281\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.5141\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.5021\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.4911\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.4815\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.4742\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.4693\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.4651\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.4598\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.4527\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.4447\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.4369\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.4301\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.4238\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.4177\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.4115\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.4054\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.3994\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.3940\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.3893\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.3855\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.3824\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.3796\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.3772\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.3750\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.3730\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.3710\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.3689\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss at epoch 41: 0.3665\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss at epoch 42: 0.3640\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss at epoch 43: 0.3613\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss at epoch 44: 0.3584\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss at epoch 45: 0.3555\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss at epoch 46: 0.3525\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss at epoch 47: 0.3498\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss at epoch 48: 0.3474\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss at epoch 49: 0.3452\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss at epoch 50: 0.3432\n",
      "\n",
      "Start of epoch 51\n",
      "Training loss at epoch 51: 0.3412\n",
      "\n",
      "Start of epoch 52\n",
      "Training loss at epoch 52: 0.3394\n",
      "\n",
      "Start of epoch 53\n",
      "Training loss at epoch 53: 0.3376\n",
      "\n",
      "Start of epoch 54\n",
      "Training loss at epoch 54: 0.3360\n",
      "\n",
      "Start of epoch 55\n",
      "Training loss at epoch 55: 0.3344\n",
      "\n",
      "Start of epoch 56\n",
      "Training loss at epoch 56: 0.3327\n",
      "\n",
      "Start of epoch 57\n",
      "Training loss at epoch 57: 0.3311\n",
      "\n",
      "Start of epoch 58\n",
      "Training loss at epoch 58: 0.3294\n",
      "\n",
      "Start of epoch 59\n",
      "Training loss at epoch 59: 0.3277\n",
      "\n",
      "Start of epoch 60\n",
      "Training loss at epoch 60: 0.3261\n",
      "\n",
      "Start of epoch 61\n",
      "Training loss at epoch 61: 0.3246\n",
      "\n",
      "Start of epoch 62\n",
      "Training loss at epoch 62: 0.3231\n",
      "\n",
      "Start of epoch 63\n",
      "Training loss at epoch 63: 0.3218\n",
      "\n",
      "Start of epoch 64\n",
      "Training loss at epoch 64: 0.3206\n",
      "\n",
      "Start of epoch 65\n",
      "Training loss at epoch 65: 0.3195\n",
      "\n",
      "Start of epoch 66\n",
      "Training loss at epoch 66: 0.3184\n",
      "\n",
      "Start of epoch 67\n",
      "Training loss at epoch 67: 0.3173\n",
      "\n",
      "Start of epoch 68\n",
      "Training loss at epoch 68: 0.3163\n",
      "\n",
      "Start of epoch 69\n",
      "Training loss at epoch 69: 0.3152\n",
      "\n",
      "Start of epoch 70\n",
      "Training loss at epoch 70: 0.3140\n",
      "\n",
      "Start of epoch 71\n",
      "Training loss at epoch 71: 0.3129\n",
      "\n",
      "Start of epoch 72\n",
      "Training loss at epoch 72: 0.3116\n",
      "\n",
      "Start of epoch 73\n",
      "Training loss at epoch 73: 0.3104\n",
      "\n",
      "Start of epoch 74\n",
      "Training loss at epoch 74: 0.3091\n",
      "\n",
      "Start of epoch 75\n",
      "Training loss at epoch 75: 0.3078\n",
      "\n",
      "Start of epoch 76\n",
      "Training loss at epoch 76: 0.3066\n",
      "\n",
      "Start of epoch 77\n",
      "Training loss at epoch 77: 0.3053\n",
      "\n",
      "Start of epoch 78\n",
      "Training loss at epoch 78: 0.3040\n",
      "\n",
      "Start of epoch 79\n",
      "Training loss at epoch 79: 0.3027\n",
      "\n",
      "Start of epoch 80\n",
      "Training loss at epoch 80: 0.3014\n",
      "\n",
      "Start of epoch 81\n",
      "Training loss at epoch 81: 0.3001\n",
      "\n",
      "Start of epoch 82\n",
      "Training loss at epoch 82: 0.2989\n",
      "\n",
      "Start of epoch 83\n",
      "Training loss at epoch 83: 0.2978\n",
      "\n",
      "Start of epoch 84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 84: 0.2967\n",
      "\n",
      "Start of epoch 85\n",
      "Training loss at epoch 85: 0.2957\n",
      "\n",
      "Start of epoch 86\n",
      "Training loss at epoch 86: 0.2946\n",
      "\n",
      "Start of epoch 87\n",
      "Training loss at epoch 87: 0.2936\n",
      "\n",
      "Start of epoch 88\n",
      "Training loss at epoch 88: 0.2926\n",
      "\n",
      "Start of epoch 89\n",
      "Training loss at epoch 89: 0.2916\n",
      "\n",
      "Start of epoch 90\n",
      "Training loss at epoch 90: 0.2907\n",
      "\n",
      "Start of epoch 91\n",
      "Training loss at epoch 91: 0.2897\n",
      "\n",
      "Start of epoch 92\n",
      "Training loss at epoch 92: 0.2887\n",
      "\n",
      "Start of epoch 93\n",
      "Training loss at epoch 93: 0.2877\n",
      "\n",
      "Start of epoch 94\n",
      "Training loss at epoch 94: 0.2867\n",
      "\n",
      "Start of epoch 95\n",
      "Training loss at epoch 95: 0.2857\n",
      "\n",
      "Start of epoch 96\n",
      "Training loss at epoch 96: 0.2847\n",
      "\n",
      "Start of epoch 97\n",
      "Training loss at epoch 97: 0.2836\n",
      "\n",
      "Start of epoch 98\n",
      "Training loss at epoch 98: 0.2825\n",
      "\n",
      "Start of epoch 99\n",
      "Training loss at epoch 99: 0.2814\n",
      "\n",
      "Start of epoch 100\n",
      "Training loss at epoch 100: 0.2803\n",
      "\n",
      "Start of epoch 101\n",
      "Training loss at epoch 101: 0.2791\n",
      "\n",
      "Start of epoch 102\n",
      "Training loss at epoch 102: 0.2779\n",
      "\n",
      "Start of epoch 103\n",
      "Training loss at epoch 103: 0.2767\n",
      "\n",
      "Start of epoch 104\n",
      "Training loss at epoch 104: 0.2755\n",
      "\n",
      "Start of epoch 105\n",
      "Training loss at epoch 105: 0.2742\n",
      "\n",
      "Start of epoch 106\n",
      "Training loss at epoch 106: 0.2730\n",
      "\n",
      "Start of epoch 107\n",
      "Training loss at epoch 107: 0.2717\n",
      "\n",
      "Start of epoch 108\n",
      "Training loss at epoch 108: 0.2704\n",
      "\n",
      "Start of epoch 109\n",
      "Training loss at epoch 109: 0.2691\n",
      "\n",
      "Start of epoch 110\n",
      "Training loss at epoch 110: 0.2678\n",
      "\n",
      "Start of epoch 111\n",
      "Training loss at epoch 111: 0.2665\n",
      "\n",
      "Start of epoch 112\n",
      "Training loss at epoch 112: 0.2652\n",
      "\n",
      "Start of epoch 113\n",
      "Training loss at epoch 113: 0.2640\n",
      "\n",
      "Start of epoch 114\n",
      "Training loss at epoch 114: 0.2627\n",
      "\n",
      "Start of epoch 115\n",
      "Training loss at epoch 115: 0.2614\n",
      "\n",
      "Start of epoch 116\n",
      "Training loss at epoch 116: 0.2601\n",
      "\n",
      "Start of epoch 117\n",
      "Training loss at epoch 117: 0.2589\n",
      "\n",
      "Start of epoch 118\n",
      "Training loss at epoch 118: 0.2577\n",
      "\n",
      "Start of epoch 119\n",
      "Training loss at epoch 119: 0.2564\n",
      "\n",
      "Start of epoch 120\n",
      "Training loss at epoch 120: 0.2552\n",
      "\n",
      "Start of epoch 121\n",
      "Training loss at epoch 121: 0.2540\n",
      "\n",
      "Start of epoch 122\n",
      "Training loss at epoch 122: 0.2528\n",
      "\n",
      "Start of epoch 123\n",
      "Training loss at epoch 123: 0.2516\n",
      "\n",
      "Start of epoch 124\n",
      "Training loss at epoch 124: 0.2505\n",
      "\n",
      "Start of epoch 125\n",
      "Training loss at epoch 125: 0.2493\n",
      "\n",
      "Start of epoch 126\n",
      "Training loss at epoch 126: 0.2483\n",
      "\n",
      "Start of epoch 127\n",
      "Training loss at epoch 127: 0.2472\n",
      "\n",
      "Start of epoch 128\n",
      "Training loss at epoch 128: 0.2462\n",
      "\n",
      "Start of epoch 129\n",
      "Training loss at epoch 129: 0.2452\n",
      "\n",
      "Start of epoch 130\n",
      "Training loss at epoch 130: 0.2442\n",
      "\n",
      "Start of epoch 131\n",
      "Training loss at epoch 131: 0.2433\n",
      "\n",
      "Start of epoch 132\n",
      "Training loss at epoch 132: 0.2424\n",
      "\n",
      "Start of epoch 133\n",
      "Training loss at epoch 133: 0.2415\n",
      "\n",
      "Start of epoch 134\n",
      "Training loss at epoch 134: 0.2407\n",
      "\n",
      "Start of epoch 135\n",
      "Training loss at epoch 135: 0.2399\n",
      "\n",
      "Start of epoch 136\n",
      "Training loss at epoch 136: 0.2392\n",
      "\n",
      "Start of epoch 137\n",
      "Training loss at epoch 137: 0.2384\n",
      "\n",
      "Start of epoch 138\n",
      "Training loss at epoch 138: 0.2377\n",
      "\n",
      "Start of epoch 139\n",
      "Training loss at epoch 139: 0.2371\n",
      "\n",
      "Start of epoch 140\n",
      "Training loss at epoch 140: 0.2364\n",
      "\n",
      "Start of epoch 141\n",
      "Training loss at epoch 141: 0.2358\n",
      "\n",
      "Start of epoch 142\n",
      "Training loss at epoch 142: 0.2352\n",
      "\n",
      "Start of epoch 143\n",
      "Training loss at epoch 143: 0.2347\n",
      "\n",
      "Start of epoch 144\n",
      "Training loss at epoch 144: 0.2341\n",
      "\n",
      "Start of epoch 145\n",
      "Training loss at epoch 145: 0.2335\n",
      "\n",
      "Start of epoch 146\n",
      "Training loss at epoch 146: 0.2330\n",
      "\n",
      "Start of epoch 147\n",
      "Training loss at epoch 147: 0.2324\n",
      "\n",
      "Start of epoch 148\n",
      "Training loss at epoch 148: 0.2318\n",
      "\n",
      "Start of epoch 149\n",
      "Training loss at epoch 149: 0.2312\n",
      "\n",
      "Start of epoch 150\n",
      "Training loss at epoch 150: 0.2307\n",
      "\n",
      "Start of epoch 151\n",
      "Training loss at epoch 151: 0.2301\n",
      "\n",
      "Start of epoch 152\n",
      "Training loss at epoch 152: 0.2295\n",
      "\n",
      "Start of epoch 153\n",
      "Training loss at epoch 153: 0.2289\n",
      "\n",
      "Start of epoch 154\n",
      "Training loss at epoch 154: 0.2283\n",
      "\n",
      "Start of epoch 155\n",
      "Training loss at epoch 155: 0.2277\n",
      "\n",
      "Start of epoch 156\n",
      "Training loss at epoch 156: 0.2270\n",
      "\n",
      "Start of epoch 157\n",
      "Training loss at epoch 157: 0.2264\n",
      "\n",
      "Start of epoch 158\n",
      "Training loss at epoch 158: 0.2258\n",
      "\n",
      "Start of epoch 159\n",
      "Training loss at epoch 159: 0.2253\n",
      "\n",
      "Start of epoch 160\n",
      "Training loss at epoch 160: 0.2247\n",
      "\n",
      "Start of epoch 161\n",
      "Training loss at epoch 161: 0.2241\n",
      "\n",
      "Start of epoch 162\n",
      "Training loss at epoch 162: 0.2235\n",
      "\n",
      "Start of epoch 163\n",
      "Training loss at epoch 163: 0.2229\n",
      "\n",
      "Start of epoch 164\n",
      "Training loss at epoch 164: 0.2223\n",
      "\n",
      "Start of epoch 165\n",
      "Training loss at epoch 165: 0.2218\n",
      "\n",
      "Start of epoch 166\n",
      "Training loss at epoch 166: 0.2212\n",
      "\n",
      "Start of epoch 167\n",
      "Training loss at epoch 167: 0.2206\n",
      "\n",
      "Start of epoch 168\n",
      "Training loss at epoch 168: 0.2200\n",
      "\n",
      "Start of epoch 169\n",
      "Training loss at epoch 169: 0.2194\n",
      "\n",
      "Start of epoch 170\n",
      "Training loss at epoch 170: 0.2188\n",
      "\n",
      "Start of epoch 171\n",
      "Training loss at epoch 171: 0.2182\n",
      "\n",
      "Start of epoch 172\n",
      "Training loss at epoch 172: 0.2176\n",
      "\n",
      "Start of epoch 173\n",
      "Training loss at epoch 173: 0.2170\n",
      "\n",
      "Start of epoch 174\n",
      "Training loss at epoch 174: 0.2164\n",
      "\n",
      "Start of epoch 175\n",
      "Training loss at epoch 175: 0.2158\n",
      "\n",
      "Start of epoch 176\n",
      "Training loss at epoch 176: 0.2152\n",
      "\n",
      "Start of epoch 177\n",
      "Training loss at epoch 177: 0.2145\n",
      "\n",
      "Start of epoch 178\n",
      "Training loss at epoch 178: 0.2139\n",
      "\n",
      "Start of epoch 179\n",
      "Training loss at epoch 179: 0.2132\n",
      "\n",
      "Start of epoch 180\n",
      "Training loss at epoch 180: 0.2126\n",
      "\n",
      "Start of epoch 181\n",
      "Training loss at epoch 181: 0.2119\n",
      "\n",
      "Start of epoch 182\n",
      "Training loss at epoch 182: 0.2112\n",
      "\n",
      "Start of epoch 183\n",
      "Training loss at epoch 183: 0.2104\n",
      "\n",
      "Start of epoch 184\n",
      "Training loss at epoch 184: 0.2097\n",
      "\n",
      "Start of epoch 185\n",
      "Training loss at epoch 185: 0.2090\n",
      "\n",
      "Start of epoch 186\n",
      "Training loss at epoch 186: 0.2082\n",
      "\n",
      "Start of epoch 187\n",
      "Training loss at epoch 187: 0.2074\n",
      "\n",
      "Start of epoch 188\n",
      "Training loss at epoch 188: 0.2066\n",
      "\n",
      "Start of epoch 189\n",
      "Training loss at epoch 189: 0.2058\n",
      "\n",
      "Start of epoch 190\n",
      "Training loss at epoch 190: 0.2050\n",
      "\n",
      "Start of epoch 191\n",
      "Training loss at epoch 191: 0.2042\n",
      "\n",
      "Start of epoch 192\n",
      "Training loss at epoch 192: 0.2033\n",
      "\n",
      "Start of epoch 193\n",
      "Training loss at epoch 193: 0.2025\n",
      "\n",
      "Start of epoch 194\n",
      "Training loss at epoch 194: 0.2016\n",
      "\n",
      "Start of epoch 195\n",
      "Training loss at epoch 195: 0.2007\n",
      "\n",
      "Start of epoch 196\n",
      "Training loss at epoch 196: 0.1999\n",
      "\n",
      "Start of epoch 197\n",
      "Training loss at epoch 197: 0.1991\n",
      "\n",
      "Start of epoch 198\n",
      "Training loss at epoch 198: 0.1982\n",
      "\n",
      "Start of epoch 199\n",
      "Training loss at epoch 199: 0.1974\n",
      "\n",
      "Start of epoch 200\n",
      "Training loss at epoch 200: 0.1966\n",
      "\n",
      "Start of epoch 201\n",
      "Training loss at epoch 201: 0.1959\n",
      "\n",
      "Start of epoch 202\n",
      "Training loss at epoch 202: 0.1951\n",
      "\n",
      "Start of epoch 203\n",
      "Training loss at epoch 203: 0.1944\n",
      "\n",
      "Start of epoch 204\n",
      "Training loss at epoch 204: 0.1937\n",
      "\n",
      "Start of epoch 205\n",
      "Training loss at epoch 205: 0.1931\n",
      "\n",
      "Start of epoch 206\n",
      "Training loss at epoch 206: 0.1925\n",
      "\n",
      "Start of epoch 207\n",
      "Training loss at epoch 207: 0.1919\n",
      "\n",
      "Start of epoch 208\n",
      "Training loss at epoch 208: 0.1913\n",
      "\n",
      "Start of epoch 209\n",
      "Training loss at epoch 209: 0.1907\n",
      "\n",
      "Start of epoch 210\n",
      "Training loss at epoch 210: 0.1902\n",
      "\n",
      "Start of epoch 211\n",
      "Training loss at epoch 211: 0.1896\n",
      "\n",
      "Start of epoch 212\n",
      "Training loss at epoch 212: 0.1891\n",
      "\n",
      "Start of epoch 213\n",
      "Training loss at epoch 213: 0.1885\n",
      "\n",
      "Start of epoch 214\n",
      "Training loss at epoch 214: 0.1880\n",
      "\n",
      "Start of epoch 215\n",
      "Training loss at epoch 215: 0.1874\n",
      "\n",
      "Start of epoch 216\n",
      "Training loss at epoch 216: 0.1868\n",
      "\n",
      "Start of epoch 217\n",
      "Training loss at epoch 217: 0.1863\n",
      "\n",
      "Start of epoch 218\n",
      "Training loss at epoch 218: 0.1857\n",
      "\n",
      "Start of epoch 219\n",
      "Training loss at epoch 219: 0.1851\n",
      "\n",
      "Start of epoch 220\n",
      "Training loss at epoch 220: 0.1845\n",
      "\n",
      "Start of epoch 221\n",
      "Training loss at epoch 221: 0.1839\n",
      "\n",
      "Start of epoch 222\n",
      "Training loss at epoch 222: 0.1833\n",
      "\n",
      "Start of epoch 223\n",
      "Training loss at epoch 223: 0.1827\n",
      "\n",
      "Start of epoch 224\n",
      "Training loss at epoch 224: 0.1821\n",
      "\n",
      "Start of epoch 225\n",
      "Training loss at epoch 225: 0.1815\n",
      "\n",
      "Start of epoch 226\n",
      "Training loss at epoch 226: 0.1808\n",
      "\n",
      "Start of epoch 227\n",
      "Training loss at epoch 227: 0.1802\n",
      "\n",
      "Start of epoch 228\n",
      "Training loss at epoch 228: 0.1796\n",
      "\n",
      "Start of epoch 229\n",
      "Training loss at epoch 229: 0.1790\n",
      "\n",
      "Start of epoch 230\n",
      "Training loss at epoch 230: 0.1784\n",
      "\n",
      "Start of epoch 231\n",
      "Training loss at epoch 231: 0.1778\n",
      "\n",
      "Start of epoch 232\n",
      "Training loss at epoch 232: 0.1771\n",
      "\n",
      "Start of epoch 233\n",
      "Training loss at epoch 233: 0.1765\n",
      "\n",
      "Start of epoch 234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 234: 0.1759\n",
      "\n",
      "Start of epoch 235\n",
      "Training loss at epoch 235: 0.1753\n",
      "\n",
      "Start of epoch 236\n",
      "Training loss at epoch 236: 0.1747\n",
      "\n",
      "Start of epoch 237\n",
      "Training loss at epoch 237: 0.1741\n",
      "\n",
      "Start of epoch 238\n",
      "Training loss at epoch 238: 0.1735\n",
      "\n",
      "Start of epoch 239\n",
      "Training loss at epoch 239: 0.1729\n",
      "\n",
      "Start of epoch 240\n",
      "Training loss at epoch 240: 0.1722\n",
      "\n",
      "Start of epoch 241\n",
      "Training loss at epoch 241: 0.1716\n",
      "\n",
      "Start of epoch 242\n",
      "Training loss at epoch 242: 0.1710\n",
      "\n",
      "Start of epoch 243\n",
      "Training loss at epoch 243: 0.1704\n",
      "\n",
      "Start of epoch 244\n",
      "Training loss at epoch 244: 0.1697\n",
      "\n",
      "Start of epoch 245\n",
      "Training loss at epoch 245: 0.1690\n",
      "\n",
      "Start of epoch 246\n",
      "Training loss at epoch 246: 0.1683\n",
      "\n",
      "Start of epoch 247\n",
      "Training loss at epoch 247: 0.1676\n",
      "\n",
      "Start of epoch 248\n",
      "Training loss at epoch 248: 0.1668\n",
      "\n",
      "Start of epoch 249\n",
      "Training loss at epoch 249: 0.1660\n",
      "\n",
      "Start of epoch 250\n",
      "Training loss at epoch 250: 0.1652\n",
      "\n",
      "Start of epoch 251\n",
      "Training loss at epoch 251: 0.1643\n",
      "\n",
      "Start of epoch 252\n",
      "Training loss at epoch 252: 0.1633\n",
      "\n",
      "Start of epoch 253\n",
      "Training loss at epoch 253: 0.1623\n",
      "\n",
      "Start of epoch 254\n",
      "Training loss at epoch 254: 0.1611\n",
      "\n",
      "Start of epoch 255\n",
      "Training loss at epoch 255: 0.1599\n",
      "\n",
      "Start of epoch 256\n",
      "Training loss at epoch 256: 0.1585\n",
      "\n",
      "Start of epoch 257\n",
      "Training loss at epoch 257: 0.1570\n",
      "\n",
      "Start of epoch 258\n",
      "Training loss at epoch 258: 0.1554\n",
      "\n",
      "Start of epoch 259\n",
      "Training loss at epoch 259: 0.1536\n",
      "\n",
      "Start of epoch 260\n",
      "Training loss at epoch 260: 0.1517\n",
      "\n",
      "Start of epoch 261\n",
      "Training loss at epoch 261: 0.1495\n",
      "\n",
      "Start of epoch 262\n",
      "Training loss at epoch 262: 0.1472\n",
      "\n",
      "Start of epoch 263\n",
      "Training loss at epoch 263: 0.1448\n",
      "\n",
      "Start of epoch 264\n",
      "Training loss at epoch 264: 0.1423\n",
      "\n",
      "Start of epoch 265\n",
      "Training loss at epoch 265: 0.1396\n",
      "\n",
      "Start of epoch 266\n",
      "Training loss at epoch 266: 0.1370\n",
      "\n",
      "Start of epoch 267\n",
      "Training loss at epoch 267: 0.1343\n",
      "\n",
      "Start of epoch 268\n",
      "Training loss at epoch 268: 0.1317\n",
      "\n",
      "Start of epoch 269\n",
      "Training loss at epoch 269: 0.1292\n",
      "\n",
      "Start of epoch 270\n",
      "Training loss at epoch 270: 0.1268\n",
      "\n",
      "Start of epoch 271\n",
      "Training loss at epoch 271: 0.1244\n",
      "\n",
      "Start of epoch 272\n",
      "Training loss at epoch 272: 0.1220\n",
      "\n",
      "Start of epoch 273\n",
      "Training loss at epoch 273: 0.1198\n",
      "\n",
      "Start of epoch 274\n",
      "Training loss at epoch 274: 0.1176\n",
      "\n",
      "Start of epoch 275\n",
      "Training loss at epoch 275: 0.1156\n",
      "\n",
      "Start of epoch 276\n",
      "Training loss at epoch 276: 0.1138\n",
      "\n",
      "Start of epoch 277\n",
      "Training loss at epoch 277: 0.1122\n",
      "\n",
      "Start of epoch 278\n",
      "Training loss at epoch 278: 0.1106\n",
      "\n",
      "Start of epoch 279\n",
      "Training loss at epoch 279: 0.1091\n",
      "\n",
      "Start of epoch 280\n",
      "Training loss at epoch 280: 0.1077\n",
      "\n",
      "Start of epoch 281\n",
      "Training loss at epoch 281: 0.1061\n",
      "\n",
      "Start of epoch 282\n",
      "Training loss at epoch 282: 0.1045\n",
      "\n",
      "Start of epoch 283\n",
      "Training loss at epoch 283: 0.1029\n",
      "\n",
      "Start of epoch 284\n",
      "Training loss at epoch 284: 0.1012\n",
      "\n",
      "Start of epoch 285\n",
      "Training loss at epoch 285: 0.0996\n",
      "\n",
      "Start of epoch 286\n",
      "Training loss at epoch 286: 0.0979\n",
      "\n",
      "Start of epoch 287\n",
      "Training loss at epoch 287: 0.0962\n",
      "\n",
      "Start of epoch 288\n",
      "Training loss at epoch 288: 0.0946\n",
      "\n",
      "Start of epoch 289\n",
      "Training loss at epoch 289: 0.0929\n",
      "\n",
      "Start of epoch 290\n",
      "Training loss at epoch 290: 0.0912\n",
      "\n",
      "Start of epoch 291\n",
      "Training loss at epoch 291: 0.0896\n",
      "\n",
      "Start of epoch 292\n",
      "Training loss at epoch 292: 0.0880\n",
      "\n",
      "Start of epoch 293\n",
      "Training loss at epoch 293: 0.0865\n",
      "\n",
      "Start of epoch 294\n",
      "Training loss at epoch 294: 0.0851\n",
      "\n",
      "Start of epoch 295\n",
      "Training loss at epoch 295: 0.0837\n",
      "\n",
      "Start of epoch 296\n",
      "Training loss at epoch 296: 0.0823\n",
      "\n",
      "Start of epoch 297\n",
      "Training loss at epoch 297: 0.0810\n",
      "\n",
      "Start of epoch 298\n",
      "Training loss at epoch 298: 0.0798\n",
      "\n",
      "Start of epoch 299\n",
      "Training loss at epoch 299: 0.0786\n",
      "\n",
      "Start of epoch 300\n",
      "Training loss at epoch 300: 0.0775\n",
      "\n",
      "Start of epoch 301\n",
      "Training loss at epoch 301: 0.0764\n",
      "\n",
      "Start of epoch 302\n",
      "Training loss at epoch 302: 0.0755\n",
      "\n",
      "Start of epoch 303\n",
      "Training loss at epoch 303: 0.0746\n",
      "\n",
      "Start of epoch 304\n",
      "Training loss at epoch 304: 0.0737\n",
      "\n",
      "Start of epoch 305\n",
      "Training loss at epoch 305: 0.0729\n",
      "\n",
      "Start of epoch 306\n",
      "Training loss at epoch 306: 0.0721\n",
      "\n",
      "Start of epoch 307\n",
      "Training loss at epoch 307: 0.0714\n",
      "\n",
      "Start of epoch 308\n",
      "Training loss at epoch 308: 0.0707\n",
      "\n",
      "Start of epoch 309\n",
      "Training loss at epoch 309: 0.0700\n",
      "\n",
      "Start of epoch 310\n",
      "Training loss at epoch 310: 0.0694\n",
      "\n",
      "Start of epoch 311\n",
      "Training loss at epoch 311: 0.0688\n",
      "\n",
      "Start of epoch 312\n",
      "Training loss at epoch 312: 0.0681\n",
      "\n",
      "Start of epoch 313\n",
      "Training loss at epoch 313: 0.0675\n",
      "\n",
      "Start of epoch 314\n",
      "Training loss at epoch 314: 0.0669\n",
      "\n",
      "Start of epoch 315\n",
      "Training loss at epoch 315: 0.0663\n",
      "\n",
      "Start of epoch 316\n",
      "Training loss at epoch 316: 0.0657\n",
      "\n",
      "Start of epoch 317\n",
      "Training loss at epoch 317: 0.0651\n",
      "\n",
      "Start of epoch 318\n",
      "Training loss at epoch 318: 0.0645\n",
      "\n",
      "Start of epoch 319\n",
      "Training loss at epoch 319: 0.0639\n",
      "\n",
      "Start of epoch 320\n",
      "Training loss at epoch 320: 0.0633\n",
      "\n",
      "Start of epoch 321\n",
      "Training loss at epoch 321: 0.0627\n",
      "\n",
      "Start of epoch 322\n",
      "Training loss at epoch 322: 0.0620\n",
      "\n",
      "Start of epoch 323\n",
      "Training loss at epoch 323: 0.0614\n",
      "\n",
      "Start of epoch 324\n",
      "Training loss at epoch 324: 0.0607\n",
      "\n",
      "Start of epoch 325\n",
      "Training loss at epoch 325: 0.0600\n",
      "\n",
      "Start of epoch 326\n",
      "Training loss at epoch 326: 0.0593\n",
      "\n",
      "Start of epoch 327\n",
      "Training loss at epoch 327: 0.0585\n",
      "\n",
      "Start of epoch 328\n",
      "Training loss at epoch 328: 0.0577\n",
      "\n",
      "Start of epoch 329\n",
      "Training loss at epoch 329: 0.0568\n",
      "\n",
      "Start of epoch 330\n",
      "Training loss at epoch 330: 0.0558\n",
      "\n",
      "Start of epoch 331\n",
      "Training loss at epoch 331: 0.0547\n",
      "\n",
      "Start of epoch 332\n",
      "Training loss at epoch 332: 0.0536\n",
      "\n",
      "Start of epoch 333\n",
      "Training loss at epoch 333: 0.0523\n",
      "\n",
      "Start of epoch 334\n",
      "Training loss at epoch 334: 0.0509\n",
      "\n",
      "Start of epoch 335\n",
      "Training loss at epoch 335: 0.0494\n",
      "\n",
      "Start of epoch 336\n",
      "Training loss at epoch 336: 0.0479\n",
      "\n",
      "Start of epoch 337\n",
      "Training loss at epoch 337: 0.0463\n",
      "\n",
      "Start of epoch 338\n",
      "Training loss at epoch 338: 0.0446\n",
      "\n",
      "Start of epoch 339\n",
      "Training loss at epoch 339: 0.0430\n",
      "\n",
      "Start of epoch 340\n",
      "Training loss at epoch 340: 0.0414\n",
      "\n",
      "Start of epoch 341\n",
      "Training loss at epoch 341: 0.0398\n",
      "\n",
      "Start of epoch 342\n",
      "Training loss at epoch 342: 0.0384\n",
      "\n",
      "Start of epoch 343\n",
      "Training loss at epoch 343: 0.0370\n",
      "\n",
      "Start of epoch 344\n",
      "Training loss at epoch 344: 0.0358\n",
      "\n",
      "Start of epoch 345\n",
      "Training loss at epoch 345: 0.0346\n",
      "\n",
      "Start of epoch 346\n",
      "Training loss at epoch 346: 0.0336\n",
      "\n",
      "Start of epoch 347\n",
      "Training loss at epoch 347: 0.0327\n",
      "\n",
      "Start of epoch 348\n",
      "Training loss at epoch 348: 0.0318\n",
      "\n",
      "Start of epoch 349\n",
      "Training loss at epoch 349: 0.0309\n",
      "\n",
      "Start of epoch 350\n",
      "Training loss at epoch 350: 0.0301\n",
      "\n",
      "Start of epoch 351\n",
      "Training loss at epoch 351: 0.0294\n",
      "\n",
      "Start of epoch 352\n",
      "Training loss at epoch 352: 0.0286\n",
      "\n",
      "Start of epoch 353\n",
      "Training loss at epoch 353: 0.0280\n",
      "\n",
      "Start of epoch 354\n",
      "Training loss at epoch 354: 0.0274\n",
      "\n",
      "Start of epoch 355\n",
      "Training loss at epoch 355: 0.0269\n",
      "\n",
      "Start of epoch 356\n",
      "Training loss at epoch 356: 0.0264\n",
      "\n",
      "Start of epoch 357\n",
      "Training loss at epoch 357: 0.0260\n",
      "\n",
      "Start of epoch 358\n",
      "Training loss at epoch 358: 0.0256\n",
      "\n",
      "Start of epoch 359\n",
      "Training loss at epoch 359: 0.0252\n",
      "\n",
      "Start of epoch 360\n",
      "Training loss at epoch 360: 0.0249\n",
      "\n",
      "Start of epoch 361\n",
      "Training loss at epoch 361: 0.0246\n",
      "\n",
      "Start of epoch 362\n",
      "Training loss at epoch 362: 0.0243\n",
      "\n",
      "Start of epoch 363\n",
      "Training loss at epoch 363: 0.0240\n",
      "\n",
      "Start of epoch 364\n",
      "Training loss at epoch 364: 0.0237\n",
      "\n",
      "Start of epoch 365\n",
      "Training loss at epoch 365: 0.0235\n",
      "\n",
      "Start of epoch 366\n",
      "Training loss at epoch 366: 0.0232\n",
      "\n",
      "Start of epoch 367\n",
      "Training loss at epoch 367: 0.0230\n",
      "\n",
      "Start of epoch 368\n",
      "Training loss at epoch 368: 0.0227\n",
      "\n",
      "Start of epoch 369\n",
      "Training loss at epoch 369: 0.0224\n",
      "\n",
      "Start of epoch 370\n",
      "Training loss at epoch 370: 0.0222\n",
      "\n",
      "Start of epoch 371\n",
      "Training loss at epoch 371: 0.0219\n",
      "\n",
      "Start of epoch 372\n",
      "Training loss at epoch 372: 0.0216\n",
      "\n",
      "Start of epoch 373\n",
      "Training loss at epoch 373: 0.0213\n",
      "\n",
      "Start of epoch 374\n",
      "Training loss at epoch 374: 0.0210\n",
      "\n",
      "Start of epoch 375\n",
      "Training loss at epoch 375: 0.0207\n",
      "\n",
      "Start of epoch 376\n",
      "Training loss at epoch 376: 0.0205\n",
      "\n",
      "Start of epoch 377\n",
      "Training loss at epoch 377: 0.0202\n",
      "\n",
      "Start of epoch 378\n",
      "Training loss at epoch 378: 0.0199\n",
      "\n",
      "Start of epoch 379\n",
      "Training loss at epoch 379: 0.0196\n",
      "\n",
      "Start of epoch 380\n",
      "Training loss at epoch 380: 0.0193\n",
      "\n",
      "Start of epoch 381\n",
      "Training loss at epoch 381: 0.0190\n",
      "\n",
      "Start of epoch 382\n",
      "Training loss at epoch 382: 0.0187\n",
      "\n",
      "Start of epoch 383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 383: 0.0184\n",
      "\n",
      "Start of epoch 384\n",
      "Training loss at epoch 384: 0.0182\n",
      "\n",
      "Start of epoch 385\n",
      "Training loss at epoch 385: 0.0179\n",
      "\n",
      "Start of epoch 386\n",
      "Training loss at epoch 386: 0.0176\n",
      "\n",
      "Start of epoch 387\n",
      "Training loss at epoch 387: 0.0173\n",
      "\n",
      "Start of epoch 388\n",
      "Training loss at epoch 388: 0.0170\n",
      "\n",
      "Start of epoch 389\n",
      "Training loss at epoch 389: 0.0168\n",
      "\n",
      "Start of epoch 390\n",
      "Training loss at epoch 390: 0.0165\n",
      "\n",
      "Start of epoch 391\n",
      "Training loss at epoch 391: 0.0162\n",
      "\n",
      "Start of epoch 392\n",
      "Training loss at epoch 392: 0.0160\n",
      "\n",
      "Start of epoch 393\n",
      "Training loss at epoch 393: 0.0157\n",
      "\n",
      "Start of epoch 394\n",
      "Training loss at epoch 394: 0.0155\n",
      "\n",
      "Start of epoch 395\n",
      "Training loss at epoch 395: 0.0152\n",
      "\n",
      "Start of epoch 396\n",
      "Training loss at epoch 396: 0.0149\n",
      "\n",
      "Start of epoch 397\n",
      "Training loss at epoch 397: 0.0147\n",
      "\n",
      "Start of epoch 398\n",
      "Training loss at epoch 398: 0.0144\n",
      "\n",
      "Start of epoch 399\n",
      "Training loss at epoch 399: 0.0142\n",
      "\n",
      "Start of epoch 400\n",
      "Training loss at epoch 400: 0.0139\n",
      "\n",
      "Start of epoch 401\n",
      "Training loss at epoch 401: 0.0137\n",
      "\n",
      "Start of epoch 402\n",
      "Training loss at epoch 402: 0.0134\n",
      "\n",
      "Start of epoch 403\n",
      "Training loss at epoch 403: 0.0132\n",
      "\n",
      "Start of epoch 404\n",
      "Training loss at epoch 404: 0.0129\n",
      "\n",
      "Start of epoch 405\n",
      "Training loss at epoch 405: 0.0127\n",
      "\n",
      "Start of epoch 406\n",
      "Training loss at epoch 406: 0.0124\n",
      "\n",
      "Start of epoch 407\n",
      "Training loss at epoch 407: 0.0121\n",
      "\n",
      "Start of epoch 408\n",
      "Training loss at epoch 408: 0.0119\n",
      "\n",
      "Start of epoch 409\n",
      "Training loss at epoch 409: 0.0116\n",
      "\n",
      "Start of epoch 410\n",
      "Training loss at epoch 410: 0.0114\n",
      "\n",
      "Start of epoch 411\n",
      "Training loss at epoch 411: 0.0111\n",
      "\n",
      "Start of epoch 412\n",
      "Training loss at epoch 412: 0.0108\n",
      "\n",
      "Start of epoch 413\n",
      "Training loss at epoch 413: 0.0106\n",
      "\n",
      "Start of epoch 414\n",
      "Training loss at epoch 414: 0.0103\n",
      "\n",
      "Start of epoch 415\n",
      "Training loss at epoch 415: 0.0101\n",
      "\n",
      "Start of epoch 416\n",
      "Training loss at epoch 416: 0.0098\n",
      "\n",
      "Start of epoch 417\n",
      "Training loss at epoch 417: 0.0096\n",
      "\n",
      "Start of epoch 418\n",
      "Training loss at epoch 418: 0.0093\n",
      "\n",
      "Start of epoch 419\n",
      "Training loss at epoch 419: 0.0091\n",
      "\n",
      "Start of epoch 420\n",
      "Training loss at epoch 420: 0.0089\n",
      "\n",
      "Start of epoch 421\n",
      "Training loss at epoch 421: 0.0086\n",
      "\n",
      "Start of epoch 422\n",
      "Training loss at epoch 422: 0.0084\n",
      "\n",
      "Start of epoch 423\n",
      "Training loss at epoch 423: 0.0082\n",
      "\n",
      "Start of epoch 424\n",
      "Training loss at epoch 424: 0.0079\n",
      "\n",
      "Start of epoch 425\n",
      "Training loss at epoch 425: 0.0077\n",
      "\n",
      "Start of epoch 426\n",
      "Training loss at epoch 426: 0.0075\n",
      "\n",
      "Start of epoch 427\n",
      "Training loss at epoch 427: 0.0073\n",
      "\n",
      "Start of epoch 428\n",
      "Training loss at epoch 428: 0.0071\n",
      "\n",
      "Start of epoch 429\n",
      "Training loss at epoch 429: 0.0069\n",
      "\n",
      "Start of epoch 430\n",
      "Training loss at epoch 430: 0.0067\n",
      "\n",
      "Start of epoch 431\n",
      "Training loss at epoch 431: 0.0065\n",
      "\n",
      "Start of epoch 432\n",
      "Training loss at epoch 432: 0.0063\n",
      "\n",
      "Start of epoch 433\n",
      "Training loss at epoch 433: 0.0061\n",
      "\n",
      "Start of epoch 434\n",
      "Training loss at epoch 434: 0.0060\n",
      "\n",
      "Start of epoch 435\n",
      "Training loss at epoch 435: 0.0058\n",
      "\n",
      "Start of epoch 436\n",
      "Training loss at epoch 436: 0.0057\n",
      "\n",
      "Start of epoch 437\n",
      "Training loss at epoch 437: 0.0056\n",
      "\n",
      "Start of epoch 438\n",
      "Training loss at epoch 438: 0.0054\n",
      "\n",
      "Start of epoch 439\n",
      "Training loss at epoch 439: 0.0053\n",
      "\n",
      "Start of epoch 440\n",
      "Training loss at epoch 440: 0.0052\n",
      "\n",
      "Start of epoch 441\n",
      "Training loss at epoch 441: 0.0050\n",
      "\n",
      "Start of epoch 442\n",
      "Training loss at epoch 442: 0.0049\n",
      "\n",
      "Start of epoch 443\n",
      "Training loss at epoch 443: 0.0048\n",
      "\n",
      "Start of epoch 444\n",
      "Training loss at epoch 444: 0.0046\n",
      "\n",
      "Start of epoch 445\n",
      "Training loss at epoch 445: 0.0045\n",
      "\n",
      "Start of epoch 446\n",
      "Training loss at epoch 446: 0.0043\n",
      "\n",
      "Start of epoch 447\n",
      "Training loss at epoch 447: 0.0041\n",
      "\n",
      "Start of epoch 448\n",
      "Training loss at epoch 448: 0.0040\n",
      "\n",
      "Start of epoch 449\n",
      "Training loss at epoch 449: 0.0038\n",
      "\n",
      "Start of epoch 450\n",
      "Training loss at epoch 450: 0.0037\n",
      "\n",
      "Start of epoch 451\n",
      "Training loss at epoch 451: 0.0036\n",
      "\n",
      "Start of epoch 452\n",
      "Training loss at epoch 452: 0.0034\n",
      "\n",
      "Start of epoch 453\n",
      "Training loss at epoch 453: 0.0033\n",
      "\n",
      "Start of epoch 454\n",
      "Training loss at epoch 454: 0.0033\n",
      "\n",
      "Start of epoch 455\n",
      "Training loss at epoch 455: 0.0032\n",
      "\n",
      "Start of epoch 456\n",
      "Training loss at epoch 456: 0.0031\n",
      "\n",
      "Start of epoch 457\n",
      "Training loss at epoch 457: 0.0030\n",
      "\n",
      "Start of epoch 458\n",
      "Training loss at epoch 458: 0.0030\n",
      "\n",
      "Start of epoch 459\n",
      "Training loss at epoch 459: 0.0029\n",
      "\n",
      "Start of epoch 460\n",
      "Training loss at epoch 460: 0.0029\n",
      "\n",
      "Start of epoch 461\n",
      "Training loss at epoch 461: 0.0028\n",
      "\n",
      "Start of epoch 462\n",
      "Training loss at epoch 462: 0.0027\n",
      "\n",
      "Start of epoch 463\n",
      "Training loss at epoch 463: 0.0027\n",
      "\n",
      "Start of epoch 464\n",
      "Training loss at epoch 464: 0.0026\n",
      "\n",
      "Start of epoch 465\n",
      "Training loss at epoch 465: 0.0026\n",
      "\n",
      "Start of epoch 466\n",
      "Training loss at epoch 466: 0.0025\n",
      "\n",
      "Start of epoch 467\n",
      "Training loss at epoch 467: 0.0025\n",
      "\n",
      "Start of epoch 468\n",
      "Training loss at epoch 468: 0.0025\n",
      "\n",
      "Start of epoch 469\n",
      "Training loss at epoch 469: 0.0024\n",
      "\n",
      "Start of epoch 470\n",
      "Training loss at epoch 470: 0.0024\n",
      "\n",
      "Start of epoch 471\n",
      "Training loss at epoch 471: 0.0023\n",
      "\n",
      "Start of epoch 472\n",
      "Training loss at epoch 472: 0.0023\n",
      "\n",
      "Start of epoch 473\n",
      "Training loss at epoch 473: 0.0023\n",
      "\n",
      "Start of epoch 474\n",
      "Training loss at epoch 474: 0.0022\n",
      "\n",
      "Start of epoch 475\n",
      "Training loss at epoch 475: 0.0022\n",
      "\n",
      "Start of epoch 476\n",
      "Training loss at epoch 476: 0.0022\n",
      "\n",
      "Start of epoch 477\n",
      "Training loss at epoch 477: 0.0021\n",
      "\n",
      "Start of epoch 478\n",
      "Training loss at epoch 478: 0.0021\n",
      "\n",
      "Start of epoch 479\n",
      "Training loss at epoch 479: 0.0021\n",
      "\n",
      "Start of epoch 480\n",
      "Training loss at epoch 480: 0.0020\n",
      "\n",
      "Start of epoch 481\n",
      "Training loss at epoch 481: 0.0020\n",
      "\n",
      "Start of epoch 482\n",
      "Training loss at epoch 482: 0.0020\n",
      "\n",
      "Start of epoch 483\n",
      "Training loss at epoch 483: 0.0020\n",
      "\n",
      "Start of epoch 484\n",
      "Training loss at epoch 484: 0.0019\n",
      "\n",
      "Start of epoch 485\n",
      "Training loss at epoch 485: 0.0019\n",
      "\n",
      "Start of epoch 486\n",
      "Training loss at epoch 486: 0.0019\n",
      "\n",
      "Start of epoch 487\n",
      "Training loss at epoch 487: 0.0019\n",
      "\n",
      "Start of epoch 488\n",
      "Training loss at epoch 488: 0.0018\n",
      "\n",
      "Start of epoch 489\n",
      "Training loss at epoch 489: 0.0018\n",
      "\n",
      "Start of epoch 490\n",
      "Training loss at epoch 490: 0.0018\n",
      "\n",
      "Start of epoch 491\n",
      "Training loss at epoch 491: 0.0018\n",
      "\n",
      "Start of epoch 492\n",
      "Training loss at epoch 492: 0.0018\n",
      "\n",
      "Start of epoch 493\n",
      "Training loss at epoch 493: 0.0017\n",
      "\n",
      "Start of epoch 494\n",
      "Training loss at epoch 494: 0.0017\n",
      "\n",
      "Start of epoch 495\n",
      "Training loss at epoch 495: 0.0017\n",
      "\n",
      "Start of epoch 496\n",
      "Training loss at epoch 496: 0.0017\n",
      "\n",
      "Start of epoch 497\n",
      "Training loss at epoch 497: 0.0017\n",
      "\n",
      "Start of epoch 498\n",
      "Training loss at epoch 498: 0.0016\n",
      "\n",
      "Start of epoch 499\n",
      "Training loss at epoch 499: 0.0016\n"
     ]
    }
   ],
   "source": [
    "maxdepth = range(1,5+1)\n",
    "N = 4\n",
    "\n",
    "dloss = [[]*6]\n",
    "\n",
    "for depth in maxdepth:\n",
    "    dloss.append([])\n",
    "    for randIt in range(5):\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=0.02)#tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.0, nesterov=False)\n",
    "        loss_fn = tf.losses.mse\n",
    "\n",
    "        model, quantum_model_circuit, qubits, readoutqubit = setup(N, param, extra=False, full=True, firstOne=False, cnot=False, depth=depth, random=True)\n",
    "        inputs, labels = generate_data(qubits)\n",
    "\n",
    "        ninp = len(inputs)\n",
    "        split = int(ninp*1)\n",
    "\n",
    "        train_excitations = inputs[:split]\n",
    "        train_labels = labels[:split]\n",
    "        #train_labels = tf.cast(train_labels, dtype=tf.float64)\n",
    "\n",
    "        test_excitations = inputs[split:]\n",
    "        test_labels = labels[split:]\n",
    "\n",
    "\n",
    "\n",
    "        print(model.weights)\n",
    "\n",
    "\n",
    "        \"\"\"batch_size = 16\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((train_excitations, train_labels))\n",
    "        train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\"\"\"\n",
    "\n",
    "\n",
    "        loss_list = []\n",
    "\n",
    "        epochs = 500\n",
    "        train(model, train_excitations, train_labels, optimizer, loss_fn, loss_list, epochs=epochs)\n",
    "        dloss[-1].append(loss_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "id": "e9f55c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAAsTAAALEwEAmpwYAABmIUlEQVR4nO3dd3xUVdrA8d+ZmfQeCC2FJBBaSKEXEUGkiIqCqGBHFPXVxa64irCuu9ixIa4romJBLAgrqAgIgtJ7h0ACKRBICOltZp73j0nGVAiQYQI53w/zmZlz27kz4T5z7jn3uUpE0DRN0xovg7MroGmapjmXDgSapmmNnA4EmqZpjZwOBJqmaY2cDgSapmmNnA4EmqZpjZwOBJqmaY2cDgSadp6UUm5KqVlKqcNKqVyl1Fal1NXOrpem1ZUOBJp2/kxAMnAF4Ac8D8xTSoU7s1KaVldKX1msafVPKbUd+IeIfOfsumjamegWgabVM6VUc6AdsMvZddG0utAtAk2rR0opF+An4KCI3O/s+mhaXehAoGn1RCllAL4EfIHrRaTUyVXStDoxObsCmnYpUEopYBbQHBiug4B2MdGBQNPqx0ygI3CViBQ6uzKadjb0qSFNO09KqdZAElAMmCtMul9EvnBKpTTtLOhAoGma1sjp4aOapmmNnA4EmqZpjZwOBJqmaY2cDgSapmmN3EU3fLRp06YSHh7u7GpomqZdVDZt2pQhIkE1TbvoAkF4eDgbN250djU0TdMuKkqpw7VN06eGNE3TGjkdCDRN0xo5HQg0TdMauYuuj0C7tJSWlpKSkkJRUZGzq6JplwR3d3dCQkJwcXGp8zI6EGhOlZKSgo+PD+Hh4dgSeGqadq5EhMzMTFJSUoiIiKjzcvrUkOZURUVFNGnSRAcBTasHSimaNGly1i1sHQg0p9NBQNPqz7n8f2o0gaCk0Exmah7mUouzq6JpmtagNJpAcHhXJnP/uZ6cE7pTUqtMKcXtt99uf282mwkKCuLaa68FYOHChbz88sunXUdSUhKdO3d2aD3P1smTJxk8eDBRUVEMHjyYrKysGuf79NNPiYqKIioqik8//dRe/txzzxEaGoq3t3e1ZebNm0enTp2Ijo7m1ltvtZc//fTTREdH07FjRyZOnIiIUFBQwDXXXEOHDh2Ijo5m0qRJ9vk/+OADYmJiiI+Pp1+/fuzevbvSdo4cOYK3tzevv/56pXKLxUKXLl3s3xHYzo8/99xztGvXjo4dO/LOO+8AsGDBAmJjY4mPj6d79+6sXr0agN9++434+Hj7w93dnR9++AGAZcuW0bVrV3u9EhISAPj999/p2rUrJpOJb7/9tlKdhg0bhr+/f6U6Abz33nu0bdsWpRQZGRn28uzsbK677jri4uKIjo5m9uzZlZbLyckhJCSEhx9+uNrnX+9E5KJ6dOvWTc7FoW0n5L37l0l6UvY5La85xu7du51dBfHy8pK4uDgpKCgQEZHFixdLXFycXHPNNXVeR2JiokRHRzuqiufkqaeekmnTpomIyLRp0+Tpp5+uNk9mZqZERERIZmamnDx5UiIiIuTkyZMiIrJmzRpJS0sTLy+vSsvs379f4uPj7fOlp6eLiMgff/whffv2FbPZLGazWXr37i2//fab5Ofny/Lly0VEpLi4WPr16yeLFy8WEZHs7L/+Py5YsECGDh1aaVs33nijjB49Wl577bVK5W+88YaMHTu20nf08ccfyx133CEWi6VSvXJzc8VqtYqIyLZt26R9+/Y1fg4BAQGSn58vIiJRUVH2v80ZM2bIXXfdJSK273nbtm1yxx13yDfffFNpHUuXLpWFCxdW+7vZvHmzJCYmSuvWreXEiRP28n/961/27+T48eMSEBAgxcXF9ukTJ06UsWPHykMPPVStvmdS0/8rYKPUclx1WItAKfWxUuq4UmpnLdNvU0ptV0rtUEr9qZSKc1RdAEyutl01l+hTQ1p1w4cPZ9GiRQB89dVXjB071j7tk08+sf8qu/vuu5k4cSJ9+/YlMjKy2q/CqpYtW0aXLl2IiYnhnnvuobi4GIBJkybRqVMnYmNjefLJJwH45ptv6Ny5M3FxcfTv3/+892nBggXcddddANx11132X7sV/fLLLwwePJjAwEACAgIYPHgwP//8MwC9e/emZcuW1Zb573//y0MPPURAQAAAzZo1A2wtq6KiIkpKSiguLqa0tJTmzZvj6enJwIEDAXB1daVr166kpKQA4Ovra19vfn5+pfPbP/zwAxEREURHR1fafkpKCosWLeLee++tVD5z5kxeeOEFDAZDpXp5e3vb11t1G+W+/fZbrr76ajw9Pe37kpOTA9h+ubdq1QqwpbiJjY21b6OiQYMG4ePjU628S5cu1JQfTSlFbm4uIkJeXh6BgYGYTLaBnJs2bSI9PZ0hQ4ZUW84RHDl89BPgPeCzWqYnAleISJZS6mrgQ6CXoypjcjECYC6xOmoT2nn6x/92sTstp17X2amVL1Ouiz7jfGPGjOHFF1/k2muvZfv27dxzzz2sWrWqxnmPHj3K6tWr2bt3LyNGjGD06NE1zldUVMTdd9/NsmXLaNeuHXfeeSczZ87kjjvuYP78+ezduxelFKdOnQLgxRdf5JdffiE4ONheVlFubi6XX355jdv68ssv6dSpU6Wy9PR0+4G8RYsWpKenV1suNTWV0NBQ+/uQkBBSU1Nr3Ea5/fv3A3DZZZdhsViYOnUqw4YNo0+fPgwcOJCWLVsiIjz88MN07Nix0rKnTp3if//7H4888oi9bMaMGbz55puUlJSwfPlyAPLy8njllVf49ddfq50WevTRR3n11VfJzc2tVH7w4EG+/vpr5s+fT1BQEO+88w5RUVEAzJ8/n2effZbjx4/bA35Fc+fO5fHHH7e//+ijjxg+fDgeHh74+vqydu3a034m5+Lhhx9mxIgRtGrVitzcXL7++msMBgNWq5UnnniCzz//nKVLl9b7dmvisBaBiPwOnDzN9D9FpPyk5VogxFF1gYotAh0ItOpiY2NJSkriq6++Yvjw4aed94YbbsBgMNCpU6caD67l9u3bR0REBO3atQNsv8p///13/Pz8cHd3Z/z48Xz//ff2X6GXXXYZd999N//973+xWKq3XH18fNi6dWuNj6pBoCqlVL2NzjKbzRw4cIAVK1bw1Vdfcd9993Hq1CkSEhLYs2cPKSkppKamsnz58krB1Gw2M3bsWCZOnEhkZKS9/KGHHuLgwYO88sorvPTSSwBMnTqVxx57rFr/xI8//kizZs3o1q1btXoVFxfj7u7Oxo0bue+++7jnnnvs00aOHMnevXv54YcfmDx5cqXljh49yo4dOxg6dKi9bPr06SxevJiUlBTGjRtXKUjUl19++YX4+HjS0tLYunUrDz/8MDk5Obz//vsMHz6ckBCHHhIraSgXlI0HfqptolJqAjABICws7Jw2YHIpCwR61FCDVZdf7o40YsQInnzySVasWEFmZmat87m5udlfyznc89tkMrF+/XqWLVvGt99+y3vvvcfy5cv54IMPWLduHYsWLaJbt25s2rSJJk2a2Jc72xZB8+bNOXr0KC1btuTo0aP2UyUVBQcHs2LFCvv7lJQUBgwYcNr6h4SE0KtXL1xcXOyBrjww9O7d237wvvrqq1mzZo29zhMmTCAqKopHH320xvWOGTOGBx98EIB169bx7bff8vTTT3Pq1CkMBgPu7u6kpqaycOFCFi9eTFFRETk5Odx+++18/vnnhISEMGrUKMB24B83bly1bfTv359Dhw6RkZFB06ZNAVvH98iRI+1X4p44cYJt27bRq5ftBMUtt9zCsGHDTvuZnIvZs2czadIklFK0bduWiIgI9u7dy5o1a1i1ahXvv/8+eXl5lJSU4O3tfcYBC+fD6aOGlFIDsQWCZ2qbR0Q+FJHuItI9KKjGdNpnZHLVp4a007vnnnuYMmUKMTEx9bK+9u3bk5SUZB9xMmfOHK644gry8vLIzs5m+PDhTJ8+nW3btgG2Uxu9evXixRdfJCgoiOTk5ErrO9sWwYgRI+yjgD799FOuv/76avMMHTqUJUuWkJWVRVZWFkuWLKn0y7gmN9xwgz14ZGRksH//fiIjIwkLC2PlypWYzWZKS0tZuXKl/dTQ888/T3Z2Nm+99ValdR04cMD+etGiRfZTOatWrSIpKYmkpCQeffRR/v73v/Pwww8zbdo0UlJSSEpKYu7cuVx55ZV8/vnn9nr99ttvAKxcudLeEktISLAH7M2bN1NcXFwpwFbtEwoICCA7O9t+CuzXX3+tdoqrPoSFhbFs2TLAdhpv3759REZG8sUXX3DkyBGSkpJ4/fXXufPOOx0aBADHjhoCwoGdp5keCxwE2tV1nec6aqggt1jeu3+ZbFt+5JyW1xyjoYwaquq3336zj/6YPXu2feTGXXfdVWm0SPmyiYmJYjKZJDg42P6YN2+eLF26VOLj46Vz584ybtw4KSoqkrS0NOnRo4fExMRI586d5ZNPPhERkZEjR0rnzp0lOjpaJk6caB/pcq4yMjLkyiuvlLZt28qgQYMkMzNTREQ2bNgg48ePt883a9YsadOmjbRp00Y+/vhje/lTTz0lwcHBopSS4OBgmTJlioiIWK1Weeyxx6Rjx47SuXNn+eqrr0RExGw2y4QJE6RDhw7SsWNHeeyxx0REJDk5WQDp0KGDxMXFSVxcnPz3v/8VEdvImE6dOklcXJwMGDBAdu7cWW0/pkyZUm3UkEjl70hEJCsrS4YPHy6dO3eW3r17y9atW0VE5OWXX7Zvo3fv3rJq1Sr7MomJidKqVSv7SKNy33//vXTu3FliY2PliiuukIMHD4qIyPr16yU4OFg8PT0lMDBQOnXqZF+mX79+0rRpU3F3d5fg4GD5+eefRUTk7bffluDgYDEajdKyZUv7Z5+amiqDBw+2f+dz5sypto8V//bOxtmOGlJyDk3bulJKhQM/iki1AdZKqTBgOXCniPxZ13V2795dzuXGNKUlFj6cuJI+I9vQdWjrs15ec4w9e/Y45NeWpjVmNf2/UkptEpHuNc3vsD4CpdRXwACgqVIqBZgCuACIyAfAC0AT4P2yTixzbZWsDyaT7SxYqR4+qmmaVonDAoGIjD3D9HuBe083T31SBoXRxYBF9xFomqZV4vTO4gvJ5GrQF5RpmqZV0bgCgYsRc6luEWiaplXUuAKBbhFomqZV08gCgZFS3UegaZpWSeMKBC4GLPrKYq0KnYa6ehrq06WOLvfdd9+hlKLicO5p06bRtm1b2rdvzy+//GIvP3XqFKNHj6ZDhw507NiRNWvWALBt2zb69OlDTEwM1113nT3RW0lJCePGjSMmJoa4uLhKVz+XGzFiRKXP/FzW9dVXXxETE0NsbCzDhg2rlCYa4I033qiUPnrFihX4+fnZU1e/+OKL9nnDw8PtKbW7d/9rAOSZvocNGzZUSmt9uvTYUkuq7fNW2wUGDfVxrheUiYjMf3OzfPfqxnNeXqt/DeWCMp2GunIa6tOljhYRycnJkcsvv1x69eolGzZsEBGRXbt2SWxsrBQVFcmhQ4ckMjJSzGaziIjceeed9ovIiouLJSsrS0REunfvLitWrBAR24Vtzz//vIiIvPfee3L33XeLiC2ddNeuXStd9PXdd9/J2LFjK33mZ7uu0tJSCQoKsqeGfuqpp+wXzYmIHDlyRIYMGSJhYWH2eapexFZR1TTTdfkezGazDBw4UK6++upqaa3Lv5+K6bFrS7VdVYNJQ90QubgZKSnWLQKtOp2GunIa6tOljgaYPHkyzzzzDO7u7pW2N2bMGNzc3IiIiKBt27asX7+e7Oxsfv/9d8aPH29fn7+/P2DLZFq+r4MHD+a7774DYPfu3Vx55ZWALZ20v7+/veWRl5fHm2++yfPPP19pX852XeUHwfz8fESEnJwce7ppgMcee4xXX331vJP1ne57ePfdd7nxxhtrzAMF1dNj15Zq+3w1lKRzF4SLm5HSIrOzq6HV5qdJcGxH/a6zRQxcfeY8LToNtU1Naairpo7evHkzycnJXHPNNbz22muV1tW7d+9q6/Lw8CAoKIhx48axbds2unXrxttvv42XlxfR0dEsWLCAG264gW+++caeXykuLo6FCxcyduxYkpOT2bRpE8nJyfTs2ZPJkyfzxBNP2A+O5c5lXTNnziQmJgYvLy+ioqKYMWMGYDt4BwcHExdX/TYpa9asIS4ujlatWvH666/b75eglGLIkCEopbj//vuZMGHCab+H1NRU5s+fz2+//caGDRtq+Farp8c+Xart89GoWgSu7kZKdYtAq4FOQ12zqqmjrVYrjz/+OG+88cZZrWPz5s08+OCDbNmyBS8vL3ufy8cff8z7779Pt27dyM3NxdXVFbAlAAwJCaF79+48+uij9O3bF6PRyNatWzl48CAjR46stp2zXVdpaSkzZ85ky5YtpKWlERsby7Rp0ygoKODf//53pfP/5bp27crhw4fZtm0bf/vb37jhhhvs01avXs3mzZv56aefmDFjBr///nu15St+D48++iivvPJKjTe5gZrTY58u1fb5aFwtAncTJUU6EDRYdfjl7kg6DXX1NNRVU0fn5uayc+dO+zzHjh1jxIgRLFy4kODg4EoZU1NSUggODiYkJMSeuhpg9OjR9kDQoUMHlixZAthO7ZSfnjOZTEyfPt2+rr59+9KuXTtWrlzJxo0bCQ8Px2w2c/z4cQYMGMCKFSvOel1bt24FoE2bNgDcfPPNvPzyy1x//fUkJibaWwMpKSl07dqV9evX06JFC/t6hg8fzv/93//ZU1oHBwcDttM1I0eOZP369fTv37/W72Hjxo2MGTMGsGVxXbx4MSaTyR5cqqbHBuqUavuc1NZ50FAf59NZvP7HQ/Le/cvEYraceWbtgmgoncUitiyZb7/9toicW/bRqp3FhYWFEhoaKgcOHLAv+9Zbb0lubq69k+/UqVMSGBgoIiIJCQn2Zbt37y5btmw5r/168sknK3VSPvXUU9XmyczMlPDwcDl58qScPHlSwsPD7VlKn3vuORk1alS1zJwVXXHFFfbO4p07d1bqLI6IiLB3Fvfr10/27t0rIrZsok8++aSI/NXZabFY5I477pBZs2aJiEh+fr7k5eWJiMiSJUvk8ssvr7btqp/52a4rNTVVWrRoIcePHxcRkeeff14ef/zxatup2Al89OhRe1bYdevWSWhoqFitVsnLy5OcnBwREcnLy5M+ffrITz/9JCJ1+x6q/l2JiPTq1cveYV/umWeese/Xb7/9Jt27d6+2LpGz7yxuXC0CN9s9CUqKLLh7NaqzYlodhISEMHHixHNeft++fZXuKjV9+nRmz57NTTfdhNlspkePHjzwwAOcPHmS66+/nqKiIkSEN998E4CnnnqKAwcOICIMGjSoxvPTZ2PSpEncfPPNzJo1i9atWzNv3jzA9kv0gw8+4KOPPiIwMJDJkyfTo0cPAF544QUCAwNJSUnhX//6Fx06dKBr166A7daKVe8TXFF0dDQ333wznTp1wmQyMWPGDIxG2/+5d999l9tuu42SkhIiIyOZPXs2YOuYLz8vP2rUKPsv3OPHjzN06FAMBgPBwcHMmTPnjPt7tutq1aoVU6ZMoX///ri4uNC6dWs++eST027j22+/ZebMmZhMJjw8PJg7dy5KKdLT0+2nq8xmM7feeqv9Zja1fQ+nk5SURHJyMldccUWl8kmTJnHbbbcxffp0vL29+eijj864rrpwaBpqRzjXNNQAu1en8dvne7nz333xCXQ/8wKaw+k01JpW/842DXWj+lns4l7eItAjhzRN08o1rkBQdmqoVHcYa5qm2TWqQODqbusS0YFA0zTtL40qENhPDRXrU0OapmnlGlUgcHXXp4Y0TdOqalSBwM3TdmFGUX6pk2uiaZrWcDSuQOBhQhkURXk6EGh/0Wmoq6ehBhg2bBhxcXFER0fzwAMP2NNe3HLLLfYUyeHh4cTHxwOwfv16e3lcXBzz58+3r6u2NNSTJ08mNjaW+Ph4hgwZQlpamn2ZFStWEB8fT3R0dKXx9D///DPt27enbdu2lb6X8ePHExcXR2xsLKNHjyYvLw+wJY8rr1e7du3sCe/K99Hf39/+XZd77733aNu2baUU1AB79+6lT58+uLm58frrr9vLk5OTGThwIJ06dSI6Opq3337bPm3r1q307t3bnp56/fr1AHzxxRfExsYSExND37592bZtG2DLUdWzZ0/7Zz9lyhT7uu6++24iIiLs+1N+dfR5q+1Ks4b6OJ8ri0VEZj21SpbP2XNe69DqT0O5slinoa6chlpEJDs7W0RErFarjBo1Sr766qtqyz/++OPyj3/8Q0RsV/CWlpaKiEhaWpoEBQXZ39eWhrp8GyIib7/9ttx///0iIpKVlSUdO3aUw4cPi8hfVw2bzWaJjIyUgwcPSnFxscTGxsquXbuqreuxxx6z73tF77zzjowbN87+funSpbJw4cJq3/XmzZslMTGxWmrp9PR0Wb9+vfz973+X1157zV6elpYmmzZtEhFbiu6oqCh7vQYPHmxP4b1o0SK54oorRETkjz/+sH/Wixcvlp49e9o/79zcXBERKSkpkZ49e8qaNWtEpOYrkGui01CfgYe3i24RaNXoNNSV01AD+Pr6ArYWUklJSbWkdSLCvHnz7J+Vp6cnJpNtZF5RUZF9/tOloS7fBkB+fr59mS+//JJRo0YRFhYG/JVuef369bRt25bIyEhcXV0ZM2YMCxYsqLQuEaGwsLDGJHtVv9tBgwbh4+NTbb4uXboQHh5erbxZs2b06NGjUv4fgJYtW9qvwPbx8aFjx472LK5KKftNcrKzs+2prvv27UtAQAAAvXv3tqf5Vkrh7e0NQGlpKaWlpeedCvtMGlWKCbAFgsK8EmdXQ6vBK+tfYe/JvfW6zg6BHXim5zNnnE+nobapmoZ66NChrF+/nquvvrrafq5atYrmzZtXSoO8bt067rnnHg4fPsycOXMwmUwkJibWmoYa4LnnnuOzzz7Dz8+P3377DbAljSstLWXAgAHk5ubyyCOPcOedd9ZY33Xr1tnfjxs3jsWLF9OpU6dqGVIPHz5MYmKi/d4EjpKUlMSWLVvsSfbeeusthg4dypNPPonVauXPP/+stsysWbO4+uqr7e8tFgvdunUjISGBhx56yL4usH1eL774IoMGDeLll1+ulATxXDW6FoG7twuFubpFoFWm01DX7JdffuHo0aMUFxezfPnyStOq/roG6NWrF7t27WLDhg1MmzaNoqKi06ahBvjXv/5FcnIyt912G++99x5ga4Vs2rSJRYsW8csvv/DPf/6T/fv3n7G+s2fPJi0tjY4dO/L1119XmjZ37lxGjx5tz3/kCHl5edx444289dZb9hbKzJkzmT59OsnJyUyfPt3eMir322+/MWvWLF555RV7WXnK7ZSUFNavX8/OnTsB261A9+7dy4YNGzh58mSlZc5HI2wRuFKUd8rZ1dBqUJdf7o6k01BXT0MN4O7uzvXXX8+CBQsYPHgwYDtQf//992zatKnG+nTs2BFvb2927tx52jTUFd12220MHz6cf/zjH4SEhNCkSRO8vLzw8vKif//+bNu2jZCQkBpTXVdkNBoZM2YMr776aqU0zXPnzrUnpXOE0tJSbrzxRm677TZ7qmiwdcaXdx7fdNNNlRL3bd++nXvvvZeffvqp0nddzt/fn4EDB/Lzzz/TuXNnewvPzc2NcePGVeqwPh8OaxEopT5WSh1XSu2sZbpSSr2jlEpQSm1XSnV1VF0AdqYn8srqz7C6WSgqKMVisTpyc9pF6J577mHKlCnExMTUy/rat29PUlISCQkJAMyZM4crrriCvLw8srOzGT58ONOnT7ePFjl48CC9evXixRdfJCgoqNIBD86+RTBixAj7KKBPP/2U66+/vto8Q4cOZcmSJWRlZZGVlcWSJUsYOnQoeXl5HD16FLAd9BctWkSHDh3syy1dupQOHTpUyraamJiI2Wy7WPPw4cPs3buX8PBwWrRoQWhoKPv27QNs/Sbl9T1w4IB9+QULFti3cf3117N69WrMZjMFBQWsW7eOjh070qNHDw4cOEBiYiIlJSXMnTuXESNGICL2z1lEWLhwYaX67t27l6ysLPr06XPmL+4ciAjjx4+nY8eOle4oBrYspytXrgRg+fLl9lNpR44cYdSoUcyZM8feagQ4ceKE/dRgYWEhv/76q31fyr8TEeGHH36ov5FqtfUin+8D6A90BXbWMn048BOggN7Aurqs91xHDf17xVzp/ElnmfftGnnv/mWSk1l4TuvR6ldDGTVU1bncj8BkMklwcLD9MW/ePFm6dKnEx8dL586dZdy4cVJUVCRpaWnSo0cPiYmJkc6dO8snn3wiIiIjR46Uzp07S3R0tEycONGe9/5cZWRkyJVXXilt27aVQYMG2e8zsGHDBhk/frx9vlmzZkmbNm2kTZs28vHHH4uIyLFjx6R79+4SExMj0dHR8vDDD9tHAJV/DjNnzqy0vc8++0w6deokcXFx0qVLF5k/f7592pYtW6Rbt24SExMj119/vX20zKhRoyQ6OlpiYmLk2muvlZSUFPsyr776qnTs2FGio6Nl+vTp9vJFixZJVFSUREZGyksvvSQitnsQ9O3b1/753XrrrZVGEU2ZMkWeeeaZap9Rv379pGnTpuLu7i7BwcHy888/i4htBFNwcLAYjUZp2bKl/fM6evSoBAcHi4+Pj/j5+UlwcLBkZ2fLqlWrBJCYmBiJi4uTuLg4WbRokYiIrFq1Srp27SqxsbHSs2dP2bhxo4iIjB8/Xvz9/e3zlx/btm3bJvHx8fbPvnxUlojIwIED7ft422232UcXVXW2o4YcmoZaKRUO/Cgi1cKWUuo/wAoR+ars/T5ggIgcPd06zzUN9X/W/8R7e57mCf93yP9JuPHpbrSI9Dvr9Wj1S6eh1rT6dzGloQ4GKrZ9U8rKqlFKTVBKbVRKbTxx4sQ5baypl+2gn2u0XWSSf6r4nNajaZp2qbkoRg2JyIci0l1EugcFBZ3TOoI8bYHglDEXgDwdCDRN0wDnBoJUILTC+5CyModo7u0PQJacwmBSukWgaZpWxpmBYCFwZ9nood5A9pn6B85HeSDIKcnFy89NBwJN07QyDruOQCn1FTAAaKqUSgGmAC4AIvIBsBjbyKEEoAAYV/Oa6oefuyciRnJL8/D214FA0zStnMMCgYiMPcN0AR5y1ParUkqhrO7kl+bh5e/GieTcC7VpTdO0Bu2i6CyuLwY8KDTbAkF+VvE5XRWqXXp0GurqaagLCgq45ppr6NChA9HR0UyaNMk+/wcffEBMTAzx8fH069eP3bt3A6dPQz19+nSio6Pp3LkzY8eOpaioCKg93XNWVhYjR44kNjaWnj172lMsQO1pqOtzXeUmTpxoTwAHtgvlBg0aRGxsLAMGDLAniiuXk5NDSEiIPUkhwKZNm4iJiaFt27ZMnDix0nHn3XfftX/GTz/9tL182rRptG3blvbt2/PLL7/Yy8PDw+2ffffuNY4EPTe1XWDQUB/nk4a666zh0nf2WNny62F57/5lUphXcs7r0upHQ7mgTKehrpyGOj8/X5YvXy4itrTR/fr1s6dSrnih1oIFC2To0KEiUnsa6pSUFAkPD7d/vjfddJPMnj1bRGpP9/zkk0/K1KlTRURkz549cuWVV4rI6dNQ1+e6RGwX3t1+++2VLjgcPXq0/QLAZcuWye23317p85w4caKMHTvWfgGiiEiPHj1kzZo1YrVaZdiwYfbPcfny5TJo0CApKioSkb9Sbe/atUtiY2OlqKhIDh06JJGRkWI2m0VEqu1bbXQa6tNwVZ4UWwvw8rflitH9BFo5nYa6chpqT09PBg4cCNjSRnft2tX+67e21NG1paEGWyursLDQnjKiPBVzbemed+/ebc8S2qFDB5KSkkhPTz9tGur6XJfFYuGpp57i1VdfrXVdAwcOtM8Ptl/+6enpDBkyxF529OhRcnJy6N27N0op7rzzTvv3MHPmTCZNmmTPXVWeC2rBggWMGTMGNzc3IiIiaNu2rf1mNo7SqJLOeZi8KChOqxQImgR7n2Ep7UI59u9/U7ynftNQu3XsQIu///2M8+k01DZV01CD7e5i//vf/3jkkUfsZTNmzODNN9+kpKSkUlbSmtJQBwcH8+STTxIWFoaHhwdDhgypdLCsSVxcHN9//z2XX34569ev5/Dhw6SkpJwxDXV9reu9995jxIgR9s+v6roeeeQR5s+fT25uLpmZmQQEBPDEE0/w+eefs3Tp0kqfb8V8TBU/3/3797Nq1Sqee+453N3def311+nRowepqan07t27xmWUUgwZMgSlFPfffz8TJkw47b7XVaNqEXi5eGOhEO+yQKAvKtPK6TTUNTObzYwdO5aJEycSGRlpL3/ooYc4ePAgr7zyCi+99JK9vKY01FlZWSxYsIDExETS0tLIz8/n888/P+12J02axKlTp4iPj+fdd9+lS5cu55w++mzXlZaWxjfffMPf/va3atNef/11Vq5cSZcuXVi5ciXBwcEYjUbef/99hg8fXumgfyZms5mTJ0+ydu1aXnvtNW6++eYz9luuXr2azZs389NPPzFjxgx+//33Om/vdBpVi8DH1QcMhRg9bbutTw01LHX55e5IOg119TTUEyZMICoqikcffbTG7Y4ZM4YHH3ywWnnFNNSJiYlERERQnhVg1KhR/Pnnn5U66Kvy9fVl9uzZgO0zjoiIIDIyksLCwjOmoT7fdW3ZsoWEhATatm0L2DrO27ZtS0JCAq1ateL7778HbPce+O677/D392fNmjWsWrWK999/n7y8PEpKSvD29uaRRx6p1KFcsb4hISGMGjUKpRQ9e/bEYDCQkZFBcHBwrftY/tysWTNGjhzJ+vXr6+U0YqNqEfi7+YChhJPFJbh7u+hAoFWi01D/lYYa4Pnnnyc7O5u33nqr0jIVU0cvWrTInla5tjTUYWFhrF27loKCAkSEZcuWnTHR4KlTpygpsd1J8KOPPqJ///74+vrWmoa6Ptd1zTXXcOzYMZKSkkhKSsLT09P+HWZkZGC12lLYT5s2jXvuuQew3Yj+yJEjJCUl8frrr3PnnXfy8ssv07JlS3x9fVm7di0iwmeffWb/Hm644YZKd2QrKSmhadOmjBgxgrlz51JcXExiYiIHDhygZ8+e5Ofnk5trG/aen5/PkiVLGn4aakc9zmfU0N+XvSedP+ksaxKTZe5L6+TH97ae87q0+tFQRg1V1djTUCcnJwsgHTp0sKdJLr/5/MSJE+3ppgcMGCA7d+4UkdOnoX7hhRekffv2Eh0dLbfffrt9pExt6Z7//PNPiYqKknbt2snIkSPtaatFak5DXd/rqqji38c333wjbdu2laioKBk/frx9Pyqq+PdS/nlHR0dLZGSkPPTQQ/bvtbi4WG677TaJjo6WLl26yLJly+zLvPTSSxIZGSnt2rWzjzI6ePCgxMbGSmxsrHTq1KnW+oo0sDTUjnCuaagBpq+dw8f7XmVqly9xW2Ul/1QxtzzXs55rqJ0NnYZa0+rfxZSG+oJr7uUPwNGcLDx9XSnM0Tex1zRNa1SBINgvAIDUnCw8fFwpzC3VVxdrmtboNapAEOhhuyfB0ZwsPH1csVqF4gKzk2ulaZrmXI0qEHi72i4eO5GfjYePCwCFufr0kKZpjVujCgQ+rj4AZBZm4+HjCkBhbqkzq6RpmuZ0jSoQeLvYWgTZxbm4e9laBAW6w1jTtEauUQUCN6MbBkxYKOSU2C7h16eGNJ2GunoaaoABAwbQvn17e2rp48ePA3DkyBEGDhxIly5diI2NZfHixQBkZmYycOBAvL29K6VhBlsiv5iYGGJjYxk2bJg9TfTUqVMJDg62b6N8XaWlpdx1113ExMTQsWNHpk2bVml9FouFLl262L8jgOXLl9O1a1c6d+7MXXfdZb+4bcGCBcTGxtpTN69evRqwXfTWtWtX4uPjiY6O5oMPPjhjfW+55RZ7XcPDw4mPj7cvs337dvr06UN0dDQxMTH2VNtff/01sbGxREdH88wzz9jnP11K62HDhuHv719p/xyqtgsMGurjfC4oExHp80U/aTd9vCzbdUzee2CZrFt48LzWp52fhnJBmU5DXTkNtYjIFVdcIRs2bKi2zH333Sfvv/++iNhSJrdu3VpERPLy8mTVqlUyc+bMShdUlZaWSlBQkD198lNPPSVTpkwREZEpU6bIa6+9Vm0bX3zxhdxyyy0iYktv3bp1a0lMTLRPf+ONN2Ts2LH278hisUhISIjs27dPREQmT54sH330kYiI5Obm2i/i2rZtm7Rv315EbBd0lV8QlpubK61bt5bU1NTT1reixx9/XP7xj3/Y9zEmJka2brVdpJqRkSFms1kyMjIkNDRUjh8/LiIid955pyxdulRETp/SeunSpbJw4cKz+husSKehPgNfNx+UoYiDGfm4e7noPgIN0Gmoq6ahPh2lFDk5OQBkZ2fbU0p7eXnRr18/3N3dK81ffrDJz89HRMjJybEvc7pt5Ofn29NXu7q62tNfp6SksGjRIu699177/JmZmbi6utoT/A0ePJjvvvsOAG9vb3vCvYpps11dXe15o4qLi+2pI+pSXxFh3rx59r+TJUuWEBsbS1xcHABNmjTBaDRy6NAhoqKi7HmWrrrqKnu9TpfSetCgQfj4+Jz2M6pPjSrpHICfmw9uriUcOJ5LvI+rPjXUgKyat5+M5Lx6XWfTUG8uv7ndGefTaahtqqahHjduHEajkRtvvJHnn38epRRTp05lyJAhvPvuu+Tn51dKu1wTFxcXZs6cSUxMDF5eXkRFRTFjxgz79Pfee4/PPvuM7t2788YbbxAQEMDo0aNZsGABLVu2pKCggOnTpxMYGAjAo48+yquvvmrPuwPQtGlTzGYzGzdupHv37nz77beVcjXNnz+fZ599luPHj9sDPkBycjLXXHMNCQkJvPbaa/YD/unqC7Bq1SqaN29uz7O0f/9+lFIMHTqUEydOMGbMGJ5++mnatm3Lvn37SEpKIiQkhB9++MGe96i2lNYVEw1eKI2uReDj4oO7WwkJx/Pw9HGhQAcCDZ2GuiZffPEFO3bsYNWqVaxatYo5c+YAthbT3XffTUpKCosXL+aOO+6w/5quSWlpKTNnzmTLli2kpaURGxtrP+f/4IMPcvDgQbZu3UrLli154oknANttL41GI2lpaSQmJvLGG29w6NAhfvzxR5o1a0a3bt2q7d/cuXN57LHH6NmzJz4+PpVSTY8cOZK9e/fyww8/MHnyZHt5aGgo27dvJyEhgU8//ZT09PTT1rdc1Vaj2Wxm9erVfPHFF6xevZr58+ezbNkyAgICmDlzJrfccguXX3454eHh9nrVltLaGRpdi8Db1RuTKY0Dx/NwD/YjM6V+f4Fq564uv9wdSaehrpyGujzlsY+PD7feeivr16/nzjvvZNasWfbTR3369KGoqIiMjIwa1w+wdetWANq0aQPAzTffbO98b968uX2+++67z945+uWXXzJs2DBcXFxo1qwZl112GRs3bmTLli0sXLiQxYsXU1RURE5ODrfffjuff/45ffr0sbfilixZwv79+6vVpX///hw6dIiMjAyaNm1qL2/VqhWdO3dm1apVtG7dutb6gu2g//3337Np0yZ7WUhICP3797evc/jw4WzevJlBgwZx3XXXcd111wHw4Ycf2g/2taW0doZG1yLwdvFGDIXkFplRbgZ9akiz02mo/0pDbTab7SNlSktL+fHHH+2josLCwli2bBlgS25WVFRkPwdek+DgYHbv3s2JEycA+PXXX+0J0Y4ePWqfb/78+ZW2UX7ns/z8fNauXUuHDh2YNm0aKSkpJCUlMXfuXK688kr7TW7KRzUVFxfzyiuv8MADDwCQkJBgD9ibN2+muLiYJk2akJKSQmFhIWC7wf3q1atp3779aesLsHTpUjp06FDpJjRDhw5lx44dFBQUYDabWblypf07Ka9XVlYW77//vr1vo7aU1s7Q6FoEPq4+lEoBALlYKS4wYzFbMZoaXUzUqggJCWHixInnvPy+ffsqHRymT5/O7NmzuemmmzCbzfTo0YMHHniAkydPcv3111NUVISI8OabbwLw1FNPceDAAUSEQYMG2Tsez9WkSZO4+eabmTVrFq1bt2bevHkAbNy4kQ8++ICPPvqIwMBAJk+eTI8ePQB44YUXCAwMJD8/n6FDh1JaWorFYuGqq67ivvvuA+CNN97gvvvuY/r06Sil+OSTT+ynncLDw8nJyaGkpIQffviBJUuW0KlTJ6ZMmUL//v1xcXGhdevWfPLJJwA8/fTTbN26FaUU4eHh/Oc//wFsd0AbN24c0dHRiAjjxo0jNjb2tPv72muv8eOPP2K1WnnwwQftHbHfffcdn332GS4uLnh4ePD111+jlGLPnj088cQTKKUQEZ588kn7j4Da6gswd+7cSqeFAAICAnj88cfp0aMHSimGDx/ONddcA8AjjzxiD/YvvPCC/VThihUrePbZZ1FK0b9//0r9EJdffjl79+4lLy+PkJAQZs2aZb9PhCM0qjTUAO9vfZ+Z22aSu+dfPBMVhnXDSe6adhneAW5nXlirdzoNtabVvwaVhlopNUwptU8plaCUmlTD9DCl1G9KqS1Kqe1KqdP30p2H/HXrOXznXTTPtZ2fax5gJaXANpRPnx7SNK0xc1ggUEoZgRnA1UAnYKxSquqJzOeBeSLSBRgDvO+o+ljz8yhYv57AQlsgiGwuHMyxnR/UgUDTtMbMkS2CnkCCiBwSkRJgLlC1t0oA37LXfkCaoypj9LOloPYrKeuxb2LmgA4EDcLFdnpS0xqyc/n/5MhAEAxUHPaQUlZW0VTgdqVUCrAY+JujKmMsuyrRp9i2y018S8nF1mNfoK8udhp3d3cyMzN1MNC0eiAiZGZmVru6+0ycPWpoLPCJiLyhlOoDzFFKdRaRSlenKKUmABPANqzsXBh8bS0Cr0LbAcfbs4gS/MCodIvAiUJCQkhJSbEP1dM07fy4u7tXGr1WF44MBKlAaIX3IWVlFY0HhgGIyBqllDvQFDhecSYR+RD4EGyjhs6lMkY/W4vAJb8Yk4cJMeTi5dYKS7EOBM7k4uJCRESEs6uhaY2aI08NbQCilFIRSilXbJ3BC6vMcwQYBKCU6gi4Aw75aWhwd0e5umLNySHAPYDMokw6tPSlQIlOPKdpWqPmsEAgImbgYeAXYA+20UG7lFIvKqVGlM32BHCfUmob8BVwtzjwZLHBzxdrTg4tvVuSlp9Gx5Y+ZFksOt+QpmmNmkP7CERkMbZO4IplL1R4vRu4zJF1qMjo64clO4dgr2B2ZOxgUKgfv8tRck8VX6gqaJqmNTiNKq+C0c8PS04OwT7BHMs/RnQrbwoMQlFeqR61omlao9W4AoGvL5acbFp5t8IsZvx9iig2KrAIpUXV0/5qmqY1Bo0nEKRtxZh7AGtWFsHetssZjhem4R9oG2+r+wk0TWusGk8gyEnFkLsPS062PRCk5acR0sILgPxs3U+gaVrj1HgCgVcQRhfBml9IC/dmKBSpuam0CbVdaJaYnOPkCmqapjlHIwoETTG62i5YNuYXEeQZRGpeKrHtbXeASjyS7czaaZqmOU0jCgRBGMoCgTUnhxDvENLy02gf6kexEtKP5ju5gpqmac7ReAKBqzdGD9tlE5acHIK9g0nOTcZkNFDqZiA/S/cRaJrWODWeQKCUPRW15VQ2oT6hpOenU2IpwcXXBfLNmC3WM6xE0zTt0tN4AgFg9A8AwJKTTahvKIKQkpdCYHNPfC2KhPQ8J9dQ0zTtwmtcgaBJcwAsp04R6mNLjJqck0zrCH9cUWzdl+HM6mmapjlF4woEIe1ACZaMDMJ8bPc1SM5Npn1UIAAJCVnOrJ6maZpTNKpAoJpGYnS1Yk47gr+bP94u3hzJPUKTYNtFZSdS9akhTdMan0YVCGjSBpOHFXN6KkopQn1CSc5Nxs3TBau7AXNWCaW6w1jTtEamkQWCKExuFswn0gHsgQDAo6k7AWbFvmO5zqyhpmnaBVenQKCUekQp5atsZimlNiulhji6cvXOLwSTrzuWzJMAhPmGkZqXitlqpmWoL00siu0pp5xbR03TtAusri2Ce0QkBxgCBAB3AC87rFaOohTGFiGYc4sRq5VQn1DMVjPH8o/ROsIPVxS7dYexpmmNTF0DgSp7Hg7MEZFdFcouKi4RHRGLwpKw/q8hpLnJNGll6zBOPaxzDmma1rjUNRBsUkotwRYIflFK+QAXZa+qS4ztzpilG3+pFAgCywJBYUYRRaX6JjWapjUedQ0E44FJQA8RKQBcgHEOq5UDubbvAkDJ7nU082yGm9HNPnLI6GUioFR3GGua1rjUNRD0AfaJyCml1O3A88BFeQ7FJdTWCig9tB+D2EYOJWUnARDY0oumVgPbUy/KXdM0TTsndQ0EM4ECpVQc8ARwEPjMYbVyIIOHByZ/b0pOlsKJPbTxb0PCqQQAWob50NSq2JGsO4w1TWs86hoIzCIiwPXAeyIyA/BxXLUcyz02hsJMV0haTVv/tqTkpVBQWkCTYG9MokhI1C0CTdMaj7oGglyl1LPYho0uUkoZsPUTXJQ8e/alJNeEeedy2vq3BeBQ9iECW9o6jHOPF1JYojuMNU1rHOoaCG4BirFdT3AMCAFec1itHMyrb18Acn7fTMfADgDsyNhBQAtPAALMit1H9T2MNU1rHOoUCMoO/l8Afkqpa4EiETljH4FSaphSap9SKkEpNamWeW5WSu1WSu1SSn15VrU/R+6dOuHZIZSMLQYCd+6mmUczth7fipunC24+LgRaFTv0FcaapjUSdU0xcTOwHrgJuBlYp5QafYZljMAM4GqgEzBWKdWpyjxRwLPAZSISDTx6tjtwrlpOeRZlFA5PeJzRh5qyMX0jIkKTll40x8iOVN0i0DStcajrqaHnsF1DcJeI3An0BCafYZmeQIKIHBKREmAuts7miu4DZohIFoCIHK971c+Pa9wVRFxXhEdrPwZ8sp2IzcfYmbGTwBZeBFoUO1L0yCFN0xqHugYCQ5WDdGYdlg0Gkiu8Tykrq6gd0E4p9YdSaq1SalhNK1JKTVBKbVRKbTxx4kQdq3wGBgOmdj0IHWLBJSaaBxZbWbT5S/xbeGKyQGp6PgUl5vrZlqZpWgNW10Dws1LqF6XU3Uqpu4FFwOJ62L4JiAIGAGOB/yql/KvOJCIfikh3EekeFBRUD5stE9oLw8m9hE59Hg+zwvfj/4F/CQABFgO70/TpIU3TLn117Sx+CvgQiC17fCgiz5xhsVQgtML7kLKyilKAhSJSKiKJwH5sgeHCCO0JCG5uGbiNHc3AbRb+3P4JQFlKan09gaZpl74635hGRL4TkcfLHvPrsMgGIEopFaGUcgXGAAurzPMDttYASqmm2E4VHaprnc5bcDdQBkheT8SjT1Po40aLz+djdFWEmFzYoVNNaJrWCJw2ECilcpVSOTU8cpVSpz1vIiJm4GHgF2APME9EdimlXlRKjSib7RcgUym1G/gNeEpEMs9/t+rIzQdaxELiKoze3vj97UE6pFiATEKMJrYc0R3GmqZd+kynmygi55VGQkQWU6UvQUReqPBagMfLHs7RdhCsfguKsom8/T5WfP8FAakHsYT6k5RZzIncYoJ83JxWPU3TNEdrXPcsrknbq0AscGglymAg/PXpuBYdg0IIzjvJpsO6VaBp2qVNB4KQnuDmBwm/AhDRthsHrvIDZWDKlvkcXLnWyRXUNE1zLB0IjCaIvAIO/ApW203XLrvmagDyA0K5/P3JZC+s2setaZp26dCBAKDDtZB7FFI3AdA3qidF7rlsiGnH3oAw0p5+hqxvvnFyJTVN0xxDBwKAdkPB4AJ7FgCglMI/zA3fgmZMHjSYwvieHJsylbyVK51cUU3TtPqnAwGAhz9EDoDdC0EEgNjOUfgUN8E/YA/fXfcQbu3bk/rU05QkJ592VZqmaRcbHQjKdRoBpw7Dse0AhLZtCkALayFLjqQR/PZbAKQ88gjWoiJn1VLTNK3e6UBQrv01oIy2VgEQFOaD0U0Reqodp4xr2aN8afXKyxTv3sOxf/7TyZXVNE2rPzoQlPNqAhGXw85vQQSjyUB4dBCR2XG4+W3gu03J+AwcSJMH7if7u+9157GmaZcMHQgqihsLWUlwZA0A4TFNcCv2IsjsyoK9f1BUaiHob3/Dq29f0v/5EoU7djq3vpqmafVAB4KKOl4Hrt6w1XbHzLDoJqAgMjueEo81/LLrGMpopNUbr2Ns2oQj99xD3uo/nFxpTdO086MDQUWuXtDpBtg1HwpP4enrSvNwX2IKeuPit4P/rNqJiGAKCCB8zhxcWrUiecIEMmbORMz6Jjaapl2cdCCoqtcEKMmDzZ8CttNDLhk+eJS6k1C0lD8SbMlRXYKDCf/yC3yvvpoTb79D0thbKdq3z5k11zRNOyc6EFTVMg4i+sPaD8BcQkSc7Y5og62jcWv6G68sXY/VarvWwODlRfAbrxP81nRKU1JIHHUj6S+/giUv35l7oGmadlZ0IKjJZY9Cbhpsmk2TYG8CW3kRndUbo9HCAcunfLc5pdLsvsOG0eanxfiPHs3JTz/l0PDh5Pz8M1J2cZqmaVpDpgNBTdpcaWsVrHwFinKI6tGcrKQi/tb2cVx8dvPPP94hJaug0iJGf39a/mMq4XO/wti0CamPPkbyvfdRkpTknH3QNE2rIx0IaqIUDH4RCjLht3/TrkdzAGIyL2NA8DDE/2dum/cqRaWWaot6xMURMW8ezZ97jsJt2zh03QhOvPOOvhpZ07QGSweC2rTqAj3uhXUf4Fu4g7DoQHatSuO1/i8RG9Cfk+7fceNXL2K2WKstqkwmAu+4ncjFi/AZOpSM92dy6NrryFu12gk7ommadno6EJzOoCngFwLfjCO2jw8FOSUc3pLFp9e+TQfvARyR77l+3kRKzCU1Lu7SrBnBr79G2CezUS4uJN93H8ffeFMPNdU0rUHRgeB03H3hls+hIJOwDePwD3Jh+/JkjMrIvFHv0NlzNEdKVnLdt3eSVVT7LS29evcm4of5+N98M5n//S/J9z+ANV+PLNI0rWHQgeBMWsXDzZ+hTiUSa/6I44dzSd9+AKUUX9z4Ah2ND5JauI8R39/CoexDta7G4OZGyxf/QcuX/kn+2rUcvnsc5ix9P2RN05xPB4K6aDcE7l9J+zh3XFU+22bPhbm3YUhcwee33E8n9QwnC3O5eeGtLElactpho/6jRxPy7rsU79/P4VtvozQ9/QLuiKZpWnU6ENRVYCSuY/5Dp37BHCy+jLxDe2HODbh+0JMvojLpbn2cggI/nlj5BGMXjWXevnkk5yTXGBR8rhxI2MezMKenc+SuuzGfOOGEHdI0TbNRF9tFT927d5eNGzc6bfs5GYXMmbyGnsND6RG2GTZ8BCnrERdP1ntfwYtFHqQ1TcZssv3Sb+LehKiAKNr6t6VdQDuiAqII9w3H29Wbgk2bOHLfBFxatqT1Z59iatLEafuladqlTSm1SUS61zhNB4Kz9/3rmygpNDNmci9bwdFttoCwcz6U5JKHBwsNbdkU0IyClj6cdC3gYE4ixZZi+zq8Xbxp4dWCrmlu3PD+TvKbe7Pp+etxaxKEj4sP3q7e+Lj64O3ibXtdVubl4oVB6Yacpmlnx2mBQCk1DHgbMAIficjLtcx3I/At0ENETnuUbwiBYNvyZFbPO8Bt/+iNf3PPvyaYi+HQSix7fiT3wGr88w7aijFwwrsd2ZFdSA4KJtnDh2OWAo7lHyO9IJ1mu9O597N00gIVL441kOepat22QuHl4oW3qzfeLrZg4eXiZQ8UFYNG+XT7c1mZt4s3RoPR0R+TpmkNiFMCgVLKCOwHBgMpwAZgrIjsrjKfD7AIcAUevhgCQV5WEZ8++ye9b4ik27DwWucz52WyYfUvHN25kpbZ24kzHMRT2VoFVt9gDE3bgW8w+LYkL6mYlOk/4BLWEu83JpHv50+ewUCeuYDc0lzySvLIK80jtyT3r+cqZXkleeSW5mK2nvk6BU+TZ7WgUd4KaeHZgmCfYIK9bY8gjyCUqj04aZrW8J0uEJgcuN2eQIKIHCqrxFzgemB3lfn+CbwCPOXAutQr7wB3mkf4cnDzidMGApN3E/oMuxWG3UrC8TzeXneIvdvWEFG4k57ZCcSaj9Py+F6M+el4i5WQPm4kry6l8L57Cb/iJAYXBR4B4NkUvJqCZ+Bfrz1agb8PuPmCW8VnH4pNruQCeeb86oGiYiCpEDyyi7NJzUslpySHk0UnK++vizdRAVG0C2hH+8D2dAzsSPvA9rgYXBz7QWuadkE4MhAEA8kV3qcAvSrOoJTqCoSKyCKlVK2BQCk1AZgAEBYW5oCqnr02XZrx5/cJ5GQU4tvU44zzt23mzbPXxWK5JoZ1iZl8uymFiVvTMBgUD/Zvzf/18MW7OIvgn34m9dXZpOzvQ+h9fVDFWZCfYct7dGI/FPwJBSeB2ltyboAbiqZlgaHyo2rgaA6+PraL58rKi0xupFkLSbUWk5p/lIOnDrI/az+LDi3i631fA+Bh8iC2aSxdmnehS1AXYoNi8Xb1rqdPV9O0C8mRgeC0lFIG4E3g7jPNKyIfAh+C7dSQY2tWN5Fdgvjz+wQSt2UQNyi0zssZDYq+bZrSt01THruqHa8v2cfbyxP53w4v3r6lCzHjnsLiEcaxqVNJ+zmaVq+9gTJU6Ry2WqA4B4pzKz+KsquXFeeWzZtjm56d8ld5SV6NdXQHIoFIgwl8W4FfKPiFIqE3k9oklJ1G2JqdwOb0zXy4/UOsYsWgDHQK7ESvlr3o1bIX8c3i8TCdOUBqmuZ8juwj6ANMFZGhZe+fBRCRaWXv/YCDQPnRqAVwEhhxun6ChtBHUO7LqWvx8nfj+ke7nNd6ft9/gme+205GXjF/H96Ru/uGk/nfjzjx5psE3HEHLZ77ez3VuAqrxRYMiqoGlRwozIKcVDiVbAsepw7b3pdrEQPth5Pf+Ua2lWayOX0z64+tZ8eJHZjFjIvBhfhm8fRs0ZM+rfoQ0zRGj3bSNCdyVmexCVtn8SAgFVtn8a0isquW+VcAT14MncXl/vguge3Lkxn/xuW4up9f4yorv4Qnv9nGsr3HuSamJa/fFEfOG69x8tNPaTF1CgFjxtRTrc9DwUnbUNnUTZCwFI6sBWWAmNFw1VTwbUVBaQGb0jex/th61h1dx96TexGEVl6tuDriam6MupFQ37q3oDRNqx/OHD46HHgL2/DRj0XkX0qpF4GNIrKwyrwruMgCQeq+LH6YvoWr748hskvQea9PRPjP74d45ee9dG7lx4e3daF00mPk/7mGsI9n4dWzZz3Uuh6dSoa1M2HjLDC6woh3IHpk5VmKTrEqdRWLExezJm0NVrFyVeuruKfzPXRu2tlJFde0xkdfUOYgFouVj59cTZuuQVx5R8d6W+/S3ek8MncLXm4mPrqxA16P3oe1sJDIBT9g9Pevt+3Um5OH4Pv7IWU9XPk8XP6k7eY+VZwoOMFXe79i7r655JbkcnXE1Tze7XFaeLVwQqU1rXE5XSDQJ23Pg9FoIKxTIId3ZCLW+guoV3VqzrcP9sXFaODmL3aQ8tCzmDMzOfbPl+ptG/UqMBLu/hFib4HlL8Evfwdr9Rv2BHkGMbHrRJaOXsr9sfez7PAyRvwwgi/2fKHv76xpTqQDwXlqHdOEgpwSMlJqHoFzrjq29OWHhy6jXXMf7lmTx4kbbiVn0SLy/vijXrdTb0xucMMH0OtBWPs+LHwYLDVf2Obp4snDXR5m4ciFdG/enZfXv8zDyx8muzj7Alda0zTQgeC8hXYMBCB5z8kzzHn2gnzc+PK+3vQMD2R8cUeKmgeT/uI/sZbUfEc0pzMYYNg0GPgcbP0CvrkLSmu/V3OwdzAzBs3g2Z7P8mfan9z1010cyz92ASusaRroQHDevPzcCGzl5ZBAAODtZmL2uB4MiAnhn22GU3L4MJkffeSQbdULpeCKp+HqV2Hvj/DlTbYhqbXOrri1463856r/kF6Qzu2Lbyc1L7XW+TVNq386ENSD0I6BHE3Ixlxiccj63V2MvH9bV4IHD+T3VrGkz/wPxcnJZ17QmXrdDyM/hKQ/4NPrbNcinEbPlj35ZNgnFJgLeODXBzhVdOrC1FPTNB0I6kNop0AsZitpCacctg0Xo4G3boknZez9lFjhz0f/3vA7WONugTFfQsYBmHkZ7F102tnbB7ZnxqAZpOalMvmPyQ1//zTtEqEDQT1oFeWPwaRI3uPYexAbDYp/jB/IrqG30GLXRma8NJsSc/XROQ1K+2Fw/+8Q0Brm3go/TQJz7X0cXZp14YnuT7AiZQXf7P/mAlZU0xovHQjqgYurkZZt/BzWT1CRwaC47eUnyW0RRufv/8u9H6zgVEED7Twu16QNjP8Vej0A62bCJ9dAdu39ALd2uJWeLXry7pZ3ySnJuYAV1bTGSQeCehLaMZDMlDwKchx/UDa4utL5zZdpVpRNl0VzuOad1fyZkOHw7Z4Xkxtc/QqMng3Hd8N/LrelqaiBUoqnejxFdnE2H21vwB3jmnaJ0IGgnpQPI03Z6/hWAYBn1y40uWccwxLXEn90N7d+tI4n5m0j+WTBBdn+Oes8Cu77Dbyawec32k4VleRXm61DYAeGRQzjm/3fUFDawPdJ0y5yOhDUk6ahPrh5mS7I6aFyQRMn4hbVlkc2z+PhbkH8b3saA19fwd++2sLqAxmYLQ20/yCoHUz4DXrebztV9FYM/P66LeNpBWM7jCWvNI+fk352UkU1rXHQuYbq0c8f7uTYwVPc9fJlF+zWjoW7dpF0yxh8hw3DOPmf/Of3g3y/OZXswlJ83Ez0btOEbq0D6BLqT0yIH56uTrsFRc2S18PKVyHhV3DxhLix0PdvEBiBiDBq4SjcjG7MvXaus2uqaRc1Z92qstEJ6xTIwc3HyTpaQGArrwuyTY/oaJr+34NkvPMuLfv2ZcqokTwzrAMr9h1n5f4M/jyYwa+70wHbqKP2zX3oEuZPl7AAuoT5E9HEC4PBifcjDu0Jt38Lx3bA2g9gyxzY9hVc8yYqfiwj247ktY2vcSTnCGG+DePudJp2qdEtgnqUk1nInOfW0O+mqLO6a9n5EouFI/eMp3DbNsK//hr39u0qTc/MK2Zbyim2HDnF1uRTbD1yitxiWx4gX3cTcaH+xIf6ExviT1yIH8183S9Y3avJToH5D0DSKhj1X9Ii+zH0u6E83u1xxnUe57x6adpFTqehvoA+f2EN/s09ufahuAu6XfOJExwaNQqjpxfh877G6OdX67xWq3DwRB5bjpxiS3IW25Kz2Zeei6Usg6q/pwttgrxpE+RFmyBvwpt60bqJJ6EBnni5XYBGpLkE5txguwnOwxu45ffHMBlMfDH8C8dvW9MuUToQXEArv9rH3rXHuPeNyzGaLmxffMGmTRy+exxePboT+uGHKFPdD9qFJRZ2pWWzLSWbgyfyOHg8j4Mn8snIK640X1NvN8ICPWjdxIuwQE/CAj1p3cSTsCaeBHm71V/fyMlEeK8HdLmdD1t34t0t77LspmU082xWP+vXtEZG9xFcQKEdA9m5MpVjh7IJbhdwQbft2a0bLadO4ehzz5M+7WVaTH6+zst6uBrpHh5I9/DASuXZBaUcPpnP4cwCjpws4EhmAYdP5rM+8SQ/bE2l4u8IDxcjYYGehJYFh9ZNyl4HehIS4Inr2QTGwAiIvxW2zWVA9x95F/gj9Q9GRo0846Kapp0dHQjqWUj7AAxGRdKOzAseCAD8b7yR4gMJnPzkE9yi2p73vY79PF2I9bT1H1RVbLaQklX4V4AoDxYn81mdcIKi0r+GrxoUBAd4EN7Ei/AmtlNNEU297C2LGoNE93tg86dEpWynmUczVqeu1oFA0xxAB4J65uphIrSjbfRQ31FtLtgw0oqaPfUkxYcOcuylf+EaHoFX714O2Y6byVjWl+BdbZqIcCK3mMMnywJEZj6JmQUczsznh62p5Bb9ddMag4JmPu4093Onha8bLXzdaebrTgufJgz3DsO8fSFxET1Zk7aSUkspLkYXh+yPpjVWOhA4QJuuQRz+LJMTR3Jp1tr3gm9fGY0Ev/EGSWPGkvLII0TM+xrX1q0vbB2UolnZAb1HldNNIkJWQSlJmfkkZeSTlFlA2qlC0nOKSMzIZ83BTHLKAkWWKZo7cn/lp2PdMIXk0nnaLAIMUQR4uRLg6UKAlyuBnq5lzy4EersR6OlKoJftEeDlgpvJeEH3XdMuNjoQOEBEbBDKsI+Dm487JRAAGH18CJ35Pkk33Uzyg/9H+NdzMfr4OKUuVSml7AfqrmE1nz4rKDGTnlOMeU8Bbst+4rUuETx7QtGt/QlCVB9O5peSVVDCnqM5nMwvIbuwlNrGPXi7mQjwcqGJlxvB/h6EBnoSGuhBaIAn7Vv40NyZw2U1rQHQgcAB3L1dCIsOZN/aY/QaEYnB6JxMHq5hYQS/8w5Hxo8n9fEnCJ35/lmNJHImT1cTEU1N0H0wLFNc65nK7IAoPN0P8+qQ6kNzzRYr2YW24JCZV2J7zi8hK7+Ek/mlnMwvJiOvhN1Hc1iy+xillr+iRjMfN7qE+TOwfTMGdWxOkI/bhdxVTXO6i+OocBHqdFkrftqxgyO7ThIe29Rp9fDq1ZMWkydzbMoUjr85neZPP+W0upwTD39o0RkO/0H3Dn34/sD3NfYTmIwGmni70cTbjbZnGGFqsQrpOUUcOVnAnqM57EjJZl3iSX7ZlY6rcRcj4lvxfwPaEFlD34emXYp0IHCQ1jFN8PB1ZfcfaU4NBAABt9xM0d49nPz4Yzx7dMdn4ECn1uestb4MNn1Kt8sf4Mu9X7IrcxfxzeLPeXVGg6KVvwet/D3oHdkEsPVb7D2Wy9z1R5i3MYWFW9N4Ykg7JvSPdEqHv6ZdSDr7qIMYjQY69mlB0o5M8rOLz7yAgzWfNAm3jh05OulZSo8edXZ1zk7ry8BcSDdxBWBT+qZ634RSio4tffnH9Z1Z+fQABnYIYtpPe3n62+32K6417VLl0ECglBqmlNqnlEpQSk2qYfrjSqndSqntSqllSqkLO7TFwTr2bYVYhT1/pDm7Khjc3AiZ/iZSWkra3y+C+x1XFNYbgCbHdhHpF8nGdMdeWd7Mx50Pbu/GxCvb8s2mFJ7/YcfF9Xlp2llyWCBQShmBGcDVQCdgrFKqU5XZtgDdRSQW+BZ41VH1cQb/5p6ERQeyfUUq5lKLs6uDa3g4zZ5+moI1azk19yJK6+zdDJq0hSNr6da8G1uOb8FideznqZTi8SHteWhgG75an8y7yxMcuj1NcyZHtgh6AgkickhESoC5wPUVZxCR30Sk/PZTa4EQB9bHKeIHh1GYU8L+9enOrgoA/rfcjNdll5H+2uuUJCc7uzp1F9Ybjqyhe7Nu5Jfmszdr7wXZ7JND2jOqazBv/rqfhduc37LTNEdwZCAIBioeaVLKymozHvippglKqQlKqY1KqY0nTpyoxyo6Xkj7AJqGerP11yNIAzjXrJSi5Uv/RBkMHH3274i1gd7FrKqwPlCYRTcXfwA2Hav/foKaKKWYNiqGnuGBPPnNNjYdzjrzQpp2kWkQncVKqduB7sBrNU0XkQ9FpLuIdA8KCrqwlTtPSinirwoj61gBh3dlOrs6ALi0bEnzv/+dgo0byZozx9nVqZuwPgA0P7abUJ9Qh/cTVORmMvLBHd1o6efOhM82Nvz7QmvaWXJkIEgFKt6dJaSsrBKl1FXAc8AIEXH+8BoHaNu9GV7+bmz99Yizq2LnN/IGvAcM4Pib0ylJqfa1NDyBkRAQDgeW0L15dzYf34xVLlxrJtDLlVl39aDUYuXu2es5ml14wbataY7myECwAYhSSkUopVyBMcDCijMopboA/8EWBI47sC5OZTQa6DI4jNT9p0jZ1zBOLSilaDF1ChgMHH/9dWdX58yUgnZXw6GVdAvsRHZxNgmnLmwHbttm3vz3zu6k5xQzcsafrDnYMFp4mna+HBYIRMQMPAz8AuwB5onILqXUi0qpEWWzvQZ4A98opbYqpRbWsrqLXnT/VngHuLFuwcEGMxTRpUULmtw7ntyff6Zg8xZnV+fMYm8GSzHdMlMA2Hjswt+gqFdkE+bd3wc3FwNj/7uWyT/sJDPvkmzIao2IvkPZBbRrVSorvtjHNQ/FEh7j3KuNy1kLCkgYeCWePXsQ8u67zq7O6YnAf69E8k8wJKQFsUFxvDHgDadUpaDEzKs/7+OzNUl4uBi5r38k4/tF4OOuU2RrDdPp7lDWIDqLG4sOfVviF+TBn98fxGJpGKN1DJ6e+N9yC7lLlzX84aRKwZB/orKT6WaGjekbnda68nQ1MXVENEse68/lUUG8tfQA/V75jXeWHSCnqNQpddK0c6UDwQVkNBrod1MUWUfz2bas4Rx0A267FYxGsi6Gi8zC+0G/x+iZupuTRSc5cOqAU6vTtpkPH9zRjYUPX0aP8EDe/HU/l728nK83NJyBAZp2JjoQXGDhsU0Jj23Khh8TyT1Z5OzqAODSvDnel11Gzk8/XRzXFQx8nr6B0QCs3jffyZWxiQ3x56O7uvPj3/oRE+zHM9/t4J8/7m4w/UGadjo6EDjB5TdHgcDyz/Y0iIvMAHyHX4057SiFW7c5uypnZjTRYvRntCu1snr3V2BuOJ21nYP9mDO+F3f3DWfW6kRm/KZTU2gNnw4ETuDb1IN+N0eRsjeLjT8lObs6AHgPGoRydSVn8WJnV6VufFvSr/UgthjM5C1/0dm1qcRoULxwbSdGdgnm9SX7Wbq7YaQX0bTa6EDgJJ36taJdr+as/18iu1Y5/4Iuo7c3Xv36kbt82UVzOqNfzB2YlWLdto/hyDpnV6cSg8GWmqJzsC+PzdvK4cx8Z1dJ02qlA4GTKKW48o6OtO7chBVf7OOP7xKwOnkkkfeAKzCnHaX4gHM7YOsqvlk83i5erPJtCj88AEXZzq5SJe4uRmbe1g2DUjzw+WaKGkAGWk2riQ4ETmQ0Gbj6gRhirghm669HmP/GFk6mOe+Xo3f//gDk//670+pwNlwMLvRp1Zffff2wnDoC8+4Ec4mzq1VJaKAnb90Sz95jOTz/w86LprWlNS46EDiZ0WSg/9j2DL6nE1np+Xz9r/WsW3gIc8mF//Xo0qIFbh06kLfy4ggEAEPCh3CiJJsNA5+AQyvgs+sht2Gdkx/YoRl/uzKKbzel8OmfSc6ujqZVowNBA9GuZwtum9qbqO7N2bg4ia9eXMf+Dccu+Kgi7/79Kdi8GUtOzgXd7rkaEDIAX1dfvig9CjfOgrQt8OEVkLze2VWr5JFBUVzVsTlT/7ebr9brawy0hkUHggbEw8eVq8Z14vpH43FxN/HrrN18MXUtm35OIjM174IEBe8BV4DFQv6ffzp8W/XB3eTO7Z1uZ0XyClYFNId7fwWjK3w8FJZMhtKGkSXUaFDMuK0LA9sH8ez3O/QFZ1qDonMNNVBiFRI2HWfn76mkHTgFgKu7Ef8WXvgFedgezTzwDnDH08cVTz9X3DxNKKXOb7tmM/sv64fPlVfSatq/62FPHK/IXMSti28loyCDedfNo4XRA359ATZ9AoFt4PoZ0LqPs6sJQFGphfvnbOL3Ayd4ZVQsN/cIPfNCmlYPTpdrSAeCi0BOZiFHD5ziWGIOp9ILyMkoJDeziKpfncGgcPEw4uJmxNXdhIub0f6wv3evoaz8UTYt8+V/UbJpHe1/W4LRZHTOTp+lQ6cOMXbRWEJ9Qvlk2Cd4u3rb+gwWToRTR6DHvTBoMrj7ObuqFJVamDBnE6sOnODVG2O5qbsOBprj6UBwCbKYreRmFpF3qpiCnGIKc0opyC2htNBMabGFkmILpcUWSovK3heVv7dgMdd9mKrJxVAheJjKAoixSgAxVQsmf81XJQC5GlGG82u11OaP1D94aNlD9G7Zm3cHvYuLwQVK8mHZP2HdB+AVBH0egm53gUeAQ+pQV0WlFu77bCOrEzJ4bXQco7tdcrfr1hoYHQi0SiwWK+aKwaFCwCgttlCcU0jam+9g6hCN+2UDKk2rFFSKzZQW2YKL9Sz6L0zlgaJK4HBxM9nf/zXNhJuHEVcPE67uJtuzhwk3DxMuHkaMxsrdXN/t/46pa6ZyY9SNTOkz5a9TZambYekUSPzd1ocQ2gsiB9iS2LXqAia3evyE66ZiMHjlxlhu1i0DzYF0INDO2tGpUzn13fdELvgB14gIgNP2P1jM1rIgUSFoVAw0p51mrvS+PNDUpXPc5GKwBwdbgDBypCiJvXl7aBkQRJ/w3jTx88fF3YibhwnXwmRck3/F7difuGRuw81QgNFkQIX2gDYDocO10LSdLeX1BVB+muj3/SeYeGVbJg6KwmTUYzi0+qcDgXbWSo8fJ/G6EVgLCsDFBaOXF82ffx7foUMuyPZFBEuplZIiCyWFZkqKzLbnQgvFheYqZWaKC22tmvJpWbk5lBZZcLGc+Ze+QVlxNRTiSi6uKh83FzMmT09MXj6YvH0xefth8vbD6GrE5GLA5GLE5GrA6GLAxdWI0cX22mBUGI0KZbC9tj8MCoPxrzKj0YAqe60UFJutTF24i283pxIR5Mm4fpEM7dScZr7uF+CT1hoLHQi0c1J8KJGsL78EpSjcvJmiPXsI/WCm/Qrkhi41L5WZm2fyS8JSWrmE8mTs07TxjCoLHOYKgaMs2OTmUJKRTnFuHubCYsxmMOOKWVyxiBtmXLGK6YLUXRBAgcL2StlaZAaDwmiwBZDyvhalbPMpRaWWTKU2jarxZeX5a2oEVVqu5pXU2niqqS6Vlqt5wTqtrw4NttrnqWVCbcVn2Tg825F7ZzN7+94tiR14bv1JOhBo582an0/S7XdQeuQIrb/6Evd27ZxdpTrbcWIHT//+NGn5adwfez8TYidgMtThgF6YBSf2w4m9kGF7th5PwHzqGOaywGAx+GJu3gVL825Ym8dhDYjCihGrVbBayh/Wv15bK78XEdvor7JnsQqZeSUcOpFH2qlCcovMeJiMHM8twmoVFGBA4ethItjfg2bebjTxcsPbzWiLGGUq/a+u+KbC/3epYXrl5WqeUNu6pZaZajzE1FSP0y5Xh7rUMnvlzZ7d8e6sD4+1LHD29ay5vG23IDr2bXWWlbLRgUCrF6XHjpF0080oV1fC536FKSjI2VWqs7ySPP697t/879D/6NKsC8/1eo52Ae3O7bqL4jxbYMjYb7uSOekPSN9hm+biCWF9IKI/RFwOLePBcP5DcE/ml3DkZAEH0nM5lJHP3qM5rE7IoNRi+/8b6OVKfKg/8aH+dAnzJzbEHz8Pff9k7S86EGj1pnDHTg7fcQcGT0+aPfUUfiOuQxkvjmsNAH489CMvrX2J/NJ83IxuuJvccTO44WJ0wc3ohp+bH8Hewfi6+uJicMFkMOFidMGkqjwbTH9NN7hgKi3CcGIfpO+yPXJSbBs0uqH8QiGgNfiHgU9L8G4Gnk1RxpoP1HUNTmaLkHaqkMSMAg6eyLO1IrL/ur6kpZ87bZp50ybIm8imXoQGetpOK9VyDqTG8lrPolyYznStslberWjt2/qcltWBQKtXRfv2cXTyCxRt345rmzYE/e1v+AwZjDJcHKNdThSc4PeU30nMTqTEWkKJpYRiSzHFlmKyirJIzUslvzSfUmspZquZUqu+Gb3WMNzT+R4e6/bYOS2rA4FW78RqJXfJEk688y4lhw5hat4ctzZtUK6uYDSijEYM3t6YmjTB1LQJBh9fDO5uKDc3lKsbys0Vg5sbmEy2FoUy2Do/jUZQylZmMNh+HZdPNxrAYKg83VBWVuF1fQckEcEiFkqtpX8FB0spZil7LgsWUsMJX3uZAPnHITsNco+WPY7ZHvnHoSgHSgtqPZdca3m1H+YGMBgRg8n+bMVIKYoSi6LIYqDAojCLwooBM0Yw2L4Dg9GEMpgwmEwYjC4YDEZUWVn5s8FY9tpowmC0TTfa35c/XDAaXTCWrRND+cNoeyiT/Xu09XKXvVYG2/tKZbZeEfv0Su8rlqm/nqs6Uy/4aYpqbRLVWF7Xbde0aN3ma+7VgmDfsLqts9omag8EF2YIhHbJUQYDvsOG4TN4MDmLF5O3YiUlyclgNiNWK1jMWHJyMZ88CaVO+EVdU3Aof20/wNSDsvWc38kxH9tDYesltPUeV+gxrPK6XG1lqryoyvQKZSJWRCxAaYUO1Orz2XZPKh3iVO1dn5qDuV0VB69/U+/r1YFAOy/KaMTvuuvwu+66GqeLCNbsbCx5+UhxEVJcjLW4GCkuQUqKkdLSssBhBbHaXpc9pGJZTa9rK7NaEaleVul1vai/A2K9tczrsYVvsVgxWwVL1YfYnsVqxWq1YrVayl5bbAHGWuEhFvt3ahXbd4DVihUpm142cgpBrJWfKZ8mFV5jC0QVg1H5+7qG9vMNZFWXV2XDfO3tEWUrK/+tUTmIVi6oNO0MjRQFHAvshCMGbzs0ECilhgFvY/vB9JGIvFxluhvwGdANyARuEZEkR9ZJu7CUUhj9/TH6+zu7KtolQEQwW4VSi5USs5VSi2CVmgNVbWVWq20dFhEsFttzeVn5uszW6mWV1mWpsp3TrEsErFJ2mtD2D2v5cOGyfZKy6eUNQkFsy5S1zmzrEIbHtHTI5+qwQKCUMgIzgMFACrBBKbVQRHZXmG08kCUibZVSY4BXgFscVSdN0y5uSilcjAoXowFPV2fX5tLhyGEePYEEETkkIiXAXOD6KvNcD3xa9vpbYJA634T6mqZp2llx5KmhYCC5wvsUoFdt84iIWSmVDTQBMirOpJSaAEwoe5unlNp3jnVqWnXdjYDe58ZB73PjcD77XOsFCBdFZ7GIfAh8eL7rUUptrG341KVK73PjoPe5cXDUPjvy1FAqUDHBekhZWY3zKKVMgB+2TmNN0zTtAnFkINgARCmlIpRSrsAYYGGVeRYCd5W9Hg0sl4vtCjdN07SLnMNODZWd838Y+AXb8NGPRWSXUupFYKOILARmAXOUUgnASWzBwpHO+/TSRUjvc+Og97lxcMg+X3QpJjRN07T6dXFkCdM0TdMcRgcCTdO0Rq7RBAKl1DCl1D6lVIJSapKz61NflFIfK6WOK6V2VigLVEr9qpQ6UPYcUFaulFLvlH0G25VSXZ1X83OnlApVSv2mlNqtlNqllHqkrPyS3W+llLtSar1SalvZPv+jrDxCKbWubN++LhuYgVLKrex9Qtn0cKfuwDlSShmVUluUUj+Wvb+k9xdAKZWklNqhlNqqlNpYVubQv+1GEQgqpLu4GugEjFVKdXJurerNJ8CwKmWTgGUiEgUsK3sPtv2PKntMAGZeoDrWNzPwhIh0AnoDD5V9n5fyfhcDV4pIHBAPDFNK9caWlmW6iLQFsrClbYEK6VuA6WXzXYweAfZUeH+p72+5gSISX+GaAcf+bUuFDH+X6gPoA/xS4f2zwLPOrlc97l84sLPC+31Ay7LXLYF9Za//A4ytab6L+QEswJbTqlHsN+AJbMZ2pX4GYCort/+dYxut16fstalsPuXsup/lfoaUHfSuBH7EloDzkt3fCvudBDStUubQv+1G0SKg5nQXwU6qy4XQXESOlr0+BjQve33JfQ5lpwC6AOu4xPe77DTJVuA48CtwEDglIuayWSruV6X0LUB5+paLyVvA00B53vAmXNr7W06AJUqpTWXpdcDBf9sXRYoJ7dyJiCilLskxwkopb+A74FERyamYr/BS3G+x3UkmXinlD8wHOji3Ro6jlLoWOC4im5RSA5xcnQutn4ikKqWaAb8qpfZWnOiIv+3G0iKoS7qLS0m6UqolQNnz8bLyS+ZzUEq5YAsCX4jI92XFl/x+A4jIKeA3bKdG/MvSs0Dl/brY07dcBoxQSiVhy1x8JbZ7m1yq+2snIqllz8exBfyeOPhvu7EEgrqku7iUVEzdcRe2c+jl5XeWjTToDWRXaG5eNJTtp/8sYI+IvFlh0iW730qpoLKWAEopD2x9InuwBYTRZbNV3eeLNn2LiDwrIiEiEo7t/+tyEbmNS3R/yymlvJRSPuWvgSHAThz9t+3sjpEL2AEzHNiP7bzqc86uTz3u11fAUaAU2/nB8djOjS4DDgBLgcCyeRW20VMHgR1Ad2fX/xz3uR+286jbga1lj+GX8n4DscCWsn3eCbxQVh4JrAcSgG8At7Jy97L3CWXTI529D+ex7wOAHxvD/pbt37ayx67yY5Wj/7Z1iglN07RGrrGcGtI0TdNqoQOBpmlaI6cDgaZpWiOnA4GmaVojpwOBpmlaI6cDgaY5mFJqQHn2TE1riHQg0DRNa+R0INC0Mkqp28ty/m9VSv2nLMlbnlJqetk9AJYppYLK5o1XSq0tywE/v0J++LZKqaVl9w3YrJRqU7Z6b6XUt0qpvUqpL8qujkYp9bKy3Vdhu1LqdSftutbI6UCgaYBSqiNwC3CZiMQDFuA2wAvYKCLRwEpgStkinwHPiEgstis6y8u/AGaI7b4BfbFd9Q22DKmPYrsfRiRwmVKqCTASiC5bz0uO3EdNq40OBJpmMwjoBmwoS/U8CNsB2wp8XTbP50A/pZQf4C8iK8vKPwX6l+WICRaR+QAiUiQiBWXzrBeRFBGxYkuJEY4tVXIRMEspNQoon1fTLigdCDTNRgGfiu2uUPEi0l5EptYw37nmZCmu8NqC7eYqZmyZJb8FrgV+Psd1a9p50YFA02yWAaPLcsCX3yO2Nbb/I+XZLm8FVotINpCllLq8rPwOYKWI5AIpSqkbytbhppTyrG2DZfdT8BORxcBjQJwD9kvTzkjfmEbTABHZrZR6HtudoQzYsrk+BOQDPcumHcfWjwC2VMAflB3oDwHjysrvAP6jlHqxbB03nWazPsACpZQ7thbJ4/W8W5pWJzr7qKadhlIqT0S8nV0PTXMkfWpI0zStkdMtAk3TtEZOtwg0TdMaOR0INE3TGjkdCDRN0xo5HQg0TdMaOR0INE3TGrn/B91INN8JZGwbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for it, dl in enumerate(dloss):\n",
    "    plt.title(\"{it}\".format(it=it))\n",
    "    for l in dl:\n",
    "        plt.plot(l, label=\"MinLoss = {}\".format(min(l)))\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "id": "cacb94cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'parameters:0' shape=(93,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>]\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss at epoch 0: 1.3187\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss at epoch 1: 1.1104\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss at epoch 2: 0.9913\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss at epoch 3: 0.9038\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss at epoch 4: 0.8130\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss at epoch 5: 0.7335\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss at epoch 6: 0.6791\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss at epoch 7: 0.6488\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss at epoch 8: 0.6311\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss at epoch 9: 0.6159\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss at epoch 10: 0.5998\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss at epoch 11: 0.5829\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss at epoch 12: 0.5654\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss at epoch 13: 0.5457\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss at epoch 14: 0.5227\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss at epoch 15: 0.4971\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss at epoch 16: 0.4711\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss at epoch 17: 0.4468\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss at epoch 18: 0.4265\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss at epoch 19: 0.4114\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss at epoch 20: 0.4014\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss at epoch 21: 0.3951\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss at epoch 22: 0.3905\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss at epoch 23: 0.3865\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss at epoch 24: 0.3827\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss at epoch 25: 0.3783\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss at epoch 26: 0.3732\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss at epoch 27: 0.3675\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss at epoch 28: 0.3611\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss at epoch 29: 0.3541\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss at epoch 30: 0.3466\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss at epoch 31: 0.3390\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss at epoch 32: 0.3316\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss at epoch 33: 0.3243\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss at epoch 34: 0.3170\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss at epoch 35: 0.3099\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss at epoch 36: 0.3032\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss at epoch 37: 0.2977\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss at epoch 38: 0.2938\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss at epoch 39: 0.2909\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss at epoch 40: 0.2881\n",
      "\n",
      "Start of epoch 41\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-744-8af258a732cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_excitations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mdddloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-430-f060922d2958>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_excitations, train_labels, optimizer, loss_fn, loss_list, epochs)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1082\u001b[0m                           for x in nest.flatten(output_gradients)]\n\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1085\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     72\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/custom_gradient.py\u001b[0m in \u001b[0;36mactual_grad_fn\u001b[0;34m(*result_grads)\u001b[0m\n\u001b[1;32m    566\u001b[0m                          \"@custom_gradient grad_fn.\")\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0minput_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m       \u001b[0mvariable_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0mflat_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow_quantum/python/differentiators/differentiator.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(grad)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m                 return self._differentiate_ana(programs, symbol_names,\n\u001b[0m\u001b[1;32m    161\u001b[0m                                                \u001b[0msymbol_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpauli_sums\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                                                forward_pass_vals, grad)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow_quantum/python/differentiators/differentiator.py\u001b[0m in \u001b[0;36m_differentiate_ana\u001b[0;34m(self, programs, symbol_names, symbol_values, pauli_sums, forward_pass_vals, grad)\u001b[0m\n\u001b[1;32m    189\u001b[0m     def _differentiate_ana(self, programs, symbol_names, symbol_values,\n\u001b[1;32m    190\u001b[0m                            pauli_sums, forward_pass_vals, grad):\n\u001b[0;32m--> 191\u001b[0;31m         return None, None, self.differentiate_analytic(\n\u001b[0m\u001b[1;32m    192\u001b[0m             \u001b[0mprograms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             pauli_sums, forward_pass_vals, grad), \\\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow_quantum/python/differentiators/differentiator.py\u001b[0m in \u001b[0;36mnew_diff\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mret_zero\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_or\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mempty_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mempty_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mret_zero\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_or\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret_zero\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mempty_symbols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         return tf.cond(ret_zero, lambda: tf.zeros_like(symbol_values),\n\u001b[0m\u001b[1;32m     44\u001b[0m                        lambda: func(*args, **kwargs))\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mcond_for_tf_v2\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m   1450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m   \"\"\"\n\u001b[0;32m-> 1452\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrue_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfalse_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                 instructions)\n\u001b[0;32m--> 552\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mcond\u001b[0;34m(pred, true_fn, false_fn, strict, name, fn1, fn2)\u001b[0m\n\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1262\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eager_cond_implementation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m   \u001b[0;31m# Always enable control flow v2 if building a function, regardless of toggle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_eager_cond_implementation\u001b[0;34m(pred, true_fn, false_fn, strict, name)\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_UnpackIfSingleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow_quantum/python/differentiators/differentiator.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mret_zero\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_or\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret_zero\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mempty_symbols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         return tf.cond(ret_zero, lambda: tf.zeros_like(symbol_values),\n\u001b[0;32m---> 44\u001b[0;31m                        lambda: func(*args, **kwargs))\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_diff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    947\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    950\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "maxdepth = range(6,6+1)\n",
    "N = 4\n",
    "\n",
    "dddloss = []\n",
    "\n",
    "for depth in maxdepth:\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.0, nesterov=False)\n",
    "    loss_fn = tf.losses.mse\n",
    "\n",
    "    model, quantum_model_circuit, qubits, readoutqubit = setup(N, param, extra=False, full=True, cnot=False, depth=depth)\n",
    "    inputs, labels = generate_data(qubits)\n",
    "\n",
    "    ninp = len(inputs)\n",
    "    split = int(ninp*1)\n",
    "\n",
    "    train_excitations = inputs[:split]\n",
    "    train_labels = labels[:split]\n",
    "    #train_labels = tf.cast(train_labels, dtype=tf.float64)\n",
    "\n",
    "    test_excitations = inputs[split:]\n",
    "    test_labels = labels[split:]\n",
    "\n",
    "\n",
    "\n",
    "    print(model.weights)\n",
    "\n",
    "\n",
    "    \"\"\"batch_size = 16\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train_excitations, train_labels))\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\"\"\"\n",
    "\n",
    "\n",
    "    loss_list = []\n",
    "\n",
    "    epochs = 1200\n",
    "    train(model, train_excitations, train_labels, optimizer, loss_fn, loss_list, epochs=epochs)\n",
    "    dddloss.append(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "id": "10bf7d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16c0662e0>]"
      ]
     },
     "execution_count": 735,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dddloss[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747d83cc",
   "metadata": {},
   "source": [
    "Solution to the excitation problem is found with depth of 3 full layers and:\n",
    "Initial parameters:\n",
    "```\n",
    "array([3.142743  , 1.6211308 , 6.2127533 , 1.403728  , 0.5748421 ,\n",
    "       5.8714156 , 5.158472  , 5.786588  , 1.6906012 , 3.3182492 ,\n",
    "       4.858122  , 0.38375887, 0.3583126 , 5.866459  , 5.0671377 ,\n",
    "       5.828251  , 0.97697425, 0.2249117 , 0.5937352 , 5.895576  ,\n",
    "       5.1195526 , 4.471942  , 1.0231847 , 2.0065742 , 2.158195  ,\n",
    "       1.0113435 , 0.55272895, 0.31191644, 5.727847  , 5.3882537 ,\n",
    "       0.3614315 , 5.183798  , 0.8544393 , 1.5969969 , 3.1413836 ,\n",
    "       5.9380727 , 0.51083434, 1.2580216 , 4.3443036 , 2.3086405 ,\n",
    "       1.8087461 , 3.083661  , 0.77426183, 1.2260948 , 5.415547  ]\n",
    "```\n",
    "Solution parameters:\n",
    "```\n",
    "array([ 2.6328497 ,  1.5712917 ,  6.9862733 ,  1.9362755 ,  0.1883689 ,\n",
    "        5.5261497 ,  5.3186984 ,  6.458927  ,  0.6774356 ,  3.831779  ,\n",
    "        4.091107  ,  0.51859134,  0.79823154,  5.6697216 ,  4.712743  ,\n",
    "        6.8606434 ,  1.5702574 ,  0.06955462,  1.2834837 ,  5.8312583 ,\n",
    "        4.732993  ,  4.8076997 ,  0.890339  ,  2.2350447 ,  2.0360186 ,\n",
    "        1.0049291 ,  1.9898651 , -0.15972897,  6.0006113 ,  5.6948442 ,\n",
    "       -1.5710593 ,  3.9472854 ,  1.5704038 ,  1.0506094 ,  3.4380832 ,\n",
    "        6.2635283 ,  1.3604025 ,  3.0867598 ,  3.2895849 ,  2.1519923 ,\n",
    "        1.5507632 ,  1.5626886 ,  0.13279505,  2.5531113 ,  4.712026  ]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "id": "0b7558fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "weightsSolve = np.array([  3.142743  , 1.6211308 , 6.2127533 , 1.403728  , 0.5748421 ,\\\n",
    "                           5.8714156 , 5.158472  , 5.786588  , 1.6906012 , 3.3182492 ,\\\n",
    "                           4.858122  , 0.38375887, 0.3583126 , 5.866459  , 5.0671377 ,\\\n",
    "                           5.828251  , 0.97697425, 0.2249117 , 0.5937352 , 5.895576  ,\\\n",
    "                           5.1195526 , 4.471942  , 1.0231847 , 2.0065742 , 2.158195  ,\\\n",
    "                           1.0113435 , 0.55272895, 0.31191644, 5.727847  , 5.3882537 ,\\\n",
    "                           0.3614315 , 5.183798  , 0.8544393 , 1.5969969 , 3.1413836 ,\\\n",
    "                           5.9380727 , 0.51083434, 1.2580216 , 4.3443036 , 2.3086405 ,\\\n",
    "                           1.8087461 , 3.083661  , 0.77426183, 1.2260948 , 5.415547  ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6151fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST CONVERGENCE WAS ACHIEVED STARTING WITH:\n",
    "\"\"\"\n",
    "[<tf.Variable 'parameters:0' shape=(45,) dtype=float32, numpy=\n",
    "array([3.142743  , 1.6211308 , 6.2127533 , 1.403728  , 0.5748421 ,\n",
    "       5.8714156 , 5.158472  , 5.786588  , 1.6906012 , 3.3182492 ,\n",
    "       4.858122  , 0.38375887, 0.3583126 , 5.866459  , 5.0671377 ,\n",
    "       5.828251  , 0.97697425, 0.2249117 , 0.5937352 , 5.895576  ,\n",
    "       5.1195526 , 4.471942  , 1.0231847 , 2.0065742 , 2.158195  ,\n",
    "       1.0113435 , 0.55272895, 0.31191644, 5.727847  , 5.3882537 ,\n",
    "       0.3614315 , 5.183798  , 0.8544393 , 1.5969969 , 3.1413836 ,\n",
    "       5.9380727 , 0.51083434, 1.2580216 , 4.3443036 , 2.3086405 ,\n",
    "       1.8087461 , 3.083661  , 0.77426183, 1.2260948 , 5.415547  ],\n",
    "      dtype=float32)>]\"\"\"\n",
    "# With DEPTH = 3, ADAMS OPTIMIZER\n",
    "\n",
    "optW = np.array([3.142743  , 1.6211308 , 6.2127533 , 1.403728  , 0.5748421 ,\\\n",
    "       5.8714156 , 5.158472  , 5.786588  , 1.6906012 , 3.3182492 ,\\\n",
    "       4.858122  , 0.38375887, 0.3583126 , 5.866459  , 5.0671377 ,\\\n",
    "       5.828251  , 0.97697425, 0.2249117 , 0.5937352 , 5.895576  ,\\\n",
    "       5.1195526 , 4.471942  , 1.0231847 , 2.0065742 , 2.158195  ,\\\n",
    "       1.0113435 , 0.55272895, 0.31191644, 5.727847  , 5.3882537 ,\\\n",
    "       0.3614315 , 5.183798  , 0.8544393 , 1.5969969 , 3.1413836 ,\\\n",
    "       5.9380727 , 0.51083434, 1.2580216 , 4.3443036 , 2.3086405 ,\\\n",
    "       1.8087461 , 3.083661  , 0.77426183, 1.2260948 , 5.415547  ])\n",
    "\n",
    "param = sympy.symbols('p:100')\n",
    "\n",
    "depth = 3\n",
    "N = 4\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.02)#tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.0, nesterov=False)\n",
    "loss_fn = tf.losses.mse\n",
    "\n",
    "best_loss = []\n",
    "\n",
    "model, quantum_model_circuit, qubits, readoutqubit = setup(N, param, extra=False, full=True, firstOne=False, cnot=False, depth=depth, random=True)\n",
    "inputs, labels = generate_data(qubits)\n",
    "\n",
    "ninp = len(inputs)\n",
    "split = int(ninp*1)\n",
    "\n",
    "train_excitations = inputs[:split]\n",
    "train_labels = labels[:split]\n",
    "#train_labels = tf.cast(train_labels, dtype=tf.float64)\n",
    "\n",
    "test_excitations = inputs[split:]\n",
    "test_labels = labels[split:]\n",
    "\n",
    "\n",
    "\n",
    "#print(model.weights)\n",
    "model.set_weights([optW])\n",
    "#print(model.weights)\n",
    "\n",
    "epochs = 1000\n",
    "train(model, train_excitations, train_labels, optimizer, loss_fn, best_loss, epochs=epochs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76e0ead0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'parameters:0' shape=(45,) dtype=float32, numpy=\n",
      "array([ 2.6328497 ,  1.5712917 ,  6.9862733 ,  1.9362755 ,  0.1883689 ,\n",
      "        5.5261497 ,  5.3186984 ,  6.458927  ,  0.6774356 ,  3.831779  ,\n",
      "        4.091107  ,  0.51859134,  0.79823154,  5.6697216 ,  4.712743  ,\n",
      "        6.8606434 ,  1.5702574 ,  0.06955462,  1.2834837 ,  5.8312583 ,\n",
      "        4.732993  ,  4.8076997 ,  0.890339  ,  2.2350447 ,  2.0360186 ,\n",
      "        1.0049291 ,  1.9898651 , -0.15972897,  6.0006113 ,  5.6948442 ,\n",
      "       -1.5710593 ,  3.9472854 ,  1.5704038 ,  1.0506094 ,  3.4380832 ,\n",
      "        6.2635283 ,  1.3604025 ,  3.0867598 ,  3.2895849 ,  2.1519923 ,\n",
      "        1.5507632 ,  1.5626886 ,  0.13279505,  2.5531113 ,  4.712026  ],\n",
      "      dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "sol_weights = model.weights\n",
    "print(sol_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5eda89ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.83806205, shape=(), dtype=float32) 0.8333333333333334\n",
      "tf.Tensor(0.50015765, shape=(), dtype=float32) 0.5\n",
      "tf.Tensor(2.2237997, shape=(), dtype=float32) 2.216666666666667\n",
      "tf.Tensor(0.61633563, shape=(), dtype=float32) 0.6166666666666667\n",
      "tf.Tensor(0.059959684, shape=(), dtype=float32) 0.06666666666666667\n",
      "tf.Tensor(1.7590281, shape=(), dtype=float32) 1.7666666666666666\n",
      "tf.Tensor(1.6929942, shape=(), dtype=float32) 1.7\n",
      "tf.Tensor(2.0559404, shape=(), dtype=float32) 2.05\n",
      "tf.Tensor(0.21563444, shape=(), dtype=float32) 0.21666666666666667\n",
      "tf.Tensor(1.2196931, shape=(), dtype=float32) 1.2166666666666666\n",
      "tf.Tensor(1.3022398, shape=(), dtype=float32) 1.3\n",
      "tf.Tensor(0.16507275, shape=(), dtype=float32) 0.16666666666666666\n",
      "tf.Tensor(0.25408497, shape=(), dtype=float32) 0.25\n",
      "tf.Tensor(1.8047284, shape=(), dtype=float32) 1.8\n",
      "tf.Tensor(1.5001125, shape=(), dtype=float32) 1.5\n",
      "tf.Tensor(2.1838105, shape=(), dtype=float32) 2.183333333333333\n",
      "tf.Tensor(0.49982846, shape=(), dtype=float32) 0.5\n",
      "tf.Tensor(0.022139922, shape=(), dtype=float32) 0.016666666666666666\n",
      "tf.Tensor(0.40854555, shape=(), dtype=float32) 0.4166666666666667\n",
      "tf.Tensor(1.8561472, shape=(), dtype=float32) 1.85\n",
      "tf.Tensor(1.5065584, shape=(), dtype=float32) 1.5\n",
      "tf.Tensor(1.5303383, shape=(), dtype=float32) 1.5333333333333334\n",
      "tf.Tensor(0.2834037, shape=(), dtype=float32) 0.2833333333333333\n",
      "tf.Tensor(0.7114368, shape=(), dtype=float32) 0.7166666666666667\n",
      "tf.Tensor(0.6480848, shape=(), dtype=float32) 0.65\n",
      "tf.Tensor(0.31987885, shape=(), dtype=float32) 0.31666666666666665\n",
      "tf.Tensor(0.6333937, shape=(), dtype=float32) 0.6333333333333333\n",
      "tf.Tensor(-0.05084331, shape=(), dtype=float32) -0.05\n",
      "tf.Tensor(1.9100538, shape=(), dtype=float32) 1.9166666666666667\n",
      "tf.Tensor(1.8127252, shape=(), dtype=float32) 1.8166666666666667\n",
      "tf.Tensor(-0.5000837, shape=(), dtype=float32) -0.5\n",
      "tf.Tensor(1.25646, shape=(), dtype=float32) 1.25\n",
      "tf.Tensor(0.49987504, shape=(), dtype=float32) 0.5\n",
      "tf.Tensor(0.33441934, shape=(), dtype=float32) 0.3333333333333333\n",
      "tf.Tensor(1.0943758, shape=(), dtype=float32) 1.1\n",
      "tf.Tensor(1.993743, shape=(), dtype=float32) 2.0\n",
      "tf.Tensor(0.43302953, shape=(), dtype=float32) 0.43333333333333335\n",
      "tf.Tensor(0.98254615, shape=(), dtype=float32) 0.9833333333333333\n",
      "tf.Tensor(1.0471073, shape=(), dtype=float32) 1.05\n",
      "tf.Tensor(0.6850004, shape=(), dtype=float32) 0.6833333333333333\n",
      "tf.Tensor(0.49362326, shape=(), dtype=float32) 0.5\n",
      "tf.Tensor(0.4974192, shape=(), dtype=float32) 0.5\n",
      "tf.Tensor(0.042269975, shape=(), dtype=float32) 0.05\n",
      "tf.Tensor(0.81268054, shape=(), dtype=float32) 0.8166666666666667\n",
      "tf.Tensor(1.4998845, shape=(), dtype=float32) 1.5\n"
     ]
    }
   ],
   "source": [
    "for w in sol_weights[0]:\n",
    "    print(w/np.pi , np.round(w/np.pi*60)/60 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "838100c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.9967101812362671 =?   1   --->   yes! \n",
      "  0.9986864924430847 =?   1   --->   yes! \n",
      "  0.9977095723152161 =?   1   --->   yes! \n",
      "  0.9989843964576721 =?   1   --->   yes! \n",
      "  0.9978319406509399 =?   1   --->   yes! \n",
      "  0.9967343807220459 =?   1   --->   yes! \n",
      "  0.9980698823928833 =?   1   --->   yes! \n",
      " -0.9972653388977051 =?  -1   --->   yes! \n",
      "  0.9981792569160461 =?   1   --->   yes! \n",
      "  0.9985648989677429 =?   1   --->   yes! \n",
      "  0.9990745782852173 =?   1   --->   yes! \n",
      " -0.9978370666503906 =?  -1   --->   yes! \n",
      "  0.9982478618621826 =?   1   --->   yes! \n",
      " -0.9987651109695435 =?  -1   --->   yes! \n",
      " -0.9970437288284302 =?  -1   --->   yes! \n",
      " -0.9956232309341431 =?  -1   --->   yes! \n"
     ]
    }
   ],
   "source": [
    "print(*tuple(\"{:20} =? {:3}   --->   {:5}\".format(x[0], train_labels[i], \"yes!\" if abs(train_labels[i]-x[0])<1 else \"no!\")  for i,x in enumerate(model.predict(train_excitations))), sep='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
